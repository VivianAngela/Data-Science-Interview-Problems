{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简要说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.数据集构造: ** \n",
    "在读取json数据后，获取itemList中当前时间段10：00商品的销售率和其它特征。然后再获取brandList中之前两个时间段00：00和8：00的商品销售率和其它特征。将来两份数据合并后，我对各个特征两两做乘法和除法这两种非线性方法来构造新特征，(没有采用加减法是因为他们是线性变换，并不能构造有信息量的新特征)，按7：3比例划分训练集和测试集。后续的实验证明了新构造特征的有效性。\n",
    "\n",
    "**2.评价指标：**  \n",
    "MSE(均方误差)\n",
    "\n",
    "**3.机器学习**  \n",
    "1) 单模型：  \n",
    "这里我采用了5个算法：Xgboosting(xgb), Random forest(rf), Gradient boosting(gb), Extra tree(et), Supoort vector regressor(svr)训练预测，并用10-fold cross validation调参，展示了训练和测试误差，以及各特征的重要性。\n",
    "\n",
    "2) Stacking  \n",
    "我写了一个Ensemble的类，一开始先用xgb, rf, gb, et做2-layer stacking, 最后一层的stacker采用gb, 调参后发现结果并不如单模型的好，分析发现是因为这几个模型的预测结果太相似了，即Pearson相关系数过大, 于是我加入svr的预测结果，计算它们两两间的Pearson相关系数，选出相关系数最小的三个模型做satcking, 结果发现用**XGB, ETR, SVR**做stacking， MSE降低了15%, 从127降到了108。最后用**XGB, ETR, SVR**的stacking对18：00商品销售率做预测并输出'submission.csv',其中'Pred_soldRate'那列为预测值。(注：在excel里'Pred_soldRate'那列显示为空，可能是因为中文编码的问题，但是用pd.read_csv()可以正常获取)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf8 -*-\n",
    "import json\n",
    "import pandas as pd\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'34'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('seckillList_new.json','rb') as data_file:\n",
    "    data = json.load(data_file)\n",
    "df = data['seckillInfo']\n",
    "df['gid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = data['seckillInfo']\n",
    "df['newAccount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>25</th>\n",
       "      <th>30</th>\n",
       "      <th>35</th>\n",
       "      <th>40</th>\n",
       "      <th>45</th>\n",
       "      <th>50</th>\n",
       "      <th>55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>brandIdOld</th>\n",
       "      <td>7817</td>\n",
       "      <td>8551</td>\n",
       "      <td>9889</td>\n",
       "      <td>14917</td>\n",
       "      <td>7408</td>\n",
       "      <td>6742</td>\n",
       "      <td>189726</td>\n",
       "      <td>21360</td>\n",
       "      <td>10107</td>\n",
       "      <td>17519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brandImg</th>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s620*221_jfs/...</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s620*221_jfs/...</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s620*221_jfs/...</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s620*221_jfs/...</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s620*221_jfs/...</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s620*221_jfs/...</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s620*221_jfs/...</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s620*221_jfs/...</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s620*221_jfs/...</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s620*221_jfs/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brandName</th>\n",
       "      <td>海尔（Haier）</td>\n",
       "      <td>华硕（ASUS）</td>\n",
       "      <td>君华仕（GENVAS）</td>\n",
       "      <td>润本（RUNBEN）</td>\n",
       "      <td>格兰仕（Galanz）</td>\n",
       "      <td>飞利浦（PHILIPS）</td>\n",
       "      <td>雅萌（YA-MAN）</td>\n",
       "      <td>beats</td>\n",
       "      <td>卡西欧（CASIO）</td>\n",
       "      <td>维达（Vinda）</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>endTimeRemain</th>\n",
       "      <td>48765</td>\n",
       "      <td>48705</td>\n",
       "      <td>77565</td>\n",
       "      <td>77565</td>\n",
       "      <td>77565</td>\n",
       "      <td>77565</td>\n",
       "      <td>77565</td>\n",
       "      <td>77565</td>\n",
       "      <td>77565</td>\n",
       "      <td>77565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goodsList</th>\n",
       "      <td>[{u'soldRate': 25, u'startTimeShow': u'00:00',...</td>\n",
       "      <td>[{u'soldRate': 16, u'startTimeShow': u'00:00',...</td>\n",
       "      <td>[{u'soldRate': 24, u'startTimeShow': u'08:00',...</td>\n",
       "      <td>[{u'soldRate': 76, u'startTimeShow': u'08:00',...</td>\n",
       "      <td>[{u'soldRate': 31, u'startTimeShow': u'08:00',...</td>\n",
       "      <td>[{u'soldRate': 30, u'startTimeShow': u'08:00',...</td>\n",
       "      <td>[{u'soldRate': 28, u'startTimeShow': u'08:00',...</td>\n",
       "      <td>[{u'soldRate': 37, u'startTimeShow': u'08:00',...</td>\n",
       "      <td>[{u'soldRate': 31, u'startTimeShow': u'08:00',...</td>\n",
       "      <td>[{u'soldRate': 38, u'startTimeShow': u'08:00',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>6375</td>\n",
       "      <td>6380</td>\n",
       "      <td>6355</td>\n",
       "      <td>6367</td>\n",
       "      <td>6377</td>\n",
       "      <td>6378</td>\n",
       "      <td>6379</td>\n",
       "      <td>6382</td>\n",
       "      <td>6385</td>\n",
       "      <td>6390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>position</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sourceValue</th>\n",
       "      <td>10_7817_2</td>\n",
       "      <td>15_8551_2</td>\n",
       "      <td>20_9889_2</td>\n",
       "      <td>25_14917_2</td>\n",
       "      <td>30_7408_2</td>\n",
       "      <td>35_6742_2</td>\n",
       "      <td>40_189726_2</td>\n",
       "      <td>45_21360_2</td>\n",
       "      <td>50_10107_2</td>\n",
       "      <td>55_17519_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>startTimeRemain</th>\n",
       "      <td>-37634</td>\n",
       "      <td>-37634</td>\n",
       "      <td>-8834</td>\n",
       "      <td>-8834</td>\n",
       "      <td>-8834</td>\n",
       "      <td>-8834</td>\n",
       "      <td>-8834</td>\n",
       "      <td>-8834</td>\n",
       "      <td>-8834</td>\n",
       "      <td>-8834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subTitle</th>\n",
       "      <td>55寸电视2699</td>\n",
       "      <td>爆款直降限时抢购</td>\n",
       "      <td>满199减100</td>\n",
       "      <td>爆款低至9.9元</td>\n",
       "      <td>部分2件8.5折</td>\n",
       "      <td>爆品低至9.9元</td>\n",
       "      <td>iphone红现货抢</td>\n",
       "      <td>乐享千遍 不止一面</td>\n",
       "      <td>换个视角看世界</td>\n",
       "      <td>爆款直降</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>titile</th>\n",
       "      <td>海尔家装季</td>\n",
       "      <td>华硕冰点直击</td>\n",
       "      <td>品质出游包你满意</td>\n",
       "      <td>妈妈的安心之选</td>\n",
       "      <td>品质厨电疯抢</td>\n",
       "      <td>个护健康变形记</td>\n",
       "      <td>从新开始 红遍中国</td>\n",
       "      <td>娱乐影音专场</td>\n",
       "      <td>潮流相机专场</td>\n",
       "      <td>清洁品质榜单</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                10  \\\n",
       "brandIdOld                                                    7817   \n",
       "brandImg         http://m.360buyimg.com/mobilecms/s620*221_jfs/...   \n",
       "brandName                                                海尔（Haier）   \n",
       "endTimeRemain                                                48765   \n",
       "goodsList        [{u'soldRate': 25, u'startTimeShow': u'00:00',...   \n",
       "id                                                            6375   \n",
       "position                                                        10   \n",
       "sourceValue                                              10_7817_2   \n",
       "startTimeRemain                                             -37634   \n",
       "subTitle                                                 55寸电视2699   \n",
       "titile                                                       海尔家装季   \n",
       "\n",
       "                                                                15  \\\n",
       "brandIdOld                                                    8551   \n",
       "brandImg         http://m.360buyimg.com/mobilecms/s620*221_jfs/...   \n",
       "brandName                                                 华硕（ASUS）   \n",
       "endTimeRemain                                                48705   \n",
       "goodsList        [{u'soldRate': 16, u'startTimeShow': u'00:00',...   \n",
       "id                                                            6380   \n",
       "position                                                        15   \n",
       "sourceValue                                              15_8551_2   \n",
       "startTimeRemain                                             -37634   \n",
       "subTitle                                                  爆款直降限时抢购   \n",
       "titile                                                      华硕冰点直击   \n",
       "\n",
       "                                                                20  \\\n",
       "brandIdOld                                                    9889   \n",
       "brandImg         http://m.360buyimg.com/mobilecms/s620*221_jfs/...   \n",
       "brandName                                              君华仕（GENVAS）   \n",
       "endTimeRemain                                                77565   \n",
       "goodsList        [{u'soldRate': 24, u'startTimeShow': u'08:00',...   \n",
       "id                                                            6355   \n",
       "position                                                        20   \n",
       "sourceValue                                              20_9889_2   \n",
       "startTimeRemain                                              -8834   \n",
       "subTitle                                                  满199减100   \n",
       "titile                                                    品质出游包你满意   \n",
       "\n",
       "                                                                25  \\\n",
       "brandIdOld                                                   14917   \n",
       "brandImg         http://m.360buyimg.com/mobilecms/s620*221_jfs/...   \n",
       "brandName                                               润本（RUNBEN）   \n",
       "endTimeRemain                                                77565   \n",
       "goodsList        [{u'soldRate': 76, u'startTimeShow': u'08:00',...   \n",
       "id                                                            6367   \n",
       "position                                                        25   \n",
       "sourceValue                                             25_14917_2   \n",
       "startTimeRemain                                              -8834   \n",
       "subTitle                                                  爆款低至9.9元   \n",
       "titile                                                     妈妈的安心之选   \n",
       "\n",
       "                                                                30  \\\n",
       "brandIdOld                                                    7408   \n",
       "brandImg         http://m.360buyimg.com/mobilecms/s620*221_jfs/...   \n",
       "brandName                                              格兰仕（Galanz）   \n",
       "endTimeRemain                                                77565   \n",
       "goodsList        [{u'soldRate': 31, u'startTimeShow': u'08:00',...   \n",
       "id                                                            6377   \n",
       "position                                                        30   \n",
       "sourceValue                                              30_7408_2   \n",
       "startTimeRemain                                              -8834   \n",
       "subTitle                                                  部分2件8.5折   \n",
       "titile                                                      品质厨电疯抢   \n",
       "\n",
       "                                                                35  \\\n",
       "brandIdOld                                                    6742   \n",
       "brandImg         http://m.360buyimg.com/mobilecms/s620*221_jfs/...   \n",
       "brandName                                             飞利浦（PHILIPS）   \n",
       "endTimeRemain                                                77565   \n",
       "goodsList        [{u'soldRate': 30, u'startTimeShow': u'08:00',...   \n",
       "id                                                            6378   \n",
       "position                                                        35   \n",
       "sourceValue                                              35_6742_2   \n",
       "startTimeRemain                                              -8834   \n",
       "subTitle                                                  爆品低至9.9元   \n",
       "titile                                                     个护健康变形记   \n",
       "\n",
       "                                                                40  \\\n",
       "brandIdOld                                                  189726   \n",
       "brandImg         http://m.360buyimg.com/mobilecms/s620*221_jfs/...   \n",
       "brandName                                               雅萌（YA-MAN）   \n",
       "endTimeRemain                                                77565   \n",
       "goodsList        [{u'soldRate': 28, u'startTimeShow': u'08:00',...   \n",
       "id                                                            6379   \n",
       "position                                                        40   \n",
       "sourceValue                                            40_189726_2   \n",
       "startTimeRemain                                              -8834   \n",
       "subTitle                                                iphone红现货抢   \n",
       "titile                                                   从新开始 红遍中国   \n",
       "\n",
       "                                                                45  \\\n",
       "brandIdOld                                                   21360   \n",
       "brandImg         http://m.360buyimg.com/mobilecms/s620*221_jfs/...   \n",
       "brandName                                                    beats   \n",
       "endTimeRemain                                                77565   \n",
       "goodsList        [{u'soldRate': 37, u'startTimeShow': u'08:00',...   \n",
       "id                                                            6382   \n",
       "position                                                        45   \n",
       "sourceValue                                             45_21360_2   \n",
       "startTimeRemain                                              -8834   \n",
       "subTitle                                                 乐享千遍 不止一面   \n",
       "titile                                                      娱乐影音专场   \n",
       "\n",
       "                                                                50  \\\n",
       "brandIdOld                                                   10107   \n",
       "brandImg         http://m.360buyimg.com/mobilecms/s620*221_jfs/...   \n",
       "brandName                                               卡西欧（CASIO）   \n",
       "endTimeRemain                                                77565   \n",
       "goodsList        [{u'soldRate': 31, u'startTimeShow': u'08:00',...   \n",
       "id                                                            6385   \n",
       "position                                                        50   \n",
       "sourceValue                                             50_10107_2   \n",
       "startTimeRemain                                              -8834   \n",
       "subTitle                                                   换个视角看世界   \n",
       "titile                                                      潮流相机专场   \n",
       "\n",
       "                                                                55  \n",
       "brandIdOld                                                   17519  \n",
       "brandImg         http://m.360buyimg.com/mobilecms/s620*221_jfs/...  \n",
       "brandName                                                维达（Vinda）  \n",
       "endTimeRemain                                                77565  \n",
       "goodsList        [{u'soldRate': 38, u'startTimeShow': u'08:00',...  \n",
       "id                                                            6390  \n",
       "position                                                        55  \n",
       "sourceValue                                             55_17519_2  \n",
       "startTimeRemain                                              -8834  \n",
       "subTitle                                                      爆款直降  \n",
       "titile                                                      清洁品质榜单  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_pos = pd.DataFrame(df['mBrandPos'])\n",
    "brand_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brandIdOld</th>\n",
       "      <th>brandImg</th>\n",
       "      <th>brandName</th>\n",
       "      <th>endTimeRemain</th>\n",
       "      <th>goodsList</th>\n",
       "      <th>id</th>\n",
       "      <th>position</th>\n",
       "      <th>sourceValue</th>\n",
       "      <th>startTimeRemain</th>\n",
       "      <th>subTitle</th>\n",
       "      <th>titile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7817</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s620*221_jfs/...</td>\n",
       "      <td>海尔（Haier）</td>\n",
       "      <td>48765</td>\n",
       "      <td>[{u'soldRate': 25, u'startTimeShow': u'00:00',...</td>\n",
       "      <td>6375</td>\n",
       "      <td>10</td>\n",
       "      <td>10_7817_2</td>\n",
       "      <td>-37634</td>\n",
       "      <td>55寸电视2699</td>\n",
       "      <td>海尔家装季</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8551</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s620*221_jfs/...</td>\n",
       "      <td>华硕（ASUS）</td>\n",
       "      <td>48705</td>\n",
       "      <td>[{u'soldRate': 16, u'startTimeShow': u'00:00',...</td>\n",
       "      <td>6380</td>\n",
       "      <td>15</td>\n",
       "      <td>15_8551_2</td>\n",
       "      <td>-37634</td>\n",
       "      <td>爆款直降限时抢购</td>\n",
       "      <td>华硕冰点直击</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9889</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s620*221_jfs/...</td>\n",
       "      <td>君华仕（GENVAS）</td>\n",
       "      <td>77565</td>\n",
       "      <td>[{u'soldRate': 24, u'startTimeShow': u'08:00',...</td>\n",
       "      <td>6355</td>\n",
       "      <td>20</td>\n",
       "      <td>20_9889_2</td>\n",
       "      <td>-8834</td>\n",
       "      <td>满199减100</td>\n",
       "      <td>品质出游包你满意</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14917</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s620*221_jfs/...</td>\n",
       "      <td>润本（RUNBEN）</td>\n",
       "      <td>77565</td>\n",
       "      <td>[{u'soldRate': 76, u'startTimeShow': u'08:00',...</td>\n",
       "      <td>6367</td>\n",
       "      <td>25</td>\n",
       "      <td>25_14917_2</td>\n",
       "      <td>-8834</td>\n",
       "      <td>爆款低至9.9元</td>\n",
       "      <td>妈妈的安心之选</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7408</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s620*221_jfs/...</td>\n",
       "      <td>格兰仕（Galanz）</td>\n",
       "      <td>77565</td>\n",
       "      <td>[{u'soldRate': 31, u'startTimeShow': u'08:00',...</td>\n",
       "      <td>6377</td>\n",
       "      <td>30</td>\n",
       "      <td>30_7408_2</td>\n",
       "      <td>-8834</td>\n",
       "      <td>部分2件8.5折</td>\n",
       "      <td>品质厨电疯抢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6742</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s620*221_jfs/...</td>\n",
       "      <td>飞利浦（PHILIPS）</td>\n",
       "      <td>77565</td>\n",
       "      <td>[{u'soldRate': 30, u'startTimeShow': u'08:00',...</td>\n",
       "      <td>6378</td>\n",
       "      <td>35</td>\n",
       "      <td>35_6742_2</td>\n",
       "      <td>-8834</td>\n",
       "      <td>爆品低至9.9元</td>\n",
       "      <td>个护健康变形记</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>189726</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s620*221_jfs/...</td>\n",
       "      <td>雅萌（YA-MAN）</td>\n",
       "      <td>77565</td>\n",
       "      <td>[{u'soldRate': 28, u'startTimeShow': u'08:00',...</td>\n",
       "      <td>6379</td>\n",
       "      <td>40</td>\n",
       "      <td>40_189726_2</td>\n",
       "      <td>-8834</td>\n",
       "      <td>iphone红现货抢</td>\n",
       "      <td>从新开始 红遍中国</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21360</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s620*221_jfs/...</td>\n",
       "      <td>beats</td>\n",
       "      <td>77565</td>\n",
       "      <td>[{u'soldRate': 37, u'startTimeShow': u'08:00',...</td>\n",
       "      <td>6382</td>\n",
       "      <td>45</td>\n",
       "      <td>45_21360_2</td>\n",
       "      <td>-8834</td>\n",
       "      <td>乐享千遍 不止一面</td>\n",
       "      <td>娱乐影音专场</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10107</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s620*221_jfs/...</td>\n",
       "      <td>卡西欧（CASIO）</td>\n",
       "      <td>77565</td>\n",
       "      <td>[{u'soldRate': 31, u'startTimeShow': u'08:00',...</td>\n",
       "      <td>6385</td>\n",
       "      <td>50</td>\n",
       "      <td>50_10107_2</td>\n",
       "      <td>-8834</td>\n",
       "      <td>换个视角看世界</td>\n",
       "      <td>潮流相机专场</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17519</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s620*221_jfs/...</td>\n",
       "      <td>维达（Vinda）</td>\n",
       "      <td>77565</td>\n",
       "      <td>[{u'soldRate': 38, u'startTimeShow': u'08:00',...</td>\n",
       "      <td>6390</td>\n",
       "      <td>55</td>\n",
       "      <td>55_17519_2</td>\n",
       "      <td>-8834</td>\n",
       "      <td>爆款直降</td>\n",
       "      <td>清洁品质榜单</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brandIdOld                                           brandImg  \\\n",
       "0        7817  http://m.360buyimg.com/mobilecms/s620*221_jfs/...   \n",
       "1        8551  http://m.360buyimg.com/mobilecms/s620*221_jfs/...   \n",
       "2        9889  http://m.360buyimg.com/mobilecms/s620*221_jfs/...   \n",
       "3       14917  http://m.360buyimg.com/mobilecms/s620*221_jfs/...   \n",
       "4        7408  http://m.360buyimg.com/mobilecms/s620*221_jfs/...   \n",
       "5        6742  http://m.360buyimg.com/mobilecms/s620*221_jfs/...   \n",
       "6      189726  http://m.360buyimg.com/mobilecms/s620*221_jfs/...   \n",
       "7       21360  http://m.360buyimg.com/mobilecms/s620*221_jfs/...   \n",
       "8       10107  http://m.360buyimg.com/mobilecms/s620*221_jfs/...   \n",
       "9       17519  http://m.360buyimg.com/mobilecms/s620*221_jfs/...   \n",
       "\n",
       "      brandName  endTimeRemain  \\\n",
       "0     海尔（Haier）          48765   \n",
       "1      华硕（ASUS）          48705   \n",
       "2   君华仕（GENVAS）          77565   \n",
       "3    润本（RUNBEN）          77565   \n",
       "4   格兰仕（Galanz）          77565   \n",
       "5  飞利浦（PHILIPS）          77565   \n",
       "6    雅萌（YA-MAN）          77565   \n",
       "7         beats          77565   \n",
       "8    卡西欧（CASIO）          77565   \n",
       "9     维达（Vinda）          77565   \n",
       "\n",
       "                                           goodsList    id position  \\\n",
       "0  [{u'soldRate': 25, u'startTimeShow': u'00:00',...  6375       10   \n",
       "1  [{u'soldRate': 16, u'startTimeShow': u'00:00',...  6380       15   \n",
       "2  [{u'soldRate': 24, u'startTimeShow': u'08:00',...  6355       20   \n",
       "3  [{u'soldRate': 76, u'startTimeShow': u'08:00',...  6367       25   \n",
       "4  [{u'soldRate': 31, u'startTimeShow': u'08:00',...  6377       30   \n",
       "5  [{u'soldRate': 30, u'startTimeShow': u'08:00',...  6378       35   \n",
       "6  [{u'soldRate': 28, u'startTimeShow': u'08:00',...  6379       40   \n",
       "7  [{u'soldRate': 37, u'startTimeShow': u'08:00',...  6382       45   \n",
       "8  [{u'soldRate': 31, u'startTimeShow': u'08:00',...  6385       50   \n",
       "9  [{u'soldRate': 38, u'startTimeShow': u'08:00',...  6390       55   \n",
       "\n",
       "   sourceValue  startTimeRemain    subTitle     titile  \n",
       "0    10_7817_2           -37634   55寸电视2699      海尔家装季  \n",
       "1    15_8551_2           -37634    爆款直降限时抢购     华硕冰点直击  \n",
       "2    20_9889_2            -8834    满199减100   品质出游包你满意  \n",
       "3   25_14917_2            -8834    爆款低至9.9元    妈妈的安心之选  \n",
       "4    30_7408_2            -8834    部分2件8.5折     品质厨电疯抢  \n",
       "5    35_6742_2            -8834    爆品低至9.9元    个护健康变形记  \n",
       "6  40_189726_2            -8834  iphone红现货抢  从新开始 红遍中国  \n",
       "7   45_21360_2            -8834   乐享千遍 不止一面     娱乐影音专场  \n",
       "8   50_10107_2            -8834     换个视角看世界     潮流相机专场  \n",
       "9   55_17519_2            -8834        爆款直降     清洁品质榜单  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand = pd.DataFrame(df['brandList'])\n",
    "brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biInfo</th>\n",
       "      <th>classifyType</th>\n",
       "      <th>endRemainTime</th>\n",
       "      <th>imageurl</th>\n",
       "      <th>jdPrice</th>\n",
       "      <th>miaoSha</th>\n",
       "      <th>miaoShaPrice</th>\n",
       "      <th>promotionId</th>\n",
       "      <th>seckillNum</th>\n",
       "      <th>soldRate</th>\n",
       "      <th>sourceValue</th>\n",
       "      <th>spuId</th>\n",
       "      <th>startRemainTime</th>\n",
       "      <th>startTimeShow</th>\n",
       "      <th>tagText</th>\n",
       "      <th>tagType</th>\n",
       "      <th>top</th>\n",
       "      <th>wareId</th>\n",
       "      <th>wname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>48766</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s220x220_jfs/...</td>\n",
       "      <td>1998</td>\n",
       "      <td>True</td>\n",
       "      <td>1299</td>\n",
       "      <td>197428790</td>\n",
       "      <td>1000</td>\n",
       "      <td>25</td>\n",
       "      <td>null_1_1156051_0_2</td>\n",
       "      <td>1015707</td>\n",
       "      <td>-37634</td>\n",
       "      <td>00:00</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1156051</td>\n",
       "      <td>海尔(Haier)80升D系列数显无线遥控 大容量 一级能效 双管变频加热 专利防电墙电热水...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>48766</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s220x220_jfs/...</td>\n",
       "      <td>5299</td>\n",
       "      <td>True</td>\n",
       "      <td>4999</td>\n",
       "      <td>197513270</td>\n",
       "      <td>2000</td>\n",
       "      <td>20</td>\n",
       "      <td>null_1_2827318_0_2</td>\n",
       "      <td>2827318</td>\n",
       "      <td>-37634</td>\n",
       "      <td>00:00</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2827318</td>\n",
       "      <td>【成交价3999】海尔（Haier）BCD-642WDVMU1 642升变频风冷无霜对开门智...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>48766</td>\n",
       "      <td>http://m.360buyimg.com/mobilecms/s220x220_jfs/...</td>\n",
       "      <td>9999</td>\n",
       "      <td>True</td>\n",
       "      <td>7999</td>\n",
       "      <td>197481654</td>\n",
       "      <td>200</td>\n",
       "      <td>32</td>\n",
       "      <td>null_1_3517689_0_2</td>\n",
       "      <td>1338399</td>\n",
       "      <td>-37634</td>\n",
       "      <td>00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3517689</td>\n",
       "      <td>海尔模卡（MOOKA）U70H3 70英寸 4K安卓智能网络纤薄窄边框UHD高清LED液晶电...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  biInfo classifyType  endRemainTime  \\\n",
       "0      2         None          48766   \n",
       "1      2         None          48766   \n",
       "2      2         None          48766   \n",
       "\n",
       "                                            imageurl jdPrice miaoSha  \\\n",
       "0  http://m.360buyimg.com/mobilecms/s220x220_jfs/...    1998    True   \n",
       "1  http://m.360buyimg.com/mobilecms/s220x220_jfs/...    5299    True   \n",
       "2  http://m.360buyimg.com/mobilecms/s220x220_jfs/...    9999    True   \n",
       "\n",
       "  miaoShaPrice  promotionId  seckillNum  soldRate         sourceValue  \\\n",
       "0         1299    197428790        1000        25  null_1_1156051_0_2   \n",
       "1         4999    197513270        2000        20  null_1_2827318_0_2   \n",
       "2         7999    197481654         200        32  null_1_3517689_0_2   \n",
       "\n",
       "     spuId  startRemainTime startTimeShow tagText  tagType  top   wareId  \\\n",
       "0  1015707           -37634         00:00                0    1  1156051   \n",
       "1  2827318           -37634         00:00                0    1  2827318   \n",
       "2  1338399           -37634         00:00    None        0    1  3517689   \n",
       "\n",
       "                                               wname  \n",
       "0  海尔(Haier)80升D系列数显无线遥控 大容量 一级能效 双管变频加热 专利防电墙电热水...  \n",
       "1  【成交价3999】海尔（Haier）BCD-642WDVMU1 642升变频风冷无霜对开门智...  \n",
       "2  海尔模卡（MOOKA）U70H3 70英寸 4K安卓智能网络纤薄窄边框UHD高清LED液晶电...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haier_goods = pd.DataFrame(brand.iloc[0]['goodsList'])\n",
    "haier_goods.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jdPrice</th>\n",
       "      <th>miaoShaPrice</th>\n",
       "      <th>soldRate</th>\n",
       "      <th>startRemainTime</th>\n",
       "      <th>endRemainTime</th>\n",
       "      <th>startTimeShow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>1299</td>\n",
       "      <td>25</td>\n",
       "      <td>-37634</td>\n",
       "      <td>48766</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5299</td>\n",
       "      <td>4999</td>\n",
       "      <td>20</td>\n",
       "      <td>-37634</td>\n",
       "      <td>48766</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9999</td>\n",
       "      <td>7999</td>\n",
       "      <td>32</td>\n",
       "      <td>-37634</td>\n",
       "      <td>48766</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4529</td>\n",
       "      <td>3699</td>\n",
       "      <td>16</td>\n",
       "      <td>-37634</td>\n",
       "      <td>48706</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6049</td>\n",
       "      <td>4899</td>\n",
       "      <td>31</td>\n",
       "      <td>-37634</td>\n",
       "      <td>48706</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  jdPrice miaoShaPrice  soldRate  startRemainTime  endRemainTime startTimeShow\n",
       "0    1998         1299        25           -37634          48766         00:00\n",
       "1    5299         4999        20           -37634          48766         00:00\n",
       "2    9999         7999        32           -37634          48766         00:00\n",
       "0    4529         3699        16           -37634          48706         00:00\n",
       "1    6049         4899        31           -37634          48706         00:00"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "将brandList每个品牌里的goodsList拼接，添加到训练集中\n",
    "\"\"\"\n",
    "temp_cols = ['jdPrice','miaoShaPrice','soldRate','startRemainTime','endRemainTime','startTimeShow']\n",
    "temp = None\n",
    "for i in xrange(len(brand)):\n",
    "    temp_df = pd.DataFrame(brand.iloc[i]['goodsList'])\n",
    "    temp = pd.concat([temp,temp_df[temp_cols]],axis=0)\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jdPrice            False\n",
       "miaoShaPrice       False\n",
       "soldRate           False\n",
       "startRemainTime    False\n",
       "endRemainTime      False\n",
       "startTimeShow      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "检查有无缺失值\n",
    "\"\"\"\n",
    "temp.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jdPrice</th>\n",
       "      <th>miaoShaPrice</th>\n",
       "      <th>soldRate</th>\n",
       "      <th>startRemainTime</th>\n",
       "      <th>endRemainTime</th>\n",
       "      <th>startTimeShow</th>\n",
       "      <th>discount</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998.0</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>25</td>\n",
       "      <td>-37634</td>\n",
       "      <td>48766</td>\n",
       "      <td>00:00</td>\n",
       "      <td>699.0</td>\n",
       "      <td>0.650150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5299.0</td>\n",
       "      <td>4999.0</td>\n",
       "      <td>20</td>\n",
       "      <td>-37634</td>\n",
       "      <td>48766</td>\n",
       "      <td>00:00</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.943386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9999.0</td>\n",
       "      <td>7999.0</td>\n",
       "      <td>32</td>\n",
       "      <td>-37634</td>\n",
       "      <td>48766</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.799980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4529.0</td>\n",
       "      <td>3699.0</td>\n",
       "      <td>16</td>\n",
       "      <td>-37634</td>\n",
       "      <td>48706</td>\n",
       "      <td>00:00</td>\n",
       "      <td>830.0</td>\n",
       "      <td>0.816737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6049.0</td>\n",
       "      <td>4899.0</td>\n",
       "      <td>31</td>\n",
       "      <td>-37634</td>\n",
       "      <td>48706</td>\n",
       "      <td>00:00</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.809886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   jdPrice  miaoShaPrice  soldRate  startRemainTime  endRemainTime  \\\n",
       "0   1998.0        1299.0        25           -37634          48766   \n",
       "1   5299.0        4999.0        20           -37634          48766   \n",
       "2   9999.0        7999.0        32           -37634          48766   \n",
       "0   4529.0        3699.0        16           -37634          48706   \n",
       "1   6049.0        4899.0        31           -37634          48706   \n",
       "\n",
       "  startTimeShow  discount      rate  \n",
       "0         00:00     699.0  0.650150  \n",
       "1         00:00     300.0  0.943386  \n",
       "2         00:00    2000.0  0.799980  \n",
       "0         00:00     830.0  0.816737  \n",
       "1         00:00    1150.0  0.809886  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "将所有值转换为数值型,并计算折扣差价discount和折扣率rate\n",
    "\"\"\"\n",
    "temp[temp_cols[:-1]] = temp[temp_cols[:-1]].apply(pd.to_numeric)\n",
    "temp['discount'] = temp.jdPrice - temp.miaoShaPrice\n",
    "temp['rate'] = temp.miaoShaPrice / temp.jdPrice \n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activeId                                                      232257\n",
       "adword                                                              \n",
       "book                                                           false\n",
       "cName                                                               \n",
       "canBuy                                                          true\n",
       "canFreeRead                                                    false\n",
       "cid                                                                 \n",
       "clockNum                                                           0\n",
       "colorRGB                                                     #7A44FB\n",
       "discount                                                      131.00\n",
       "endRemainTime                                                  84764\n",
       "good                                                                \n",
       "imageurl           http://m.360buyimg.com/mobilecms/s220x220_jfs/...\n",
       "jdPrice                                                          298\n",
       "message                                                             \n",
       "miaoSha                                                         True\n",
       "miaoShaPrice                                                     167\n",
       "moreFunId                                             searchCatelogy\n",
       "promotion                                                      false\n",
       "promotionId                                                197497512\n",
       "rate                                                            5.6折\n",
       "resultSort                                                         3\n",
       "soldRate                                                          26\n",
       "sourceValue                                          34_1_594835_0_2\n",
       "spuId                                                         841536\n",
       "startRemainTime                                                -1634\n",
       "startTimeShow                                                  10:00\n",
       "tagText                                                           萌宝\n",
       "tagType                                                            1\n",
       "wareId                                                        594835\n",
       "wname              【京东超市】妈咪宝贝 (MamyPoko) 婴儿小内裤电商箱装大号尿不湿 【男】 L160片...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = pd.DataFrame(df['itemList'])\n",
    "item.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  startTimeShow   soldRate\n",
      "0         00:00  24.500000\n",
      "1         08:00  32.875000\n",
      "2         10:00  31.396226\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAGDCAYAAAD6X2MbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJUmqgIEsSVIFDGRJkirwv9pJpNIJPtdWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa4be7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = temp[['startTimeShow','soldRate']]\n",
    "gg = pd.concat([gg,item[['startTimeShow','soldRate']]] ,axis=0)\n",
    "#gg['startTimeShow'].unique()\n",
    "grouped_gg = gg.groupby('startTimeShow').mean()\n",
    "grouped_gg.plot(kind='bar',rot=360,figsize=(8,6),title= 'Figure 1: Average Soldrate in different Showtime')\n",
    "print grouped_gg.reset_index().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由Figure 1可知，深夜0点的平均销售率小于8：00和10：00两个正常时间段，且8：00和10：00差距不大，这点与常识相符."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discount</th>\n",
       "      <th>jdPrice</th>\n",
       "      <th>miaoShaPrice</th>\n",
       "      <th>soldRate</th>\n",
       "      <th>startRemainTime</th>\n",
       "      <th>endRemainTime</th>\n",
       "      <th>startTimeShow</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>26</td>\n",
       "      <td>-1634</td>\n",
       "      <td>84764</td>\n",
       "      <td>10:00</td>\n",
       "      <td>0.560403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129.2</td>\n",
       "      <td>299.0</td>\n",
       "      <td>169.8</td>\n",
       "      <td>30</td>\n",
       "      <td>-1634</td>\n",
       "      <td>84764</td>\n",
       "      <td>10:00</td>\n",
       "      <td>0.567893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>411.0</td>\n",
       "      <td>2599.0</td>\n",
       "      <td>2188.0</td>\n",
       "      <td>31</td>\n",
       "      <td>-1634</td>\n",
       "      <td>84764</td>\n",
       "      <td>10:00</td>\n",
       "      <td>0.841862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300.0</td>\n",
       "      <td>2788.0</td>\n",
       "      <td>2488.0</td>\n",
       "      <td>26</td>\n",
       "      <td>-1634</td>\n",
       "      <td>84764</td>\n",
       "      <td>10:00</td>\n",
       "      <td>0.892396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>34</td>\n",
       "      <td>-1634</td>\n",
       "      <td>84764</td>\n",
       "      <td>10:00</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discount  jdPrice  miaoShaPrice  soldRate  startRemainTime  endRemainTime  \\\n",
       "0     131.0    298.0         167.0        26            -1634          84764   \n",
       "1     129.2    299.0         169.8        30            -1634          84764   \n",
       "2     411.0   2599.0        2188.0        31            -1634          84764   \n",
       "3     300.0   2788.0        2488.0        26            -1634          84764   \n",
       "4      49.0     98.0          49.0        34            -1634          84764   \n",
       "\n",
       "  startTimeShow      rate  \n",
       "0         10:00  0.560403  \n",
       "1         10:00  0.567893  \n",
       "2         10:00  0.841862  \n",
       "3         10:00  0.892396  \n",
       "4         10:00  0.500000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "对itemList中的数据做相同处理\n",
    "\"\"\"\n",
    "cols = ['discount','jdPrice','miaoShaPrice','soldRate','startRemainTime','endRemainTime','startTimeShow']\n",
    "train = item[cols]\n",
    "train[cols[:-1]]= train[cols[:-1]].apply(pd.to_numeric)\n",
    "train['rate'] = train.miaoShaPrice / train.jdPrice\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "将temp和train合并，构造数据集\n",
    "\"\"\"\n",
    "showtime = {'00:00':0, '08:00':1,'10:00':2}\n",
    "new_train = pd.concat([temp,train],axis=0)\n",
    "new_train['startTimeShow'] = new_train.startTimeShow.map(showtime)\n",
    "len(new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 83 entries, 0 to 52\n",
      "Data columns (total 8 columns):\n",
      "discount           83 non-null float64\n",
      "endRemainTime      83 non-null int64\n",
      "jdPrice            83 non-null float64\n",
      "miaoShaPrice       83 non-null float64\n",
      "rate               83 non-null float64\n",
      "soldRate           83 non-null int64\n",
      "startRemainTime    83 non-null int64\n",
      "startTimeShow      83 non-null int64\n",
      "dtypes: float64(4), int64(4)\n",
      "memory usage: 5.8 KB\n"
     ]
    }
   ],
   "source": [
    "new_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discount</th>\n",
       "      <th>endRemainTime</th>\n",
       "      <th>jdPrice</th>\n",
       "      <th>miaoShaPrice</th>\n",
       "      <th>rate</th>\n",
       "      <th>soldRate</th>\n",
       "      <th>startRemainTime</th>\n",
       "      <th>startTimeShow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>699.0</td>\n",
       "      <td>48766</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.650150</td>\n",
       "      <td>25</td>\n",
       "      <td>-37634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300.0</td>\n",
       "      <td>48766</td>\n",
       "      <td>5299.0</td>\n",
       "      <td>4999.0</td>\n",
       "      <td>0.943386</td>\n",
       "      <td>20</td>\n",
       "      <td>-37634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>48766</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>7999.0</td>\n",
       "      <td>0.799980</td>\n",
       "      <td>32</td>\n",
       "      <td>-37634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>830.0</td>\n",
       "      <td>48706</td>\n",
       "      <td>4529.0</td>\n",
       "      <td>3699.0</td>\n",
       "      <td>0.816737</td>\n",
       "      <td>16</td>\n",
       "      <td>-37634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1150.0</td>\n",
       "      <td>48706</td>\n",
       "      <td>6049.0</td>\n",
       "      <td>4899.0</td>\n",
       "      <td>0.809886</td>\n",
       "      <td>31</td>\n",
       "      <td>-37634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discount  endRemainTime  jdPrice  miaoShaPrice      rate  soldRate  \\\n",
       "0     699.0          48766   1998.0        1299.0  0.650150        25   \n",
       "1     300.0          48766   5299.0        4999.0  0.943386        20   \n",
       "2    2000.0          48766   9999.0        7999.0  0.799980        32   \n",
       "0     830.0          48706   4529.0        3699.0  0.816737        16   \n",
       "1    1150.0          48706   6049.0        4899.0  0.809886        31   \n",
       "\n",
       "   startRemainTime  startTimeShow  \n",
       "0           -37634              0  \n",
       "1           -37634              0  \n",
       "2           -37634              0  \n",
       "0           -37634              0  \n",
       "1           -37634              0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discount</th>\n",
       "      <th>endRemainTime</th>\n",
       "      <th>jdPrice</th>\n",
       "      <th>miaoShaPrice</th>\n",
       "      <th>rate</th>\n",
       "      <th>soldRate</th>\n",
       "      <th>startRemainTime</th>\n",
       "      <th>startTimeShow</th>\n",
       "      <th>discount*jdPrice</th>\n",
       "      <th>discount/jdPrice</th>\n",
       "      <th>...</th>\n",
       "      <th>miaoShaPrice*startRemainTime</th>\n",
       "      <th>miaoShaPrice/startRemainTime</th>\n",
       "      <th>miaoShaPrice*endRemainTime</th>\n",
       "      <th>miaoShaPrice/endRemainTime</th>\n",
       "      <th>rate*startRemainTime</th>\n",
       "      <th>rate/startRemainTime</th>\n",
       "      <th>rate*endRemainTime</th>\n",
       "      <th>rate/endRemainTime</th>\n",
       "      <th>startRemainTime*endRemainTime</th>\n",
       "      <th>startRemainTime/endRemainTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>699.0</td>\n",
       "      <td>48766</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.650150</td>\n",
       "      <td>25</td>\n",
       "      <td>-37634</td>\n",
       "      <td>0</td>\n",
       "      <td>1396602.0</td>\n",
       "      <td>0.349850</td>\n",
       "      <td>...</td>\n",
       "      <td>-48886566.0</td>\n",
       "      <td>-0.034517</td>\n",
       "      <td>63347034.0</td>\n",
       "      <td>0.026637</td>\n",
       "      <td>-24467.750751</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>31705.222222</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-1835259644</td>\n",
       "      <td>-0.771726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300.0</td>\n",
       "      <td>48766</td>\n",
       "      <td>5299.0</td>\n",
       "      <td>4999.0</td>\n",
       "      <td>0.943386</td>\n",
       "      <td>20</td>\n",
       "      <td>-37634</td>\n",
       "      <td>0</td>\n",
       "      <td>1589700.0</td>\n",
       "      <td>0.056614</td>\n",
       "      <td>...</td>\n",
       "      <td>-188132366.0</td>\n",
       "      <td>-0.132832</td>\n",
       "      <td>243781234.0</td>\n",
       "      <td>0.102510</td>\n",
       "      <td>-35503.371580</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>46005.139460</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-1835259644</td>\n",
       "      <td>-0.771726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>48766</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>7999.0</td>\n",
       "      <td>0.799980</td>\n",
       "      <td>32</td>\n",
       "      <td>-37634</td>\n",
       "      <td>0</td>\n",
       "      <td>19998000.0</td>\n",
       "      <td>0.200020</td>\n",
       "      <td>...</td>\n",
       "      <td>-301034366.0</td>\n",
       "      <td>-0.212547</td>\n",
       "      <td>390079234.0</td>\n",
       "      <td>0.164028</td>\n",
       "      <td>-30106.447245</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>39011.824582</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-1835259644</td>\n",
       "      <td>-0.771726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>830.0</td>\n",
       "      <td>48706</td>\n",
       "      <td>4529.0</td>\n",
       "      <td>3699.0</td>\n",
       "      <td>0.816737</td>\n",
       "      <td>16</td>\n",
       "      <td>-37634</td>\n",
       "      <td>0</td>\n",
       "      <td>3759070.0</td>\n",
       "      <td>0.183263</td>\n",
       "      <td>...</td>\n",
       "      <td>-139208166.0</td>\n",
       "      <td>-0.098289</td>\n",
       "      <td>180163494.0</td>\n",
       "      <td>0.075945</td>\n",
       "      <td>-30737.064694</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>39779.972179</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-1833001604</td>\n",
       "      <td>-0.772677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1150.0</td>\n",
       "      <td>48706</td>\n",
       "      <td>6049.0</td>\n",
       "      <td>4899.0</td>\n",
       "      <td>0.809886</td>\n",
       "      <td>31</td>\n",
       "      <td>-37634</td>\n",
       "      <td>0</td>\n",
       "      <td>6956350.0</td>\n",
       "      <td>0.190114</td>\n",
       "      <td>...</td>\n",
       "      <td>-184368966.0</td>\n",
       "      <td>-0.130175</td>\n",
       "      <td>238610694.0</td>\n",
       "      <td>0.100583</td>\n",
       "      <td>-30479.247148</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>39446.304183</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-1833001604</td>\n",
       "      <td>-0.772677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discount  endRemainTime  jdPrice  miaoShaPrice      rate  soldRate  \\\n",
       "0     699.0          48766   1998.0        1299.0  0.650150        25   \n",
       "1     300.0          48766   5299.0        4999.0  0.943386        20   \n",
       "2    2000.0          48766   9999.0        7999.0  0.799980        32   \n",
       "0     830.0          48706   4529.0        3699.0  0.816737        16   \n",
       "1    1150.0          48706   6049.0        4899.0  0.809886        31   \n",
       "\n",
       "   startRemainTime  startTimeShow  discount*jdPrice  discount/jdPrice  \\\n",
       "0           -37634              0         1396602.0          0.349850   \n",
       "1           -37634              0         1589700.0          0.056614   \n",
       "2           -37634              0        19998000.0          0.200020   \n",
       "0           -37634              0         3759070.0          0.183263   \n",
       "1           -37634              0         6956350.0          0.190114   \n",
       "\n",
       "               ...                miaoShaPrice*startRemainTime  \\\n",
       "0              ...                                 -48886566.0   \n",
       "1              ...                                -188132366.0   \n",
       "2              ...                                -301034366.0   \n",
       "0              ...                                -139208166.0   \n",
       "1              ...                                -184368966.0   \n",
       "\n",
       "   miaoShaPrice/startRemainTime  miaoShaPrice*endRemainTime  \\\n",
       "0                     -0.034517                  63347034.0   \n",
       "1                     -0.132832                 243781234.0   \n",
       "2                     -0.212547                 390079234.0   \n",
       "0                     -0.098289                 180163494.0   \n",
       "1                     -0.130175                 238610694.0   \n",
       "\n",
       "   miaoShaPrice/endRemainTime  rate*startRemainTime  rate/startRemainTime  \\\n",
       "0                    0.026637         -24467.750751             -0.000017   \n",
       "1                    0.102510         -35503.371580             -0.000025   \n",
       "2                    0.164028         -30106.447245             -0.000021   \n",
       "0                    0.075945         -30737.064694             -0.000022   \n",
       "1                    0.100583         -30479.247148             -0.000022   \n",
       "\n",
       "   rate*endRemainTime  rate/endRemainTime  startRemainTime*endRemainTime  \\\n",
       "0        31705.222222            0.000013                    -1835259644   \n",
       "1        46005.139460            0.000019                    -1835259644   \n",
       "2        39011.824582            0.000016                    -1835259644   \n",
       "0        39779.972179            0.000017                    -1833001604   \n",
       "1        39446.304183            0.000017                    -1833001604   \n",
       "\n",
       "   startRemainTime/endRemainTime  \n",
       "0                      -0.771726  \n",
       "1                      -0.771726  \n",
       "2                      -0.771726  \n",
       "0                      -0.772677  \n",
       "1                      -0.772677  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "这里我对相邻两列的数据做乘法和除法来用非线性关系构造新特征，加减法这种线性的关系是不必要的，\n",
    "他们只能分散原特征的feature importance,并不能提高结果。\n",
    "\"\"\"\n",
    "\n",
    "count = 0\n",
    "part_cols = ['discount','jdPrice','miaoShaPrice','rate','startRemainTime','endRemainTime']\n",
    "for id1 in xrange(len(part_cols)-1):\n",
    "    for id2 in xrange(id1+1, len(part_cols)):\n",
    "        new_col1 = '{}*{}'.format(part_cols[id1],part_cols[id2])\n",
    "        new_train[new_col1] = new_train[part_cols[id1]] * new_train[part_cols[id2]]\n",
    "        new_col2 = '{}/{}'.format(part_cols[id1],part_cols[id2])\n",
    "        new_train[new_col2] = new_train[part_cols[id1]] / new_train[part_cols[id2]]\n",
    "        #print new_col1,new_col2\n",
    "new_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 83 entries, 0 to 52\n",
      "Data columns (total 38 columns):\n",
      "discount                         83 non-null float64\n",
      "endRemainTime                    83 non-null int64\n",
      "jdPrice                          83 non-null float64\n",
      "miaoShaPrice                     83 non-null float64\n",
      "rate                             83 non-null float64\n",
      "soldRate                         83 non-null int64\n",
      "startRemainTime                  83 non-null int64\n",
      "startTimeShow                    83 non-null int64\n",
      "discount*jdPrice                 83 non-null float64\n",
      "discount/jdPrice                 83 non-null float64\n",
      "discount*miaoShaPrice            83 non-null float64\n",
      "discount/miaoShaPrice            83 non-null float64\n",
      "discount*rate                    83 non-null float64\n",
      "discount/rate                    83 non-null float64\n",
      "discount*startRemainTime         83 non-null float64\n",
      "discount/startRemainTime         83 non-null float64\n",
      "discount*endRemainTime           83 non-null float64\n",
      "discount/endRemainTime           83 non-null float64\n",
      "jdPrice*miaoShaPrice             83 non-null float64\n",
      "jdPrice/miaoShaPrice             83 non-null float64\n",
      "jdPrice*rate                     83 non-null float64\n",
      "jdPrice/rate                     83 non-null float64\n",
      "jdPrice*startRemainTime          83 non-null float64\n",
      "jdPrice/startRemainTime          83 non-null float64\n",
      "jdPrice*endRemainTime            83 non-null float64\n",
      "jdPrice/endRemainTime            83 non-null float64\n",
      "miaoShaPrice*rate                83 non-null float64\n",
      "miaoShaPrice/rate                83 non-null float64\n",
      "miaoShaPrice*startRemainTime     83 non-null float64\n",
      "miaoShaPrice/startRemainTime     83 non-null float64\n",
      "miaoShaPrice*endRemainTime       83 non-null float64\n",
      "miaoShaPrice/endRemainTime       83 non-null float64\n",
      "rate*startRemainTime             83 non-null float64\n",
      "rate/startRemainTime             83 non-null float64\n",
      "rate*endRemainTime               83 non-null float64\n",
      "rate/endRemainTime               83 non-null float64\n",
      "startRemainTime*endRemainTime    83 non-null int64\n",
      "startRemainTime/endRemainTime    83 non-null float64\n",
      "dtypes: float64(33), int64(5)\n",
      "memory usage: 25.3 KB\n"
     ]
    }
   ],
   "source": [
    "new_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KrystalU\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\KrystalU\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn import grid_search\n",
    "from sklearn.metrics import mean_squared_error, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "配置XGB环境\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-6.3.0-posix-seh-rt_v5-rev1\\\\mingw64\\\\bin'\n",
    "\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "对原数据集按7：3划分训练集和测试集\n",
    "\"\"\"\n",
    "soldRate_index = new_train.columns.tolist().index('soldRate')\n",
    "X_cols =  new_train.columns.tolist()[:soldRate_index] + new_train.columns.tolist()[soldRate_index+1:]\n",
    "y_col = ['soldRate']\n",
    "col_list = new_train.columns.tolist()\n",
    "X_total= new_train[X_cols]\n",
    "y_total = new_train[y_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_total, y_total, test_size=0.3, random_state=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import grid_search\n",
    "def mean_squared_error_(ground_truth, predictions):\n",
    "    return mean_squared_error(ground_truth, predictions) ** 0.5\n",
    "\n",
    "RMSE = make_scorer(mean_squared_error_, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.单模型预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   1 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=8)]: Done   3 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=8)]: Done   4 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=8)]: Done   5 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=8)]: Done   6 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=8)]: Done   7 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=8)]: Done   8 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=8)]: Done  10 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=8)]: Done  11 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=8)]: Done  12 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=8)]: Done  13 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=8)]: Done  14 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=8)]: Done  15 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=8)]: Done  17 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=8)]: Done  18 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=8)]: Done  19 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=8)]: Done  20 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=8)]: Done  21 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=8)]: Done  22 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=8)]: Done  23 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=8)]: Done  24 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=8)]: Done  26 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=8)]: Done  27 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=8)]: Done  28 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=8)]: Done  29 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=8)]: Done  30 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=8)]: Done  31 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=8)]: Done  32 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=8)]: Done  33 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=8)]: Done  35 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=8)]: Done  36 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=8)]: Done  37 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=8)]: Done  38 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=8)]: Done  39 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=8)]: Done  40 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=8)]: Done  41 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=8)]: Done  42 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=8)]: Done  43 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=8)]: Done  44 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=8)]: Done  46 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=8)]: Done  47 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=8)]: Done  48 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=8)]: Done  49 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=8)]: Done  50 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=8)]: Done  51 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=8)]: Done  52 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=8)]: Done  53 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=8)]: Done  54 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=8)]: Done  55 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=8)]: Done  57 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=8)]: Done  58 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=8)]: Done  59 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=8)]: Done  60 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=8)]: Done  61 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=8)]: Done  62 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=8)]: Done  63 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=8)]: Done  64 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=8)]: Done  65 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=8)]: Done  66 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=8)]: Done  67 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=8)]: Done  68 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=8)]: Done  70 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=8)]: Done  71 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=8)]: Done  72 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=8)]: Done  73 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=8)]: Done  74 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=8)]: Done  75 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=8)]: Done  76 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=8)]: Done  77 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=8)]: Done  78 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=8)]: Done  79 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=8)]: Done  80 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=8)]: Done  81 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=8)]: Done  83 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=8)]: Done  84 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=8)]: Done  85 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=8)]: Done  86 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=8)]: Done  87 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=8)]: Done  88 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=8)]: Done  89 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=8)]: Done  90 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=8)]: Done  91 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=8)]: Done  92 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=8)]: Done  93 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=8)]: Done  94 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=8)]: Done  95 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=8)]: Done  96 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=8)]: Done  98 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=8)]: Done  99 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=8)]: Done 100 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=8)]: Done 101 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=8)]: Done 102 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=8)]: Done 103 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=8)]: Done 104 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=8)]: Done 105 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=8)]: Done 106 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=8)]: Done 107 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=8)]: Done 108 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=8)]: Done 109 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=8)]: Done 110 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=8)]: Done 111 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=8)]: Done 113 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=8)]: Done 114 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=8)]: Done 115 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=8)]: Done 116 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=8)]: Done 117 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=8)]: Done 118 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=8)]: Done 119 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=8)]: Done 120 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=8)]: Done 121 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=8)]: Done 122 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=8)]: Done 123 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=8)]: Done 124 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=8)]: Done 125 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=8)]: Done 126 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=8)]: Done 127 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=8)]: Done 128 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=8)]: Done 129 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=8)]: Done 130 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=8)]: Done 131 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=8)]: Done 132 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=8)]: Done 133 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=8)]: Done 134 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=8)]: Done 135 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=8)]: Done 136 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=8)]: Done 137 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=8)]: Done 138 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=8)]: Done 139 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=8)]: Done 140 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=8)]: Done 141 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=8)]: Done 142 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=8)]: Done 143 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=8)]: Done 144 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=8)]: Done 145 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=8)]: Done 147 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=8)]: Done 148 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=8)]: Done 149 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=8)]: Done 150 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=8)]: Done 151 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=8)]: Done 152 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=8)]: Done 153 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=8)]: Done 154 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=8)]: Done 155 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=8)]: Done 156 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=8)]: Done 157 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=8)]: Done 158 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=8)]: Done 159 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=8)]: Done 160 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=8)]: Done 161 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=8)]: Done 162 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=8)]: Done 163 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=8)]: Done 164 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=8)]: Done 165 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=8)]: Done 166 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=8)]: Done 167 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=8)]: Done 168 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=8)]: Done 169 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=8)]: Done 170 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=8)]: Done 171 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=8)]: Done 172 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=8)]: Done 173 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=8)]: Done 174 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=8)]: Done 175 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=8)]: Done 176 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=8)]: Done 177 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=8)]: Done 178 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=8)]: Done 179 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=8)]: Done 180 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=8)]: Done 181 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=8)]: Done 182 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=8)]: Done 183 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=8)]: Done 185 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=8)]: Done 186 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=8)]: Done 187 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=8)]: Done 188 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=8)]: Done 189 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=8)]: Done 190 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=8)]: Done 191 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=8)]: Done 192 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=8)]: Done 193 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=8)]: Done 194 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=8)]: Done 195 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=8)]: Done 196 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=8)]: Done 197 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=8)]: Done 198 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=8)]: Done 199 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=8)]: Done 200 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=8)]: Done 201 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=8)]: Done 202 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=8)]: Done 203 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=8)]: Done 204 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=8)]: Done 205 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=8)]: Done 206 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=8)]: Done 207 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=8)]: Done 208 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=8)]: Done 209 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=8)]: Done 210 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=8)]: Done 211 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=8)]: Done 212 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=8)]: Done 213 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=8)]: Done 214 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=8)]: Done 215 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=8)]: Done 216 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=8)]: Done 217 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=8)]: Done 218 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=8)]: Done 219 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=8)]: Done 220 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=8)]: Done 221 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=8)]: Done 222 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=8)]: Done 223 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=8)]: Done 224 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=8)]: Done 225 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=8)]: Done 226 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=8)]: Done 227 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=8)]: Done 228 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=8)]: Done 229 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=8)]: Done 230 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=8)]: Done 231 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=8)]: Done 232 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=8)]: Done 233 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=8)]: Done 234 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=8)]: Done 235 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=8)]: Done 236 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=8)]: Done 237 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=8)]: Done 238 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=8)]: Done 239 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=8)]: Done 240 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=8)]: Done 241 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=8)]: Done 242 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=8)]: Done 243 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=8)]: Done 244 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=8)]: Done 245 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=8)]: Done 246 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=8)]: Done 247 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=8)]: Done 248 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=8)]: Done 249 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=8)]: Done 250 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=8)]: Done 251 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=8)]: Done 252 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=8)]: Done 253 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=8)]: Done 254 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=8)]: Done 255 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=8)]: Done 256 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=8)]: Done 257 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=8)]: Done 258 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=8)]: Done 259 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=8)]: Done 260 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=8)]: Done 261 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=8)]: Done 262 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=8)]: Done 263 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=8)]: Done 264 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=8)]: Done 265 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=8)]: Done 266 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=8)]: Done 267 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=8)]: Done 268 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=8)]: Done 269 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=8)]: Done 270 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=8)]: Done 271 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=8)]: Done 272 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=8)]: Done 273 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=8)]: Done 274 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=8)]: Done 275 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=8)]: Done 276 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=8)]: Done 277 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=8)]: Done 278 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=8)]: Done 279 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=8)]: Done 280 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=8)]: Done 281 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=8)]: Done 282 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=8)]: Done 283 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=8)]: Done 284 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=8)]: Done 285 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=8)]: Done 286 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=8)]: Done 287 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=8)]: Done 288 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=8)]: Done 289 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=8)]: Done 290 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=8)]: Done 291 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=8)]: Done 292 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=8)]: Done 293 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=8)]: Done 294 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=8)]: Done 295 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=8)]: Done 296 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=8)]: Done 297 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=8)]: Done 298 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=8)]: Done 299 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=8)]: Done 300 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=8)]: Done 301 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=8)]: Done 302 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=8)]: Done 303 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=8)]: Done 304 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=8)]: Done 305 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=8)]: Done 306 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=8)]: Done 307 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=8)]: Done 308 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=8)]: Done 309 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=8)]: Done 310 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=8)]: Done 311 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=8)]: Done 312 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=8)]: Done 313 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=8)]: Done 314 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=8)]: Done 315 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=8)]: Done 316 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=8)]: Done 317 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=8)]: Done 318 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=8)]: Done 319 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=8)]: Done 320 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=8)]: Done 321 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=8)]: Done 322 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=8)]: Done 323 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=8)]: Done 324 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=8)]: Done 325 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=8)]: Done 326 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=8)]: Done 327 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=8)]: Done 328 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=8)]: Done 329 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=8)]: Done 330 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=8)]: Done 331 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=8)]: Done 332 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=8)]: Done 333 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=8)]: Done 334 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=8)]: Done 335 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=8)]: Done 336 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=8)]: Done 337 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=8)]: Done 338 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=8)]: Done 339 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=8)]: Done 340 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=8)]: Done 341 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=8)]: Done 342 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=8)]: Done 343 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=8)]: Done 344 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=8)]: Done 345 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=8)]: Done 346 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=8)]: Done 347 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=8)]: Done 348 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=8)]: Done 349 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=8)]: Done 350 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=8)]: Done 351 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=8)]: Done 352 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=8)]: Done 353 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=8)]: Done 354 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=8)]: Done 355 tasks      | elapsed:   22.1s\n",
      "[Parallel(n_jobs=8)]: Done 356 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=8)]: Done 357 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=8)]: Done 358 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=8)]: Done 359 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=8)]: Done 360 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=8)]: Done 361 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=8)]: Done 362 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=8)]: Done 363 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=8)]: Done 364 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=8)]: Done 365 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=8)]: Done 366 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=8)]: Done 367 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=8)]: Done 368 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=8)]: Done 369 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=8)]: Done 370 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=8)]: Done 371 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=8)]: Done 372 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=8)]: Done 373 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=8)]: Done 374 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=8)]: Done 375 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=8)]: Done 376 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=8)]: Done 377 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=8)]: Done 378 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=8)]: Done 379 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=8)]: Done 380 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=8)]: Done 381 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=8)]: Done 382 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=8)]: Done 383 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=8)]: Done 384 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=8)]: Done 385 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=8)]: Done 386 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=8)]: Done 387 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=8)]: Done 388 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=8)]: Done 389 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=8)]: Done 390 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=8)]: Done 391 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=8)]: Done 392 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=8)]: Done 393 tasks      | elapsed:   24.7s\n",
      "[Parallel(n_jobs=8)]: Done 394 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=8)]: Done 395 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=8)]: Done 396 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=8)]: Done 397 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=8)]: Done 398 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=8)]: Done 399 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=8)]: Done 400 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=8)]: Done 401 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=8)]: Done 402 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=8)]: Done 403 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=8)]: Done 404 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=8)]: Done 405 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=8)]: Done 406 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=8)]: Done 407 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=8)]: Done 408 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=8)]: Done 409 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=8)]: Done 410 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=8)]: Done 411 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=8)]: Done 412 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=8)]: Done 413 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=8)]: Done 414 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=8)]: Done 415 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=8)]: Done 416 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=8)]: Done 417 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=8)]: Done 418 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=8)]: Done 419 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=8)]: Done 420 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=8)]: Done 421 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=8)]: Done 422 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=8)]: Done 423 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=8)]: Done 424 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=8)]: Done 425 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=8)]: Done 426 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=8)]: Done 427 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=8)]: Done 428 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=8)]: Done 429 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=8)]: Done 430 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=8)]: Done 431 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=8)]: Done 432 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=8)]: Done 433 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=8)]: Done 435 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=8)]: Done 436 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=8)]: Done 437 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=8)]: Done 438 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=8)]: Done 439 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=8)]: Done 440 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=8)]: Done 441 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=8)]: Done 442 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=8)]: Done 443 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=8)]: Done 444 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=8)]: Done 445 tasks      | elapsed:   27.2s\n",
      "[Parallel(n_jobs=8)]: Done 446 tasks      | elapsed:   27.2s\n",
      "[Parallel(n_jobs=8)]: Done 447 tasks      | elapsed:   27.3s\n",
      "[Parallel(n_jobs=8)]: Done 448 tasks      | elapsed:   27.4s\n",
      "[Parallel(n_jobs=8)]: Done 449 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=8)]: Done 450 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=8)]: Done 451 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=8)]: Done 452 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=8)]: Done 453 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=8)]: Done 454 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=8)]: Done 455 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=8)]: Done 456 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=8)]: Done 457 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=8)]: Done 458 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=8)]: Done 459 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=8)]: Done 460 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=8)]: Done 461 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=8)]: Done 462 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=8)]: Done 463 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=8)]: Done 464 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=8)]: Done 465 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=8)]: Done 466 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=8)]: Done 467 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=8)]: Done 468 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=8)]: Done 469 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=8)]: Done 470 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=8)]: Done 471 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=8)]: Done 472 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=8)]: Done 473 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=8)]: Done 474 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=8)]: Done 475 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=8)]: Done 476 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=8)]: Done 477 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=8)]: Done 478 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=8)]: Done 479 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=8)]: Done 480 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=8)]: Done 481 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=8)]: Done 482 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=8)]: Done 483 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=8)]: Done 484 tasks      | elapsed:   30.1s\n",
      "[Parallel(n_jobs=8)]: Done 485 tasks      | elapsed:   30.1s\n",
      "[Parallel(n_jobs=8)]: Done 486 tasks      | elapsed:   30.1s\n",
      "[Parallel(n_jobs=8)]: Done 487 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=8)]: Done 488 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=8)]: Done 489 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=8)]: Done 490 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=8)]: Done 491 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=8)]: Done 492 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=8)]: Done 493 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=8)]: Done 494 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=8)]: Done 495 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=8)]: Done 496 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=8)]: Done 497 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=8)]: Done 498 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=8)]: Done 499 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=8)]: Done 500 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=8)]: Done 501 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=8)]: Done 502 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=8)]: Done 503 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=8)]: Done 504 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=8)]: Done 505 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=8)]: Done 506 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=8)]: Done 507 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=8)]: Done 508 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=8)]: Done 509 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=8)]: Done 510 tasks      | elapsed:   31.1s\n",
      "[Parallel(n_jobs=8)]: Done 511 tasks      | elapsed:   31.1s\n",
      "[Parallel(n_jobs=8)]: Done 512 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=8)]: Done 513 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=8)]: Done 514 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=8)]: Done 515 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=8)]: Done 516 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=8)]: Done 517 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=8)]: Done 518 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=8)]: Done 519 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=8)]: Done 520 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=8)]: Done 521 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=8)]: Done 522 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=8)]: Done 523 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=8)]: Done 524 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=8)]: Done 525 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=8)]: Done 526 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=8)]: Done 527 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=8)]: Done 528 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=8)]: Done 529 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=8)]: Done 530 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=8)]: Done 531 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=8)]: Done 532 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=8)]: Done 533 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=8)]: Done 534 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=8)]: Done 535 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=8)]: Done 536 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=8)]: Done 537 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=8)]: Done 538 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=8)]: Done 539 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=8)]: Done 540 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=8)]: Done 541 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=8)]: Done 542 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=8)]: Done 543 tasks      | elapsed:   32.9s\n",
      "[Parallel(n_jobs=8)]: Done 544 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=8)]: Done 545 tasks      | elapsed:   33.1s\n",
      "[Parallel(n_jobs=8)]: Done 546 tasks      | elapsed:   33.1s\n",
      "[Parallel(n_jobs=8)]: Done 547 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=8)]: Done 548 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=8)]: Done 549 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=8)]: Done 550 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=8)]: Done 551 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=8)]: Done 552 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=8)]: Done 553 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=8)]: Done 554 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=8)]: Done 555 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=8)]: Done 556 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=8)]: Done 557 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=8)]: Done 558 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=8)]: Done 559 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=8)]: Done 560 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=8)]: Done 561 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=8)]: Done 562 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=8)]: Done 563 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=8)]: Done 564 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=8)]: Done 565 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=8)]: Done 566 tasks      | elapsed:   34.3s\n",
      "[Parallel(n_jobs=8)]: Done 567 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=8)]: Done 568 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=8)]: Done 569 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=8)]: Done 570 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=8)]: Done 571 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=8)]: Done 572 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=8)]: Done 573 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=8)]: Done 574 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=8)]: Done 575 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=8)]: Done 576 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=8)]: Done 577 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=8)]: Done 578 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=8)]: Done 579 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=8)]: Done 580 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=8)]: Done 581 tasks      | elapsed:   34.9s\n",
      "[Parallel(n_jobs=8)]: Done 582 tasks      | elapsed:   35.0s\n",
      "[Parallel(n_jobs=8)]: Done 583 tasks      | elapsed:   35.0s\n",
      "[Parallel(n_jobs=8)]: Done 584 tasks      | elapsed:   35.0s\n",
      "[Parallel(n_jobs=8)]: Done 585 tasks      | elapsed:   35.1s\n",
      "[Parallel(n_jobs=8)]: Done 586 tasks      | elapsed:   35.1s\n",
      "[Parallel(n_jobs=8)]: Done 587 tasks      | elapsed:   35.1s\n",
      "[Parallel(n_jobs=8)]: Done 588 tasks      | elapsed:   35.2s\n",
      "[Parallel(n_jobs=8)]: Done 589 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=8)]: Done 590 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=8)]: Done 591 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=8)]: Done 592 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=8)]: Done 593 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=8)]: Done 594 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=8)]: Done 595 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=8)]: Done 596 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=8)]: Done 597 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=8)]: Done 598 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=8)]: Done 599 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=8)]: Done 600 tasks      | elapsed:   35.8s\n",
      "[Parallel(n_jobs=8)]: Done 601 tasks      | elapsed:   35.8s\n",
      "[Parallel(n_jobs=8)]: Done 602 tasks      | elapsed:   35.9s\n",
      "[Parallel(n_jobs=8)]: Done 603 tasks      | elapsed:   35.9s\n",
      "[Parallel(n_jobs=8)]: Done 604 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=8)]: Done 605 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=8)]: Done 606 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=8)]: Done 607 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=8)]: Done 608 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=8)]: Done 609 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=8)]: Done 610 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=8)]: Done 611 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=8)]: Done 612 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=8)]: Done 613 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=8)]: Done 614 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=8)]: Done 615 tasks      | elapsed:   36.6s\n",
      "[Parallel(n_jobs=8)]: Done 616 tasks      | elapsed:   36.6s\n",
      "[Parallel(n_jobs=8)]: Done 617 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=8)]: Done 618 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=8)]: Done 619 tasks      | elapsed:   36.9s\n",
      "[Parallel(n_jobs=8)]: Done 620 tasks      | elapsed:   36.9s\n",
      "[Parallel(n_jobs=8)]: Done 621 tasks      | elapsed:   37.1s\n",
      "[Parallel(n_jobs=8)]: Done 622 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=8)]: Done 623 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=8)]: Done 624 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=8)]: Done 625 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=8)]: Done 626 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=8)]: Done 627 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=8)]: Done 628 tasks      | elapsed:   37.9s\n",
      "[Parallel(n_jobs=8)]: Done 629 tasks      | elapsed:   37.9s\n",
      "[Parallel(n_jobs=8)]: Done 630 tasks      | elapsed:   37.9s\n",
      "[Parallel(n_jobs=8)]: Done 631 tasks      | elapsed:   38.0s\n",
      "[Parallel(n_jobs=8)]: Done 632 tasks      | elapsed:   38.1s\n",
      "[Parallel(n_jobs=8)]: Done 633 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=8)]: Done 634 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=8)]: Done 635 tasks      | elapsed:   38.5s\n",
      "[Parallel(n_jobs=8)]: Done 636 tasks      | elapsed:   38.5s\n",
      "[Parallel(n_jobs=8)]: Done 637 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=8)]: Done 638 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=8)]: Done 639 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=8)]: Done 640 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=8)]: Done 641 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=8)]: Done 642 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=8)]: Done 643 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=8)]: Done 644 tasks      | elapsed:   38.9s\n",
      "[Parallel(n_jobs=8)]: Done 645 tasks      | elapsed:   38.9s\n",
      "[Parallel(n_jobs=8)]: Done 646 tasks      | elapsed:   38.9s\n",
      "[Parallel(n_jobs=8)]: Done 647 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=8)]: Done 648 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=8)]: Done 649 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=8)]: Done 650 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=8)]: Done 651 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=8)]: Done 652 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=8)]: Done 653 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=8)]: Done 654 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=8)]: Done 655 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=8)]: Done 656 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=8)]: Done 657 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=8)]: Done 658 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=8)]: Done 659 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=8)]: Done 660 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=8)]: Done 661 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=8)]: Done 662 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=8)]: Done 663 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=8)]: Done 664 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=8)]: Done 665 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=8)]: Done 666 tasks      | elapsed:   39.8s\n",
      "[Parallel(n_jobs=8)]: Done 667 tasks      | elapsed:   39.8s\n",
      "[Parallel(n_jobs=8)]: Done 668 tasks      | elapsed:   39.9s\n",
      "[Parallel(n_jobs=8)]: Done 669 tasks      | elapsed:   39.9s\n",
      "[Parallel(n_jobs=8)]: Done 670 tasks      | elapsed:   39.9s\n",
      "[Parallel(n_jobs=8)]: Done 671 tasks      | elapsed:   40.0s\n",
      "[Parallel(n_jobs=8)]: Done 672 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=8)]: Done 673 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=8)]: Done 674 tasks      | elapsed:   40.2s\n",
      "[Parallel(n_jobs=8)]: Done 675 tasks      | elapsed:   40.2s\n",
      "[Parallel(n_jobs=8)]: Done 676 tasks      | elapsed:   40.2s\n",
      "[Parallel(n_jobs=8)]: Done 677 tasks      | elapsed:   40.3s\n",
      "[Parallel(n_jobs=8)]: Done 678 tasks      | elapsed:   40.4s\n",
      "[Parallel(n_jobs=8)]: Done 679 tasks      | elapsed:   40.4s\n",
      "[Parallel(n_jobs=8)]: Done 680 tasks      | elapsed:   40.5s\n",
      "[Parallel(n_jobs=8)]: Done 681 tasks      | elapsed:   40.5s\n",
      "[Parallel(n_jobs=8)]: Done 682 tasks      | elapsed:   40.6s\n",
      "[Parallel(n_jobs=8)]: Done 683 tasks      | elapsed:   40.7s\n",
      "[Parallel(n_jobs=8)]: Done 684 tasks      | elapsed:   40.7s\n",
      "[Parallel(n_jobs=8)]: Done 685 tasks      | elapsed:   40.7s\n",
      "[Parallel(n_jobs=8)]: Done 686 tasks      | elapsed:   40.8s\n",
      "[Parallel(n_jobs=8)]: Done 687 tasks      | elapsed:   40.9s\n",
      "[Parallel(n_jobs=8)]: Done 688 tasks      | elapsed:   40.9s\n",
      "[Parallel(n_jobs=8)]: Done 689 tasks      | elapsed:   41.0s\n",
      "[Parallel(n_jobs=8)]: Done 690 tasks      | elapsed:   41.1s\n",
      "[Parallel(n_jobs=8)]: Done 691 tasks      | elapsed:   41.1s\n",
      "[Parallel(n_jobs=8)]: Done 692 tasks      | elapsed:   41.2s\n",
      "[Parallel(n_jobs=8)]: Done 693 tasks      | elapsed:   41.2s\n",
      "[Parallel(n_jobs=8)]: Done 694 tasks      | elapsed:   41.3s\n",
      "[Parallel(n_jobs=8)]: Done 695 tasks      | elapsed:   41.4s\n",
      "[Parallel(n_jobs=8)]: Done 696 tasks      | elapsed:   41.4s\n",
      "[Parallel(n_jobs=8)]: Done 697 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=8)]: Done 698 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=8)]: Done 699 tasks      | elapsed:   41.6s\n",
      "[Parallel(n_jobs=8)]: Done 700 tasks      | elapsed:   41.6s\n",
      "[Parallel(n_jobs=8)]: Done 701 tasks      | elapsed:   41.9s\n",
      "[Parallel(n_jobs=8)]: Done 702 tasks      | elapsed:   42.0s\n",
      "[Parallel(n_jobs=8)]: Done 703 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=8)]: Done 704 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=8)]: Done 705 tasks      | elapsed:   42.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Grid Search Completed: 0.73 minutes ---\n",
      "Param grid:\n",
      "{'n_estimators': [50, 80, 100, 200], 'subsample': [0.7, 0.8], 'learning_rate': [0.05, 0.08, 0.1], 'max_depth': [7, 9, 10]}\n",
      "Best Params:\n",
      "{'n_estimators': 80, 'subsample': 0.8, 'learning_rate': 0.05, 'max_depth': 9}\n",
      "Best CV Score:\n",
      "0.0143665471352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 720 out of 720 | elapsed:   43.5s finished\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GridSearch寻找最佳参数, 这里做的是10-fold cross validation\n",
    "\"\"\"\n",
    "start_time = time.clock()\n",
    "clf = xgb.XGBRegressor(seed=2017)\n",
    "param_grid = {\n",
    "        'n_estimators': [50,80,100,200],\n",
    "        'learning_rate': [0.05,0.08,0.1],\n",
    "        'max_depth': [7, 9, 10],\n",
    "        'subsample': [0.7, 0.8]\n",
    "    }\n",
    "\n",
    "model = GridSearchCV(estimator=clf, param_grid=param_grid,n_jobs=8,cv=10,verbose=20)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "print('--- Grid Search Completed: %s minutes ---' % round(((time.clock() - start_time) / 60), 2))\n",
    "print('Param grid:')\n",
    "print(param_grid)\n",
    "print('Best Params:')\n",
    "print(model.best_params_)\n",
    "print('Best CV Score:')\n",
    "print(-model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mse:7.77646465603\n",
      "Test mse:157.566031983\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Best Params:\n",
    "{'n_estimators': 80, 'subsample': 0.8, 'learning_rate': 0.08, 'max_depth': 9}\n",
    "Best CV Score:\n",
    "0.362555032839\n",
    "\"\"\"\n",
    "xgb_best = XGBRegressor(n_estimators=80,subsample=0.8,learning_rate=0.05,max_depth=9)\n",
    "xgb_best.fit(X_train,y_train)\n",
    "xgb_train_pred = xgb_best.predict(X_train)\n",
    "xgb_test_pred = xgb_best.predict(X_test)\n",
    "print 'Training mse:{}'.format(mse(y_train,xgb_train_pred))\n",
    "print 'Test mse:{}'.format(mse(y_test,xgb_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xc9fc2b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc81ca58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train_range = xrange(len(y_train))\n",
    "plt.plot(x_train_range, y_train, '-',label='Train')\n",
    "plt.plot(x_train_range, xgb_train_pred, '-',label='Predict')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xca7e2e8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXd4m9X1xz9X8t7b8Uyc5WzbWYQkkIQkQAgjUGYLpECh\nLaW0pZRCW9r+Cm2BtnQyGmba0lBGgDACZBEIAbL38khiO06897Z0f39cyVOyJFvyvJ/nySNLevXq\nxuPovOd+z/cIKSUajUajGfwY+nsBGo1Go3EPOqBrNBrNEEEHdI1Goxki6ICu0Wg0QwQd0DUajWaI\noAO6RqPRDBF0QNdoNJohgg7oGo1GM0TQAV2j0WiGCF59+WZRUVFy1KhRffmWGo1GM+jZvXt3iZQy\n2tFxfRrQR40axa5du/ryLTUajWbQI4Q47cxxTpVchBA/EkIcFkIcEkKsEUL4CSEihBAbhBCZltvw\n3i1Zo9FoNL3BYUAXQiQA9wIzpZRTACNwI/AgsElKOQ7YZLmv0Wg0mn7C2U1RL8BfCOEFBAAFwFXA\nasvzq4EV7l+eRqPRaJzFYQ1dSnlGCPFHIBeoBz6WUn4shIiVUp61HHYOiPXgOjUazRCiubmZ/Px8\nGhoa+nspAwo/Pz8SExPx9vbu0esdBnRLbfwqIAWoAF4XQtzc/hgppRRC2DRWF0LcBdwFkJyc3KNF\najSaoUV+fj7BwcGMGjUKIUR/L2dAIKWktLSU/Px8UlJSenQOZ0ouS4CTUspiKWUzsBaYCxQKIeIA\nLLdFdha5Sko5U0o5MzraoepGo9EMAxoaGoiMjNTBvB1CCCIjI3t11eJMQM8F5gghAoT67i8GjgLr\ngJWWY1YC7/R4FRqNZtihg3lXevs9cRjQpZRfAW8Ae4CDltesAh4DlgohMlFZ/GO9Wkl/YzbDnn+D\nqbm/V6LRaDQ9wqnGIinlr4BfdXq4EZWtDw3yd8C6eyAoBsZf0t+r0Wg0HqS0tJTFi1X4OnfuHEaj\nEWtJeMeOHfj4+Dh1nhdffJHLLruMESNGeGytrtCnnaIDmtpiy21J/65Do9F4nMjISPbt2wfAr3/9\na4KCgrj//vtdPs+LL77I9OnTdUAfcNSVqdv68v5dh0aj6VdWr17NU089RVNTE3PnzuUf//gHZrOZ\n2267jX379iGl5K677iI2NpZ9+/Zxww034O/v71Jm7yl0QLdSrwO6RtMf/N+7hzlSUOXWc06KD+FX\nV0x2+XWHDh3irbfeYvv27Xh5eXHXXXfx6quvMmbMGEpKSjh48CAAFRUVhIWF8fe//51//OMfpKen\nu3X9PUUHdCs6Q9dohj0bN25k586dzJw5E4D6+nqSkpK45JJLOH78OPfeey/Lly/n4osv7ueV2kYH\ndCutGXpZ/65Doxlm9CST9hRSSm6//XYeeeSRLs8dOHCA9evX89RTT/Hmm2+yatWqflhh9+gBF1Z0\nhq7RDHuWLFnCa6+9RkmJEkeUlpaSm5tLcXExUkquu+46fvOb37Bnzx4AgoODqa6u7s8ld0Bn6FZ0\nQNdohj1Tp07lV7/6FUuWLMFsNuPt7c2zzz6L0WjkjjvuQEqJEILHH38cgNtuu41vfetbA2ZTVEhp\n04LFI8ycOVMO2AEX/5gFJScgLBl+eLC/V6PRDGmOHj3KxIkT+3sZAxJb3xshxG4p5UxHr9UlFyut\nGXpF/65Do9FoeogO6ABSqlKLMEBjlW7/12g0gxId0AEaKkGaVLkFdJau0WgGJTqgQ5tUMWKM5b7e\nGNVoNIMPHdAB6iwBPFIHdI1GM3jRAR3aMvTIsR3vazQazSBCB3SAulJ1qzN0jWbYYDQaSU9PZ8qU\nKVx33XXU1dX1+FyffPIJl19+OQDr1q3jscfsj4eoqKjg6aef7vF7dYcO6NAmWdQ1dI1m2ODv78++\nffs4dOgQPj4+PPvssx2el1JiNptdPu+VV17Jgw8+aPd5HdA9TX2ZkiyGJqlbHdA1mmHFBRdcQFZW\nFqdOnSI1NZVbb72VKVOmkJeXx8cff8z555/P9OnTue6666ipqQHgww8/ZMKECUyfPp21a9e2nuvl\nl1/mnnvuAaCwsJCrr76atLQ00tLS2L59Ow8++CDZ2dmkp6fzk5/8xK3/D936DypD9wsDo5e6rdM1\ndI2mz1j/IJxzc3f2iKmwzLmpmC0tLaxfv55LL70UgMzMTFavXs2cOXMoKSnh0UcfZePGjQQGBvL4\n44/z5JNP8sADD3DnnXeyefNmxo4dyw033GDz3Pfeey8LFizgrbfewmQyUVNTw2OPPcahQ4daB2y4\nE52hg8rQAyLU1wEROkPXaIYB9fX1pKenM3PmTJKTk7njjjsAGDlyJHPmzAHgyy+/5MiRI8ybN4/0\n9HRWr17N6dOnOXbsGCkpKYwbNw4hBDfffLPN99i8eTPf/e53AVWzDw0N9ej/SWfooDJyf0tA9w/X\nAV2j6UuczKTdjbWG3pnAwMDWr6WULF26lDVr1nQ4xhPZtTvQGTp0zNB1QNdoNBbmzJnD559/TlZW\nFgC1tbWcOHGCCRMmcOrUKbKzswG6BHwrixcv5plnngHAZDJRWVnpUctdHdBBNRZ1yNB1DV2j0UB0\ndDQvv/wyN910E9OmTeP888/n2LFj+Pn5sWrVKpYvX8706dOJiYmx+fq//vWvbNmyhalTpzJjxgyO\nHDlCZGQk8+bNY8qUKW7fFNX2uQC/jYOZt8Mlv1UbNPtegYfy+ntVGs2QRdvn2kfb5/aG5nporutY\nctGOixqNZhDiMKALIVKFEPva/asSQvxQCBEhhNgghMi03Ib3xYLdjlWi2L7kAsqBUaPRaAYRDgO6\nlPK4lDJdSpkOzADqgLeAB4FNUspxwCbL/cGHtV4e0Cmgay26RuNR+rLcO1jo7ffE1ZLLYiBbSnka\nuApYbXl8NbCiVyvpLzpn6AGWgK6VLhqNx/Dz86O0tFQH9XZIKSktLcXPz6/H53BVh34jYNXnxEop\nz1q+PgfE2nqBEOIu4C6A5OTknqzRs9jL0HVA12g8RmJiIvn5+RQXF/f3UgYUfn5+JCYm9vj1Tgd0\nIYQPcCXwUOfnpJRSCGHzo1ZKuQpYBUrl0sN1eg57NXQd0DUaj+Ht7U1KSkp/L2PI4UrJZRmwR0pZ\naLlfKISIA7DcFrl7cX2C3Qxd19A1Gs3gwpWAfhNt5RaAdcBKy9crgXfctag+pa4cvAPBy1fd9w3V\njosajWZQ4lRAF0IEAkuBte0efgxYKoTIBJZY7g8+2rf9AxgMynFRB3SNRjPIcKqGLqWsBSI7PVaK\nUr0MbupKOwZ00H4uGo1mUKI7Rds7LVrxD9c6dI1GM+jQAb1zyQW0J7pGoxmU6IBuL0PXAV2j0Qwy\nhndAN5uUZ4vNGnpF/6xJo9FoesjwDuj1FYC0naE3VoKppV+WpdFoND1hmAf0Tk1FVqwBvkFn6RqN\nZvAwvAN657Z/K7r9X6PRDEKGd0BvzdA7WbnrgK7RaAYhwzugO8rQtRZdo9EMIoZ5QC9VtwGRHR/X\nnugajWYQMrwDen0ZGLzAN7jj47rkotFoBiHDO6Bbm4qE6Pi4byggdEDXaDSDiuEd0G21/YNyXPQP\n057oGo1mUDG8A3pdedcNUSv+2s9Fo9EMLoZ3QLeXoYP2c9FoNIOO4R3Q68raNkA7owO6RqMZZAzf\ngC6l4wxd69A1Gs0gYvgG9KZaMDXZr6EHRGjHRY1GM6gYvgHdXlORFe24qNFoBhnDN6Dbc1q0Yq2t\nN1T2zXo0Go2mlwzfgG7Px8VKa7eorqNrNJrBwfAN6FYFi90MPaLjcRqNRjPAGb4B3ekMXQd0jUYz\nOHAqoAshwoQQbwghjgkhjgohzhdCRAghNgghMi23dgTdAxRrKcWuDj3McpwO6BqNZnDgbIb+V+BD\nKeUEIA04CjwIbJJSjgM2We4PHurKlAmX0cv289oTXaPRDDIcBnQhRChwIfACgJSySUpZAVwFrLYc\nthpY4alFeoT6sq6TitrjF4Z2XNRoNIMJZzL0FKAYeEkIsVcI8bwQIhCIlVKetRxzDoi19WIhxF1C\niF1CiF3FxcXuWbU7sFrn2qPVcVEHdI1GMzhwJqB7AdOBZ6SUGUAtncorUkoJSFsvllKuklLOlFLO\njI6O7u163Uddqf2mIivaz0Wj0QwinAno+UC+lPIry/03UAG+UAgRB2C5LfLMEj1Edz4uVvzDtQ5d\no9EMGhwGdCnlOSBPCJFqeWgxcARYB6y0PLYSeMcjK/QU3XmhW9Ge6BqNZhBhR+LRhe8DrwghfIAc\n4DbUh8FrQog7gNPA9Z5ZogdoaYKmaucy9NLMvlmTRqPR9BKnArqUch8w08ZTi927nD7CmnXb06Bb\n0TV0jabfqG8y4eNlwGgQjg/WAMO1U9SRMZcV/3BlzqUdFzWaPkVKydI/b+XpLVn9vZRBxfAM6I7a\n/q1YA752XNRo+pTimkbyy+v58mRpfy9lUDE8A7orGTrosotG08fkFNcCcLigCqWK1jjD8Azozmbo\nOqBrNP2CNaBX1DVztrKhn1czeBimAd06rcjZgK616BpNX5JTXNP69ZGCqn5cyeBieAb0+jLw8gPv\ngO6P0xm6RtMv5JTUkhwRgBBw5KwO6M7irA59aGFtKhIO5FA6oGs0/UJOcQ1TE0IxGgSHC7QowVmG\nb4buqNwC4BeKdlzUaPqWphYzeeX1jI4OZFJ8iM7QXWB4BvS6MsdNRQAGowrq2hNdo+kzcstqMZml\nCuhxIeSV1VNZ39zfyxoUDM+A7myGDuo4naFrNH1GtkXhMjoqiEnxIQAc1Vm6UwzPgO7IC709uv1f\no+lTrJLF0dGBTI5TAV0rXZxj+G2KSqkCtLMZun+4LrloNH1ITnEN0cG+BPt5E+znTVSQr66jO8nw\ny9AbKkGaXMzQdUDXaPqKnJJaRkcFtt6fFB+iM3QnGX4B3dmmIiu65KLR9Ck5xTWMjg5qvT8pLoTM\nomqaWsz9uKrBwfAL6Nbg7Gj8nBX/CJXVm02eW5NGowGgvLaJ8rpmxkS3ZeiT40NoNkkyi6r7cWWD\ng+EX0J31cbFilTdqx0WNxuPklKiW/9HRHUsuoDdGnWH4BXRnnRatWAO63hjVaDxOe8milVGRgfh7\nG/XGqBMMv4DemqE70VjU/jhdR9doPE5OcS3eRkFiuH/rY0aDYEJcMId1hu6Q4RfQ68tAGMAvzLnj\nrZm8DugajcfJKa5hZGQgXsaOoWlyfAhHtTe6Q4ZfQK8rU8Hc4OR/XWfoGk2f0VmyaGVSXCjVjS3k\nl9f3w6oGD8MvoLvS9g/aE12j6SNaTGZOl9Z2kCxasW6M6rJL9wy/gO5K2z9ox0WNpo/IL6+n2SQ7\nKFysTBgRjEHAEW2l2y3DM6C7kqFbHRd1QNdoPIpVsjjGRkD38zYyJjpIK10c4FRAF0KcEkIcFELs\nE0LssjwWIYTYIITItNw6KRvpZ+pdzNBBd4tqNH1Ajg3JYnu0BYBjXMnQF0kp06WUMy33HwQ2SSnH\nAZss9wc+rmbooA26NJo+ILu4lvAAb8IDfWw+PykuhILKBsprm/p4ZYOH3pRcrgJWW75eDazo/XI8\nTHM9tNT3LKDrDF2j8SidPVw6Mzk+FOj/GaObjxWSNUBtCJwN6BLYKITYLYS4y/JYrJTyrOXrc0Cs\nrRcKIe4SQuwSQuwqLi7u5XJ7iatt/1b0kAuNxuPYkyxamRgXDPSvBYCUknvX7OOPH53otzV0h7N+\n6POllGeEEDHABiHEsfZPSimlEMKm4l9KuQpYBTBz5sz+7Qpwte3fis7QNRqPUt3QTHF1Y7cZemSQ\nLyNC/Po1Qy+saqSmsYUD+RX9tobucCpDl1KesdwWAW8Bs4FCIUQcgOW2yFOLdBs9zdD9w7Xjokbj\nQdpPKeqOSfEhHO5H6WJOsVLiFFQ2UFTd0G/rsIfDgC6ECBRCBFu/Bi4GDgHrgJWWw1YC73hqkW6j\nNxk6UjsuajQeojvJYnsmx4eQXVxLQ3P/JFfZJbWtXx/IG3jxwJkMPRbYJoTYD+wA3pdSfgg8BiwV\nQmQCSyz3BzY9ztC1n4tG40lyimsxCEiOcJChx4VgMktOFPbPpmROcQ1+3gYMggFZdnFYQ5dS5gBp\nNh4vBRZ7YlEeo1cZOjqgazQeIqe4lqSIAHy8us8x23ujT0t00mDPjeQU1zImOgiTWbI/f3Bm6EOH\nujLwDgQvX9depz3RNRqPkl1c063CxUpSeADBvl795umSU6KkldMSQ9mfXzHg3B+HX0B3dvRce3SG\nrtF4DLNZcsqOKVdnDAbBxLiQflG6NDSbyC+vZ3RUIGlJYVTUNZNXNrDcH4dXQK8vg4AeOBRoT3SN\nxmMUVNbT0Gx2qHCxMik+hKNnqzCb+zY7Pl1ah5RKiZNmKffsH2B19OEV0F11WrTipzrUdEDXaNyP\nIw+XzkyKC6GuycTpsjpPLqsLVsnimOggUkcE4+NlYH+eDuj9h6te6FZaHRd1DV2jcTdtgdL5DB3o\ncz16jkWymBIViLfRwOT4EA4MsI3R4RXQe5qhg+4W1Wg8RE5JLUG+XkQHOydWGBcbhJdB9LkFQHZx\nDSNC/Aj0VeLAtMQwDp6ppMVk7tN1dMfwCehmk2oM6kmGDuqDQAd0jcbt5BTXMjo6ECGEU8f7ehkZ\nG9P33ujWdVqZlhhKfbOJLMsVxkBg+AT0+gpA6gxdoxlg5DgpWWxPX3ujSyktbpBt60xLUhujA6lj\ndBgF9B42FVnRnugajdupa2qhoLLBKclieybHh1JU3UhxdaOHVtaR0tomqhpaOmzcpkQGEuzrNaCU\nLsMnoNeVqludoWs0A4aTJc6ZcnVmUpylY7SPyi62zMMMBsFUS4PRQGEYBfReZugBEdpxUaNxM91K\nFo+vh7KTNl/XGtD7qOzSXrLYnrSkMI6dre43s7DODJ+A7o6Si3Zc1GjcijWgp3SuoZua4X+3wIZf\n2nxdaIA3ieH+fZehl9Ti42UgPsy/w+NpiaG0mCVHB8jw6uET0HvqtGhFt/9rNG4np6SGhDB//H2M\nHZ8oPw3mZsjeDC226+ST4vrOGz2nuIaUyECMho5KHKtB2EBpMBo+Ab2+DAxe4Bvcs9frgK7RuJ3O\nUsBWSjPVbVMNnPrM5msnxYdwsqSWuqYWD65QYW+dcaF+RAf7DpgGo+ET0K1NRU5qXbugPdE1GrfS\nKgW0JVkssczsNPrCsQ9svn5SXAhSwrFznvVGbzaZyS2r61oWAoQQpA2gjdHhE9B72vZvRWfoGo1b\nKapupLbJZFuyWJIJAVEwbqnaHLVhUzs5QXksedpKN7esjhaztCutnJYYRnZxLVUNzR5dhzMMn4Be\nV97z+jloT3SNxs1kW5QjtksuWRA1DlIvg+oCOLu/yyHxoX6E+nt7XOniaN6ptcHo0AAouwyfgN7b\nDF07Lmo0bqUtUNrJ0CPHwvhLQBjgeNeyixCCSX3gjd4qWbTjBjnNcqUwECYYDZ+AXlfalmX3BKOX\nxXFRB3SNxh3kFNfi520gLsSv4xP15VBXojL0wChIOs9mQAc1NPrY2SqPGmTlFNcSGehDaIC3zefD\nA31IjggYEEqX4RHQpbRMK+pFhg66W1SjcSM5JTWkRAVh6CQFpCRL3UaOU7epy+DcQajI63KOSfEh\nNLaYWztOPbVOR52saUlhA2Jo9PAI6E01StPak/Fz7fEP157oGo2bcChZjLIG9OXq9sSHXQ5tHRrt\nwbJLTnGtw+EbaYmhFFQ2UFTd4LF1OMPwCOi9bSqyojN0jcYtNLaYyC+vY4xNyWKm6hkJH6XuR41V\n2fqx97scOiY6CB8vg8c2RivrmimtbXIqQ4f+d14cHgHdibb/8tomHlp7sHv3Nu2JrtG4hdOldZil\nnQ3R0kwVzI3tatapy+DUti7WG95GA6mxwR7L0LNLrEqc7jP0yfEhGAT9XnZxOqALIYxCiL1CiPcs\n9yOEEBuEEJmW217sOHoYJzL0P204zpoduazZkWv/PDpD12jcQk53ksWSrLb6uZXUy1TZNGtTl8OV\nBUAV0oZWvffrdM4NMsDHi/Gxwf2udHElQ/8BcLTd/QeBTVLKccAmy/2BiTUI28nQTxRW89+vchEC\n3tp7xv4vhn+4GpShHRc1ml6Rbc+Uy2yCspy2+rmVpNlqD+z4+i7nmhQfQlltE4VV7vdGzymuwcsg\nSI4IcHhsWmIY+/MrPPLB4ixOBXQhRCKwHHi+3cNXAastX68GVrh3aW7EQYb+6PtHCfL14qeXTuBk\nSa39T1ntuKjpQyrrmvnfztx+DRCeIqe4lphgX4L9OkkBK3LB1Ng1oBuMMP5SyPxIOTG2o21j1P1/\nlznFtSRHBOBtdBwqpyWFUlHXTF5ZvdvX4SzOZuh/AR4A2os9Y6WUZy1fnwNibb1QCHGXEGKXEGJX\ncXFxz1faG6w1dBs69C3Hi/j0RDH3Lh7HTbOT8fEy8PbeM7bPE6D9XDR9x0NvHeCnbx5kx8mhp6yy\nKwUs7SRZbE/qMpVM5X7R4eGJHvRGd0ayaCXN6rzYj3V0hwFdCHE5UCSl3G3vGKlSCJtphJRylZRy\nppRyZnR0dM9X2hvqSsE3VDUHtaPZZOa37x8lJSqQW88fRai/N0smxvDu/gKabTUqtPq59L/eVDO0\n+eDgWT44eA6AT070UyLkIZQpV639DlHomqEDjLlImXV1KrsE+XoxKjLA7Z4uJrPkVGmd0+PxUkcE\n4+Nl6NcGI2cy9HnAlUKIU8CrwEVCiP8AhUKIOADLbZHHVtlb6sogoGt2/uqOXLKKanho2QR8vNS3\nYkV6AqW1TWzLLOl6ntaAPvQyJs3Aoay2iYffPsTUhFBmjgxn6/GhFdDLapuorG+277LoF2a7Z8Qn\nEEYvVPLFTmWoSfHutwA4U15PU4vZ6QHW3kYDk+ND+tVK12FAl1I+JKVMlFKOAm4ENkspbwbWASst\nh60E3vHYKntLfVmXX5DK+mae3HCCOaMjWDqprVq0MDWGsABv3rJVdtGOi5o+4NfrDlPV0MwfrpvG\nRRNjOHK2iqKq/m1YcSc5lq7OzuPcgDZTLns216nLoOI0FB3t8PDk+FBOl9ZR7UbHQ2cli+1JSwzj\n4JlKj1oRdEdvdOiPAUuFEJnAEsv9gYnVC70d/9icSUV9Mw9fPgnR7pfHx8vA5dPi+PjIOWoaOxnn\na090jYf5+PA51u0v4J5F45gwIoSF42MA2DqEyi7dSxYzbdfPrYy/VN128naxzhh1pze6s5LF9qQl\nhVLfbCLL8n/sa1wK6FLKT6SUl1u+LpVSLpZSjpNSLpFSDtw6RCenxVMltby8/RTXzUhkcnxol8Ov\nzkigodnMh4fOdXzCHY6L7/8Yvnym568fZpjMckiqPGxRUdfEz98+xMS4EO5eNAaAiXHBxAT7DrGA\nXouP0UBieCcpYEMV1JxTnaH2CImDhBld6uhWpcvhM+4rd+QU1xDi50VkoI/Tr7GOpOuvjtHh0Sna\nyQv99+uP4m00cP/FqTYPn54cTlKEf1e1i9FLba721BO9oRJ2vQibHx0aG6tlJ20OHnAn3/73bu59\ndZ9H32Og8Jv3jlBW28Qfrp3WKpMTQrBgfDSfZZb022W8u8kurmVkZECX+ZzdKlzak7oMzuyC6raE\nKybYl8hAH7fW0a0bt8KFKWcpkYEE+3r1m9Jl6Af0liZoqm7N0L/ILuWjw4XcvXAMMZ1tOy0IIbg6\nPYHPs0so7Fy79A/reYZ+ahtIszIL2/Viz84xUDj2PvwtHTb9n8feory2iS3Hi9h6vAizeWhn6ZuP\nFbJ2zxm+u2AMUxI6XjUuSI2msr6537sQ3YVDyaIthUt7Ui9Tt+3MuoQQbt8YdUWyaMVgEExL6r+R\ndEM/oFuDr384ZrPk0fePEB/qx7cuGN3ty1ZkJCAlrNtX0PGJgF74ueRsBS9/GHUBfPUsNA/Sja6a\nYlh3LwgjfP43KPBMBv3JiSJMZklVQ0vrRtpQpKqhmZ+tPcT42CC+v7hruWH+2CgMYmjU0ZtNZnLt\nSQFLMtUwi4ju/zaJmQRhI22WXU6cq7EtOXaRmsYWCqsabW/cOmBaYhjHzlbT0Nz3HeXDIKC3GXO9\nuSefwwVV/HTZBPy8jd2+bHR0EGlJYV3VLr3xczm5FUbOhQvvh5pCOPC/np2nP5ES3v0BNFbBN99T\nAwjWfR9M7p+8vvFIEb4WOeme3KG7Ef3b945SVN3AH65Nw9er6+9lWIAPGcnhbD0+cJXBzpJnnc9p\nSwpYmglhyeDl2/1JhFBZes4n0NT2QT8pLoQmk5kThb3fGD1p3RB1UrLYnrTEUFrMkqMenqRki6Ef\n0OtKAaj3CuUPHx0nPSmMK9PinXrp1enxHDlbxfH2O+c99USvPgfFx2D0AkhZAHFpsP1vg88XZt8r\ncPx9WPxL9eF02R/g3AH44u9ufZvGFhNbTxSzIj2BED8v9uYOgT0HG3x6opj/7crjzgtHt1qw2mLB\n+GgOnKmktMb9fiV9iXUQhe0M3YYplz1Sl0FLA2RvaX1odooqq35mq4fERXJ6IFm0Yv059keD0TAI\n6Cr4vnGkjqLqxi4yxe64PC0eo0F0zNJ7mqHnbFW3KQtUhjHvB6pmaGe01oCk/DSsfxBGzoc531OP\nTboKJl4BW37fNmnGDXyVU0ZNYwsXT44lPTmcvUMwQ69pbOGhtQcZHR3Ij5aM7/bYhanRSOmeYNWf\nWKWAYzrXps1miwa9++9DKyPnKtVZu7JLXKg/UxJC2HiksNfrzC6uRQgYGenYlKszI0L8iA727ZcG\no6Ef0C3Z9At7K7kiLZ4ZI513+Y0K8uXCcVG8s+9M26acf4TFcdHFOt3JrerDYMQ0dX/iVaoOuO0v\nbleK7Mur4LH1x9wr9zOb4e271dcrngZDu1+dy/4I3n7w7r2uf1/ssPFoIX7eBuaNjWJ6chgnCqu7\n9gUMcn7/wVEKKuv5w7XTHJYAp8SHEhHoM+jr6DklNUQE+hAW0EkKWHUGWuq7lyy2x+gN4y5WG6Pt\nrnKXTIxld255r69kcoprSAz3d/hzsYUQgrTEUPb1w8bo0A/olgy9TAbz00ttyxS7Y0VGAmcrG/jq\nZHuDLwla3fe7AAAgAElEQVSNLnz6Sqky9JQL2wKh0Qvmfl/JrzqZDfWGZpOZH7+2j2e3ZrPzlBuz\n2i+fgtPbYNljED6y43PBI+DiR+H057Dn5V6/lZSSjUcKuWBcNH7eRjKSwzFLODAAhvC6i+1ZJbzy\nVS63z0thxkjHk7QMBsGF46L49ETxoFb8ZBfX2q+fg/MlF1Bll7oSyN/V+tCSibFICZuP9W6/wZmx\nc92RlhhGTnEtVW7sXHWGIR/Qi4rO0iC9uXn+hK6NDE5w8aQRBPoY2zTp1vZ/V7ToZTlQla/KLe1J\n/4ayJPj8ry6vyx5rduSSXVyL0SB4tbthHa5QeAQ2/UbNdkz/hu1jMm5RH1gf/xIq7bhVOsmRs1UU\nVDawdKKyZEi3NGvsHSIBva6phZ+uPcCoyAC7vRC2WJgaQ2ltE4cKBq980e4c0RInJYvtGbsEDN5q\nT8fC5PgQ4kL92Hi052UXs1lyssTOOp1kmqWOfqiPyy5DOqBLKTmUeZJKEczdi5y8lOuEv4+RS6aM\n4IODZ5UMqSeOizmWjZvRCzs+7hMAs7+tLhsLj/Rofe2prGvmzxZ/mptmJ/H+wbNU1vUyQ2hpgrfu\nAt8QuOKv9j02hIAr/gbmFnj/vl6VkTYeKUIIWDRBtb2HBngzNiZoyNTRn/jwOHll9Tz+tWn4+zh/\nSX/BuCiEYNCadVU1NFNS02hnQ/QE+ARDkE0Xbtv4hcKo+R3q6EIIlkyM5dMTJT2WDZ6raqC+2dSj\nDVEr0yy9BH1ddhnSAf39g2cx1ZbhExxFkK+X4xfY4ZqMRKobW9RlXE880XO2QmiSbX3t7DvBOwC2\n914l8vd2/jQ3zkqmscXMW3vze3fSrY/BuYNw5d8gyIH9cUQKXPQL9QF16M0ev+XGo4VkJIURHdwm\nX8tICmNPbv9Og3EHO0+VsfqLU6w8fyTnjbbhKNgNkUG+TEsIHbR2ujndSQFLM1X93IWuTEDJF0tO\ndNiQXzIplvpmE19kl/ZqnTYHWDtJeKAPIyMD+twCYMgG9IZmE4+tP0a8Tz1hkS586tvg/DGRxAT7\nKrWLq46LZhOc+qxN3dKZgAhVrjj4Wq9KFSdLaln9RZs/zZSEUKYlhvLqzryeB8Hcr2DbnyH9Zpiw\n3LnXzPkuxE+H9T/tkUXC2cp6Dp6pZMmkjj+zjORwymqbyC2rc/mcA4X6JhMPvHGAxHB/Hrh0Qo/O\nsWB8NHtzy3t/5dUPtJly9VKy2J5Ui1nXibYsfc7oCAJ9jGzoYdmlN5LF9kxLDOvzodFDNqC/+PlJ\n8svrSQlsRNiZJeosRoPgqvR4PjleRIW0fGo7q0U/d0AF/9EL7B9z/vdUieLLp3u8xsds+NPcOCuZ\nY+eqe1Z7bqyBt74NIYlw6e+df53BCFf9Axoq4MOHXH7bTUfVZpa1fm5l+khLHX0Q69Gf3HCckyW1\nPH7NNAJ7eMW4IDUas4TPsgZflp5j2dvpMp+zqVbtMblSP7cSlgyxU+FYm/zX18vIgtRoNh0t7NEG\nck5xLYE+RmJDHDQ4OSAtMZSCygaKqvuuI3xIBvTaxhae+SSbxRNiCGipsDtL1BVWZCTQbJK8l2mZ\nF+hsht5ef26P8JEw5RrY/XKPTLvs+dNcmR5PgI+xZ5ujGx6G8lNw9TPgF+Laa2Mnw/z74MCrkLnR\npZduPFrIyMgAxsZ0zI7GxQQT6GMctB2jr+3M4/ltJ/n6ecnMHRvV4/OkJYYR6u89KOvoOSU1JEcE\ntA6TaaU0W91G9myfiwmXQd6XUNtWYlkyMZbCqsYebSBnF9eQEh3okimXLawNRn1ZdhmSAf31XXlU\nN7Rwz6LRKvD2MkMH1VY8PjaIt/YXKsdFZwP6ya0QPRGCHZR95t7bI9MuUzf+NEG+XlyZFs+7+8+6\nZvyfuUGt4/zvqU2nnnDh/RCVCu/9EBqda8WubWxhe1YpSybGdvljMhoEaUlhgzJDf2N3Pj9de4D5\nY6P45eWTenUuL6OB+eOi2HqieNDtJ+Q4kiz2JEMHJV+UZsj8uPWhRakxGAQ9ajLqrWTRyuT4EAyC\nPi27DLmAbjZLXtp+iunJYWTEGNQP2g0ZuhCCFRkJ7D5dTouzAb2lEU5/0X25xUrcNDUz8ctnXDLt\ncuRPc+PsZOqbTbzT2WTMHnVl8M49ygDpooedXkcXvHxV6aUyHzY94tRLPssspslkZslE2x9+05PD\nOXq2ivqmwWOXsHZPPj95Yz/zx0bx3K0ze9So0pkF46Mpqm7k6Fn3DXPwNN1KAa0bmhFjenbyuHQI\nju/QdR0e6MPMURFsOOqaHr2h2URBZX2vJItWAny8GB8bzL4+lC4OuYC+6VgRp0vruH1+StumnK35\nhD1gRXoCAKXmQOc2/PJ2qO637sot7Zn3A6gtUqUKJ6htbHHoT5OWGMrEuBBe3elE2UVKJTmsK4Wr\n/6m6P3tD0myYfRfsWKU2WB2w4UgRof7ezBxlu5s3IzmMFrPkoBuHGHiSt/ee4cev72fumEhW3eKe\nYA6wcLxSGw2mrtEzFfU0tphtbzSWZioVmI/rfSKAxaxrGWRt6pAMLZ0Yy9GzVeSXO7+RfrKkFil7\nvyFqJc2yMdpXV1NDLqC/sC2HhDB/Lp08oi2LdkPJBSA+zJ85oyPIq/dFOpOhn9yqLGZHzXPuDVpN\nu/7ulGnXP7dmU+zAn0YIwU2zkzh0poqDjjKFg2/A4bdg4YPqisEdLP4lhCYqR8YW++3YJrNk87FC\nFqVGtw536Ex6knVjdODX0d/Zd4b7XtvHnJRInr91lkt6c0fEhPgxMS6ETwaR+6LV/tj2YOjMntfP\nraReBs21SlFmwaqU2uRClt6ttLIHTEsKpaKumbyyereczxFDKqAfLqjky5wyVs4diZfR0JZFu6Hk\nYuXqjAQKmvxprHZC45qzFRKmt42uc4QQMO+HTpl2FVTUs+qzHKf8aa5KT8DP28Ca7rL0yjPwwY8h\ncbZag7vwDYIr/gIlx+HTP9o9bE9uOeV1zV3kiu2JDPJlZGTAgK+jv7u/gB/9bx+zRkXwwjdnujWY\nW1mYGs3u0+VuHYrsSexKFqV0zZTLHikXgE9Qh7+blKhAxkQHutQ12u280x6QZuly7qsGoyEV0F/c\ndooAHyM3zEpWD7TzQncXl06Jo1oEY651UHJpqIIzu50vt1iZeCWEj3Jo2vXEh8cwS5zypwn192b5\n1HjW7Sug1pbBVW0pvP5NMDXD1c8qnxl3MnYJpN0E256Ec4dsHrLxSCHeRsGF47tvXpqeHM6e3PIB\nuyH4/oGz/PB/+5g5MoKXbptFgI+bv5cWFoyPpsUs2d65eSZ7C3y1ym0mae4iu7iGYD8vooI6mXJV\nn1NigJ5uiFrx8lV7UMfXd/i/L5kUy5c5pU57quSU1BIX6ue2n1vqiGB8vQx95kM0ZAJ6UXUD7+4v\n4LoZiYT6e6sH69obarmHUH9vwqNi8DVV09zSjfvf6c9Bmrq2+zvC6AXn39Otade+vAre3lfAt+an\nOO1Pc9PsJGoaW3jvQKfN0XOH4LmFcHY/rHgGInu4MeWIS34HfmGw7h6bwzA2HC1kzuhIQvy8uz1N\nRnIYRdWNFFT287Qns6lL0Fx/8Cz3vrqX6clhHg3mADNGhhPk68UnneWLH/0c1v8EXr+1w/CH/mbX\nqXKmJYZ2LQ22mnL1suQCqvmt+izkbG59aOnEWJpNkk+d3G/IKXZ97Fx3eBsNTIoP6TMr3cER0Jtq\nIX93t4f858tcms1mvjkvpe3B+jI10srP/uCAnjA6KQkjZr48ctL+QdZxc0mzXX8Dq2nXtr90eUpK\nySPvHSEqyNclf5oZI8MZGxPEmh15bQ8eeQdeWKoy89vXw+QVrq/VWQIi4LInoGCvGr/XjuziGnKK\na+2qW9qTkaQ+nPu1ji4lvPp1eHZ+66DiDw+d4/tr9pKeFMZLt83uceOQs3gbDcwbG8mn7eWLlWeg\n6DAknQdH34MXL1Uqo36muLqRY+eqmWdLf1/SS8lieyZeqT4Y3v2hGsiO6jCOCPRxSr4opXSbZLE9\naYlhHDxT2SdDvgdHQH/3B/Cfq6Eiz+bTDc0mXvnyNIsnxJDSfjOjrkwFc4N7/5tjR6qSzpa9x+0f\ndHIrJM9xPE7LFlbTrsyPuph2vX/wLLtPl3P/xeNd8qdRm6PJ7Mur4GhBBWz+Lbx2K8ROgbs+gYQZ\nLi2xprGF331wlFOuzPqcfA2MXwabH4Wytg/DTZYa5+KJMQ5PMSEuGD9vQ//W0TM/Vn41RUfg5cv5\nZNcB7vnvHqYmhvLybbN65RvkCgvGx3Cmop6sIlX3JcvSxHX5n+Hr/1Pf4+cucpgMeZrt2Woox3xb\nAb00S3kZBTs3RaxbfAKUOqvqTGuXstEgWJQaw+ZjRQ5njRbXNFLd2OLWDB0gLSmU+mYTWZb6vCdx\nGOmEEH5CiB1CiP1CiMNCiP+zPB4hhNgghMi03LqvrtGZRT9Tl7dr77Sp/nhn3xlKa5uUVLE9daVu\nrZ9b8QpU5zyQdcr20IXqQvXH7oz+3B42TLus/jQT40K4bmaSy6e8JiOBcGMD4n/fgE+fgIyb1VzQ\n4BEunUdKyQNv7GfVpzn84NW9zmceQsDyP4HBSzUcWTLLjUeKmBgX4lT5yNtoYFpCWP91jJpa4OOH\nlWZ65TpaKgtIfvd6LhjRwurbZxPsoGTkThakdpIvZm1QgTFmEoy/BO74WCUUL1+mFEz9xOdZJYT4\neTE53oY4oOSEKvO5K+lKnAkX/FiNSjz6HgBLJ8VQ1dDCLgfzAVoVLm6SLFpJSwwjJSqQ8lrPb2A7\n811sBC6SUqYB6cClQog5wIPAJinlOGCT5b5niBitAkHuF/DZnzo8JaXkxW2nmDAimPM7u9fVl7lV\n4dKKpSYfaKrio0Pnuj5/8lN1O3phz98jIAKm39rBtMvqT/OL5RMxGlxvSw5vyOODwN8wtnI7zRc/\nBlf+o0dXEP/8NIcPDp5j8YQY9udX8vy2bkpPnQlNgKW/VgN+9/2Xstomdp0uY6kT2bmVjOQwDp+p\norGlHxqM9v5LKXaW/oYtjRO4ueEB4gwVPC9/RUhT3+rCE8L8GRcTpAK6qVmV+cYtaTOBi50Ed26B\n+Ax48w7Y8rs+3yyVUvJ5Vilzx0TZ/p0tyeyZKVd3XPiAmgz27g+gppgLxkXjYzQ4VLu4W7JoZXR0\nEFvuX8j5Y9zTD9MdDgO6VFivFbwt/yRwFbDa8vhqwIMFWCDtBph6PXzyWIcmlc+zSjleWM0d81O6\nbrjUlbutqagDloA+Oqip47xRKyc/UaWeEb3Ucs+5u9W0q7i6kae3ZLNkYoztWqQjsjbBc4uIooJb\nmh7iXb8rXLcqRXVzPvHhMS6fFsfzK2dy8aRYntxwou2y3xlm3A7Jc+Gjn7F9/xHMkm7lip3JSA6n\nyWTmSEEfT1VvqFJBMXkunxpm8+1/76Y2diamr7+JsbYYXrqsz2vWC8ZH81VOGQ0nv4DGKhi7tOMB\ngVFw6ztqX2br4/DGbdDUd46Vp0vrOFNRz7yxNv4OmxugItc99fP2ePnANauU5cR7PyTQx8jcsZFs\nPFrYrToqp7gGXy8DCWH+7l1PH+LUdY4QwiiE2AcUARuklF8BsVLKs5ZDzgE2/yKFEHcJIXYJIXYV\nF/cyg1n+J9WksvZbrZseL35+kqggH65Mt1GDqy/zSMnFes4LE734PLuEE4XtWrBbx81doJwHe0M7\n06433n4Dc3MDP7tsomvnkBK+eApeuRZCEvH6zieci5jNmh4YduWV1fH9NXsZFxPME9dOQwjBo1dP\nwd/byANv7MfkrLOdwaD81ZvrGLH9V8SG+DLF1uW4HTKS1Sb3nr6uo3/+V6gtxrz0ER5ed5iRkQH8\n+47ZBI2bB7e8pUp8Ly+3u9fjCRamxtBkMnNu97uqlDV6YdeDvHzhqqdg6W/URvhLy6DKSSuIXrIt\nS9XPbSYhZTmAdH+GDhAzERY/DMfeg/2vsmRiLKdL67pNPHJKakmJCsTQg6vfgYJTAV1KaZJSpgOJ\nwGwhxJROz0tU1m7rtauklDOllDOjox0MSHCEXwh87QVVgnjvR2QXVbP5WBE3zxmJr5eN4FlX5lbJ\nYts6VECZE2cgwNvI3ze3m3ZflgOVeb0rt7Rn3g8xm1v4bvbdHPC9g9HvrIAPf6Y6Oh35pzc3wNvf\nhY9+piRdd3yMiEjhhllJ7DxVTlaR814gDc0mvvOf3ZjMkn/eMqNVkhcT7MevrpjEntwKXvrchdJL\n1Dia5/+EmTWf8L34TJf+iGJD/EgI8+9bpUvlGfjiHzDlWr5sHMXp0jq+t2hs27DjpFlwy9vqqvDl\n5Srz7ANmpYTj723E99RmSJpj3xlTCGUtcdMatRH53EVwZo/H17c9u4T4UL+OYgUrraZcbpAs2mLO\n3TByHqx/gKUJTQBs7KZr1N2Sxf7ApZ0IKWUFsAW4FCgUQsQBWG77pg85aRYseggOvcne957Bx8vA\nzXNGdj2uuV75qHgiQzd6gW8I/i2V3Dp3FO8dKGgLjietdrkL3fJWMnYy90Sv5j7up2XmXcpKYNcL\nqhHoz5PgyUnw2kqVheftaGuvrypQmdj+NbDo53Ddv1TXJnDtjES8jYJXdziXSUop+dlbBzlytoq/\n3pjOqE5/nFdnJHDRhBj++PFxl1Qv20d8g6PmJG4o/HPrFZezZCT3sfPi5kfV1c7iX/LfHbmE+ntz\n6ZROm8mJM+DWt5QX/MvLofy0x5fl62XkspGSuPosVT93ROoyuP0jlc2/dJlKDDyE2dL4NHdslG1r\nihI3atBtYTDCiqdBmondfB/T4oPt1tGbWszklde7XbLY1zijcokWQoRZvvYHlgLHgHXASsthK4F3\nPLXILsy/j5bE81l2+k/cMdFMVJCNjT0PtP13wD8M6su584LR+LfP0nO2QkiC2xp0Nh8r4oOTJqYs\nuRm/5b+DOz6CB/Pgzs1w6eNKGnlmj8rCX1gKv0+E55fAqoVKQXDDK7DggQ4qgqggX5ZOiuXNPflO\nbSz+64vTrN1zhh8uHs9FE7pW1oQQ/O7qqXgbDTzw5gGnhwpsOF7GL+V38Gkoho2/dvZbAqg6+pmK\neoqq+qDB6Ox+9cE45zuUeo/g48OFXDM9wbbZVsIMVbNuqLIE9VMeX97XQo8BcCbKSavjEVPUZmnc\nNJUYbH2iVzNg7XHkbBUVdc225YqgrhSC48A32O3v3Ur4KNXUdvJT7gvbyp7cckpqunoK5ZbVYjLL\nYZGhxwFbhBAHgJ2oGvp7wGPAUiFEJrDEcr9vMBj5b+LDNGPk3orH1SDjznig7b8D/uFQX05EoA+3\nnD+Sd/cXkF1UpRQu9sbNuUizycxvPzjK6KhAbjm/3VWIl48KHHO+A9e+CD86CD8+Djf8B877jsq+\nwpLhjg0w8XKb575xVjLldc18dLj7nf8dJ8t45L0jLJkYw/cvsp9JjQj14+Hlk9hxsoz/fOU4M5VS\nsvFIERHj5yDm3K3810997vB1VuzW0Qv2wgsX92qmaaeFwse/UD/v+fexds8ZmkxmbpqdbP818Rkq\nqDdWw0vLO2juPUFa4y7Oygg2lLggAAiKhlvXwbQbYctv4fWVTvvWO4u1fj7XnrrDHaZczjD9Vhh3\nCRee/jujOaNmA3ci20OSxb7GGZXLASllhpRympRyipTyN5bHS6WUi6WU46SUS6SUrg+Q7CHNJjNP\n72ng5cgf4V+8Hz75XdeDPJ6hR7S6Od55wWh8vYy8vf5D9UEyeqFb3uI/X54mp7iWn1020a4DYSvB\nI2DiFXDxI3D7h/CtjUq2Zof5Y6NIDPdnzVf2a72FVQ3c/coekiICePKGdId17utmJnLh+GgeW3+M\nPAezPw8XVHGuqkF1hy76GYSNhHfvddoLfnJ8CD5GA3vz2tXR9/wbXrgE8nfCm3fC8Q+dOle3ZG5Q\nH9ILH0T6hbJmZy4zRoYzPtZBVhmfDivXKQfAl5dbNgA9gKmFwLzP2OM9na2ZJa691tsPrn4WufQR\n5NF3VV29+ITblvZ5VgnjY4M6TNFqRUrLYOhemnI5gxBw5d8RPoH8w+9ZthzuuvfUpkEf+hn6gGP9\noXOcq2pg6tJbYfpK1SJvHfVmpc5iWuTJDN3yoREV5MvNc5JpzNyinku5sNenr6hr4i8bM5k3NtKp\nDkpXMRgEN85K4oucUpt176YWM9/9z27qmlr45y0zHHqsgCq9/P6aqRiE4MG1B7qViG04UogQcNGE\nGPAJhCv+qi7BP33CqfX7ehmZnBDC3tMVat/g3R8on5jkOfD9PZZywko4tc2p89nE1KKy84gxMOM2\ndp4qJ6e4lhtnOdnUFZcGK99V+zkvLW8bteZO8ndAYyU1SYv4IqeUhmbntfnltU088dFxpnw0nvUZ\n/1S/z88tUkqYXtLQbGLnqTLmjrFTbqktUfsm7pYs2iM4FnH5n5kos5mU/XyX71NOcQ1RQb5O/Z73\niG6so93JoAvoUkpe2HaS0VGBLEqNUQOMI8eqgcbth07UezpDD+8wteiuC8cw33CYcz4jISSu16f/\n26Ysqhua+cVy+17nveW6mUkYDYJXd3bdHP2/dw+zJ7eCP16X5jgbbUdCmD8PXTaBz7NKO/rGdGLj\n0UJmJIcTad3/GLNIaaU//yucO+jUe2UkhVN0Jgvzi8vUPNZ5P4Sb10JECnzjTVV2+u+NULDP6fV3\noF0TEV4+rNmRS7CvF8unufDzHTFVBXVToyVTd3P5JXMDGLyIm76MhmYzO046vlCurGvmTx8f54In\ntvDM1my8jAb+eCIG+e2tED1BWUJ8/LBNEzVn2ZNbTkOzuZv6uXVDtI8COsDkFRSOupLviLUc3PlJ\nh6dy7E1TcgeZG+Cv6X2iKhp0AX1Pbjn78yq4bd4oVQLwCYRrX1AZ+Tv3tG3u1Ll3uEUX/MOVmsHS\neRftL5jjdZyP61M5Xdo7l7uc4hr+9cUpbpiVxMQ4Fwc0u0BsiB8XTYjhjd15NLW0dRC+tjOPV77K\n5TsLxnDZVNc/nL4+O5m5YyL53QdHOVPR1di/oKKewwVVXZuJLn5UfV/Xfd+pYLI04DhvGH6GLD4G\n1/8blv5fm/VvYKSSEfqHwX+ucb2U0Fjd2kTEhOVU1DXx/sGzrMhIcN1FccQUWPle2zndSdYGSDqP\nWamj8PEydDvFqLK+mSc3nGD+45v5++YsLhwfxYc/uJCfXTaBnJJaDlQFwW0fwKxvwfa/wb9XQE3P\neke2Z5ViNAjOG23n76/Ew5JFO4R97S+UEkry1vvUlZOFnOIaxrg7oJua1QfjK9eqOOTJzV8Lgy6g\nv7jtFCF+XlwzPbHtwbg0WPJrOP5+25Dl+jJleN8TcyxnCIhQ80obLd2K+TvxMTfwJdN4aktW9691\nwO8+OIavl4H7ljr2Ou8tN81OoqSmqdUga39eBb945xDzx0Zx/8U9q28KIXj8a9MwS8lDaw92Kb1Y\n36uLu2JABCyzOjI+Y/8NpITP/8acbbdTLoN5d/YrMOnKrseFJqjNSWGAf9s3d7OJpYmIix8FIXhr\n7xmaWszcONt1Dx1A7Wekfx2OvN3jINmF6nPqambsEvx9jJyXEmFzilFVQzN/3ZjJ/Mc387dNmcwb\nG8X6H1zA09+YQeqIYC6dEoePl0F1PXv5qga+Fc+qvYhVCyB/l8tL25ZVQlpiqH1vm9JMMPqq0XN9\niG9wJK8nPERs4ymkZdZteW0T5XXN7pUslp9WsuHtf4OZd6g9rT4oLw2qgJ5fXsf6Q2e56bzkrvak\n530XxixW8r2iY5amIg9l59DWsGQt7ZzcCsJAcsZS1u4543BT0B7bs0rYeLSQuxeNJTrYQx9G7Vgw\nPoa4UD/W7MyjpKaR7/5nN9FBvvz9pgw19amHJEUE8NNLJ/DpiWJe392xHX7D0aLWaTJdmHy1xZHx\nt7bLE43VSmq34WGYeAV3+jzO1rJumscix6gyTGO18xln5RnYrpqISJyBlJJXd+SRlhhq22DKWWZ9\nC0xNsGe142OdwequOE61+y9MjSG7uLb1d6+6oZm/b8rkgse38OeNJ5gzOpL3753Ps7fM6HDlF+rv\nzZKJMby7v6DNkTD9JqWSMngpG96dLzgtbaxqaOZAfoX9cgtYFC5jet9N3QMSZ13G6pal8OXTcPIz\nckrcO6WIo+/CPy+A4uNw3ctw+ZPg3Td2AoMqoP/ri9MIIVh5/qiuTxoMakCDT5AyIqo+CwGeM4Bs\nC+iW0k7OVojP4JuL0zEI0aMs3WSWPPL+URLC/Lmjs3OkhzAaBNfPTOKzzGLueHknpbVN/POWGYQH\n+jh+sQNumTOS2SkRPPLeEc5ZBlJUNzTzRXYJSybG2N4bsOPICKgg8NxiOLoOlj6CuG41qSPjHHeM\nxk1TdrKVZ1T5xVET05bfqquvxb8EYG9eBccLq7mxO6miM0Snqg3zXS85NTPWIZkblI47VjVuL7BM\ne1p/6CxPbcnigie28KcNJ5g1Kpz3vj+f526dafcDaUV6AqW1TWxrr5SJmwbf3qr2N96/D96+u0OZ\nwh5fZpdiljDXYUDv23KLlUWpMfzB/HUq/BLh7bs5XaCuGHstWWxugA9+Av+7WRkKfvtTlaD0IYMm\noNc2trBmRy7Lpowg3p55TnCsCuqFh1TG3CcZernK/s7sgtELGRHqx42zk3hjd75L08YB3tidx9Gz\nVTy4bILbJsQ7w/UW1cb+/Ep+f81UpiT0Igtth8EgeOJr02g2mfn5W6r08llmCc0m2f0wi9AEVQ/P\n+UTZoILKelYtUnslt74D8+4FIZieHM6p0jrKam30IrRn5Plww7+VrfF/b7QfmM4egH3/VRr/cKX9\nX/NVLgE+Rq5Ic4Nn96w7oSpf+an3BlML5GyBsYtbex7GRAeSGO7P7z44xh8+Ok5GUhjvfG8ez6+c\n5fBnujA1hrAA765mc/7hcNP/YOFDqrnqhaUON3a3Z5fi721s7RXoQkuTarjqK4VLJ8ICfJg8Mo7f\neBoiptEAABJASURBVN0LVflM2fEAU425JIXZkFc6S2m2+t7sWKUmjt3+sdqc72MGTUB/fVce1Q0t\njjPX8Rer8gt4bkMU2j4s6ivg9HYwt7TOD/3uwjEYhODpT5yXqdU0tvCHj04wY2Q4l7uionADCWH+\n3L1wDD+5JLXj3oQbGBUVyP0Xp7LpWBHv7Ctg45FCwgK8HQ62ZsZtrY6MrH9QZT3R41XG2E4WmpHs\nwgSjcUvVAITcL5RdgqmTP7WU8PHPW5uIQF1RvHfgLFelx7tncEXqZaqTeMdzvTtP/k51pdHOXVEI\nwbcvHM0lk2N56+65vHTbbNKSnJvW5eNlYPnUOD4+cq6rx7/BAAsfhK+/pjxqVi1UVwd22JZVwqyU\nCNv+SqCCuTT1rcKlE0snxfJWSQIV5z/I2PJtvOv9IF5PzYANv1QDQVzpnD3wOvzzQuXhdNOrcMlv\nVfNfPzAoArrZLHlp+ykyksNa/4C7Zcmv1cDYUU62QvcEa4ZeV2YZN+enRn8BcaH+XDczkdd35dlU\nedjimU+yKKlp5OHLPSdT7I6fXDKB77kw0s4VbpuXwvTkMH797mE2HSviotQYx/X5VkfGerVBOuM2\nuG29cttsx9SEULwMwnlfl6nXqppm5kfKuKy9P3i7JiL8VSB8Z18B9c0mbpzVy3KLFaOX+r/kbIGS\nXmyeZ21Qvj6jF3Z4+JbzR/HPW2Y693fSiWumJ9DQbLbt8Q8qWbprK4QlwSvXqUSmE+cqG8gqqmG+\nLbtcK62mXP0X0BdbrhDfDrye64Ne5l9R96kyyRdPwfMXwZ+nqETi9Bf2PeSb6pSybu23VNnrO9uU\nV04/MigC+qZjRZwurXO+ruztp+xMZ97uuUVZ/uCpL1elgaTz1PtasM77fOYTx3+0+eV1PPfZSVak\nx5PuZEY1mDAaBE9cm0Zdk4nK+mbnvc+jxsH1/4LrVsMVf7GpWPL3MTIxLqRjx6gjZt4Oi38FB1+H\n9Q+obMzUojZaLU1EVtbsyGViXAjTEt1ThgJUK7rBG3Y+3/NzZCq5YuvvoTuWlRxOUoQ/b+/rxsUz\nIgVu+1BdZXzwQJe9AOu4ObsNReB5Uy4nSIkKZGxMEB8ePsf+cm/OjLkeblkLP8lSCp+4aUox99Kl\n8OQEeO8+9XduldMWHVWdtXv/AxfcD998v0uy0R8MjoB+tJD4UD8unezaqDSPYvQGn2BlgFV0uEum\nlBDmz7UzknhtZz5nK7vP0p/48DgCeODSCR5bbn8zNiaIh5ZNICrIlwvGuTCgI3WZw+HVGclh7Mut\ncN6PHWD+j2DuvbDzObUJuvffUHxM1e4tl8sH8ys5XFDF12cnufeqKThWySz3/VcNQHeV6kI4d8A5\nd0UXEEJwdXoCn2eVUNid6ZlvkLKYKDzYRbGzLauE8ABvJnXXP1GaCYHRbv0w6glLJsbyZU4ZzSbJ\nGKtk0T9cKXxuWgMPZCu77uQ5av/gX1fBH8fB67dZ9nNK1IfA4ofb+h/6mUER0H9/zVTevHtur2R0\nHiEgvG1zy8b80LsXjsEsJc92U0vfk1vOuv0F3HXhaPubvUOE2+alsPPni90+dzMjOYzaJhOZLvi7\nI4TqAM24BT79gxoqnDwXJrSZmf13Ry5+3gauykhw63oBtTnaWAkHXnP9tVa5YufpRG7gqowEzBLW\n7XMwAGPy1TByPmx6pFXpJaVke5ayy+3W96ckq1/r51aWTmqz1LApWfQNViW66/8FP8lW5ndjl0D2\nZhg5F77zuSrtDiAGWIS0jRCCuNABGOz8w6GpBvxCIS69y9NJEQF8bXoia3bm2cx4pJQ88t4RYoJ9\n+c4C99jtDnQ8sT8wvXVj1EV/dCGUh8ykq1RrvqWJCJSqat2+MyyfGu8Zf4/kOaruuvN5161rszZA\n0AhlK+BmxkQHkZYYanu0YnuEgGWPq27pLb8HlGPhuaoG5nVXbgGLKVf/lVuspCeFE2mR5zqULPoE\nKPO7rz0HPz2lMvNg58cm9hWDIqAPWKwbo6Psj5v73qKxmMySZ7d2zdLX7S9gb24F91+S2rVRSuM0\nyREBRAT6sOd0DyYYGYxw7UvwgwNqQIWF9w4UUNtk4uvneaiTUQjVaFR4CHK/dP51phaVIY5d4haL\nZlusyEjgyNkqjp9zcMUzYoraj9j5PBQeaa2fd9tQVFempKd94bLoAKNBcMmUEcSF+hHhSt9FP4gW\nnEUH9N5gDeijF9o9JDkygGsyEvjvV7kdhjE0NJt4fP0xJseHcK2bpYLDDSEEGUlh7M3r4QQjg1Ep\nN9rx3x15jIsJas3+PcK068E3VNXxneXMLiVXdHP9vD1XpMVjNIjuN0etLPq5Kk18+FO2nSgmMdyf\n5MgA+8eXWkQCA6DkAvDw8km88715/b0Mt6EDem+watFTutbP2/O9RWNpMUv++WmbJ/YL205SUNnA\nw5dPGtRDaQcK00eGk1VUQ2V9s+ODHXD0bBX78yq4aXayZyWkPoEWf5d1aqPTGTKtcsVFHltWVJAv\nF46L4p29ZxxPnwqIgIt+ASc/JeDk+u6zc2hnyjUwArq/j9G2X/sgRQf03jB6oaqrOfjlHBUVyFXp\n8bzy1WmKqxspqm7g6S1ZXDI5ljmjXZgyo7FLhkXuua+nWXo7Xt2Ri4+XgWume2AztDOzvgXmZuf9\nXbI2QNJsjytEVmQkUFDZwI5TTsytmXEb9eETuF+uZn6Kg1p0aaaSbIbZmAOs6TU6oPeGSVeqnW8n\nsrh7Fo2lqcXMc5/l8KePTtBkMvPQsol9sMjhwbSkMAzCyY7RbqhvMrF27xmWTRlBWEAfdPtFjVXZ\n9q6XHFsGVxeq+aZjPVdusXLxpBEE+hh5a48TZRejFx8m/4hEUcKi0le7P7YkU2nZB4jMb6ihA3of\nMTo6iCvT4lm9/RSv7c5j5fmjGBU1uMddDSSCfL0YHxvsutKlEx8cPEt1Q0v3M0Pdzew7oboAjn/Q\n/XHZm9TtOPfLFTvj72Pkkikj+ODgWaemIL1eMopPvecT+NXfurcpLskcMPXzoYgO6H3IPReNo8lk\nJszfm+8v1r/U7iYjOZx9eRWO677dsGZHLqOjAjkvxYM+QJ0Zf6nyBXe0OZq5AQJjINb9ckVbXJ2R\nQHVji82hyu1paDax63Q5+yco/xs2/NL2gaYWNVt1AEgWhyo6oPchY2OC+M1VU3jy+nRC/T00u3AY\nk5EcRmV9Mzk2ZqQ6Q2ZhNbtOl3PDLDd3hjrCYISZtykfmeLjto9pL1c09M2f7dwxUUQH+zrUpO86\nVU5Ti5kpU6bC/B/C4bW2Z7lWnFb7BTpD9xg6oPcxt8wZyaIJ7h/6rGnfYNSzOvqrO/PwNgr+v737\nj62qvOM4/v70F1QKUkBqKRTEIRlqbLEIE7Mwp07dkkLMjC4ajInsD+YwWxbY4jL/2BZjJtn+WFjY\nJLCE6ZaBymK2wZxu0jjEYsfPAMWBUltYKwiIUn5898c5xVJ623u73nt6z/m+kpt77rn3Js83T/Pt\nuc/5Ps9z380RlJHOXAiFJanXd2lpDCbxZLFcsafCAlF/0wRe33uUY30sT7y5uZ2iAnHLlDEwdwlc\nWQ1/Xnr5PYGuksUhUuESR57QXWxMHTeCUcOLBlSP/unZ86zbdpi7ZlzNuLLs7xR1mRHjgun0Tc8H\n6+v31Lwp2Eovi+WKvVkws4qz541XdrSm/ExDczszq8uDyXHFpeE6Lzth2+pLP3hxUS5P6NnSb0KX\nNEnSa5J2S9olaUl4foykTZL2h89ZnIHhXP8KCkRNdfmAZoz+dVcbx0+fHfieoYNh1mPQeRK2//7y\n9/ZvgomzsrvGfy9mVI7iuoqylMMux093svODj7i1+3K5M+qD2dN//3EwM7RLx/5gMt4IL9XNlnSu\n0M8B3zWzGcAcYLGkGcAy4FUzmwa8Gr52LlK1k0az78jJyzdp6McLb73PpDGl/a9Dkk0T64INz9/q\nsb7LqaPQ2pSVxbj6I4n5tVU0HjrGex2X78D15oEOzHpM97+4zstH8NpPPzs/RBblirN+i0HNrBVo\nDY9PStoDVAH1wLzwY2uA14GlWWmlc2maObmcCwbLN+5jQppbip05d4E33+3ge1+ZHu2sXSm4St/w\nLTjU8NkGLc1d5Yq5Gz/vrr6mimf+speXmlr4do/qrIYD7YwoKbx8Z6SK64NJU1t/E9zwrbg+uELP\nQQ19kmVU3S9pClALbAEqwmQP0Ab0uvSYpEXAIoDq6hzW9rpEqq0ezajhRaxq6Hvfy57KhhXx9Shu\nhvZ0w32w8clgi7qLCX1TsH741TdF0qSq0aXMvmYML73TwuO3f+6SCqCG5g5mTx1LcW9LW8/7Puz4\nY3CD9IG1cOqI3xDNsrQTuqQyYB3whJmd6N6pZmaSei3+NbOVwEqAurq6gRcIO5eGUcOL2frkHZw5\nl2LbsBSGFRWk3gMzl0qugNqHYMuv4EQrlI0PyhWvuztn5Yq9WVBbxbL1O9h++KOLV+Mtxz/hP+0f\n89CcFNP4u9Z5eeU78MazwTkfcsmqtP5CJBUTJPO1ZrY+PH1EUmX4fiXQ9+wD53JkWFEho4YXZ/QY\nEsm8S92jwabjjauDcsVPjkU+VHHPjZWUFBVccnO0oTlYLnduX/uH3vxIMBGq4RfBa79Cz6p0qlwE\nPAfsMbPl3d7aACwMjxcCLw9+85xLoLHXBgm8cXWwHIAKIt8Z58rSYu74/Hj+9O8POHs++PXT0NzO\nuLISpleMTP3FgkK495ngWIVQnua+wG5A0rlCnws8DNwuqSl83As8DdwpaT9wR/jaOTcYZj0Gp9rg\nXyugqi7n5Yq9mV9TRcfHnWze346Z0dDcwa3Xjut/Vu3kW+Gmb8CEmov7tbrsSKfKZTOQqse+PLjN\ncc4BwQJco6vh+Hs5WYwrHfOmj2f0FcW8+E4LE0aX0n7qTP/rn3ep/yXgt9CyzWeKOjcUFRQGZX8A\n0+6Kti2hkqICvnpjJRt3t7FxVxvApROK+lJQkHKbRjd4PKE7N1TNWQyPbgyGKoaIBbVVfHr2Aiv+\ncYApY69gYnkf2825nPOE7txQVVgE1bOjbsUlbp5czqQxpZzuPM/cdIdbXM54QnfOpU0SC2qCrfk8\noQ89vg+Ucy4jD39hCh93nudL030Z6KHGE7pzLiNXjRzGD782I+pmuF74kItzzsWEJ3TnnIsJT+jO\nORcTntCdcy4mPKE751xMeEJ3zrmY8ITunHMx4QndOediQma5W9JS0n+BQwP8+jigfRCbk2+SHL/H\nnlxJjr977JPN7Kr+vpDThP7/kPS2mdVF3Y6oJDl+jz2ZsUOy4x9I7D7k4pxzMeEJ3TnnYiKfEvrK\nqBsQsSTH77EnV5Ljzzj2vBlDd84517d8ukJ3zjnXh7xI6JLulrRXUrOkZVG3J5ckHZS0Q1KTpLej\nbk+2SVol6aiknd3OjZG0SdL+8Lk8yjZmS4rYn5LUEvZ/k6R7o2xjtkiaJOk1Sbsl7ZK0JDyflL5P\nFX9G/T/kh1wkFQL7gDuBw8BW4EEz2x1pw3JE0kGgzswSUYsr6YvAKeC3ZnZDeO4Z4EMzezr8h15u\nZkujbGc2pIj9KeCUmf0syrZlm6RKoNLMtkkaCTQC84FHSEbfp4r/fjLo/3y4Qr8FaDazd82sE3gB\nqI+4TS5LzOyfwIc9TtcDa8LjNQR/6LGTIvZEMLNWM9sWHp8E9gBVJKfvU8WfkXxI6FXA+91eH2YA\ngeYxA/4mqVHSoqgbE5EKM2sNj9uAiigbE4HHJW0Ph2RiOeTQnaQpQC2whQT2fY/4IYP+z4eEnnS3\nmVkNcA+wOPxZnlgWjBEO7XHCwbUCmArUAK3As9E2J7sklQHrgCfM7ET395LQ973En1H/50NCbwEm\ndXs9MTyXCGbWEj4fBV4kGIJKmiPhGGPXWOPRiNuTM2Z2xMzOm9kF4NfEuP8lFRMks7Vmtj48nZi+\n7y3+TPs/HxL6VmCapGsklQAPABsiblNOSBoR3iBB0gjgLmBn39+KpQ3AwvB4IfByhG3Jqa5kFlpA\nTPtfkoDngD1mtrzbW4no+1TxZ9r/Q77KBSAs1fk5UAisMrOfRNyknJA0leCqHKAI+F3cY5f0PDCP\nYKW5I8CPgJeAPwDVBKt13m9msbt5mCL2eQQ/tw04CHyz25hybEi6DXgD2AFcCE//gGAcOQl9nyr+\nB8mg//MioTvnnOtfPgy5OOecS4MndOeciwlP6M45FxOe0J1zLiY8oTvnXEx4QnfOuZjwhO6cczHh\nCd0552LifzCgmySvNBOIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcaae780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test_range = xrange(len(y_test))\n",
    "plt.plot(x_test_range, y_test, '-',label='Test')\n",
    "plt.plot(x_test_range, xgb_test_pred, '-',label='Predict')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvMAAAHiCAYAAABlZ0N0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWQ/lwbyZmZmZWQ/1/wGFm85X/mrCcAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc7efc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = xgb_best.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title(\"XGB Feature importances\")\n",
    "plt.barh(range(X_train.shape[1]), importances[indices],\n",
    "           color=\"r\", align=\"center\")\n",
    "\n",
    "plt.yticks(range(X_train.shape[1]), X_train.columns[indices],rotation='horizontal')\n",
    "plt.ylim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上图可知，xgb里前6个最重要的feature是*discount, rate, jdPrice, rate $*$ startRemainTime, miaoshaPrice, discount $/$ startRemainTime*, 其中*rate $*$ startRemainTime* 和 *discount $/$ startRemainTime*是新构造的特征。 我也测试过仅使用原来的特征做训练， 但是效果不如加了新构造的feature。 新构造的feature改善了最后的回归结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=4)]: Done  21 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=4)]: Done  22 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=4)]: Done  23 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=4)]: Done  25 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=4)]: Done  26 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=4)]: Done  27 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=4)]: Done  28 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=4)]: Done  29 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=4)]: Done  30 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=4)]: Done  31 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=4)]: Done  32 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=4)]: Done  34 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=4)]: Done  35 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=4)]: Done  36 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=4)]: Done  37 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=4)]: Done  38 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=4)]: Done  39 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=4)]: Done  40 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=4)]: Done  41 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=4)]: Done  43 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=4)]: Done  46 out of  50 | elapsed:   12.9s remaining:    1.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:   15.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Grid Search Completed: 0.28 minutes ---\n",
      "Best Params:\n",
      "{'n_estimators': 500}\n",
      "Best CV Score:\n",
      "0.525751990185\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GridSearch寻找最佳参数, 这里做的是10-fold cross validation\n",
    "\"\"\"\n",
    "start_time = time.clock()\n",
    "rf = RandomForestRegressor(n_jobs=4, random_state=2017, verbose=1)\n",
    "\n",
    "param_grid = {'n_estimators': [50,80,100,200,500]}\n",
    "model = grid_search.GridSearchCV(estimator=rf, param_grid=param_grid, n_jobs=4, cv=10, verbose=20)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('--- Grid Search Completed: %s minutes ---' % round(((time.clock() - start_time) / 60), 2))\n",
    "print('Best Params:')\n",
    "print(model.best_params_)\n",
    "print('Best CV Score:')\n",
    "print(-model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mse:17.4532802759\n",
      "Test mse:141.4946664\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Best Params:\n",
    "{'n_estimators': 500}\n",
    "Best CV Score:\n",
    "0.531218053656\n",
    "\"\"\"\n",
    "rf_best = RandomForestRegressor(n_estimators=500,random_state=2017)\n",
    "rf_best.fit(X_train,y_train)\n",
    "rf_train_pred = rf_best.predict(X_train)\n",
    "rf_test_pred = rf_best.predict(X_test)\n",
    "print 'Training mse:{}'.format(mse(y_train,rf_train_pred)) \n",
    "print 'Test mse:{}'.format(mse(y_test,rf_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xcf87198>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsvXl4W+Wd9/25paNd8hKvSZw9gYQkJCSBBii0DNDSQtcZ\noDudMuWd9pkus3SGmXeeKdNOn6HvzHTa0hXaQuZpp3sZ6EILZWkLlCUJUEISSJzEibN6t2XpHJ2j\nc79/nHNk2ZZt2ZZlOb4/15XL1tGRdMe2vvqd7/1bhJQShUKhUMx9fLO9AIVCoVCUBiXoCoVCcZag\nBF2hUCjOEpSgKxQKxVmCEnSFQqE4S1CCrlAoFGcJStAVCoXiLEEJukKhUJwlKEFXKBSKswStnC9W\nX18vly9fXs6XVCgUijnPrl27OqWUDROdV1ZBX758OTt37iznSyoUCsWcRwjRVsx5ynJRKBSKswQl\n6AqFQnGWoARdoVAozhLK6qErFAoFgGmatLe3o+v6bC+logiHw7S0tBAIBKb0eCXoCoWi7LS3t5NI\nJFi+fDlCiNleTkUgpaSrq4v29nZWrFgxpedQlotCoSg7uq5TV1enxDwPIQR1dXXTumpRgq5QKGYF\nJeajme7PpChBF0J8TAixRwjxkhDi4+6xBUKIh4QQB9yvtdNaiUKhmBS/eukUZwaUB60YYkJBF0Js\nAD4IXARsAq4TQqwGbgUellKuAR52bysUijKQsWw+9O1dfP+ZY7O9lDlJV1cXmzdvZvPmzTQ3N7N4\n8eLc7UwmU/TzfOtb3+LUqVMzuNLJUcym6DrgaSllCkAI8Rvg7cBbgNe65+wAHgP+rvRLVCgUI9Gt\nLLaEtJmd7aXMSerq6nj++ecBuO2224jH4/zN3/zNpJ/nW9/6Flu2bKG5ubnUS5wSxVgue4DLhBB1\nQogo8EZgCdAkpTzpnnMKaJqhNSoUihEYpu18texZXsnZx44dO7jooovYvHkzH/7wh7FtG8uyeO97\n38vGjRvZsGEDX/ziF/n+97/P888/z4033jjpyH6mmDBCl1LuE0J8FngQGASeB7IjzpFCCFno8UKI\nW4BbAJYuXTrtBSsUCtDdyNyw5n6E/s8/fYm9J/pL+pznLarik29aP+nH7dmzh3vvvZcnn3wSTdO4\n5ZZb+N73vseqVavo7OzkxRdfBKC3t5eamhruuOMOvvSlL7F58+aSrn+qFLUpKqX8ppRyq5TycqAH\neAU4LYRYCOB+PTPGY++UUm6TUm5raJiwWZhCoSgCT8gzKkIvKb/+9a959tln2bZtG5s3b+Y3v/kN\nra2trF69mpdffpmPfvSj/OpXv6K6unq2l1qQogqLhBCNUsozQoilOP75dmAFcBNwu/v1vhlbpUKh\nGIZ+FlkuU4mkZwopJR/4wAf49Kc/Peq+P/zhDzzwwAN8+ctf5sc//jF33nnnLKxwfIrNQ/+xEGIv\n8FPgf0kpe3GE/GohxAHgKve2QqEoA16E7nnpitJw1VVX8YMf/IDOzk7AyYY5evQoHR0dSCm5/vrr\n+dSnPsXu3bsBSCQSDAwMzOaSh1FUhC6lvKzAsS7gypKvSKFQTIgXoWeyStBLycaNG/nkJz/JVVdd\nhW3bBAIBvva1r+H3+7n55puRUiKE4LOf/SwAf/qnf8qf/dmfEYlEeOaZZwgGg7O6ftXLRaGYg+Qi\n9LNgU3S2ue2224bdfte73sW73vWuUec999xzo47dcMMN3HDDDTO1tEmjSv8VijlILkI/Czx0RelQ\ngq5QzEGGInQl6IohlKArFHOQXJaL2hRV5KEEXaGYg3iFRWpTVJGPEnSFYg7iWS2G6uWiyEMJukIx\nB1ERuqIQStAVijnIUISuBH2q+P1+Nm/ezIYNG7j++utJpVJTfq7HHnuM6667DoD777+f228fu86y\nt7eXr3zlK1N+rfFQgq5QzEGGmnMpQZ8qkUiE559/nj179hAMBvna17427H4pJbY9+Z/vm9/8Zm69\ndezxEErQFQrFMPIrRaUs2OhUMQkuu+wyDh48yJEjRzj33HN53/vex4YNGzh27BgPPvggF198MVu2\nbOH6668nmUwC8Mtf/pK1a9eyZcsWfvKTn+Se65577uEv/uIvADh9+jRve9vb2LRpE5s2beLJJ5/k\n1ltvpbW1lc2bN/OJT3yipP8PVSmqUMxB8itEDcsmHPDP4mqmyQO3wqkXS/uczRvhDcW1l7Isiwce\neIBrrrkGgAMHDrBjxw62b99OZ2cn//Iv/8Kvf/1rYrEYn/3sZ/nc5z7H3/7t3/LBD36QRx55hNWr\nV3PjjTcWfO6PfvSjvOY1r+Hee+8lm82STCa5/fbb2bNnT27ARilREbpCMQfJ986V7TI10uk0mzdv\nZtu2bSxdupSbb74ZgGXLlrF9+3YAnnrqKfbu3cull17K5s2b2bFjB21tbezfv58VK1awZs0ahBC8\n5z3vKfgajzzyCB/60IcAx7Of6ba7KkJXKOYgel664pwv/y8yki41noc+klgslvteSsnVV1/Nd7/7\n3WHnzER0XQpUhK5QzEHyo3LVoGvm2L59O0888QQHDx4EYHBwkFdeeYW1a9dy5MgRWltbAUYJvseV\nV17JV7/6VQCy2Sx9fX0z2nJXCbpCMQc5qyL0CqahoYF77rmHd77znZx//vlcfPHF7N+/n3A4zJ13\n3sm1117Lli1baGxsLPj4L3zhCzz66KNs3LiRrVu3snfvXurq6rj00kvZsGFDyTdFRTl3yLdt2yZ3\n7txZttdTKM5W3nTH47x4vA+ABz52GesWVs3yiibHvn37WLdu3WwvoyIp9LMRQuySUm6b6LEqQlco\n5iC6mSWkOW9ftSmq8ChK0IUQfymEeEkIsUcI8V0hRFgIsUAI8ZAQ4oD7tXamF6tQKBx0K0t1JAAo\ny0UxxISCLoRYDHwU2Cal3AD4gXcAtwIPSynXAA+7txUKRRkwTJsqV9Dn6qaoKogazXR/JsVaLhoQ\nEUJoQBQ4AbwF2OHevwN467RWolAoikY3s1SFnazjuRihh8Nhurq6lKjnIaWkq6uLcDg85eeYMA9d\nSnlcCPHvwFEgDTwopXxQCNEkpTzpnnYKaJryKhQKxaQwrPwIfe4JektLC+3t7XR0dMz2UiqKcDhM\nS0vLlB8/oaC73vhbgBVAL/BDIcSwsigppRRCFPyoFULcAtwCsHTp0ikvVKFQOEgpHUEPz13LJRAI\nsGLFitlexllHMZbLVcBhKWWHlNIEfgJcApwWQiwEcL+eKfRgKeWdUsptUsptDQ0NpVq3QjFtWjuS\nc9Ku8CJytSmqGEkxgn4U2C6EiAohBHAlsA+4H7jJPecm4L6ZWaJCUXoGdJM3fP533Ptc+2wvZdJ4\nfVyqIs4F9ly0XBQzQzEe+tNCiB8BuwELeA64E4gDPxBC3Ay0ATfM5EIVilLSr1tksjZn+o3ZXsqk\n0V2LJWe5qCEXCpeimnNJKT8JfHLEYQMnWlco5hzpjAVA0rBmeSWTxyv79zZF1Rg6hYeqFFXMS1IZ\nRxTnoqB7Fks85FoualC0wkUJumJekk6n+Hnw71nc/dRsL2XSeBF6JOAnpPkwVISucFGCrpiXZJMd\nrPe1sWigxJNyyoAXoYcDfoKaT3noihxK0BXzEjPtzIUMZXpmeSWTx4vQQwEfIc2vslwUOZSgK+Yl\nnqBHrd5ZXsnk8QZEhzXHclF56JVDe0+K374ye9WvStAV85Ks4Qh6zOqb5ZVMHq8y1InQfXOyUvRs\n5e4njvDh7+yetddXgq6Yl9i6I+gJe+4Jen6EHlQRekUxaFgkDQtzljaqlaAr5iV2ZhCAatk/yyuZ\nPF5EHs5F6ErQKwXvdzE4S+mwStAV8xJpOIJeSz/WHLMsvAg9pPndTdG5tf6zGW/DekBXgq5QlA1h\nulkuwmJwYG7ZLp5oRJ+9gxUcU5ZLBaEEXaGYDTKp3Lfp/oKNQisWw7IJkSHw6D9zafo3ynKpILzf\nxYBuzsrrK0FXzEt85pCgG71zTNDNLLVaBoCoMJSgVxAqQlcoZgF/dkjQMwNza2qObmap0RzBiKIr\ny6WC8D5cZ6tHkBJ0xbzEbw0JejbZOYsrmTyGZVOjOW1/w1JXm6IVxFCEriwXhaJsBKwU3VQDIAfn\nXoRe7XcEI6Ii9IrCy0AaUBG6QlE+ArZOj7+OjPRDqnu2lzMpDMumyvXQQ7auPPQKYqF5lDf7nlQe\nukJRToJ2iqwWpYcE/nTXbC9nUuhmloTPidBDUgl6JfE26wFuD9xVuZaLEOJcIcTzef/6hRAfF0Is\nEEI8JIQ44H6tLceCFYpSELJ1ZCBKt6xC0+dWhK6bNgmf46GH7DRZW2KpnugVQUjqRIVBKq3PyutP\nKOhSypellJullJuBrUAKuBe4FXhYSrkGeNi9rVDMCcJSxw7E6CVBcI610DWsLHFX0AO2IxxqDN3s\nk7UlIen8PqzU7BSrTdZyuRJolVK2AW8BdrjHdwBvLeXCFIqZwrYlYXRsLUq/v5rwHBN03bSJC8dD\nD9pOto4acjH7GFaWMM7vxdZnp0fQZAX9HcB33e+bpJQn3e9PAU0lW5VCMYMYlk0Ux3IZ9NfMuZ7o\nhpUl6kboWjYNqAi9EjBMmyjO74VKF3QhRBB4M/DDkfdJKSUgx3jcLUKInUKInR0dcys9THF2kspY\nxDCQwRgprYaonYTs7GxiTQU9Tzi0rI7AVhF6BaBbWSLCFXSjwgUdeAOwW0p52r19WgixEMD9WrB+\nWkp5p5Rym5RyW0NDw/RWq1CUgJRuEBImIhjDCNa4B+fOxqhhZYnieLUCSZgMmawqLpptdNMm4lou\nfnNgVtYwGUF/J0N2C8D9wE3u9zcB95VqUQrFTJJJOW82EYyTCS1wDqbmTuqiYdpEvEt7IIqRK2hR\nzB6Oh+78XvxmEse4KC9FCboQIgZcDfwk7/DtwNVCiAPAVe5thaLi0VNO61xfOIaVE/S5U/6vW1nC\ncigtLipULnoloJs2UddyicnUrHzIasWcJKUcBOpGHOvCyXpRKOYUmbTjb/pDcbIR9896jkToWVti\nZofS48CJ0FX5/+xjmNmc5ZIgxYBuEgn6y7oGVSmqmHeY7jxRLRxHxFxBH5wbEXpuQHSeoMdQDboq\nAd2yc5ZLQqTpn4XyfyXoinmHlXYEPRBJ4IvWA5AdnBsRem78nJ0GLQxARKgIvRIwDJ2gcD5YE6Rm\npYWuEnTFvCOrO5uiwUiCaDRMv4xizZGe6F4kHsimIdYIOJaL8tBnH8sYaskcF+lZ6eeiBF0x78i6\nA6IDkTjxkJ8umZgzPdG9CD1g6xB30oCjqE3RSsDSB3PfJ0iTVJaLQjHzSMOxXMKxKuKhAD0kkHPE\nQ/cGKGjZNMRcQVeWS0VgG3mCLlKz0kK3qCwXheJsQmacN144WkUsJOmSVYg50kLXi8T9+YKuNkUr\ngmGCTpp+ZbkoFGXAFXRfKEYirNEjE/jTc6NSVDezCGw0K5Un6MpDrwSyGcdDl9F6EkJtiioUZUGY\ng9gICESIhTS6qUIzumEWKvsmi2HZuY5+hKuQ/pCyXCoEabqbookmEqRnxXJRgq6Yd/jMNDohEIJY\nUKNbxvHbJhiz039jMuhmdqijXyCGCEaJCUNZLpWAe+Un4k3ERJpkWlkuCsWM47cGSYsIAImwE6ED\nc6JaVDfzOvoFYxCIkfCpCL0SkBmnlTGJhWjYZPTyBwhK0BXzDr+VxnAFPRbS6JYJ5445IOiGZRNz\nOy0SjEIwRlwoD70SEJYr6HFnNISVLn8LXSXoinmHlk2R8TlVlgG/jwFftXPHXBD0EZYLnuWiui3O\nOsLz0F1Bl+nyj6FTgq6YdwTsNBl/JHc7E3Tnm8+BXHTdtPMslygE486mqJpYNOv4vAg94Qr6LAy5\nUIKumHeE7DRWvqCH505PdGe4hRehRyEQddMW1abobOOzXCvMjdD9GeWhKxQzjiPo0dxtEUxgoc2J\nnui6aRPLRehxCEaJqPa5FYE/m8IgBGHHwlOCrlCUgZA0yGpDEXo8EqDfVz1nIvRqv5uH7m6KRkir\nTdEKQMvqZHwhCDlZU4HsIFaZrTAl6Ip5R0SmsQOx3O14SKNPJGAOtNDVTZuEJ+iBKARihKXaFK0E\nNFsnI8IQcrKmEqQYNMprhRU7gq5GCPEjIcR+IcQ+IcTFQogFQoiHhBAH3K+1M71YhWK62LYkgoEc\nIejdsmpOROi6mSXh8yL0GARjhGUaQ22KzjoBW8f05wm6KH8/l2Ij9C8Av5RSrgU2AfuAW4GHpZRr\ngIfd2wpFRZM2MkREBhkY8tBjIY0umZgTHrph2cR9Bvg08AchGEUjSzajT/xgxYwStHUsXxh8fiwt\n6rTQLXM/lwkFXQhRDVwOfBNASpmRUvYCbwF2uKftAN46U4tUKEqFnnI2qkRoKEJPhDXOZONzJkKP\ni4yTgy6E85W8lDnFrBG0DSy/U9+QDVS5c0UrTNCBFUAHcLcQ4jkhxDeEEDGgSUp50j3nFNA0U4tU\nKEpFTtCDQ4IeC2p0ZOOg90G2/P03JoNh2cR8hrMhCo7tAvit1DiPUpSDoNRz6bAyFJ+VqUXFCLoG\nbAG+KqW8ABhkhL0ipZRAwVZ1QohbhBA7hRA7OzrmxpgvxdmLMegUe/hdnxMgHtboyvVzqew2urnm\nXIHhgu5Tgj7rhKWB7WVPhapmZa5oMYLeDrRLKZ92b/8IR+BPCyEWArhfzxR6sJTyTinlNinltoaG\nhlKsWaGYMqbuTCvyhYc89HjIn9fPpbJ9dN2yHUEfEaEHskrQZxMzaxPGwHYjdBGudjdFK0zQpZSn\ngGNCiHPdQ1cCe4H7gZvcYzcB983IChWKEpJJO5aLlh+hu2PogIr30Q0zSwTdKSqCXKSuKQ99VjEs\n291sdwTdH3Ej9DILerEj6D4CfEcIEQQOAX+K82HwAyHEzUAbcMPMLFGhKB1W2onQA5EhQY+F/HRJ\n13Kp8H4uhmU7gh6ocw64Ebpmp5FSIoSYxdXNX3QzSxgDqTkfsP6IE6GX20MvStCllM8D2wrcdWVp\nl6NQzCxZ13IJROO5Y94YOmBOROgh9FGWSwwDMysJakrQZwPDzFKDAQHPcqlyBb3CLBeF4mwiaziC\nHoxU5Y7FQho9uAJf4YKuWzYhW8+lK3qWS1SoQdGziW7oaMIe+qANVRHBIKWXtz5ACbpiXiHdyezh\nvAg9HtKw0MholV8tqptZgjI/Qnf+H2pQ9OySca084f1ewk7AYKXK2xNdCbpiXiEzzhsvEqvOHYuH\nHOcxHayZEx560E7nrBZP2KOq4+KsYunuPNFchO5YeNkyTy1Sgq6YX5gpbCkIRfIKi1xBT/lrKjpC\nN7M20s4SsI0hy0ULIxFEhK4i9FnES4f1ex+0bsdFqStBVyiG0Zc2efClUyV5LpEZJE0Qn9+fOxbw\n+whpPgb8ld1CVzezRMibVgQgBJYWJaYi9FnFMpw6AF9oeIQuMkrQFYph/HDnMW75v7voHsxM+7l8\n5iBpERl1PBHW6PdVtodueEVFMFQpCthalAhqU3Q2sd0IXfN6BLkeermHXChBV1Q8ZwYcESuFoPut\nNIYIjToeC2n0UuV46LJgF4tZRzezefNEhzZ17YA7KFpF6LNG1o3QtbBnubhTi8wksox/T0rQFRVP\npyvofekSCHo2hV4gQo8FNaf83zbBKP/osGIYFqEHh0foalN0drFNR9ADEfeD1rVcojJV1g9aJeiK\niqcj6Qn69KvutGwa0xcedTwe1uiwK7ufi9OYy81rzhvQIYMxospymVVsN0IPjLBcEpR3yIUSdEXF\n05l0IvPe1PTfGMFsikzegGiPeMhtoQsV23FRN22iYnSETiBKVKgIHSBpWJzqK/+wD5lxBD3oReha\nGFtoJER5e6IrQVdUPJ0ljNADto7pG225xEMapyw3uqrQXHTDyo/Q8wQ9GCOiCosA+MKvX+GPv/pk\n+V/YtVxCnqALgRWIl71BlxJ0RUVj2zK3GVqKCD1kp8lqoyP0WEjjpOkKeoVmuhimnZe2OLQpKoIx\nYuhqUDRwqt/geG+6JB/+k8J0ul3mNkUBO1jlDrlQgq5QANCTypC1nSyBUrxJIzKNVUDQE2GN9ox7\nvEI9dMPKEitgufhCMSLCUIOigaTrVx/pHCzr6+YGjGhD+zMylHCHXCgPXaEAoCsvVbEUgh7GGDYg\n2iMW1Ogyg0h/sGIjdN10W+fCMMvFF4q7EbraFPUmBB3pKq+gCytNmpAz59U75nZcLOeQCyXoiorG\nS1mEEgi67VgWdoEIPR7WAIGM1MFgpQp6Ni9tcejS3h+KEREZDLO8rVorEc/eONRR7ghdR2d4fYM/\nXEUCZbkoFDm8lMWmqhC9qenloWczzptc5omhRzzktAKwwgsqNkI3LCfLRfoC4A/kjvtCjp/uZVrM\nZ2YrQteyKQwxPB3WH61Wm6IKRT5eyuKqhvi0I3TdHRAtCgq6I5BmqLZiPfRcL5cR6/e5uc9ea+D5\nzKAr6IfL7KH7LZ3MiApkX7j8U4uKEnQhxBEhxItCiOeFEDvdYwuEEA8JIQ64X2tndqmK+Uhn0kDz\nCZbVRUsn6KH4qPtiboRuBKoh3TOt15kpdNMmlj+tyMMrMjLnt6BLKXMR+uHOwbKW3Gu2jjGyYC2U\nIC5SuY3acjCZCP0KKeVmKaU3iu5W4GEp5RrgYfe2QlFSOgcM6uJBaqJB+tLmtN6kmZTTQMmLaPNJ\nhJ0WurpWuYLuZbmIwIj1exG72+t9vmJYNmZW0pAIMaBbwzbUZxrN1kdXIIer0LDR0+X7oJ2O5fIW\nYIf7/Q7grdNfjkIxnK7BDPXxENWRAGZWkspMPZMj4w4b0MKFInS3J7pW5Qi6XXkpgLppE/dlRkfo\n3m1zfnvoXnR+/mKnMVY5bZegrWMViNABrHRv2dZRrKBL4NdCiF1CiFvcY01SypPu96eAppKvTjHv\n6Uwa1MdD1EQcj3s6tkvGa3FaQNC9qUVJkQBpQ5nbnhZDLg89OGL9bsTuc4tb5ive5uOG2RJ0/0hB\nd6dilXHIRbGC/mop5WbgDcD/EkJcnn+ndK6DC14LCyFuEULsFELs7OjomN5qFfOOzgEjF6HD9KpF\ns2lP0BOj7vMEvV9Ubj8X3bQdQR+ZRx/0BH1+e+hehL62OUHAL8or6NLA8o9oKeFG6LKM3TuLEnQp\n5XH36xngXuAi4LQQYiGA+/XMGI+9U0q5TUq5raGhoTSrVswLpJR0JjPUJ4JUR6cfoVtuhB6MjhZ0\nz3Lpw72vAn103XL7oY+yXBxB91vKcgGojgZYsiBa1mrRsNSxR0bo3pALo4IidCFETAiR8L4HXgfs\nAe4HbnJPuwm4b6YWqZif9OsWmaxNfWwoQp9OT3TbcAQ9FB1tuXhj6Hqku8FYgYJumDYRaQxrnQsM\nCXp2ngu6a7kkQgFW1sfKGqGHMLC1kRG6I+i+Mm5Wa0Wc0wTcK5ySVg34bynlL4UQzwI/EELcDLQB\nN8zcMhXzEa/LYn3CyXKB6UXoQ4JeXfD+RFijy65gQbeyTun/qLRF57bfmuceuhuhx0J+ltfFePxg\nJ7Yt8fnEBI+cJlISlgb2SCvMtVwC2SRZW+Kf6XVQhKBLKQ8Bmwoc7wKunIlFKRQwVPZfKg8dt1I0\nXCBCB8d26cxWsKCbNiGpjyos8m4HsvNb0AdcQY+HNVY0xNBNm1P9OotqRrdLLiXSMvALiRwZobuW\nSxUpkoaV+xueSVSlqKJi8fKI6+MhYkE/mk/QO53ioswgKRkiGir8xoqHNDpM901ZgYKeMTMEMUdb\nLj4/GREkoCwXgpgk7EFW1Dk/o3LYLl72FIERgh50IvQ45asWVYKuqFhylks8hBCC6khgetWiZooU\nIUJa4T/7WEijL4PzRqxAQc9Vgo60XICML0zALv+knkoiaZj8ZeDHhO+5khUN5RN0I+W+xkjLxa9h\n+aMkRCpnB800StAVU6IvZXLBpx7k960z18iqc8BACFgQc/zz6miAvmlYLn4zRZowQhT2MhMhzXnj\nRWorMm0xl2deoP1vxhclZM9vy2XQyLLafxrRc5gm0Uc44CuLoJtehF7ggzYbTLgRuhJ0RQVzrCdF\nT8pk/6mZS8nqSGZYEA3mNpNqphmh+7IpdDF6QLRHLKQ5zZ2itRUZofssL0If3brA9IcJzvMIfUC3\nqBNue4fTe1heFytL6qLp1jf4Cgi6DMbduaLKclFUMN7m5EyO+vKqRBk4Dc9+k+pIgN5ppC1qVmp0\nA6U84uG8CL0SBd2L0AsIuuWLEJbzO0JPGiYLhFvEc+oFVpQpddHUndfwFfi9UOae6ErQFVOiJ1W6\nOZ9j0Zk0qE8EYfcO+PlfsTzQO60PEM1KkfGNjqI84vmWS7ryLBfN2/QsYLlYWtTJgJnHJA2LajxB\nf5EV9TGOdqewZng0n+W2LfaHRv9evKlFStAVFY2XbdJfjgi98wAALb6uaX2ABGydzDgReiyooZs2\ndrjyInQpJVp27Ag9648405js8rWMrTSSaZOE7VqAp15keX0My5a098zslUtW9wR99O/FH3GHXKhN\nUUUl0+umFE4rjXACupJOp0W6HEFfSAcDupUbGj1ZgnYKyz9OhO620M0Eayqu42Im64zPAwpG6NlA\njCg6mQLR6OHOQd79jafoL2Nf7tnANvrRyEK4BrpaWe3Wjx2e4elFWXdSlDaGoMfLOORCCbpiSvS4\nkfJ0x8KNRSpjkcpkqY8FofMgAI2209xtqlcFIVsfX9BzQy6qKq7jom7aBeeJethalKgwMMzRgv70\noS6eONjFnva+mV7mrKIZ7lXVissByUr7CACHZ3i+qO1aLoHI6II1EaqiSqSU5aKobDwhn6lN0c4B\n5/kXB/pzwrrAOj2t1wxLnezI4o88vDF0Kb8b2lVQ6qJhZokJ1yMvJOiBKFF0DGt0v3gvn7+t++wu\nPAoZbt/xla8FoLpvP4mwNuMbo7YXoYcLBAvhKqIYpNLl2d9Qgq6YEj0zLOjecOgl9vHcsSrDEfQp\n2Ty2TQQdWyuQieDijaEb9FVex0XDGt9ykYEoUQwMs5CgO7+rtq6zV9CztiRsuVcgzRshsgBx6kVW\n1sdmfGAYG6uzAAAgAElEQVS0dAeLhAr02ff6uWRS5bnaU4KumBKeqE53LNxYeFFlQ+aYc6B5I7H0\nydxrThq3cZUsIIYe3hi6gQoUdN3Mjmu5EIiiCRsjMzoS9D4cj3afvf3SBzMWtV6GS7TOEfVTf2B5\nfYxDM2y5kEmRlYJQoQjd7bgo9fJMLVKCrpgSXrbJdMfCjYUn6DWpI6CFYcl2gqkT7mtPwbd3G3PJ\nQmLo4vVE78eNtCpI0A3LJiIMsr4g+Pyj7hfuFCNviEc+XpOzszlCT+rWUA56dIEj6Kf3srIuxIm+\nNHqBK5eSYaZJEyIUGP178Rp02bqK0BUVTE8qk+uJMhO2i+ehR/sPw4JVULMUf2aABKkpbYp6wy3E\nOILuTS3qlZUn6F6Ebo9szOXi/b/MAsLhfTge7UrNyNVUJZA0LGpEElv4ndFvzedD1mBj6AxSwtEZ\n3D8QZoo0QcKFBN21XESZhlwoQVdMmqwt6UubLKtzLjFnorioa9CgOhLA130Q6ldDzRIAFovOKb2e\nkXLeUMUIerftXjpXlKDbxIQ+eoiCi3BT5rJ6gQg9mUHzCQYMK5eddLaRNCwWMIAVrAafDxaeD8Bq\n+zAws026hJVGl2M0fXPnivpNFaErKpQB3URKWOa2KJ2RCD1p0BwT0NMGdWug2hH0FYHuKb2e4W5K\n+UKFe6HDkOUyYAqn42IlZblYWSIYY+4B+DxBN4YLV8ay6UubrF/kXPq3zfAG4WyR1C1qxQDZ8ALn\nQN0a8IdoSr0CzKyg+6w0aREqPEjDjdD9mWRZro6UoCsmjRflLXcj9OmMhRuLzoEM6yI9ILNQvwaq\nWwBYGeyZUpaLl2WghceO0L0xdJXYoMvLQ5djWC5+94PKm8rk0e0WgG1ZVgvMrPUwmyQNi1qSyKgr\n6H4Nms4j1PES9fHgjDbp8mfTGCJU+E7XQ4/KQQxr5gvVihZ0IYRfCPGcEOJn7u0FQoiHhBAH3K+1\nM7dMRSXhpSzOdIS+Tjvl3KhbA7FG8AdZ6p9ahG653rI/PHpAdD6JsOZMvqmwBl266QyIFgU6+gH4\n3aIWOSJC70waCGxeU+X8LM/WjVEvQheeoIPjo596keULohyaYUHPMEZLiVD+kIuZLy6aTIT+MWBf\n3u1bgYellGuAh93binmAl2Wyoj7m3i69oHckDVYIJ02RulWOL1q1mBbROaWe6F5HvELVfPnkWuhW\nmKAblk2UAuPnXDQvQs8MF66OpMHrfTt57aNv59L46bNW0AcMJ8vFH6sfOti8EdLdbK5JzajlomX1\nsbt4BqLYwl+2FrpFCboQogW4FvhG3uG3ADvc73cAby3t0hSVSm/KRGCz7uA3aPQNlDxC180sA7rF\n4mw7xBogUuPcUd1CE51Tej0vnS8YqRr3vHhIc6bHRxZUVMdFL8ulYItWQPM+qEYIeueAwXrfEQBe\nG209a3PRk2mTGgbQ4vmC7myMXhA4RseAMWMNsjRbx/SNYbkIgRVwhlyUo0FXsRH654G/BfJNoCYp\npRtCcQpoKuXCFJVLT8pktTjBgqf+lbeFd5a8QZc3S7Qh0+7YLR41S6m3zkypJ7qdcQQ9FB3fcomF\nKtNyMSybqDBym58jCUbc/9dIQU9mWC2catvNvtazNkI39X6CIosvVjd0sGk9IFgjnUyXmfLRg1kd\nc5wunnYwXrYWuhMKuhDiOuCMlHLXWOdIZ/u24BauEOIWIcROIcTOjo6Oqa9UUTH0pjIsEs7ouUVa\nf8kj9K78oqL61UN3VLdQZXUxmJ58O1RvszA4geVSFws6G4meoFdIx0UnQtcLtmiFIStJmKM99HN8\nTkHWqsx+zgwYpGegEGy2sQfdUYjRPEEPxaFuFU0pp1vnsRnaEA5IHcs/do8gX7iaNdU2NdHCw8lL\nSTER+qXAm4UQR4DvAX8khPg2cFoIsRDA/Xqm0IOllHdKKbdJKbc1NDSUaNmK2aQnlWFlyOmbsdDX\nP605n4XoTBpUkSRodA+P0Ktb8GFTY3VNuvJPGoOkZZBoODjueU1VYU73646gSxvKVBAyEbqbtjhW\nHn0oFMGSPoQ5XLR6BgZZJk6BFqE2dYQEqbMy00V4Kab5m6IAzRuJ9+wF4HjvzPRFD0oDyz92hB6M\nVrOxzsf6RdUz8vr5TCjoUsq/l1K2SCmXA+8AHpFSvge4H7jJPe0m4L4ZW6WiouhJmSwNOILeIKY3\nRagQnQMZVnkbovX5gu7koi+aio9uDpIiRDRYoJovj8aqEAO6hRF033wVYrtYhkFQZCFY+ApD8/tI\nEcJnDRctf+8Rp0f4eW9GIDnf13pW5qL79QIROkDzRvx9bTQH9ZkZdCElIWlgjxOhE64Cozyti6eT\nh347cLUQ4gBwlXtbMQ/oS5ks9jlCVyv7pjXnsxDDM1zyLRdX0EXXpAVdmClSMkxkAkFvrnIirZ4K\nK//PZa+MkbYohCBNGL81XKzjA4ecbza9A4DNovWsjNA1r3XuKEHfBMCliVMzE6FbOj4ktjZ2hE6o\nCowKrBSVUj4mpbzO/b5LSnmllHKNlPIqKWXlpAQoZpSeVIYm4fy6a+zuGbFczg2cBp8GtcuH7qhe\nDEyt/N9npkgRIugf/0++yRX0zmyFlf97gj5Ot0hdhPGPiNDr9CPONy0XQt0aLgycnRujQW+4RWRE\nOUzzRgAuCLZzYiYE3R3cbWtj/14IJUBXvVwUFUpvyqTBdi5x42Y3/bo55bFwhehMZjhXO+WIuT9v\nIykQwQrXsVhM3nLxWyl0EUGIAuXZeTRVOelnp83KEnTpbXaO04tGJ4xmDYl11pYsMo8yEGx0RKVl\nG5tEK0c6R/d7metErF5sfM74uXwSTRBrZB1HZiZC97p4jjM4xbFc+kGV/isqkZ5UhppsJwgfmsxQ\nRWmLJjoHXMslf0PUJVvVwiLRNekWun4rNXbxRx6NboR+3HDPrRBBJzP2gGgP3RceGiSNU/a/Spxg\nILHSObB4K7WyF6OrbSZXOitErT5SWpVTgDaS5o0sNVvpTZlO0VgpcSN0OUbTNMD5MLUtsGZ+apES\n9HnKmX6dzZ96kGcOT84pM6ws2UyaqNUH9ecAzsZoKatFe5IpFmWPD09ZdPHVLJlShB7Ipsj4xnnT\nuSRCGtGgn2Mpt1CkQgQ9542PY7kYIkzAHhL0zgGdVeIERo37c2zZBkDzwB6sAsOk5ypSSuJ2P4ZW\nU/iEhedTN9hKAKv0UbqbVSTH2NsAckMuymG7KEGfp/z+UBe9KZPnjk5OsPpSJk3CfcyiCwBoEH0l\nzXTxJ08SkObwDVEXrXYJi0QnfZOM0APZdFGCLoSgqSrMyaTlvBErpONiLh1xnAg944sQyIvQB860\nERd67oOXpg1YvhAbOciJ3vLMuCwHhmVTIwcwgmMIevNGfNJijWjneIkzXbx5or5xPmgJuxlTZdgY\nVYI+T9l5xBHlyUYsPSmTZlyRW7gZgAZ6S1YtamVt6nXXEihguYiapcSEQSY5OaEN2uMXf+TTmAi5\nueg1FROh+zxvfBzhyPgiBO0hoTZP7wcguHCdc8AfIFW3gc2+g7RVQguAVDdkp/934wy3GMAKj9Ef\nsMnZGF0njtJe4gjdzA1OmWBTFMqSuqgEfZ6yq80Rqsnu/PekMjS7GS4scgW9hBF692BmKGWxfrSg\ne210/f3tk3rekExjjZeJkEdzdZjT/UZFlf/nslfGEQ7THyGUZ7n4Op1e4ImW9UPHWrayURzmaEd5\n8qLHxM7Cly+CB/522k/ljZ+zwwsKn1C3CqlFWO8/WvII3XKbvo3VYwdQlotiZkkaFvtPOX9cky22\n6E2ZQ4LeeB7SF3CKi6Yy57MAHUmDleIkZiDhNOYaiSvowcETxT+plISkTna8jas8vGpRGamtmAZd\nuc3OMQqLACx/hJAcitBDfQfplTESCxbmjkVXvIqwMNGPvzhjay2KM/tgsAN2/xf0HJnWUyV1kxqS\nyMgYgu7zIxrXsSlwrOQeutfFc6yWDIAzbWvbzRCf+XZXStDnIc8f7cWWTvvbyf6B96YyLBTd2MG4\nk44Va6BB9JVsU7QzmWGlOIFRvRIKpRjWLAUgqp8cfd9YmGm3+GOcN10ejYkQhmVjBivHcsl54+NY\nLpY/SoiME/0CVcnDHPW1IPIyP3xLnI3R8OnnZ26xxXB8p/NV2vDbf5vWU6UG+wgJCxEbQ9ABmjdw\nDm0cL7HV5E2I8o1nudQshes+B03nlfS1C6EEfR6yq60HIeC68xcyoFv0TyLlsMfbFE0sAkAkmmjy\nlc5y6RwwWOE7hSzgnwMQrSMjglQZp4p/0lyucHGC7hUXDfqqKkfQ7YkFPetZSu7/t0E/wqngsuEn\n1Syj31dDQ/8sR+jtOx1L68IPwvPfhe5DU36qTJ/T9M+f3zp3JE0bSdj9ZHqPT/l1CpE1nL2N8SZh\nlRMl6POQnW3dnNuU4NxmZ7NmMr5ibyrDQl8PotoRdOKOoJdqU7Svv5fFootA4xiCLgR9wSYWmKeL\nf1Jz/LL5kTRXO4I+IOIV03ExmE07PbcL5Vm75CwlMwWpbqrtXrqjy4efJAQn4+tZZeyfkRmXxgP/\niHHP2yY+8fguWLwNLvsrp3jst/8+5de0kk6RW2A8QW/eAEBD6gCZEo6C8yJ0bTzLpYwoQZ9nZG3J\n80d72bqslsU1jgBMTtBNFoluRJVThk+8kXpKF6Hbna0AhJrOHfOcwfBCGuwO7GKrUzMTV1nm05Rw\nBL1bxiui46JtO3sA5gRpl8MidHdDdDCxatR5gw2bWcEJuro6S7vQvuP4n/4qoSOPQLJg81UHvd/x\n0Fu2QaLZ8Zdf+C50tU7pZbODzv8jWDVON9cmZ2N4HUc51Ve6lE07k8KSPkKhiYvWyoES9HnGK6cH\nGDAsR9BrXUGfhI/eO5imnh5IuBtt8SZqZB/9g6V5kwR7nTe1KJTh4qJHF7FIdJLMFFf1Z7mpZeNm\nIuTR6Jb/d1qVUf7vDbeYKEtHBoYEXXa8DIC54JxR5/latuITku4Dvy/pOgce/Q80nN9J90sPj33i\niecA6UToAK/+OPhD8Jv/b0qvK91e6NHqxrFPClejx1pY52ujvbd0vWxkZpA0IcITNH0rF0rQzzJ+\nsrudR/ePHR156Yrbli2gPhYiqPkmtzGa7MCPDVVDlosPG1Jd01l2jtjAYWyEM0d0DKzEYppEL339\nxfUkMdJOQYcIjT/cwiMc8FMdCXDKdCPiWRd0Z/xcdqI8eu8DKzOIcXIfugwQrFs66rSq1dsBMNue\nLd0ik2cI/+Hb/Dh7Gf0yysDeX499rrchuniL8zXeCBfeDC/+ADoPTPqlfbrz+wlVjz9vwW5czzpR\n4tRFM02aECFNCbpiBvi3X73MP9z74pil3bvbeqiPh1iyIIKv/WmWVgcm9QeupdzNyJygO1FRIF2a\naVTx5BF6tEYYp9mRdFMX011Hi3pOM+UIuj9cnKCD00a33fAEfXZTF3XTGRCdnTBCdwRdZgbJntnP\nIbmIusTon+Pihc202gsJnyldpkv2yS/hs02eWfIBnuE8EiefHPvk9p1OFXD+MIpLPw5aeEpRul/v\nJotAjGzMNYJgy/msECc51VXCD2gzRVoGCQcqQ0orYxWKkmBYWU7165zs03lkjCh9Z1sPW5fVIE6+\nAN96PX8cfHpS1XORtLsZmWe5AISNcfzY5Bn4ww8m7DZ3sqOLTdkXGawZ2z8H0GqdqDNTpKBn3AHR\ngQnGz+XTWBXiaNrr59Jb9ONmAt3MEhEG9ngd/QDhWi5ZYxB/90EOykU0xEcPLw5pfl7WzqWhb0/B\n38mkN0tT3chn7uLn2Vfxhte8mvbqbSzInICeAk3ApHQE3bNbPOINcOGfwZ4fgWsXFUvA6KGfxLgb\nxgDawvPxC4l9eu+knn9czJRjuQRUhF4+rAwMlsYSyNF7FP5zA5x8obTPOw1O9Oq59+e3nx4tdmcG\ndI52p9i2bAEcdC6J1/uKvwSVUpIw3Q+KvE1RgOpsz9hj4XbeDT/5IOy7f9zn7330DppFD+arPjLu\neZ6NYPUcG33nwYfh/o/A994N33oDfOki6n7zDwBo4apxnzefpqowh5Nu695Zt1xsohjIifLo3UyL\nbLKDULKdg/Zi6hOFp9GfTKynKtsNfUM/w1TG4gP3PMv7vvXM5Bb49NfRrBQ/id3I5WsakCte46z7\n4GOjz+07BoNnco3ChnHpx0CLTDpKD2Z6SfrGH/4N5DZGI937JvX84+GzPMulMqS0MlYx0/zir+Er\n20vSNyLHK79y/jif/+7E557eC8/cVbrXHgNvCO4lq+r47Ssdo6ac725zIs0ty2qh9VEAltpH6Uwa\nRc3oHMxkaZRdZIU2NBkm5gh6g+ilf6xMly7XF/3lP4yaSj/05J2s3P91HpbbWLrlqnHXEat3cqt9\nfSMEvasVvvcu2Hufk9fs80PjWrpXvInbzPfhr2qe8P/o0VQVonXQnT86y4LuDYget6MfQ5u+8sQL\nCCQH5SLqYoVnqA7WO43VaHf87KRh8f67n+WR/Wf43YHO3KDuiRfXT/apr/JgdivbL74cn0+wfO1W\nOmQ1/S8V8NHbXd++kKDH6uH865331iSuEiJWL0l/EfM6a1egiwh1ycn79GMhrDRpGSRUIRG6NtEJ\nQogw8Fsg5J7/IynlJ4UQC4DvA8uBI8ANUsqy/eVbXUcYuPuPeWTdv9CdGPsSPZE6xg3PfQefzMKx\np2H5q0uzgDbXI9z/c7jmXwtXNboYD95GqPVXcP4NQ53XZoBjPSk+qe3gdYu2cvnhjfz3M0f5hzeu\ny92/q62boOZjQ4PP+VkAjWmnoONEb5qVDeNbEj2DGZpED+lwE3Hv8jYUx/JHabCcXHSvn3g+VscB\nrEgz4f52J9/4qk+OfvLf/huarfPzxv+HKyeYKlSdiHNa1qAl84pEbBvu/whZX5Cdb/gFF52/PjfM\nYv+BDu554RmuDU34556juSpMxvZhBxP4Zrnjom5maRYGTFAY5XP3CPynHG/8sGihNlpY0AOLNtBz\nME71w//CYONWbvpROy+09/HBy1Zw1+8O89Shbq49f2HBxw5j5zfxG318Xb6dO7c6extbli3gMXs9\nV514whHm/PdG+y7HK2/aUPDpjgWWsyQz4LQFiI+TtZJH1OqnO1jEWn0+OmOrWdJ/CNuW+HzjDzsp\nBr+VJk1kTkXoBvBHUspNwGbgGiHEduBW4GEp5RrgYfd22Tjw+/upTR5k0VOf4jO/2MtnfrGv4D8e\n/xym7SMj/Qzu+UVpXlxKaHsCggnoOwqnxqm6S/fiP+SkcGVO7inN649Be3eK6/2/ZdFLd3LNunp+\nuPPYsMh7V1sP5y+uJtT+FNgmrHgNUf0UcVJFZbr0up0WzejwnhRmpH7sYdFSku04wPcHNjJw7vXw\n5B3QeXD4OV2tyGe/wfezV7Bo9aYJ1xEO+DhJPZFUXvn/zm9C2xPcbr+XG7/bxnV3PM4v95zEtiWp\njPMziEwiivI+mKwKKP83LJsIxoSFUV75uda5FxsffZGlY4rWkoZqbs78DXbyNMmvvY7O4618+V0X\n8HfXrCUe0niytYgc9UwK+eSXeEJuYsmGS6lz/frqaICDsS3EMl2j/fDjO50unXmTqKSUPHmwk3fc\n+Xv+8bfu3+EkctITdh9GoLhAabB2LWtFGx0DpUmz9Wd1dIJzR9Clg5cfFnD/SeAtwA73+A7grTOy\nwjHIHNsNwMX+vex7j2TPP79+1L+X/nIdNwYfZ3Dje3jGXou+94HSvHhXKyRPw6s/BsLnROljYO/7\nGZp0cnN7D89s/4zkmSPERRqR6uRDK07RkzL5xYuO6Olmlj3H+9m6rBZaH3G8yq3vB2C1OFFU18Xe\ntNNp0XbL/j3sWCMNjNHPZbCDUHaQw3Ih9zf+uZO98sAnhl9SP/JpbF+Q/zT/2FnfBAgh6PQ1EPf6\nufQcgYc+SWfzZdyVvIT3bF/KoGHx59/ezRu+8DsefMnZyI1OIlfYK//XA7Nf/q9nLKIY+CaoRgwF\nA6RlEGFbnNEWUp0Y+4pr2YIYu+U5vNf8B2LZfn5V81muWZxB8/u4cHktv28tYs9p938hUp18PvMW\n3rN9eIsBa9nlANiHHss7mIETz+fsFiklj718hj/52u951zee5lDHIFWL1wJgnH5l4td3noQq2U8m\nOPHfDYBs2kCVSHGm/eDEJxeBltUxRHjC0YbloqhrUCGEH9gFrAa+LKV8WgjRJKX0QqRTwMy3Essj\n0fMSL/rXs7HWJPLobbDumuHzJwGe+SIIHwte97e0tX+eV/d+HavrCFrd8um9eNvjztfz3goHH3EE\n/Yq/L3hqcvcP6LMbqBKDGEV0uPvK9+/nt20GZ3zDc2pXNsS5631bx/3DCXQNRUPrex9jZf2b+fZT\nbbx9Swt7jveRydqOYD76CCy/FBY60fC5vuIa//cMZtgqejCqhwu6iDfRIJ7jeKEI3Y20DsuFHDyc\n5d1X/L/wy7+DfT+F897seLgv3cuupR+k45UaLlg6fupZbi2BJqrNXa7V8lEQPj7j+3OaqyLc9iZn\n8+tnfzjJlx49yI93O612I5MQ9Oa8fi5V00xb3HOsk+/c9wv+7Ma3s2oCW6sQhqGjCRsxTqdFcLJX\nBgkTIUObbwn18cJ2C8DSOiea322t5MB1/83Wx94Pd78R3v9TLllVz6Mv7+NUn55rgzAKU0c+8QX2\naBsYqLlw1AfxyjXncXRfAwtefoT49j93Dp7eA1kDFm/FtiU33f0MvzvQyaLqMJ9+y3qu37aEh/Yc\nJ/M/fpIn9lN4O3cEmUGCWGP3Qh9BpGUz7ITUsRdg/cZR99/7XDt3PHLQCVnzHxf0c9f7trGoZnim\nkWbrZIoYbVguirpOkFJmpZSbgRbgIiHEhhH3S0b9CByEELcIIXYKIXZ2dJQmV1laBi2ZQ3TVbISr\nPwVdB2HXPcNP6j0Gz30btrwPqhax5FVOf4lXHv/x9Bdw5AlnM7BuNay9Fk6/WLgFaKqb2PHH+Zm9\nnf1yKYHO8dOlpJS8de9f8h/pf2TLwgDrF1ezfnE1VZEAv953mo6B8TeqqgbcqGPlaxH7fsq7L1rM\n7qO97D3RP1RQVJtyysJX/ZEzhFkLsyl8sqjUxVR/F1FhEKhZPOy4v7rZHUNXoIVul7Omw7KZpw93\nkdz0fsc//ZW7Qfrg/4ZYI3fL61jTGKdmDM93JP2hZoIyA49/Dg7/hu5L/5H/OSx4x0VL0Pw+NL+P\nt16wmAc/fjlfefcWPn7VmpxIF0N9PIgQ0Of1c5kGZx7fwb92foRvfPU/eOX05KfW7DvqxE1VVePb\nCkHNR1o6Mnggu7BgyqJHdSTAX199Dv/35lexdfsVcNNPnR4wd1/La+qcXum/PzSO7bL7vxADJ7g9\n9SbevX3ZqEBj67JanrA3EDz2ZK77I8d3OV9bLuTJ1i5+d6CTj165hsc+cQXvvXg54YCflroER2UT\n2Y7iImiv7H/MXugjqFu1GVsKxOnC9uc9TxwhZWRz7731i6tZVR9h34lenj0y+oM9kE1j+Yr66CkL\nkzJ+pJS9wKPANcBpIcRCAPdrwcRnKeWdUsptUsptDQ3jV3IVy+mDzxPEwr94M5xzDSy/DB77V9Dz\nmvY/8Xnn66UfB+CSi17FURZi7pumj+7558sucTZ71r7ROb6/wPPuux+/zHKw4XUc9q+gZuDAuI2e\nzpw4wiLRyWJ5in+P/zd3vPMC7njnBXzi9c6m78GOsSsjBw2LJdYRBoP1jpUyeIYbG9sJaT6+/XQb\nO9t6WF4XZcGpJ5wHrLzCyQKpX8M6/8miInSrx9mEDNctGXY8UNVMtUgxODg6g0U/9TIZ6efcc9dj\nZiWPt/bCG//NyRD6zvVw9Ens19zKk+2ZouwWj3TE3QR79DOw/DK+PngZPiF4x4XDKyN9PsEbNy7k\n41edM6nLYs3voz4eoseOTVvQo2eeA+BW+04+8vWfs/fE5HrD7HzFucIITpBHH9J8pNy4dk+macyU\nRY+PXLmGi1a4QrjwfHj/zyCbYc1DN9EUtnny4Bi2i6nD45/jUOR8ntc28bYLFo86ZUV9jD8ENhG0\nBoZSe9ufdeoWqlv49lNt1EYDfPi1qwjm+c9LFkQ5LBcS6Cuu+2K6z5WdaHGCHk/UcEw0ESuQutgx\nYLDm5P08xIe44+jbuePwddxx4GruOvI69oXeT/LoiBRl2yYojQl77JSTCQVdCNEghKhxv48AVwP7\ngfuBm9zTbgLum6lFjuTMK06GRv052x1Rff1nnHFWv/sP54T+E07j/Ave7TSXx3mDdi16LWvTL9B2\nchpXCr1t0H98KFtmwUpoXF/QR8+88CMO2c2s2LCd7vgawnbK2UQdg66XnwKgZ+FlztXFXidv27tM\nbz0ztqC396RZI9oZrD4H1rwOtAjx1p/zpk2L+J/njvPskW62Llvg+OfxZmh0s18a1rLcPlpc+f+A\nM1RCGxGh+xKO22YNjO6AmD71CkdlE39y4TISYc1pS7DsEjj/Hc4HY90aWlveRl/anJSgZ2LuGrQw\nxhu/wA93neDqdU1jWwRToKkqREc2Nu2Oi40DezmqLSOhZfmU/ArvvutJ9hwvbmLQoY4kXb1uYdME\nvWiCmo8Uzv9/vzV2yuKYNK2HG3Ygetv4ZM0D/P7QGIK+6x4YOMltybfwti0txAtkDwkhMJZc6tw4\n/Bvnq1tQdKrf4KF9p7nhwiWjCnLqYkGOiYXEB48W9TM3+p0I3eel0RbBscBK6gdHpy4++eIr/JP2\nX2jxOtjwdthyE1zyF3D5JwgJi5r2R4c/wHI2Vi1tblkuC4FHhRB/AJ4FHpJS/gy4HbhaCHEAuMq9\nXRas9t0MyAgrz3Wdn4WbYNM74amvOtVpj3/e6ZL36r8a9rjlF7+NkDB5+pF7p/7iR9wId9mlQ8fW\nXgtHnxxevJQ8Q+DoE/zM3s4V65ow69zm9qdfGvOpzWPPYkkf1tvvdjIBfvpR6D9JU1WIeEijtWPs\n5pkZwaYAACAASURBVPzt3UnWiOPIxrXOG3/N1bDvft5zUQupTJbelMnWpdVw6DHHbvGi1Ya11Fpn\nSPZ1k52ge6E2OKLs38ObxFKgw56vp5XDciFrGuNcvqaBR18+41QiXv0pWHoxXPvv7Gp3PqgmJejV\ny+mSVfD6z/CL4yG6BzOjNuamS3NVmJOZyPQ6Lpo6S60jtNZehu+a/8Or5Au8z/8g77zrqaIGdD+y\n/wxRXKttvEHEuBG6a7m0ykXUj2O5jMnyV8P57+D1fd8n2Nuaq20Y+v+k4fHPcaJmK7811437M1+z\nchX77SVkDj7mBFzdrdCyje89exRbSt590ejHCiHojy0lIDNO4DQBZr/bCz0xTuvcEXTGzqHBOgHG\n8AAp+swXiQud8I3fgGv/A675P3DVbfBH/8gxbSkLe3ePeHHnZ2MXOau2HBST5fIHKeUFUsrzpZQb\npJSfco93SSmvlFKukVJeJaUsW7Judc9LHA6sJhTI2wS98n+D8MPPPu5EEJveCbXD/2Bq112BLiL4\nDjxYVCFNQdqegMgCaFg7dGzddc6b/pW8LJq99yGweSr8Gs5bWEV48XnYUpAZZ2M01vECr4hl1NfX\nw9vvci5t7/swQkpWNcRoHcdy6T1+gIjIEF3kfsitfyskT7NJ7mPDYqdC8pLYcacvyaorhh7oRurL\n5XFnMPI4hLw+LvERBTpuvrB/cISg21liyaMcYSFLFkS5Ym0jZwYMXjrRD4km+MAvYeVr2dnWw4JY\nkBX1xfeUjiZq2GZ8BfOC9/Ptp46yoj7GJauKj9KKobEqzHHdjb6maLskj72ARpZM0ybY+qew5vV8\nXH6HzeHTvPebz0wYqT/68hnOqXU/fCeI0EOanxRh+gP1DBCd0HIZk9d9GgJRPqXdzZMHR1zN7rwb\nkqf5rP42ti2rZW3z2NW325bX8nv7PPzHnoKjTmfH7KKtfO+ZY1y+piG3MTuSTNVK55uuiX100+uF\nPglBTy9Yhw+JzAuuzJ52Luu5l+drXodoWj/qMe2JCzgn89LQfgDkBL3Y4ePloDKSJyeBbWZoyRym\nr3bED71qEVzyEcdSsC2ncf5ItCCDLZdxidzFL/4wiZmU+Rx53LEM8vtGNJ8P1UuG2S72iz/moGxh\n2XnbEELQ0tRIm2wk3T5G6qJt0zy4n6PhtY7X23COYyW1PgLP3sWqhjgHx7FcrNOOJxhf6u7cr3k9\naGHE3vv466vP5erzmlja41g6rHzt0APdD6Y1vvYJbZeocYZeXy1oIy7l3Qg9qI/YROtrR5MZeiNL\nCfh9vPbcBoRgVJ+Z3W09bFlaOymPuzoSQOLj6UPd7Grr4d2vGjvneqo0JcK0G9MT9L6Djj0YXrbN\nuSp68x2IUIxvVd1JzJ/l878eu2oxaVg8c7ibV7W4a5hQ0H3cZb2R79R+GGDcLJdxiTfiu+qfeLX/\nJfTnfzR0PJOCx/+T3qbt3Ne7csIroo2Lq3mKDfizunP1jOCR/sWc6tfHfayvfjUAsohcdHuwC1sK\nwvHiPHQgV9SkHxvyxLt+8Wl82CQv+UTBhww0XUicNHp7no9uOu8XOUGPnXIy5wT9xIHdhISJtviC\n0Xde+jGoanG88wUrCz5+wQVvYpHo5vHHH5v8i/e1Ox66a7fkBiwI4dgurY84mRt9xxHHnuJ+aztX\nnOtEr8vro+yXS/F3jJHp0n2IuEzSvyAvlWrbBxxhfuifuDB2mpN9OkmjcA/wYNd+ZynelUMoDquv\ngr33c8U59dz1vm34Dj0KzRuHV+DVLsf2hzhHTJy6WGV2MBAosLHtDnOOZEYIuhthWbXO76I+HuL8\nlpphgt49mOFQ5+Ck7BaAmqhzdfblRw8S0nz8iVulWEqaqkL0Sncjcoqpi1b7c3TKKhYucUSKRBO8\n6YsEzrzI55t/xSP7T4/5Qfr4gQ7MrGRbnZs9VITl8oxcx/3mRQDjZrlMhNj2AY6GzuGNJ+5AeskG\nO78Jg2e4y38jC2JB3rBx/FYK4YCfZNOrsPHBkd9B43n81+4uFlWH+aO1Y1eB1jQtJSVDxeWip7ro\nJUY8Wvz/tXrhSvpllLQnzl2tNB74Id+3r2LrpgK6Ak4QB/Tt/83QMW+0YZHDx8vBnBP0jlecxkGN\n524ffWcoDn/xLFz7n2M+Xqx5Pf9/e2ce3lZ95f3P72qXbNmSZcmOLa+J4ziQhayQlJBQCBQoMLS0\nTFna4e0y7bxtpzAtXaYv7Qy0bxfaKW2nBcoMhUJLCxRaOk9ZCwTCkpUszuo4i+PY8RqvkiX95o97\nZTu2JEuO7Fjifp4nT6Sre+V77Kujc885v+8BKGp9NeVug+Hl/hWr+NP24yz+t+d5frdWCKy9Qi2S\nHHwJdv8RgeSvXMCq2eqtYEWBgz2RMhy9R2LqmQw0qpGcnLVk1MkKuPqnYM7hAwfuBCQNcdIu+X0H\naTcUqoObo8y/FnpPqMv8g31w5E21u2U0igE8NcwRTRNG6O5wG32WGA7daKbf4MQxdLrTk5pDN/tG\nhiysm+tl+7GuYa2QaDtlqg7daVMd+saGdq5cMCvpdsdU8OVZ6UaLiiepuGhv28GOSCVlBaOi63lX\nwuIbWdn8a9YoW3kshpAaqHcya637qNz072qLbJwgJUpUk7upsx8hwJ1qUXQ0ioH6JXdSILvo/su3\n1etnw48JlF3ILxqL+PDS0qQ0wOdV+tkhKwHo8Szktf1t3LC8DEOCu6lSt4NGWUSwdWLNFTHQQafM\njVmYjUeJy069LENp1VIuL99FACNv+v8BR5z38ZVWcyRSOOIDQI/Q00GoaQu90kb5nNhaEJjtYEjw\nx831EfIt5P3GbTzyVgx5z0Q0bgBLHk8ez+cLv91KbyDEHU+8S1tvAMouUIfe7nkWdj7JfqUSb9U5\nwxeIw2Kk2VaNQELrnnFv3dPwNn3Sgrtiwekv5Hhh7VfJ69pNtTgeM48upaQ40Ei7Y8xQiJr16iSY\n3X9Ui7mRIbUgOgbFO4+5hiaOJYjQwxFJoWxn0B47Kus3F5AX7jhNenWgeS+90kph0Ugr4bpaL1LC\n3/aqudnNhzsxGQQLSlPTuMm3jdRPblw5fohDOvDlWkdF6JNIuQT7cfcf5LC5Zry86mXfRXjr+JXp\nBzje+hHBodPvvCIRSW/9i/xSfAeRVwIffxZMibspou1/pwZDuOxmjBNo4kxE7ZKLeDS8Due7D8Kz\nt0N/G0/l3Ry3oBmLJeUuNoTV9OgrfeUYFcFHlvsTHuN322iQRRg6J065GAc76SSXXItpwn2jlLhs\n1EfKcHTtUVsqdz7Br0KXsaQuviZUeYGdt+U8nK1vj6xyjjr0iVQwp5GMc+j5nbtpNM/GaEz+G3ks\nxtrLWCQO8PLWPfSkMPGew69zPG8Rt/1hJyurCnjiHy+gJxDia0/uQCoGqLlcbTVs2sSTgRXjbisD\nbi0dEmNRg6F5KztlJdW+GEWm6osBuNCwK2YevbtvgEqaGMgfM27MkjucduHgi6ooUtn549+/cC7F\ntNHeEX8hSfepU7hFL2FHbIcesBbioeu0lFCg9QCHZBGVo1ZHzp/lpDDXwkt71bTLlsOdzJ+Vl7Ke\ndJ7m0M8pcbLIn9zq0lTxOS10oZ37ZAS6WnZiIELn2HoPqH+bW5+jtfwq/jHyGJ0PXHvazzj81jPc\nE7qbgZwy1ZnnTqwUObqfO+WWxRiUue08bL+FPoMTtj9KpGodP9rrYk1N/ILmWJaUu/if8HIGTPn8\n/HAJ6+cX4c1N/MVU6rLTKIuw9R2bUCHVFOykU+bisCR//RQ4zBxQKjCFB+CPnyVgdHJf6MrEaSC7\nmR2GOmxDXcPzWqNFUWHWI/RJEQoGKBtq4FSsD0gq1KxHIcLy0BYefjPJKL3nBLQf4L+aSrhwTiEP\nfnwZi/z53H5pDc/tbuHJLU1q2kWbMP/nyHiH7vBV04d1fOtiKEheVz07ZDVl7hgfFHcl5JdxsbWe\ng63j0zWth/dgESGEd974Y+dfo/aPb3lYzQPGivK040wd8XOWPW2aVK1z/CISgJCtkEK6TtNzMXap\nLYsVo9INiiJYO7eQV/edZCAYZvuxrpTTLQBFeVY8OWY+fWH1lOlouB1mFIORQcPkFhfJJrXNbci7\nKPYOZgeFNz/E942fxt2yEX65Bpq2wN7/wf/crRyUswjf9EzSqoMGRWDUUhmTalkcgxCCc2ZXcHfk\nZqTJwVvln6blVIAbVyTfHup1Wul2zWd58D52D7r5WBJ3U3k2EyeMJapCalfiISaWYBenhDOluxEh\nBO05WvDTspOnHB/G4/FSMUGXVXO+NjIvmnaJOvQJahvTSUY59KP7tmIRQ5j8cQoXyVK8GBxebsjf\nzX2vNiQVpf/tuT+qD8ov4L6blwxHlLeurmJ5hZs7n9nFcc/5YLRx0DwXk6eK8oLTL5CKwlz2RPyE\nmse0LrbuwiiDNOfMj39hVq5hcWQXh1rHt7n1Hn0XAHtpjDRUzXowmNUvmhjpFmC40yWv92DcaTWD\n7apDN+bPivm6zPFSKLrpji7/DwVw9B/niJg1Tv9iXa2XnsEQD21sJBCKsHQSDt1uNvLO19/PVQtj\nn086EELgzbXSp+ROyqEHjm6hVebjKY7vAA0GBfuqT3Fd4JsMhcPw4Hr43U00GCr5jvd7uL2p2RdV\n/Zt0y+IYLqgu4LGBley9eRs/2++iJN/G2gSRbCyWlLnoCYSoLnRwflVyraWDuWrePWHropTYQt30\nGZMfXBIl4JpLGIVIjo+72y5MyiZT4WzahWucQ59ING06ySiH3qatEPXFKoimgqLAnEtYFtpCT/8g\nD25oTLj7o28d4ejW5xkUNv7l4x85rRhkUAQ/+PBCwlLyL0/vZ+Cqn/OV/htZN3f8BVLpyWFPpEyN\n0Ec7Ti2SGyyME8kBVF2EI9KLo3PXuHmhEa1lsbBywfjjrHnDKZu4Dt1VQUixUBk5SmcsxURgSFv2\nb3HHzn8qOT5sIkhvj1Y87GxU28Ac5eMKYKvnFGIyCH7xipojPW8SDh2YFoU7n9NCN5Nz6LJpK+9G\nKk9LOcXiI8v81CuzuafqAZhzKcHS87mu98usmBd/UHY8ooMWJt2yOIbztd7+Rza3sOFAGzcs9ycs\naMZiSYXaUvixFeM1X+IhC7SuoESti8E+TDLIgDH1lJuvIJ9fievYtujbnAqbEqZbopQXOHgzNBd5\neIMqCx3QHPoE7aTTSUY59PDxrfRKG6XV41XSUqZmPYbgKb7l38IDrzXEFpYCDp7s5Vt/2sVa637M\nVRdgNo//oJQV2Pn6FfN4/UA7n91SyqZQdcwLpNKjVteNwW5VniBq17HNtMtcXLMSfIArVTnSFXIn\nR8as3rN07uMoPvLy4lzYq/9ZndforYv9umKg31mVsHUx0q2er90T26Eb89Uc70CnJsCpRVZh13ib\ncixGlle66eofotRlG5aqnYn4nFY6Io7U2xYDvVi7DrAjUjXhgilPjoXLzynmkXd76P+7h3h6wc/p\nwZ5yJAxg1u7w0pFyAZiVb6OiwM4jbx7BqAiuX5a4oBmLK88t5pPvq+QjKRzr9vjoko7hTqmYaH+T\nZLXQR1OSb+PugWt5uF3Vf19WMXEfe3mBnbcicxGnjkPXEcLaSlOjRc+hTwpX126OWmajGNIw7qnm\ncqhcw8dO/pjLQy9w/2vjxYBC4Qhfenw7xaY+SkOHUSpWxXgjlb9fXsaamkJe3nuSXIuRpTEuEL/b\nzj6pXdSj8uiho5vYHqmm2pcgksvxMuCaywXKznGFUXffQY6bEuQ1y1aoS5kTREcRTy2zlSaauvpj\nvq70HKdH2sjLj33hW7VUTKhbXU0a0YZY2IprYu6/rlZdjDSZdMt04nNaORmyj4/Q+ztgw4/i53hP\n7EAQYTdVlLom/sDfuLKcnsEQf9p+nJf3tuJzWpg/K/VUgkWbPn8mPehjOb9abb1df87EBc1YuBxm\nvn5FXdyWwFj4C9TWxaHWBL3o/eoq0WS10EdTov1Nnt3RzOrZntMKyvEoczt4O6LVqY5sJBToJygN\nmC0zJyDJGIceCAYoH2qg50wLolGMZvj73yGq1/I90330vv7AuDmKv3jlINuPdvH9ZZoDLY8/vk4I\nwfc+tIA8m4mLar0xLxCL0cCpvJFiDACBHswd+9geqWZ2YeJBt0r1RSxT9tJ4YlS0GAriGzpGx9iW\nxRSxFNdRItppiSNxbO5v4QRunNbYH0q7W3XokR7Vofc37+GkdDLLF7s74/3zvBgUMXxLP1PxOa2c\nDDuQ/ZpDDwXUqUs/WQQv3Al//XrsA4+rCoudeXVJFeyWVbio8eXw0BuHeW1fG2vneieVUopG6AVp\nSrkArKlR1x7cnGatnET4XXYaZHHi1aJaV1DIlsIqUY2SfLWQGQxFkkq3gBqh75WlBIy5cPh1IoF+\nBmfQgGjIIId+uH4LVjGEyb9k4p2TxWSDjz5GX/k6vqXczzu/H5k2vrOpm0deeIdfznqWZe9+U81F\nz0pcjPU5rfz1ixdy97VxeuQBb6GPFsU7EqE3qwN9t8tqqgonWNo9Zy1WMUToyFvD22T7foyECbji\n99Amg3WWmo4ZOhF7Irp18ATtoiCuk7FoKReh6bmETu7nkCyOm24oL3Dw4pfW8KElqd/CTydq66ID\nBjth11Pws+Xw3DfAv0LVC6r/U+w8b/M2TooCnN7k7BNCcOPKcnY3n6InEJpUugVGIvR0pVwA1s/3\n8eJta1iRZEEzHfjdNhojRVj6jg/3e48j2uaZ5HCL0czKH4mqL6pNTta7yGnFZDRyJGchHH6DSLCf\nAcwpt9xOJRnj0Nv2qytEi2pXpPeNTVYcN/2WnTmruOzwD+j5270EW/Zy+KFP8or581za8ShUroFb\n/jxewyQGRXlWcq3xFzlUFtjZHfaPCANpov8tOUnckpavIoyC5+TG4U2njqgdM4ovRstiCkRbHk3t\nsW9xc4Mn6TLGF0AS9gJCKBj71Qjf3HWIQ5H4Dh2gwuNIucA23ficVrplDkJG4PcfVwc13/QUoY/+\njl+abkIqJtj403HHyeNb2R6pTElw7NrFJdjNBswGhdWzkxebGk20YJ+uLhdQv2wmM2npTCjJt3NI\nand3HYdi76SlXHCk/kVT5LRiUATnluQlnUZSFIHfZeNdpQ7aD2DoPsyA1CP0SSGPb6UPK0VV8aPf\nSWO0kHvzb/hrZBm5f/sGpv9cwfsDL9FWfR3i/26GjzysDgBIA5UeBzvDfnVxQigATZs5ofjw+JJo\nT7M6aXLUMbdvy3B7Yd+xXYSlwOmPU/BMFlcFQWEmtzdGESoSxhlqp9eSIGpUFLpEPpbBNhg8hT3Y\nRpMyi8I0Opazgc9p5Z3IXLryauGqn8BnXoPqdfzilYN8Z0MXm/LXw7ZHoXdUqmrwFLTtZ1soNYee\nazXx+Yvn8IlVFSnlm0cznHJJw8Kis4nNbKDTpvWsxymMyn5VmEuxpx6hGw0K1y8t5dbVlSkdV17g\n4LUh9W7Y1vw2A1j0CH0yuLt3c9QyB6FMzS+v3Ovi1YXf48HwB/hp6Gp+UPcHSm76JRScWW56LBUe\nVdNFyDCc3Its2syWcFXSEVCn73zmc5C2Nm1VZ+tuGmURJZ4zLC4qBtos5fgGY0RDva0YiDBgTTw2\n9pTBhT3YDh1qgbnfWTFjhudOFp/Twruymt+d9ygsuQUUA7uOd/MfL+5HEfDDnktUDZ+37xs56MS7\nCCQ7ZWoOHeAza6r56gcmf7dlMSnkWo0zyslMlogrsYxuuK+dbhw4rJMLGr7zdwu4Jsa0pUSUue28\n3F2ENNlRIkEGMA+nuWYCM+dMEjAwGKAidIg+d5oKonH47MXz+G7kZh533sIXrolfAD0Tqjw57Il2\nujS8jOg+xpZQFdXe5By6UnURRhGhbddLANi69rFPllLqOvPVar3O2VTIY/SNVXTUWiyH4iz7j9Jn\nKiAn1D78ARTRXuIMJsdixG420HJKLZgHQmG+9Lvt5NvN3HF5LW/2eOgpvwTeuX9EdE0riO5IMeWS\nDhwW44xuA00FT4GHdlzqYIwYhHvb6JC55MYp1E8F5QV2uoOCoVlLAbSUy8z58swIh95QvxmbCGIu\nS2NBNAYl+TZ+88kVPPp/Vqak3pbSz3DZaFKKGRIWdTk+qC2LExREoxTOex8D0gwNr8DQIHkDxzhm\nLE9pon08Qp65lIh2mlvHDKrQRs9FHMUJj++3FJAf7iR08gARKcgtynyHLoTA57TS0qMO/7jn+X3s\nbenhe9eNRHfPuT6qtjVu/Y160PFtdJuL6DW6UhpMnQ5uu6SGe65fOK0/c6rwu20cjPiQbbEj9Ehf\nO13kTNlnNRblmoZNm1v1Rf1YsGZShC6E8AshXhZC7BZC7BJCfEHb7hZCPC+E2K/9P2UNxe1aQbS4\n9gxXiCbBsgo3/lh6KmnCoAhK3Lk0mSugfT8RFHbKCmYnGaH73E62Uou7dSO07UMhQldOetJC5iL1\nVr/78Chpgv4OwrvU2aZKfuLb0yFrIS7ZxUBzPccpoNQ3s1sSk8XntNDSPcimxg7ue7WBjy7zs7bW\nizfXyrkleTzWPAtKl8PGeyEcguNbOWCcTaXHkfahGxNRVZjDgtKpESubbvwuOw2RouE1DePo76Aj\nRencM6XMrQZeB+1qTW0Qc8ZF6CHgNillHbAS+JwQog64A3hRSjkHeFF7PiUYTmynHyue8qlNuUwX\nwxIAQKu1CqM1J+mFIEII9jvOwzfYAIdeBSBYUDvBUcmRV65GdoET9WpnwbO3wz11GHY+zhPh1Vjy\nErfShexejCKCoekdGibocMkkfE4rRzv7ue332ynJt/GNK0cK0GtrvWw50knv0s+pi4y2PgwdB9kS\nqjxNlEwndfxuVXXRMNAGg+M1jJRBTQt9GlMufrcNIWBbZDZhYWRAZliELqVsllJu0R73APVACXA1\n8JC220PANVN1kudf+08MXf5DdRhDFlDpsbN5UE1f7FZmM9ubk1LxsN2rSuDKd+5nSBqweOek5bwK\nSuYwKE2cs+9ncO956mzWc66j4foXuG3os7gcE3zpaKqA9v4mVTY3ixx6y6kARzr6+eGHF54WEa6r\n9RKR8EJkiTqE4rl/BeCN/lIqk0yj6cSm1GXjkNTSfGN7/d/9PZb+E9TLsmmN0C1GA8VOKw1dETbO\nv5OHw5fMqAJ0Sl8tQogKYDHwFuCTUmrCHZwAErdAnAGKfwl5K26cqrefdio9OWrrIvDWYHnKPb7W\nssV0Szuis5EGWUyJJ3Uti1goRiP1hhqUoT7aF34GvrgDrvkZLRa12yA69i0ehlGa3S2m0imZInQ2\niBYZb11VOW5xzYKSPDw5Zl7a26bOtA32ALA1VEGlHqGfEbPybTSiOfSOUdIcHQ3w53+m3b2YX4cv\nnVaHDqp20+H2Puq9V7BDVmVmH7oQIgd4AviilPK02W1SbYqOqbsqhPiUEGKTEGLTyTjLyt9rVHjs\nvB2pZc+CL/NI//Kk8+dRqrx5bIyo6af9shR/Gjpcohy89L9YE/5Plry5mk8/3cTOpu5h4bJ8W2IH\nbcofceiDztT6e2cyl9b5+PSFVdy+fvxqXEURrKnx8sq+k4TOuR4cXgYcpXSRq0foZ4jJoBDMLSeC\nGGldDAXhD7eCovDqud8hjGFaUy4A5W4HRzr6GRwKA2RehC6EMKE6899IKZ/UNrcIIYq114uB1ljH\nSinvk1IulVIuLSxMbolttlPlySGMgftDV9KHLeUIfbbXweuaQ98XKcXvTp/a24dWzuWFr1zO5y+e\nwxsH27ny3g38+7OqHIDLkThCt7pGumCUwvSkgWYCfredr35gXtwP7rpaL90DQ2xtHoTrHuC1GrWc\npOfQzxyvO482pXDEob/0b3B8C3zwXlVCA1IaP5cOygrstPUGae8LYlAEpjMc9ZdOkulyEcCvgHop\n5T2jXnoGuEV7fAvwdPpPLzvxOS3YTAZe2qMOmE41Qi8vcPCaXMygNLFJzqU4L73ynS6HmS9dUsPr\nd6zj9ktr6A+GsJkMuCZIoTidLgakmaA0kF+UeKBxNvG+Gg9GRfDSnlaoWsMGFpNrMaZNk/y9jN+t\nSQC0H4QDL8AbP4Eln4C6q+kdDGFQxLQXJaNf1Ptbe2ZUugUgmXuVVcBNwA4hxDZt29eA7wKPCyFu\nBQ4D10/NKWYfQggqPA7qm09hNij4k5BXHY3JoKAUVLDg5AN48nKTkv6cDE6riX9aN4dPrKqkoy84\n4a1lvsPCSZlHADMV3tSlXzMVp9XEsgo3L+9p5SuX1XKorY8KjyPjV8nOBPwuO3uHfCxv24h46jNQ\nOA/W3w1AbyBEjsU47b/naC/6vpbeGZVugSQcupRyAxDvN3Zxek/nvUOlx0598ykqPPZJTWefXZhD\nw8k+SqewZz6Kw2JMSlvEaTXympxDt3Rw3nss3bCu1stdf6mnqWuAQ219nFc2s3XeM4VSl41dsggR\n7IVICG5+BszqNd8zGJr2gigwPCD7ZE+A4ryZtSp3Zt0vvIeItvRNVsUuKhWQzoLomWI0KHxD+SLf\nDH0ia1oWkyUqd/vXnSdo6hqYcOCwTnL43eqUL0CNzH0jawB6A0NnxaE7rSZcWsfXTIvQdYd+lqj0\nqA550g5dOy6dBdF04LSZ8Dktk1YLzFSqCx2Uue38emMjUkKV7tDTgt9tY2OkjmdWPw3Lbj3ttb5A\neNo7XKKUaXegMy2HPrPO5j1EVLtlTqKxcwmo0Y6L5vNmCgU5Zqo806udPRMQQrCu1ktjuzrCT4/Q\n04Mv14rZYGDX0PhlLj2Bs5NyASjXUp2WGRahv7fCqBnEIn8+P7lhMZfNT6xgGI9zS/K494bFXFI3\nZeu5JsXd1547ZUXamc7aWi///UYjgL6oKE0oiqDEZeNYx/ipRb2DQ0nNa50KooGUdYZd67pDP0sI\nIfjgwiSGWiQ4/qozOH6qOKckPatWM5EVlW5sJgN2s4G8CVbV6iRPqcvG0c7Th5eHwhG6B0Lk7IgG\nPQAABM1JREFUnqUIvUyL0GdaDl136Do6acJqMnDFgmJ6B0MT76yTNH63nZ07VJWRYCjCE1uO8fO/\nHaCtN8DcosSD1aeK8hmaQ9cduo5OGvn+hxbo/edpptRlo7N/iPtfbeDB1w/R3D3IQn8+d141n3WT\nHKZ9pgynXPQIXUcne9GdefqJtube9Zd6llW4+P/XLeB9czxn9XftzVVlc/UIXUdHRycF1swt5OMX\nVLB+fhErq9wz4ktTCMG/XlnHXN/ZSfnEQ0Snx08HS5culZs2bZq2n6ejo6OTDQghNkspl06038y6\nX9DR0dHRmTS6Q9fR0dHJEnSHrqOjo5Ml6A5dR0dHJ0vQHbqOjo5OlqA7dB0dHZ0sQXfoOjo6OlmC\n7tB1dHR0soRpXVgkhDiJOn90MniAtjSezkwhG+3SbcocstGubLSpXEpZONFO0+rQzwQhxKZkVkpl\nGtlol25T5pCNdmWjTcmip1x0dHR0sgTdoevo6OhkCZnk0O872ycwRWSjXbpNmUM22pWNNiVFxuTQ\ndXR0dHQSk0kRuo6Ojo5OAjLCoQshLhNC7BVCHBBC3HG2z2cyCCEeFEK0CiF2jtrmFkI8L4TYr/3v\nOpvnmCpCCL8Q4mUhxG4hxC4hxBe07Zlul1UI8bYQYrtm17e07RltF4AQwiCE2CqE+LP2PBtsahRC\n7BBCbBNCbNK2Zbxdk2HGO3QhhAH4GXA5UAfcIISoO7tnNSn+G7hszLY7gBellHOAF7XnmUQIuE1K\nWQesBD6n/W0y3a4AsE5KuRBYBFwmhFhJ5tsF8AWgftTzbLAJYK2UctGodsVssSslZrxDB5YDB6SU\nDVLKIPBb4OqzfE4pI6V8FegYs/lq4CHt8UPANdN6UmeIlLJZSrlFe9yD6ihKyHy7pJSyV3tq0v5J\nMtwuIUQpcAXwwKjNGW1TArLVroRkgkMvAY6Oen5M25YN+KSUzdrjE4DvbJ7MmSCEqAAWA2+RBXZp\nqYltQCvwvJQyG+z6MfBlIDJqW6bbBOqX7QtCiM1CiE9p27LBrpTRh0TPEKSUUgiRkS1HQogc4Ang\ni1LKU6OH+GaqXVLKMLBICJEPPCWEOGfM6xlllxDiSqBVSrlZCHFRrH0yzaZRrJZSNgkhvMDzQog9\no1/MYLtSJhMi9CbAP+p5qbYtG2gRQhQDaP+3nuXzSRkhhAnVmf9GSvmktjnj7YoipewCXkatf2Sy\nXauADwohGlHTluuEEI+Q2TYBIKVs0v5vBZ5CTdNmvF2TIRMc+jvAHCFEpRDCDHwUeOYsn1O6eAa4\nRXt8C/D0WTyXlBFqKP4roF5Kec+olzLdrkItMkcIYQMuAfaQwXZJKb8qpSyVUlagfoZeklLeSAbb\nBCCEcAghcqOPgUuBnWS4XZMlIxYWCSE+gJr/MwAPSinvOsunlDJCiMeAi1CV4FqA/wf8EXgcKENV\nobxeSjm2cDpjEUKsBl4DdjCSl/0aah49k+1agFpIM6AGPY9LKb8thCggg+2KoqVcbpdSXpnpNgkh\nqlCjclBTyI9KKe/KdLsmS0Y4dB0dHR2dicmElIuOjo6OThLoDl1HR0cnS9Aduo6Ojk6WoDt0HR0d\nnSxBd+g6Ojo6WYLu0HV0dHSyBN2h6+jo6GQJukPX0dHRyRL+F4GY/ljSKjU7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd110fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train_range = xrange(len(X_train))\n",
    "plt.plot(x_train_range, y_train, '-',label='Train')\n",
    "plt.plot(x_train_range, rf_train_pred, '-',label='Predict')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xd21ed68>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbmaWEW7oZmYZ4YZuZpYR/wKCI19KeDICkgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcf6ee48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test_range = xrange(len(y_test))\n",
    "plt.plot(x_test_range, y_test, '-',label='Test')\n",
    "plt.plot(x_test_range, rf_test_pred, '-',label='Predict')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvMAAAHiCAYAAABlZ0N0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5cG8mZmZmVkv9f8DsuZT/dIeKucAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcf4f2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = rf_best.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title(\"RF Feature importances\")\n",
    "plt.barh(range(X_train.shape[1]), importances[indices],\n",
    "           color=\"r\", align=\"center\")\n",
    "\n",
    "plt.yticks(range(X_train.shape[1]), X_train.columns[indices],rotation='horizontal')\n",
    "plt.ylim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上图可知，前6个最重要的特征里有5个是新构造的特征，同时经测试，回归结果mse也比仅用原来的特征好，这说明了新加入特征的有效性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n",
      "[CV] n_estimators=20, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         287.9736          -0.7565            0.02s\n",
      "         2         261.5520           2.2923            0.02s\n",
      "         3         229.4453          -0.0105            0.02s\n",
      "         4         216.3591           0.8768            0.02s\n",
      "         5         136.2679           2.7670            0.01s\n",
      "         6         102.3316          12.7564            0.01s\n",
      "         7         174.8256           2.0569            0.01s\n",
      "         8         150.2438           8.8975            0.01s\n",
      "         9         162.6161           1.1299            0.01s\n",
      "        10         114.8951          -0.1415            0.01s\n",
      "        20          78.6247          -0.7271            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.7, learning_rate=0.05, score=0.044746, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         289.8912          -1.1790            0.02s\n",
      "         2         264.0664          -0.3385            0.01s\n",
      "         3         231.1540          -0.0936            0.01s\n",
      "         4         213.5986           1.8984            0.01s\n",
      "         5         132.1037           0.6387            0.01s\n",
      "         6          99.9696          11.0747            0.01s\n",
      "         7         176.3750           1.1742            0.01s\n",
      "         8         148.8401           8.8957            0.01s\n",
      "         9         159.0204           3.5621            0.01s\n",
      "        10         118.8041           7.1564            0.01s\n",
      "        20          76.0601          -0.2070            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.7, learning_rate=0.05, score=-1.027519, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         288.7676          -0.4958            0.02s\n",
      "         2         260.8576           2.3372            0.01s\n",
      "         3         229.2588           0.0750            0.01s\n",
      "         4         213.8526           0.7059            0.01s\n",
      "         5         127.8188           1.4648            0.01s\n",
      "         6         100.9612           7.1176            0.01s\n",
      "         7         178.5623           2.5173            0.01s\n",
      "         8         144.3274           7.8547            0.01s\n",
      "         9         162.8372           2.0646            0.01s\n",
      "        10         117.9719           7.0554            0.01s\n",
      "        20          76.2296          -2.3826            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.7, learning_rate=0.05, score=0.211799, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         282.2828          -0.0102            0.02s\n",
      "         2         253.5370           1.6543            0.01s\n",
      "         3         223.2478           0.2454            0.01s\n",
      "         4         209.8703           0.5862            0.02s\n",
      "         5         125.9980           0.9530            0.02s\n",
      "         6          93.2883          10.1961            0.01s\n",
      "         7         173.7415           1.4318            0.01s\n",
      "         8         135.1072          10.4558            0.01s\n",
      "         9         153.5216           2.6928            0.01s\n",
      "        10         109.4107           7.0141            0.01s\n",
      "        20          70.8742          -1.9218            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.7, learning_rate=0.05, score=0.064409, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         218.2648           0.4686            0.02s\n",
      "         2         193.4615           2.0600            0.01s\n",
      "         3         179.8763          -0.1774            0.01s\n",
      "         4         159.6389           1.1099            0.01s\n",
      "         5          77.2999           1.1221            0.01s\n",
      "         6          87.1573           7.1577            0.01s\n",
      "         7         136.2369           0.6059            0.01s\n",
      "         8         126.6066           0.1578            0.01s\n",
      "         9         124.5734          -0.0968            0.01s\n",
      "        10          93.3076           8.4527            0.01s\n",
      "        20          57.1697           0.0664            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.7, learning_rate=0.05, score=0.230205, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         225.1204          17.0315            0.04s\n",
      "         2         207.3429          16.9920            0.02s\n",
      "         3         229.4716           1.3476            0.02s\n",
      "         4         193.4812           1.6320            0.01s\n",
      "         5         126.0808           1.2106            0.01s\n",
      "         6         131.6346           2.7756            0.01s\n",
      "         7         133.3527           9.5769            0.01s\n",
      "         8         163.2346           0.4488            0.01s\n",
      "         9         143.3374           0.6792            0.01s\n",
      "        10         124.4394           7.0784            0.01s\n",
      "        20          76.6747          -1.0176            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.7, learning_rate=0.05, score=-1.708598, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         133.9842           0.9055            0.00s\n",
      "         2         123.8410          15.3338            0.00s\n",
      "         3         171.8981           1.6232            0.00s\n",
      "         4         138.3225           1.2471            0.00s\n",
      "         5         134.5724          -0.8331            0.00s\n",
      "         6         141.8770          -0.5574            0.00s\n",
      "         7          73.2841           1.3067            0.00s\n",
      "         8         127.2879          -0.7810            0.00s\n",
      "         9         110.1483           1.5023            0.00s\n",
      "        10          91.3234           6.2794            0.00s\n",
      "        20          60.3283           0.5448            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.7, learning_rate=0.05, score=-0.054860, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         228.4113          16.0948            0.00s\n",
      "         2         208.2246          15.9924            0.00s\n",
      "         3         240.6272           1.1782            0.00s\n",
      "         4         202.7495           2.5096            0.00s\n",
      "         5         129.8965           0.5696            0.00s\n",
      "         6         196.2444          -0.3975            0.00s\n",
      "         7         132.1608           9.5669            0.00s\n",
      "         8         165.4871          -0.1151            0.00s\n",
      "         9         103.9404           3.2202            0.00s\n",
      "        10         125.6503           6.3469            0.00s\n",
      "        20          77.0482           0.0663            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.7, learning_rate=0.05, score=-1.558568, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         156.9905          35.8122            0.00s\n",
      "         2         230.4978          -1.0397            0.13s\n",
      "         3         185.0656          13.8384            0.08s\n",
      "         4         152.1994           8.4696            0.06s\n",
      "         5         185.1336           0.8325            0.04s\n",
      "         6         167.6584          -0.2808            0.03s\n",
      "         7         124.7295          11.6066            0.03s\n",
      "         8         138.4362           0.9995            0.02s\n",
      "         9          90.8820          -0.7740            0.02s\n",
      "        10         105.7159           7.3629            0.01s\n",
      "        20          56.7881           0.9323            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.7, learning_rate=0.05, score=0.176181, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         166.7912          19.1280            0.00s\n",
      "         2         201.3738          -1.0168            0.00s\n",
      "         3         202.3122           1.6514            0.00s\n",
      "         4         168.0097           0.0956            0.00s\n",
      "         5         168.4248           0.5394            0.00s\n",
      "         6         147.4937           1.5592            0.04s\n",
      "         7         113.1946          10.3537            0.03s\n",
      "         8         130.4427          -0.0372            0.02s\n",
      "         9          79.6994          -0.4040            0.02s\n",
      "        10         107.6369           1.1828            0.02s\n",
      "        20          52.2437          -0.0602            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.7, learning_rate=0.05, score=0.550730, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         268.0527          -1.5883            0.00s\n",
      "         2         241.9591           1.0539            0.00s\n",
      "         3         214.6580          -0.2809            0.00s\n",
      "         4         204.7294           1.1407            0.00s\n",
      "         5         133.0443           2.8846            0.00s\n",
      "         6         149.3782          13.3313            0.00s\n",
      "         7         162.4382           1.6519            0.00s\n",
      "         8         136.6754           8.7842            0.00s\n",
      "         9         149.1879           1.3127            0.00s\n",
      "        10         122.7701          -0.3590            0.02s\n",
      "        20          76.8949           0.6460            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.75, learning_rate=0.05, score=0.275807, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         269.8733          -2.2693            0.00s\n",
      "         2         244.5319          -0.2242            0.00s\n",
      "         3         215.6269           0.1733            0.00s\n",
      "         4         201.7632           2.4753            0.00s\n",
      "         5         129.0312           0.4536            0.00s\n",
      "         6         146.6481          14.7172            0.00s\n",
      "         7         162.4356           0.9133            0.00s\n",
      "         8         133.9593           9.4031            0.00s\n",
      "         9         145.4613           2.1809            0.00s\n",
      "        10         123.0340           8.6540            0.00s\n",
      "        20          72.2249           0.8441            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.75, learning_rate=0.05, score=-0.895913, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         270.2257          -2.1484            0.00s\n",
      "         2         243.3628           2.6208            0.00s\n",
      "         3         215.3946          -0.6160            0.00s\n",
      "         4         202.2680           2.5267            0.00s\n",
      "         5         125.4237           3.5690            0.00s\n",
      "         6         148.8767          11.1782            0.00s\n",
      "         7         164.0276           2.8294            0.00s\n",
      "         8         131.4368           8.4987            0.00s\n",
      "         9         148.9505           1.6405            0.00s\n",
      "        10         120.9108          -0.2270            0.00s\n",
      "        20          75.2901           0.4504            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.75, learning_rate=0.05, score=0.206186, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         264.1448           0.1533            0.00s\n",
      "         2         235.6200           1.7001            0.00s\n",
      "         3         209.5950          -0.2452            0.00s\n",
      "         4         199.3489           1.1566            0.00s\n",
      "         5         123.2049           1.4258            0.00s\n",
      "         6         143.4356          13.9860            0.00s\n",
      "         7         163.0826           1.6629            0.00s\n",
      "         8         124.5009          12.2335            0.00s\n",
      "         9         144.0616           2.7077            0.00s\n",
      "        10         113.1198           8.5316            0.00s\n",
      "        20          67.3918           0.6146            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.75, learning_rate=0.05, score=0.004946, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         204.1192          -0.1469            0.00s\n",
      "         2         183.1465           2.2665            0.00s\n",
      "         3         168.4147          -0.4337            0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         4         157.8817          -0.1274            0.06s\n",
      "         5          76.3381           5.4371            0.05s\n",
      "         6         137.9097          -0.4105            0.04s\n",
      "         7         125.8014          -0.1604            0.03s\n",
      "         8         114.1897          -0.5995            0.03s\n",
      "         9         115.8158          -0.9644            0.03s\n",
      "        10          85.9593           8.3826            0.02s\n",
      "        20          51.9370           0.5252            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.75, learning_rate=0.05, score=0.216623, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         209.8049          18.1789            0.02s\n",
      "         2         197.5415          19.2881            0.02s\n",
      "         3         215.5563           0.0675            0.02s\n",
      "         4         187.7647           0.9669            0.02s\n",
      "         5         122.7889           1.6851            0.01s\n",
      "         6         175.1053          -1.5282            0.01s\n",
      "         7         135.6874          11.3252            0.01s\n",
      "         8         147.2330           0.9615            0.01s\n",
      "         9         135.0989          -0.4004            0.01s\n",
      "        10         116.2827           8.4709            0.01s\n",
      "        20          71.3483           0.5402            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.75, learning_rate=0.05, score=-1.392455, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         126.5477           0.1852            0.00s\n",
      "         2         120.4698           2.2887            0.01s\n",
      "         3         164.1207           0.6620            0.01s\n",
      "         4         141.7157          -0.6886            0.01s\n",
      "         5         134.4763           0.0972            0.01s\n",
      "         6         134.7302          -0.2956            0.01s\n",
      "         7          83.9601          10.3598            0.01s\n",
      "         8         116.0170          -0.0490            0.01s\n",
      "         9         103.4701           0.9350            0.01s\n",
      "        10          85.0517           7.7244            0.01s\n",
      "        20          56.0271          -0.2888            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.75, learning_rate=0.05, score=-0.023500, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         216.0023          22.7936            0.02s\n",
      "         2         202.2616          16.5841            0.02s\n",
      "         3         226.9424           1.5440            0.02s\n",
      "         4         194.8489           2.1965            0.02s\n",
      "         5         130.0177           1.6237            0.02s\n",
      "         6         187.2252          -0.0906            0.02s\n",
      "         7         140.4913          12.1321            0.02s\n",
      "         8         156.3404          -0.0501            0.01s\n",
      "         9         100.6794           1.9714            0.01s\n",
      "        10         120.3175          -1.5733            0.01s\n",
      "        20          74.9823           0.0094            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.75, learning_rate=0.05, score=-3.063993, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         153.9567          37.6070            0.02s\n",
      "         2         227.4605           0.6571            0.02s\n",
      "         3         182.3300          15.1226            0.01s\n",
      "         4         178.1178          -0.2921            0.01s\n",
      "         5         180.9259           0.0589            0.01s\n",
      "         6         161.0233          -0.0041            0.01s\n",
      "         7         122.5322          12.7934            0.01s\n",
      "         8         135.2936           0.3861            0.01s\n",
      "         9          91.2823          -0.7171            0.01s\n",
      "        10         103.3137           5.7727            0.01s\n",
      "        20          59.4061          -1.1133            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.75, learning_rate=0.05, score=0.166754, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         163.7241          21.2369            0.02s\n",
      "         2         200.1829           0.9624            0.01s\n",
      "         3         196.6305           0.5399            0.01s\n",
      "         4         163.8048           0.8524            0.01s\n",
      "         5         162.3932           0.1074            0.01s\n",
      "         6         141.2258           1.2252            0.01s\n",
      "         7         111.0067          13.2590            0.01s\n",
      "         8         126.8180          -0.7288            0.01s\n",
      "         9          78.6346          -1.4484            0.01s\n",
      "        10         105.1129           0.9564            0.00s\n",
      "        20          56.6228          -1.0033            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.75, learning_rate=0.05, score=0.407308, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         257.4776          -2.3388            0.00s\n",
      "         2         241.7770           1.4257            0.00s\n",
      "         3         209.0030           0.4755            0.00s\n",
      "         4         200.7384           2.3963            0.00s\n",
      "         5         132.2427           2.0073            0.00s\n",
      "         6         141.7269          16.8199            0.00s\n",
      "         7         154.8332           1.6629            0.00s\n",
      "         8         130.6981          10.2961            0.00s\n",
      "         9         143.8746           1.6707            0.00s\n",
      "        10         118.3874          -1.7671            0.00s\n",
      "        20          77.2480          -0.7091            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.8, learning_rate=0.05, score=0.173971, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         258.8168          -2.8023            0.00s\n",
      "         2         244.5659           0.9362            0.00s\n",
      "         3         209.1942           0.2687            0.00s\n",
      "         4         197.9320           2.5709            0.00s\n",
      "         5         129.5730          -0.7873            0.00s\n",
      "         6         139.9396          15.3070            0.04s\n",
      "         7         155.3602           0.3441            0.03s\n",
      "         8         130.4724          12.9007            0.02s\n",
      "         9         142.3373           1.9727            0.02s\n",
      "        10         118.9281          10.6039            0.02s\n",
      "        20          73.8965          -0.8558            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.8, learning_rate=0.05, score=-0.867450, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         257.8732          -2.3651            0.00s\n",
      "         2         241.8607           1.0871            0.00s\n",
      "         3         209.9834          -0.5204            0.00s\n",
      "         4         198.1589           1.9131            0.00s\n",
      "         5         124.3352           1.9173            0.00s\n",
      "         6         141.2271          17.1872            0.04s\n",
      "         7         155.8790           0.4138            0.03s\n",
      "         8         124.3954          12.6757            0.02s\n",
      "         9         141.2854           1.1341            0.02s\n",
      "        10         114.0630           0.1947            0.02s\n",
      "        20          76.0996          -0.2641            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.8, learning_rate=0.05, score=0.201196, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         252.0375           0.6366            0.00s\n",
      "         2         234.8903           1.0437            0.00s\n",
      "         3         203.2993          -1.0737            0.00s\n",
      "         4         196.3459           1.3811            0.00s\n",
      "         5         123.4720           0.9504            0.00s\n",
      "         6         136.7778          12.2434            0.00s\n",
      "         7         158.0998           1.4039            0.00s\n",
      "         8         119.2789          11.0843            0.00s\n",
      "         9         139.9259           2.2259            0.00s\n",
      "        10         109.6036          10.3356            0.00s\n",
      "        20          68.0858           0.5082            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.8, learning_rate=0.05, score=-0.076071, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         200.1416          -0.0133            0.00s\n",
      "         2         186.6225           0.5539            0.00s\n",
      "         3         163.5990          -0.0425            0.00s\n",
      "         4         156.0444           0.4311            0.00s\n",
      "         5          77.2701           2.6414            0.00s\n",
      "         6         131.0229          -2.2096            0.00s\n",
      "         7         121.7491          -0.8032            0.00s\n",
      "         8         111.0033          -1.0983            0.00s\n",
      "         9         114.1929          -0.2507            0.00s\n",
      "        10          84.6760          10.9160            0.00s\n",
      "        20          53.8036           0.2805            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.8, learning_rate=0.05, score=0.212021, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         205.5813          22.2638            0.30s\n",
      "         2         198.9332          22.4691            0.14s\n",
      "         3         209.9556          -0.8094            0.09s\n",
      "         4         185.5978           1.7812            0.06s\n",
      "         5         117.9231           2.2885            0.05s\n",
      "         6         168.1631           0.1056            0.04s\n",
      "         7         131.8074          13.2168            0.03s\n",
      "         8         142.5929           1.0783            0.02s\n",
      "         9         130.3075          -0.8416            0.02s\n",
      "        10         112.0629          11.4218            0.02s\n",
      "        20          72.9578          -0.1754            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.8, learning_rate=0.05, score=-1.661746, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         127.4067           3.7214            0.00s\n",
      "         2         127.5733           2.2292            0.00s\n",
      "         3         159.2033          -0.4973            0.00s\n",
      "         4         140.2239          -0.0732            0.00s\n",
      "         5         128.8219           1.9968            0.05s\n",
      "         6         127.8568          -0.4449            0.04s\n",
      "         7          80.7699          11.8783            0.03s\n",
      "         8         111.7349          -1.0014            0.02s\n",
      "         9         100.8145          -0.2198            0.02s\n",
      "        10          82.1460           9.1513            0.02s\n",
      "        20          54.1039          -0.4034            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.8, learning_rate=0.05, score=-0.040242, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         210.7542          27.7115            0.00s\n",
      "         2         202.2091          22.4318            0.00s\n",
      "         3         218.3298           0.5161            0.00s\n",
      "         4         189.7704           3.1958            0.00s\n",
      "         5         124.2552           2.1012            0.00s\n",
      "         6         177.1254          -0.0853            0.00s\n",
      "         7         136.7902          15.5484            0.03s\n",
      "         8         148.7874          -0.5806            0.02s\n",
      "         9          95.9382           3.9840            0.02s\n",
      "        10         114.8695           1.8370            0.02s\n",
      "        20          74.3273          -0.2584            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.8, learning_rate=0.05, score=-4.722414, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         147.9161          49.6953            0.00s\n",
      "         2         218.0749          -0.9812            0.00s\n",
      "         3         170.0834          19.4873            0.00s\n",
      "         4         167.1435          -0.5983            0.00s\n",
      "         5         168.3374          -0.4309            0.00s\n",
      "         6         150.4835           0.1109            0.00s\n",
      "         7         116.4094          15.9285            0.00s\n",
      "         8         127.3297           1.1379            0.00s\n",
      "         9         117.8359           1.1663            0.00s\n",
      "        10          92.6741           4.0742            0.00s\n",
      "        20          58.4540          -1.2477            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.8, learning_rate=0.05, score=0.121902, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         158.3255          27.5288            0.00s\n",
      "         2         192.3097          -2.0664            0.00s\n",
      "         3         184.0155           0.5617            0.00s\n",
      "         4         154.1330           0.5367            0.00s\n",
      "         5         156.1989          -0.0544            0.00s\n",
      "         6         131.8712           0.5963            0.00s\n",
      "         7         107.6108          16.4488            0.00s\n",
      "         8         120.8746           1.2283            0.00s\n",
      "         9         111.8588          -0.9314            0.00s\n",
      "        10          95.2026          -0.3503            0.00s\n",
      "        20          52.1071          -0.1867            0.00s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  n_estimators=20, subsample=0.8, learning_rate=0.05, score=0.351278, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         287.9736          -0.7565            0.03s\n",
      "         2         261.5520           2.2923            0.03s\n",
      "         3         229.4453          -0.0105            0.02s\n",
      "         4         216.3591           0.8768            0.02s\n",
      "         5         136.2679           2.7670            0.02s\n",
      "         6         102.3316          12.7564            0.02s\n",
      "         7         174.8256           2.0569            0.02s\n",
      "         8         150.2438           8.8975            0.01s\n",
      "         9         162.6161           1.1299            0.01s\n",
      "        10         114.8951          -0.1415            0.01s\n",
      "        20          78.6247          -0.7271            0.01s\n",
      "        30          37.5994           0.2667            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.7, learning_rate=0.05, score=0.275644, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         289.8912          -1.1790            0.03s\n",
      "         2         264.0664          -0.3385            0.03s\n",
      "         3         231.1540          -0.0936            0.03s\n",
      "         4         213.5986           1.8984            0.03s\n",
      "         5         132.1037           0.6387            0.03s\n",
      "         6          99.9696          11.0747            0.02s\n",
      "         7         176.3750           1.1742            0.02s\n",
      "         8         148.8401           8.8957            0.02s\n",
      "         9         159.0204           3.5621            0.02s\n",
      "        10         118.8041           7.1564            0.02s\n",
      "        20          76.0601          -0.2070            0.01s\n",
      "        30          36.9563           0.4483            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.7, learning_rate=0.05, score=-1.026840, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         288.7676          -0.4958            0.03s\n",
      "         2         260.8576           2.3372            0.03s\n",
      "         3         229.2588           0.0750            0.03s\n",
      "         4         213.8526           0.7059            0.03s\n",
      "         5         127.8188           1.4648            0.02s\n",
      "         6         100.9612           7.1176            0.02s\n",
      "         7         178.5623           2.5173            0.02s\n",
      "         8         144.3274           7.8547            0.02s\n",
      "         9         162.8372           2.0646            0.02s\n",
      "        10         117.9719           7.0554            0.02s\n",
      "        20          76.2296          -2.3826            0.01s\n",
      "        30          34.6612           0.8876            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.7, learning_rate=0.05, score=0.221932, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         282.2828          -0.0102            0.00s\n",
      "         2         253.5370           1.6543            0.01s\n",
      "         3         223.2478           0.2454            0.02s\n",
      "         4         209.8703           0.5862            0.01s\n",
      "         5         125.9980           0.9530            0.02s\n",
      "         6          93.2883          10.1961            0.01s\n",
      "         7         173.7415           1.4318            0.01s\n",
      "         8         135.1072          10.4558            0.01s\n",
      "         9         153.5216           2.6928            0.01s\n",
      "        10         109.4107           7.0141            0.01s\n",
      "        20          70.8742          -1.9218            0.00s\n",
      "        30          33.8144           0.3714            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.7, learning_rate=0.05, score=0.137163, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         218.2648           0.4686            0.00s\n",
      "         2         193.4615           2.0600            0.00s\n",
      "         3         179.8763          -0.1774            0.00s\n",
      "         4         159.6389           1.1099            0.00s\n",
      "         5          77.2999           1.1221            0.00s\n",
      "         6          87.1573           7.1577            0.00s\n",
      "         7         136.2369           0.6059            0.00s\n",
      "         8         126.6066           0.1578            0.00s\n",
      "         9         124.5734          -0.0968            0.00s\n",
      "        10          93.3076           8.4527            0.00s\n",
      "        20          57.1697           0.0664            0.00s\n",
      "        30          26.5903           1.7657            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.7, learning_rate=0.05, score=0.107261, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         225.1204          17.0315            0.00s\n",
      "         2         207.3429          16.9920            0.00s\n",
      "         3         229.4716           1.3476            0.00s\n",
      "         4         193.4812           1.6320            0.00s\n",
      "         5         126.0808           1.2106            0.00s\n",
      "         6         131.6346           2.7756            0.00s\n",
      "         7         133.3527           9.5769            0.00s\n",
      "         8         163.2346           0.4488            0.00s\n",
      "         9         143.3374           0.6792            0.00s\n",
      "        10         124.4394           7.0784            0.00s\n",
      "        20          76.6747          -1.0176            0.00s\n",
      "        30          40.2286           0.0542            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.7, learning_rate=0.05, score=-1.553514, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         133.9842           0.9055            0.00s\n",
      "         2         123.8410          15.3338            0.00s\n",
      "         3         171.8981           1.6232            0.00s\n",
      "         4         138.3225           1.2471            0.00s\n",
      "         5         134.5724          -0.8331            0.00s\n",
      "         6         141.8770          -0.5574            0.00s\n",
      "         7          73.2841           1.3067            0.00s\n",
      "         8         127.2879          -0.7810            0.00s\n",
      "         9         110.1483           1.5023            0.00s\n",
      "        10          91.3234           6.2794            0.00s\n",
      "        20          60.3283           0.5448            0.00s\n",
      "        30          39.4301          -0.4026            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.7, learning_rate=0.05, score=0.071671, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         228.4113          16.0948            0.00s\n",
      "         2         208.2246          15.9924            0.00s\n",
      "         3         240.6272           1.1782            0.00s\n",
      "         4         202.7495           2.5096            0.00s\n",
      "         5         129.8965           0.5696            0.00s\n",
      "         6         196.2444          -0.3975            0.00s\n",
      "         7         132.1608           9.5669            0.00s\n",
      "         8         165.4871          -0.1151            0.00s\n",
      "         9         103.9404           3.2202            0.00s\n",
      "        10         125.6503           6.3469            0.00s\n",
      "        20          77.0482           0.0663            0.00s\n",
      "        30          49.1315          -0.4225            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.7, learning_rate=0.05, score=-1.893476, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         156.9905          35.8122            0.00s\n",
      "         2         230.4978          -1.0397            0.00s\n",
      "         3         185.0656          13.8384            0.00s\n",
      "         4         152.1994           8.4696            0.00s\n",
      "         5         185.1336           0.8325            0.00s\n",
      "         6         167.6584          -0.2808            0.00s\n",
      "         7         124.7295          11.6066            0.00s\n",
      "         8         138.4362           0.9995            0.00s\n",
      "         9          90.8820          -0.7740            0.00s\n",
      "        10         105.7159           7.3629            0.00s\n",
      "        20          56.7881           0.9323            0.00s\n",
      "        30          39.8741           0.0546            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.7, learning_rate=0.05, score=0.169137, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         166.7912          19.1280            0.00s\n",
      "         2         201.3738          -1.0168            0.00s\n",
      "         3         202.3122           1.6514            0.00s\n",
      "         4         168.0097           0.0956            0.00s\n",
      "         5         168.4248           0.5394            0.00s\n",
      "         6         147.4937           1.5592            0.00s\n",
      "         7         113.1946          10.3537            0.00s\n",
      "         8         130.4427          -0.0372            0.00s\n",
      "         9          79.6994          -0.4040            0.00s\n",
      "        10         107.6369           1.1828            0.00s\n",
      "        20          52.2437          -0.0602            0.00s\n",
      "        30          39.8847          -0.2959            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.7, learning_rate=0.05, score=0.615019, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         268.0527          -1.5883            0.00s\n",
      "         2         241.9591           1.0539            0.00s\n",
      "         3         214.6580          -0.2809            0.00s\n",
      "         4         204.7294           1.1407            0.00s\n",
      "         5         133.0443           2.8846            0.00s\n",
      "         6         149.3782          13.3313            0.00s\n",
      "         7         162.4382           1.6519            0.00s\n",
      "         8         136.6754           8.7842            0.00s\n",
      "         9         149.1879           1.3127            0.00s\n",
      "        10         122.7701          -0.3590            0.00s\n",
      "        20          76.8949           0.6460            0.00s\n",
      "        30          37.3772          -0.1253            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.75, learning_rate=0.05, score=0.465626, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         269.8733          -2.2693            0.00s\n",
      "         2         244.5319          -0.2242            0.00s\n",
      "         3         215.6269           0.1733            0.00s\n",
      "         4         201.7632           2.4753            0.00s\n",
      "         5         129.0312           0.4536            0.00s\n",
      "         6         146.6481          14.7172            0.00s\n",
      "         7         162.4356           0.9133            0.00s\n",
      "         8         133.9593           9.4031            0.00s\n",
      "         9         145.4613           2.1809            0.00s\n",
      "        10         123.0340           8.6540            0.00s\n",
      "        20          72.2249           0.8441            0.00s\n",
      "        30          35.9153           1.2181            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.75, learning_rate=0.05, score=-1.163921, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         270.2257          -2.1484            0.03s\n",
      "         2         243.3628           2.6208            0.01s\n",
      "         3         215.3946          -0.6160            0.02s\n",
      "         4         202.2680           2.5267            0.01s\n",
      "         5         125.4237           3.5690            0.01s\n",
      "         6         148.8767          11.1782            0.02s\n",
      "         7         164.0276           2.8294            0.01s\n",
      "         8         131.4368           8.4987            0.01s\n",
      "         9         148.9505           1.6405            0.01s\n",
      "        10         120.9108          -0.2270            0.01s\n",
      "        20          75.2901           0.4504            0.00s\n",
      "        30          32.6026           0.2156            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.75, learning_rate=0.05, score=0.220992, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         264.1448           0.1533            0.03s\n",
      "         2         235.6200           1.7001            0.01s\n",
      "         3         209.5950          -0.2452            0.03s\n",
      "         4         199.3489           1.1566            0.03s\n",
      "         5         123.2049           1.4258            0.03s\n",
      "         6         143.4356          13.9860            0.02s\n",
      "         7         163.0826           1.6629            0.02s\n",
      "         8         124.5009          12.2335            0.02s\n",
      "         9         144.0616           2.7077            0.02s\n",
      "        10         113.1198           8.5316            0.02s\n",
      "        20          67.3918           0.6146            0.01s\n",
      "        30          30.7386           0.4788            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.75, learning_rate=0.05, score=0.093679, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         204.1192          -0.1469            0.00s\n",
      "         2         183.1465           2.2665            0.01s\n",
      "         3         168.4147          -0.4337            0.02s\n",
      "         4         157.8817          -0.1274            0.01s\n",
      "         5          76.3381           5.4371            0.02s\n",
      "         6         137.9097          -0.4105            0.01s\n",
      "         7         125.8014          -0.1604            0.01s\n",
      "         8         114.1897          -0.5995            0.01s\n",
      "         9         115.8158          -0.9644            0.01s\n",
      "        10          85.9593           8.3826            0.01s\n",
      "        20          51.9370           0.5252            0.00s\n",
      "        30          26.7198           0.7155            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.75, learning_rate=0.05, score=0.065255, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         209.8049          18.1789            0.03s\n",
      "         2         197.5415          19.2881            0.03s\n",
      "         3         215.5563           0.0675            0.02s\n",
      "         4         187.7647           0.9669            0.02s\n",
      "         5         122.7889           1.6851            0.02s\n",
      "         6         175.1053          -1.5282            0.02s\n",
      "         7         135.6874          11.3252            0.02s\n",
      "         8         147.2330           0.9615            0.01s\n",
      "         9         135.0989          -0.4004            0.01s\n",
      "        10         116.2827           8.4709            0.01s\n",
      "        20          71.3483           0.5402            0.00s\n",
      "        30          37.1323           0.1841            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.75, learning_rate=0.05, score=-1.218033, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         126.5477           0.1852            0.03s\n",
      "         2         120.4698           2.2887            0.01s\n",
      "         3         164.1207           0.6620            0.02s\n",
      "         4         141.7157          -0.6886            0.01s\n",
      "         5         134.4763           0.0972            0.02s\n",
      "         6         134.7302          -0.2956            0.01s\n",
      "         7          83.9601          10.3598            0.01s\n",
      "         8         116.0170          -0.0490            0.01s\n",
      "         9         103.4701           0.9350            0.01s\n",
      "        10          85.0517           7.7244            0.01s\n",
      "        20          56.0271          -0.2888            0.00s\n",
      "        30          37.7032          -0.1053            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.75, learning_rate=0.05, score=0.054407, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         216.0023          22.7936            0.00s\n",
      "         2         202.2616          16.5841            0.00s\n",
      "         3         226.9424           1.5440            0.00s\n",
      "         4         194.8489           2.1965            0.00s\n",
      "         5         130.0177           1.6237            0.00s\n",
      "         6         187.2252          -0.0906            0.00s\n",
      "         7         140.4913          12.1321            0.00s\n",
      "         8         156.3404          -0.0501            0.00s\n",
      "         9         100.6794           1.9714            0.00s\n",
      "        10         120.3175          -1.5733            0.00s\n",
      "        20          74.9823           0.0094            0.01s\n",
      "        30          48.0922           0.0381            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.75, learning_rate=0.05, score=-3.768524, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         153.9567          37.6070            0.00s\n",
      "         2         227.4605           0.6571            0.00s\n",
      "         3         182.3300          15.1226            0.00s\n",
      "         4         178.1178          -0.2921            0.00s\n",
      "         5         180.9259           0.0589            0.00s\n",
      "         6         161.0233          -0.0041            0.00s\n",
      "         7         122.5322          12.7934            0.00s\n",
      "         8         135.2936           0.3861            0.00s\n",
      "         9          91.2823          -0.7171            0.03s\n",
      "        10         103.3137           5.7727            0.03s\n",
      "        20          59.4061          -1.1133            0.01s\n",
      "        30          40.5768          -0.0332            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.75, learning_rate=0.05, score=0.167483, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         163.7241          21.2369            0.00s\n",
      "         2         200.1829           0.9624            0.00s\n",
      "         3         196.6305           0.5399            0.00s\n",
      "         4         163.8048           0.8524            0.00s\n",
      "         5         162.3932           0.1074            0.00s\n",
      "         6         141.2258           1.2252            0.00s\n",
      "         7         111.0067          13.2590            0.00s\n",
      "         8         126.8180          -0.7288            0.00s\n",
      "         9          78.6346          -1.4484            0.00s\n",
      "        10         105.1129           0.9564            0.00s\n",
      "        20          56.6228          -1.0033            0.01s\n",
      "        30          39.2170          -1.1407            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.75, learning_rate=0.05, score=0.478472, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         257.4776          -2.3388            0.00s\n",
      "         2         241.7770           1.4257            0.00s\n",
      "         3         209.0030           0.4755            0.00s\n",
      "         4         200.7384           2.3963            0.00s\n",
      "         5         132.2427           2.0073            0.00s\n",
      "         6         141.7269          16.8199            0.00s\n",
      "         7         154.8332           1.6629            0.00s\n",
      "         8         130.6981          10.2961            0.00s\n",
      "         9         143.8746           1.6707            0.00s\n",
      "        10         118.3874          -1.7671            0.00s\n",
      "        20          77.2480          -0.7091            0.01s\n",
      "        30          35.0579          -0.1444            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.8, learning_rate=0.05, score=0.247443, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         258.8168          -2.8023            0.00s\n",
      "         2         244.5659           0.9362            0.00s\n",
      "         3         209.1942           0.2687            0.00s\n",
      "         4         197.9320           2.5709            0.00s\n",
      "         5         129.5730          -0.7873            0.00s\n",
      "         6         139.9396          15.3070            0.00s\n",
      "         7         155.3602           0.3441            0.00s\n",
      "         8         130.4724          12.9007            0.00s\n",
      "         9         142.3373           1.9727            0.00s\n",
      "        10         118.9281          10.6039            0.00s\n",
      "        20          73.8965          -0.8558            0.01s\n",
      "        30          36.6930           0.7108            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.8, learning_rate=0.05, score=-1.199165, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         257.8732          -2.3651            0.00s\n",
      "         2         241.8607           1.0871            0.00s\n",
      "         3         209.9834          -0.5204            0.00s\n",
      "         4         198.1589           1.9131            0.00s\n",
      "         5         124.3352           1.9173            0.00s\n",
      "         6         141.2271          17.1872            0.00s\n",
      "         7         155.8790           0.4138            0.00s\n",
      "         8         124.3954          12.6757            0.00s\n",
      "         9         141.2854           1.1341            0.00s\n",
      "        10         114.0630           0.1947            0.00s\n",
      "        20          76.0996          -0.2641            0.01s\n",
      "        30          31.8498          -0.2164            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.8, learning_rate=0.05, score=0.164493, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         252.0375           0.6366            0.00s\n",
      "         2         234.8903           1.0437            0.00s\n",
      "         3         203.2993          -1.0737            0.00s\n",
      "         4         196.3459           1.3811            0.00s\n",
      "         5         123.4720           0.9504            0.00s\n",
      "         6         136.7778          12.2434            0.00s\n",
      "         7         158.0998           1.4039            0.00s\n",
      "         8         119.2789          11.0843            0.00s\n",
      "         9         139.9259           2.2259            0.00s\n",
      "        10         109.6036          10.3356            0.00s\n",
      "        20          68.0858           0.5082            0.01s\n",
      "        30          29.7749           0.7168            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.8, learning_rate=0.05, score=-0.072300, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         200.1416          -0.0133            0.00s\n",
      "         2         186.6225           0.5539            0.00s\n",
      "         3         163.5990          -0.0425            0.00s\n",
      "         4         156.0444           0.4311            0.00s\n",
      "         5          77.2701           2.6414            0.00s\n",
      "         6         131.0229          -2.2096            0.00s\n",
      "         7         121.7491          -0.8032            0.00s\n",
      "         8         111.0033          -1.0983            0.00s\n",
      "         9         114.1929          -0.2507            0.00s\n",
      "        10          84.6760          10.9160            0.00s\n",
      "        20          53.8036           0.2805            0.01s\n",
      "        30          26.0121          -0.4607            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.8, learning_rate=0.05, score=0.030043, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         205.5813          22.2638            0.03s\n",
      "         2         198.9332          22.4691            0.03s\n",
      "         3         209.9556          -0.8094            0.02s\n",
      "         4         185.5978           1.7812            0.02s\n",
      "         5         117.9231           2.2885            0.02s\n",
      "         6         168.1631           0.1056            0.02s\n",
      "         7         131.8074          13.2168            0.01s\n",
      "         8         142.5929           1.0783            0.01s\n",
      "         9         130.3075          -0.8416            0.01s\n",
      "        10         112.0629          11.4218            0.01s\n",
      "        20          72.9578          -0.1754            0.00s\n",
      "        30          36.9837          -0.4933            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.8, learning_rate=0.05, score=-1.554384, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         127.4067           3.7214            0.03s\n",
      "         2         127.5733           2.2292            0.01s\n",
      "         3         159.2033          -0.4973            0.02s\n",
      "         4         140.2239          -0.0732            0.02s\n",
      "         5         128.8219           1.9968            0.02s\n",
      "         6         127.8568          -0.4449            0.02s\n",
      "         7          80.7699          11.8783            0.02s\n",
      "         8         111.7349          -1.0014            0.02s\n",
      "         9         100.8145          -0.2198            0.02s\n",
      "        10          82.1460           9.1513            0.02s\n",
      "        20          54.1039          -0.4034            0.01s\n",
      "        30          34.4313          -0.2560            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.8, learning_rate=0.05, score=0.024944, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         210.7542          27.7115            0.00s\n",
      "         2         202.2091          22.4318            0.01s\n",
      "         3         218.3298           0.5161            0.01s\n",
      "         4         189.7704           3.1958            0.01s\n",
      "         5         124.2552           2.1012            0.01s\n",
      "         6         177.1254          -0.0853            0.01s\n",
      "         7         136.7902          15.5484            0.01s\n",
      "         8         148.7874          -0.5806            0.01s\n",
      "         9          95.9382           3.9840            0.01s\n",
      "        10         114.8695           1.8370            0.01s\n",
      "        20          74.3273          -0.2584            0.00s\n",
      "        30          45.7374          -0.6486            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.8, learning_rate=0.05, score=-5.064700, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         147.9161          49.6953            0.00s\n",
      "         2         218.0749          -0.9812            0.00s\n",
      "         3         170.0834          19.4873            0.00s\n",
      "         4         167.1435          -0.5983            0.00s\n",
      "         5         168.3374          -0.4309            0.00s\n",
      "         6         150.4835           0.1109            0.00s\n",
      "         7         116.4094          15.9285            0.00s\n",
      "         8         127.3297           1.1379            0.00s\n",
      "         9         117.8359           1.1663            0.00s\n",
      "        10          92.6741           4.0742            0.00s\n",
      "        20          58.4540          -1.2477            0.00s\n",
      "        30          35.5772          -0.1097            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.8, learning_rate=0.05, score=0.161031, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         158.3255          27.5288            0.00s\n",
      "         2         192.3097          -2.0664            0.00s\n",
      "         3         184.0155           0.5617            0.00s\n",
      "         4         154.1330           0.5367            0.00s\n",
      "         5         156.1989          -0.0544            0.00s\n",
      "         6         131.8712           0.5963            0.00s\n",
      "         7         107.6108          16.4488            0.00s\n",
      "         8         120.8746           1.2283            0.00s\n",
      "         9         111.8588          -0.9314            0.00s\n",
      "        10          95.2026          -0.3503            0.00s\n",
      "        20          52.1071          -0.1867            0.00s\n",
      "        30          35.0050          -0.9010            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.8, learning_rate=0.05, score=0.451713, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         287.9736          -0.7565            0.00s\n",
      "         2         261.5520           2.2923            0.00s\n",
      "         3         229.4453          -0.0105            0.00s\n",
      "         4         216.3591           0.8768            0.00s\n",
      "         5         136.2679           2.7670            0.00s\n",
      "         6         102.3316          12.7564            0.00s\n",
      "         7         174.8256           2.0569            0.00s\n",
      "         8         150.2438           8.8975            0.00s\n",
      "         9         162.6161           1.1299            0.00s\n",
      "        10         114.8951          -0.1415            0.00s\n",
      "        20          78.6247          -0.7271            0.00s\n",
      "        30          37.5994           0.2667            0.01s\n",
      "        40          36.9691          -0.8229            0.00s\n",
      "        50          23.1494          -0.5878            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.7, learning_rate=0.05, score=0.287673, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         289.8912          -1.1790            0.00s\n",
      "         2         264.0664          -0.3385            0.00s\n",
      "         3         231.1540          -0.0936            0.00s\n",
      "         4         213.5986           1.8984            0.00s\n",
      "         5         132.1037           0.6387            0.00s\n",
      "         6          99.9696          11.0747            0.11s\n",
      "         7         176.3750           1.1742            0.09s\n",
      "         8         148.8401           8.8957            0.08s\n",
      "         9         159.0204           3.5621            0.07s\n",
      "        10         118.8041           7.1564            0.06s\n",
      "        20          76.0601          -0.2070            0.02s\n",
      "        30          36.9563           0.4483            0.01s\n",
      "        40          32.2758          -1.2277            0.00s\n",
      "        50          19.8651          -1.2161            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.7, learning_rate=0.05, score=-1.570887, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         288.7676          -0.4958            0.00s\n",
      "         2         260.8576           2.3372            0.00s\n",
      "         3         229.2588           0.0750            0.00s\n",
      "         4         213.8526           0.7059            0.00s\n",
      "         5         127.8188           1.4648            0.00s\n",
      "         6         100.9612           7.1176            0.00s\n",
      "         7         178.5623           2.5173            0.00s\n",
      "         8         144.3274           7.8547            0.00s\n",
      "         9         162.8372           2.0646            0.00s\n",
      "        10         117.9719           7.0554            0.00s\n",
      "        20          76.2296          -2.3826            0.00s\n",
      "        30          34.6612           0.8876            0.01s\n",
      "        40          32.8047          -0.7608            0.00s\n",
      "        50          22.0184          -0.3413            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.7, learning_rate=0.05, score=0.180775, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         282.2828          -0.0102            0.00s\n",
      "         2         253.5370           1.6543            0.00s\n",
      "         3         223.2478           0.2454            0.00s\n",
      "         4         209.8703           0.5862            0.00s\n",
      "         5         125.9980           0.9530            0.00s\n",
      "         6          93.2883          10.1961            0.00s\n",
      "         7         173.7415           1.4318            0.00s\n",
      "         8         135.1072          10.4558            0.00s\n",
      "         9         153.5216           2.6928            0.07s\n",
      "        10         109.4107           7.0141            0.06s\n",
      "        20          70.8742          -1.9218            0.02s\n",
      "        30          33.8144           0.3714            0.01s\n",
      "        40          33.3849           0.0600            0.00s\n",
      "        50          21.9482          -0.8878            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.7, learning_rate=0.05, score=0.192689, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         218.2648           0.4686            0.00s\n",
      "         2         193.4615           2.0600            0.00s\n",
      "         3         179.8763          -0.1774            0.00s\n",
      "         4         159.6389           1.1099            0.00s\n",
      "         5          77.2999           1.1221            0.00s\n",
      "         6          87.1573           7.1577            0.00s\n",
      "         7         136.2369           0.6059            0.00s\n",
      "         8         126.6066           0.1578            0.00s\n",
      "         9         124.5734          -0.0968            0.00s\n",
      "        10          93.3076           8.4527            0.00s\n",
      "        20          57.1697           0.0664            0.00s\n",
      "        30          26.5903           1.7657            0.00s\n",
      "        40          21.3004           0.0212            0.00s\n",
      "        50          15.4694          -0.4036            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.7, learning_rate=0.05, score=-0.292111, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         225.1204          17.0315            0.00s\n",
      "         2         207.3429          16.9920            0.02s\n",
      "         3         229.4716           1.3476            0.02s\n",
      "         4         193.4812           1.6320            0.02s\n",
      "         5         126.0808           1.2106            0.02s\n",
      "         6         131.6346           2.7756            0.02s\n",
      "         7         133.3527           9.5769            0.02s\n",
      "         8         163.2346           0.4488            0.02s\n",
      "         9         143.3374           0.6792            0.02s\n",
      "        10         124.4394           7.0784            0.02s\n",
      "        20          76.6747          -1.0176            0.01s\n",
      "        30          40.2286           0.0542            0.01s\n",
      "        40          30.0616           1.1584            0.00s\n",
      "        50          14.7093          -0.8203            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.7, learning_rate=0.05, score=-1.481445, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         133.9842           0.9055            0.00s\n",
      "         2         123.8410          15.3338            0.02s\n",
      "         3         171.8981           1.6232            0.03s\n",
      "         4         138.3225           1.2471            0.02s\n",
      "         5         134.5724          -0.8331            0.04s\n",
      "         6         141.8770          -0.5574            0.04s\n",
      "         7          73.2841           1.3067            0.04s\n",
      "         8         127.2879          -0.7810            0.03s\n",
      "         9         110.1483           1.5023            0.03s\n",
      "        10          91.3234           6.2794            0.03s\n",
      "        20          60.3283           0.5448            0.02s\n",
      "        30          39.4301          -0.4026            0.01s\n",
      "        40          23.3527           0.2605            0.00s\n",
      "        50          11.8372           0.0361            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.7, learning_rate=0.05, score=0.144835, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         228.4113          16.0948            0.00s\n",
      "         2         208.2246          15.9924            0.02s\n",
      "         3         240.6272           1.1782            0.02s\n",
      "         4         202.7495           2.5096            0.02s\n",
      "         5         129.8965           0.5696            0.02s\n",
      "         6         196.2444          -0.3975            0.02s\n",
      "         7         132.1608           9.5669            0.02s\n",
      "         8         165.4871          -0.1151            0.02s\n",
      "         9         103.9404           3.2202            0.02s\n",
      "        10         125.6503           6.3469            0.02s\n",
      "        20          77.0482           0.0663            0.01s\n",
      "        30          49.1315          -0.4225            0.01s\n",
      "        40          31.2053           0.2877            0.00s\n",
      "        50          17.1307          -0.0683            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.7, learning_rate=0.05, score=-2.368101, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         156.9905          35.8122            0.00s\n",
      "         2         230.4978          -1.0397            0.00s\n",
      "         3         185.0656          13.8384            0.00s\n",
      "         4         152.1994           8.4696            0.00s\n",
      "         5         185.1336           0.8325            0.00s\n",
      "         6         167.6584          -0.2808            0.00s\n",
      "         7         124.7295          11.6066            0.00s\n",
      "         8         138.4362           0.9995            0.00s\n",
      "         9          90.8820          -0.7740            0.00s\n",
      "        10         105.7159           7.3629            0.00s\n",
      "        20          56.7881           0.9323            0.02s\n",
      "        30          39.8741           0.0546            0.01s\n",
      "        40          20.5276          -0.3138            0.00s\n",
      "        50          20.6773          -0.2903            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.7, learning_rate=0.05, score=0.205817, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         166.7912          19.1280            0.00s\n",
      "         2         201.3738          -1.0168            0.38s\n",
      "         3         202.3122           1.6514            0.25s\n",
      "         4         168.0097           0.0956            0.18s\n",
      "         5         168.4248           0.5394            0.14s\n",
      "         6         147.4937           1.5592            0.12s\n",
      "         7         113.1946          10.3537            0.10s\n",
      "         8         130.4427          -0.0372            0.08s\n",
      "         9          79.6994          -0.4040            0.07s\n",
      "        10         107.6369           1.1828            0.06s\n",
      "        20          52.2437          -0.0602            0.02s\n",
      "        30          39.8847          -0.2959            0.01s\n",
      "        40          25.9608          -0.0217            0.00s\n",
      "        50          22.4357          -0.1229            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.7, learning_rate=0.05, score=0.663245, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         268.0527          -1.5883            0.00s\n",
      "         2         241.9591           1.0539            0.00s\n",
      "         3         214.6580          -0.2809            0.00s\n",
      "         4         204.7294           1.1407            0.00s\n",
      "         5         133.0443           2.8846            0.00s\n",
      "         6         149.3782          13.3313            0.00s\n",
      "         7         162.4382           1.6519            0.00s\n",
      "         8         136.6754           8.7842            0.00s\n",
      "         9         149.1879           1.3127            0.00s\n",
      "        10         122.7701          -0.3590            0.00s\n",
      "        20          76.8949           0.6460            0.00s\n",
      "        30          37.3772          -0.1253            0.01s\n",
      "        40          30.2933          -0.3243            0.00s\n",
      "        50          23.1466          -0.7874            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.75, learning_rate=0.05, score=0.366124, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         269.8733          -2.2693            0.00s\n",
      "         2         244.5319          -0.2242            0.00s\n",
      "         3         215.6269           0.1733            0.00s\n",
      "         4         201.7632           2.4753            0.00s\n",
      "         5         129.0312           0.4536            0.14s\n",
      "         6         146.6481          14.7172            0.12s\n",
      "         7         162.4356           0.9133            0.10s\n",
      "         8         133.9593           9.4031            0.08s\n",
      "         9         145.4613           2.1809            0.07s\n",
      "        10         123.0340           8.6540            0.06s\n",
      "        20          72.2249           0.8441            0.02s\n",
      "        30          35.9153           1.2181            0.01s\n",
      "        40          27.6550          -1.5833            0.00s\n",
      "        50          20.7931          -0.1686            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.75, learning_rate=0.05, score=-1.426294, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         270.2257          -2.1484            0.00s\n",
      "         2         243.3628           2.6208            0.00s\n",
      "         3         215.3946          -0.6160            0.00s\n",
      "         4         202.2680           2.5267            0.00s\n",
      "         5         125.4237           3.5690            0.00s\n",
      "         6         148.8767          11.1782            0.00s\n",
      "         7         164.0276           2.8294            0.00s\n",
      "         8         131.4368           8.4987            0.00s\n",
      "         9         148.9505           1.6405            0.00s\n",
      "        10         120.9108          -0.2270            0.00s\n",
      "        20          75.2901           0.4504            0.00s\n",
      "        30          32.6026           0.2156            0.01s\n",
      "        40          27.9272          -0.9515            0.00s\n",
      "        50          21.3200          -0.1229            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.75, learning_rate=0.05, score=0.076898, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         264.1448           0.1533            0.00s\n",
      "         2         235.6200           1.7001            0.00s\n",
      "         3         209.5950          -0.2452            0.00s\n",
      "         4         199.3489           1.1566            0.00s\n",
      "         5         123.2049           1.4258            0.00s\n",
      "         6         143.4356          13.9860            0.00s\n",
      "         7         163.0826           1.6629            0.00s\n",
      "         8         124.5009          12.2335            0.00s\n",
      "         9         144.0616           2.7077            0.00s\n",
      "        10         113.1198           8.5316            0.06s\n",
      "        20          67.3918           0.6146            0.02s\n",
      "        30          30.7386           0.4788            0.01s\n",
      "        40          28.5621          -0.6870            0.00s\n",
      "        50          22.5626          -0.1401            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.75, learning_rate=0.05, score=0.086454, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         204.1192          -0.1469            0.00s\n",
      "         2         183.1465           2.2665            0.14s\n",
      "         3         168.4147          -0.4337            0.11s\n",
      "         4         157.8817          -0.1274            0.08s\n",
      "         5          76.3381           5.4371            0.07s\n",
      "         6         137.9097          -0.4105            0.06s\n",
      "         7         125.8014          -0.1604            0.06s\n",
      "         8         114.1897          -0.5995            0.05s\n",
      "         9         115.8158          -0.9644            0.05s\n",
      "        10          85.9593           8.3826            0.04s\n",
      "        20          51.9370           0.5252            0.02s\n",
      "        30          26.7198           0.7155            0.01s\n",
      "        40          19.4742          -0.3531            0.01s\n",
      "        50          15.5695           0.0011            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.75, learning_rate=0.05, score=-0.318338, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         209.8049          18.1789            0.00s\n",
      "         2         197.5415          19.2881            0.02s\n",
      "         3         215.5563           0.0675            0.03s\n",
      "         4         187.7647           0.9669            0.02s\n",
      "         5         122.7889           1.6851            0.03s\n",
      "         6         175.1053          -1.5282            0.02s\n",
      "         7         135.6874          11.3252            0.02s\n",
      "         8         147.2330           0.9615            0.02s\n",
      "         9         135.0989          -0.4004            0.02s\n",
      "        10         116.2827           8.4709            0.02s\n",
      "        20          71.3483           0.5402            0.01s\n",
      "        30          37.1323           0.1841            0.01s\n",
      "        40          27.5912           0.5038            0.00s\n",
      "        50          14.7195          -0.2992            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.75, learning_rate=0.05, score=-1.150164, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         126.5477           0.1852            0.05s\n",
      "         2         120.4698           2.2887            0.02s\n",
      "         3         164.1207           0.6620            0.05s\n",
      "         4         141.7157          -0.6886            0.03s\n",
      "         5         134.4763           0.0972            0.04s\n",
      "         6         134.7302          -0.2956            0.03s\n",
      "         7          83.9601          10.3598            0.02s\n",
      "         8         116.0170          -0.0490            0.03s\n",
      "         9         103.4701           0.9350            0.03s\n",
      "        10          85.0517           7.7244            0.02s\n",
      "        20          56.0271          -0.2888            0.01s\n",
      "        30          37.7032          -0.1053            0.01s\n",
      "        40          19.5174           0.3494            0.00s\n",
      "        50          11.7854          -0.1743            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.75, learning_rate=0.05, score=0.159360, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         216.0023          22.7936            0.05s\n",
      "         2         202.2616          16.5841            0.02s\n",
      "         3         226.9424           1.5440            0.03s\n",
      "         4         194.8489           2.1965            0.02s\n",
      "         5         130.0177           1.6237            0.03s\n",
      "         6         187.2252          -0.0906            0.02s\n",
      "         7         140.4913          12.1321            0.02s\n",
      "         8         156.3404          -0.0501            0.02s\n",
      "         9         100.6794           1.9714            0.02s\n",
      "        10         120.3175          -1.5733            0.02s\n",
      "        20          74.9823           0.0094            0.01s\n",
      "        30          48.0922           0.0381            0.01s\n",
      "        40          31.3057           0.2311            0.00s\n",
      "        50          17.4502          -0.6286            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.75, learning_rate=0.05, score=-4.687004, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         153.9567          37.6070            0.00s\n",
      "         2         227.4605           0.6571            0.00s\n",
      "         3         182.3300          15.1226            0.00s\n",
      "         4         178.1178          -0.2921            0.00s\n",
      "         5         180.9259           0.0589            0.00s\n",
      "         6         161.0233          -0.0041            0.00s\n",
      "         7         122.5322          12.7934            0.00s\n",
      "         8         135.2936           0.3861            0.00s\n",
      "         9          91.2823          -0.7171            0.00s\n",
      "        10         103.3137           5.7727            0.00s\n",
      "        20          59.4061          -1.1133            0.00s\n",
      "        30          40.5768          -0.0332            0.01s\n",
      "        40          19.4983          -0.6226            0.00s\n",
      "        50          20.6462          -0.2445            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.75, learning_rate=0.05, score=0.204958, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         163.7241          21.2369            0.00s\n",
      "         2         200.1829           0.9624            0.00s\n",
      "         3         196.6305           0.5399            0.00s\n",
      "         4         163.8048           0.8524            0.00s\n",
      "         5         162.3932           0.1074            0.14s\n",
      "         6         141.2258           1.2252            0.11s\n",
      "         7         111.0067          13.2590            0.09s\n",
      "         8         126.8180          -0.7288            0.08s\n",
      "         9          78.6346          -1.4484            0.07s\n",
      "        10         105.1129           0.9564            0.06s\n",
      "        20          56.6228          -1.0033            0.02s\n",
      "        30          39.2170          -1.1407            0.01s\n",
      "        40          23.7424          -0.2411            0.01s\n",
      "        50          21.2572          -0.1544            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.75, learning_rate=0.05, score=0.557705, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         257.4776          -2.3388            0.00s\n",
      "         2         241.7770           1.4257            0.00s\n",
      "         3         209.0030           0.4755            0.00s\n",
      "         4         200.7384           2.3963            0.00s\n",
      "         5         132.2427           2.0073            0.00s\n",
      "         6         141.7269          16.8199            0.00s\n",
      "         7         154.8332           1.6629            0.00s\n",
      "         8         130.6981          10.2961            0.00s\n",
      "         9         143.8746           1.6707            0.00s\n",
      "        10         118.3874          -1.7671            0.00s\n",
      "        20          77.2480          -0.7091            0.02s\n",
      "        30          35.0579          -0.1444            0.01s\n",
      "        40          32.1287          -0.4230            0.00s\n",
      "        50          24.5360          -0.2195            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.8, learning_rate=0.05, score=0.268630, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         258.8168          -2.8023            0.00s\n",
      "         2         244.5659           0.9362            0.00s\n",
      "         3         209.1942           0.2687            0.00s\n",
      "         4         197.9320           2.5709            0.00s\n",
      "         5         129.5730          -0.7873            0.00s\n",
      "         6         139.9396          15.3070            0.00s\n",
      "         7         155.3602           0.3441            0.00s\n",
      "         8         130.4724          12.9007            0.00s\n",
      "         9         142.3373           1.9727            0.00s\n",
      "        10         118.9281          10.6039            0.00s\n",
      "        20          73.8965          -0.8558            0.00s\n",
      "        30          36.6930           0.7108            0.01s\n",
      "        40          28.3404          -0.4593            0.00s\n",
      "        50          20.5258          -0.3272            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.8, learning_rate=0.05, score=-1.588183, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         257.8732          -2.3651            0.00s\n",
      "         2         241.8607           1.0871            0.00s\n",
      "         3         209.9834          -0.5204            0.00s\n",
      "         4         198.1589           1.9131            0.00s\n",
      "         5         124.3352           1.9173            0.00s\n",
      "         6         141.2271          17.1872            0.00s\n",
      "         7         155.8790           0.4138            0.00s\n",
      "         8         124.3954          12.6757            0.08s\n",
      "         9         141.2854           1.1341            0.07s\n",
      "        10         114.0630           0.1947            0.06s\n",
      "        20          76.0996          -0.2641            0.03s\n",
      "        30          31.8498          -0.2164            0.02s\n",
      "        40          29.1867          -0.0737            0.01s\n",
      "        50          21.0118          -0.2004            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.8, learning_rate=0.05, score=-0.002766, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         252.0375           0.6366            0.05s\n",
      "         2         234.8903           1.0437            0.02s\n",
      "         3         203.2993          -1.0737            0.03s\n",
      "         4         196.3459           1.3811            0.02s\n",
      "         5         123.4720           0.9504            0.03s\n",
      "         6         136.7778          12.2434            0.03s\n",
      "         7         158.0998           1.4039            0.02s\n",
      "         8         119.2789          11.0843            0.03s\n",
      "         9         139.9259           2.2259            0.02s\n",
      "        10         109.6036          10.3356            0.02s\n",
      "        20          68.0858           0.5082            0.01s\n",
      "        30          29.7749           0.7168            0.01s\n",
      "        40          29.5987          -0.2540            0.00s\n",
      "        50          21.8601           0.0100            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.8, learning_rate=0.05, score=-0.097774, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         200.1416          -0.0133            0.05s\n",
      "         2         186.6225           0.5539            0.02s\n",
      "         3         163.5990          -0.0425            0.03s\n",
      "         4         156.0444           0.4311            0.03s\n",
      "         5          77.2701           2.6414            0.04s\n",
      "         6         131.0229          -2.2096            0.04s\n",
      "         7         121.7491          -0.8032            0.03s\n",
      "         8         111.0033          -1.0983            0.03s\n",
      "         9         114.1929          -0.2507            0.03s\n",
      "        10          84.6760          10.9160            0.03s\n",
      "        20          53.8036           0.2805            0.01s\n",
      "        30          26.0121          -0.4607            0.01s\n",
      "        40          20.7414          -0.4223            0.00s\n",
      "        50          15.2931           0.0791            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.8, learning_rate=0.05, score=-0.372131, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         205.5813          22.2638            0.00s\n",
      "         2         198.9332          22.4691            0.02s\n",
      "         3         209.9556          -0.8094            0.03s\n",
      "         4         185.5978           1.7812            0.03s\n",
      "         5         117.9231           2.2885            0.03s\n",
      "         6         168.1631           0.1056            0.03s\n",
      "         7         131.8074          13.2168            0.02s\n",
      "         8         142.5929           1.0783            0.03s\n",
      "         9         130.3075          -0.8416            0.02s\n",
      "        10         112.0629          11.4218            0.02s\n",
      "        20          72.9578          -0.1754            0.01s\n",
      "        30          36.9837          -0.4933            0.01s\n",
      "        40          29.2648           0.4016            0.00s\n",
      "        50          21.0315           0.0438            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.8, learning_rate=0.05, score=-1.574920, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         127.4067           3.7214            0.00s\n",
      "         2         127.5733           2.2292            0.00s\n",
      "         3         159.2033          -0.4973            0.00s\n",
      "         4         140.2239          -0.0732            0.00s\n",
      "         5         128.8219           1.9968            0.00s\n",
      "         6         127.8568          -0.4449            0.00s\n",
      "         7          80.7699          11.8783            0.00s\n",
      "         8         111.7349          -1.0014            0.00s\n",
      "         9         100.8145          -0.2198            0.00s\n",
      "        10          82.1460           9.1513            0.00s\n",
      "        20          54.1039          -0.4034            0.00s\n",
      "        30          34.4313          -0.2560            0.00s\n",
      "        40          19.8102           0.1104            0.00s\n",
      "        50          15.6699           0.0224            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.8, learning_rate=0.05, score=0.063639, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         210.7542          27.7115            0.00s\n",
      "         2         202.2091          22.4318            0.00s\n",
      "         3         218.3298           0.5161            0.00s\n",
      "         4         189.7704           3.1958            0.00s\n",
      "         5         124.2552           2.1012            0.00s\n",
      "         6         177.1254          -0.0853            0.00s\n",
      "         7         136.7902          15.5484            0.00s\n",
      "         8         148.7874          -0.5806            0.00s\n",
      "         9          95.9382           3.9840            0.00s\n",
      "        10         114.8695           1.8370            0.00s\n",
      "        20          74.3273          -0.2584            0.02s\n",
      "        30          45.7374          -0.6486            0.01s\n",
      "        40          30.5957           0.4334            0.00s\n",
      "        50          22.5067          -0.4684            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.8, learning_rate=0.05, score=-6.493919, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         147.9161          49.6953            0.00s\n",
      "         2         218.0749          -0.9812            0.00s\n",
      "         3         170.0834          19.4873            0.00s\n",
      "         4         167.1435          -0.5983            0.00s\n",
      "         5         168.3374          -0.4309            0.00s\n",
      "         6         150.4835           0.1109            0.00s\n",
      "         7         116.4094          15.9285            0.00s\n",
      "         8         127.3297           1.1379            0.00s\n",
      "         9         117.8359           1.1663            0.00s\n",
      "        10          92.6741           4.0742            0.00s\n",
      "        20          58.4540          -1.2477            0.00s\n",
      "        30          35.5772          -0.1097            0.00s\n",
      "        40          18.8754          -0.4059            0.00s\n",
      "        50          19.2066          -0.0673            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.8, learning_rate=0.05, score=0.189829, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         158.3255          27.5288            0.00s\n",
      "         2         192.3097          -2.0664            0.00s\n",
      "         3         184.0155           0.5617            0.00s\n",
      "         4         154.1330           0.5367            0.00s\n",
      "         5         156.1989          -0.0544            0.00s\n",
      "         6         131.8712           0.5963            0.00s\n",
      "         7         107.6108          16.4488            0.00s\n",
      "         8         120.8746           1.2283            0.00s\n",
      "         9         111.8588          -0.9314            0.00s\n",
      "        10          95.2026          -0.3503            0.06s\n",
      "        20          52.1071          -0.1867            0.02s\n",
      "        30          35.0050          -0.9010            0.01s\n",
      "        40          21.6973          -0.4732            0.00s\n",
      "        50          19.7562          -0.3959            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.8, learning_rate=0.05, score=0.514119, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         287.9736          -0.7565            0.00s\n",
      "         2         261.5520           2.2923            0.00s\n",
      "         3         229.4453          -0.0105            0.00s\n",
      "         4         216.3591           0.8768            0.00s\n",
      "         5         136.2679           2.7670            0.00s\n",
      "         6         102.3316          12.7564            0.00s\n",
      "         7         174.8256           2.0569            0.00s\n",
      "         8         150.2438           8.8975            0.00s\n",
      "         9         162.6161           1.1299            0.00s\n",
      "        10         114.8951          -0.1415            0.00s\n",
      "        20          78.6247          -0.7271            0.00s\n",
      "        30          37.5994           0.2667            0.00s\n",
      "        40          36.9691          -0.8229            0.01s\n",
      "        50          23.1494          -0.5878            0.00s\n",
      "        60          12.8760          -0.6862            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.7, learning_rate=0.05, score=0.118740, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         289.8912          -1.1790            0.88s\n",
      "         2         264.0664          -0.3385            0.43s\n",
      "         3         231.1540          -0.0936            0.28s\n",
      "         4         213.5986           1.8984            0.25s\n",
      "         5         132.1037           0.6387            0.20s\n",
      "         6          99.9696          11.0747            0.17s\n",
      "         7         176.3750           1.1742            0.14s\n",
      "         8         148.8401           8.8957            0.13s\n",
      "         9         159.0204           3.5621            0.11s\n",
      "        10         118.8041           7.1564            0.11s\n",
      "        20          76.0601          -0.2070            0.05s\n",
      "        30          36.9563           0.4483            0.03s\n",
      "        40          32.2758          -1.2277            0.02s\n",
      "        50          19.8651          -1.2161            0.01s\n",
      "        60          12.7640          -0.8902            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.7, learning_rate=0.05, score=-1.465045, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         288.7676          -0.4958            0.06s\n",
      "         2         260.8576           2.3372            0.06s\n",
      "         3         229.2588           0.0750            0.04s\n",
      "         4         213.8526           0.7059            0.04s\n",
      "         5         127.8188           1.4648            0.04s\n",
      "         6         100.9612           7.1176            0.04s\n",
      "         7         178.5623           2.5173            0.04s\n",
      "         8         144.3274           7.8547            0.04s\n",
      "         9         162.8372           2.0646            0.03s\n",
      "        10         117.9719           7.0554            0.03s\n",
      "        20          76.2296          -2.3826            0.02s\n",
      "        30          34.6612           0.8876            0.01s\n",
      "        40          32.8047          -0.7608            0.01s\n",
      "        50          22.0184          -0.3413            0.00s\n",
      "        60          11.5588          -0.4660            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.7, learning_rate=0.05, score=0.094088, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         282.2828          -0.0102            0.00s\n",
      "         2         253.5370           1.6543            0.03s\n",
      "         3         223.2478           0.2454            0.04s\n",
      "         4         209.8703           0.5862            0.03s\n",
      "         5         125.9980           0.9530            0.03s\n",
      "         6          93.2883          10.1961            0.03s\n",
      "         7         173.7415           1.4318            0.03s\n",
      "         8         135.1072          10.4558            0.03s\n",
      "         9         153.5216           2.6928            0.03s\n",
      "        10         109.4107           7.0141            0.03s\n",
      "        20          70.8742          -1.9218            0.02s\n",
      "        30          33.8144           0.3714            0.01s\n",
      "        40          33.3849           0.0600            0.01s\n",
      "        50          21.9482          -0.8878            0.00s\n",
      "        60          10.2359          -0.5246            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.7, learning_rate=0.05, score=0.209410, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         218.2648           0.4686            0.00s\n",
      "         2         193.4615           2.0600            0.03s\n",
      "         3         179.8763          -0.1774            0.02s\n",
      "         4         159.6389           1.1099            0.03s\n",
      "         5          77.2999           1.1221            0.02s\n",
      "         6          87.1573           7.1577            0.03s\n",
      "         7         136.2369           0.6059            0.02s\n",
      "         8         126.6066           0.1578            0.03s\n",
      "         9         124.5734          -0.0968            0.02s\n",
      "        10          93.3076           8.4527            0.02s\n",
      "        20          57.1697           0.0664            0.01s\n",
      "        30          26.5903           1.7657            0.00s\n",
      "        40          21.3004           0.0212            0.00s\n",
      "        50          15.4694          -0.4036            0.00s\n",
      "        60           9.6476          -0.2568            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.7, learning_rate=0.05, score=-0.430039, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         225.1204          17.0315            0.00s\n",
      "         2         207.3429          16.9920            0.00s\n",
      "         3         229.4716           1.3476            0.00s\n",
      "         4         193.4812           1.6320            0.00s\n",
      "         5         126.0808           1.2106            0.00s\n",
      "         6         131.6346           2.7756            0.00s\n",
      "         7         133.3527           9.5769            0.00s\n",
      "         8         163.2346           0.4488            0.00s\n",
      "         9         143.3374           0.6792            0.00s\n",
      "        10         124.4394           7.0784            0.00s\n",
      "        20          76.6747          -1.0176            0.00s\n",
      "        30          40.2286           0.0542            0.02s\n",
      "        40          30.0616           1.1584            0.01s\n",
      "        50          14.7093          -0.8203            0.00s\n",
      "        60          12.5212          -0.2473            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.7, learning_rate=0.05, score=-1.351058, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         133.9842           0.9055            0.94s\n",
      "         2         123.8410          15.3338            0.46s\n",
      "         3         171.8981           1.6232            0.30s\n",
      "         4         138.3225           1.2471            0.22s\n",
      "         5         134.5724          -0.8331            0.18s\n",
      "         6         141.8770          -0.5574            0.14s\n",
      "         7          73.2841           1.3067            0.12s\n",
      "         8         127.2879          -0.7810            0.10s\n",
      "         9         110.1483           1.5023            0.09s\n",
      "        10          91.3234           6.2794            0.08s\n",
      "        20          60.3283           0.5448            0.03s\n",
      "        30          39.4301          -0.4026            0.02s\n",
      "        40          23.3527           0.2605            0.01s\n",
      "        50          11.8372           0.0361            0.01s\n",
      "        60           8.4997          -0.3663            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.7, learning_rate=0.05, score=0.164302, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         228.4113          16.0948            0.00s\n",
      "         2         208.2246          15.9924            0.00s\n",
      "         3         240.6272           1.1782            0.00s\n",
      "         4         202.7495           2.5096            0.00s\n",
      "         5         129.8965           0.5696            0.00s\n",
      "         6         196.2444          -0.3975            0.00s\n",
      "         7         132.1608           9.5669            0.00s\n",
      "         8         165.4871          -0.1151            0.00s\n",
      "         9         103.9404           3.2202            0.00s\n",
      "        10         125.6503           6.3469            0.08s\n",
      "        20          77.0482           0.0663            0.03s\n",
      "        30          49.1315          -0.4225            0.02s\n",
      "        40          31.2053           0.2877            0.01s\n",
      "        50          17.1307          -0.0683            0.00s\n",
      "        60          12.4441           0.0003            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.7, learning_rate=0.05, score=-2.328524, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         156.9905          35.8122            0.00s\n",
      "         2         230.4978          -1.0397            0.00s\n",
      "         3         185.0656          13.8384            0.00s\n",
      "         4         152.1994           8.4696            0.00s\n",
      "         5         185.1336           0.8325            0.00s\n",
      "         6         167.6584          -0.2808            0.00s\n",
      "         7         124.7295          11.6066            0.00s\n",
      "         8         138.4362           0.9995            0.00s\n",
      "         9          90.8820          -0.7740            0.00s\n",
      "        10         105.7159           7.3629            0.00s\n",
      "        20          56.7881           0.9323            0.00s\n",
      "        30          39.8741           0.0546            0.00s\n",
      "        40          20.5276          -0.3138            0.01s\n",
      "        50          20.6773          -0.2903            0.00s\n",
      "        60          12.8600          -0.6354            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.7, learning_rate=0.05, score=0.232311, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         166.7912          19.1280            0.06s\n",
      "         2         201.3738          -1.0168            0.06s\n",
      "         3         202.3122           1.6514            0.04s\n",
      "         4         168.0097           0.0956            0.04s\n",
      "         5         168.4248           0.5394            0.03s\n",
      "         6         147.4937           1.5592            0.04s\n",
      "         7         113.1946          10.3537            0.03s\n",
      "         8         130.4427          -0.0372            0.03s\n",
      "         9          79.6994          -0.4040            0.03s\n",
      "        10         107.6369           1.1828            0.03s\n",
      "        20          52.2437          -0.0602            0.02s\n",
      "        30          39.8847          -0.2959            0.01s\n",
      "        40          25.9608          -0.0217            0.01s\n",
      "        50          22.4357          -0.1229            0.00s\n",
      "        60          12.9579          -0.2207            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.7, learning_rate=0.05, score=0.689239, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         268.0527          -1.5883            0.06s\n",
      "         2         241.9591           1.0539            0.06s\n",
      "         3         214.6580          -0.2809            0.06s\n",
      "         4         204.7294           1.1407            0.06s\n",
      "         5         133.0443           2.8846            0.05s\n",
      "         6         149.3782          13.3313            0.04s\n",
      "         7         162.4382           1.6519            0.05s\n",
      "         8         136.6754           8.7842            0.06s\n",
      "         9         149.1879           1.3127            0.06s\n",
      "        10         122.7701          -0.3590            0.05s\n",
      "        20          76.8949           0.6460            0.03s\n",
      "        30          37.3772          -0.1253            0.02s\n",
      "        40          30.2933          -0.3243            0.01s\n",
      "        50          23.1466          -0.7874            0.01s\n",
      "        60          12.1141          -0.3245            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.75, learning_rate=0.05, score=0.182864, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         269.8733          -2.2693            0.06s\n",
      "         2         244.5319          -0.2242            0.03s\n",
      "         3         215.6269           0.1733            0.04s\n",
      "         4         201.7632           2.4753            0.04s\n",
      "         5         129.0312           0.4536            0.03s\n",
      "         6         146.6481          14.7172            0.04s\n",
      "         7         162.4356           0.9133            0.04s\n",
      "         8         133.9593           9.4031            0.03s\n",
      "         9         145.4613           2.1809            0.03s\n",
      "        10         123.0340           8.6540            0.03s\n",
      "        20          72.2249           0.8441            0.02s\n",
      "        30          35.9153           1.2181            0.01s\n",
      "        40          27.6550          -1.5833            0.01s\n",
      "        50          20.7931          -0.1686            0.00s\n",
      "        60          10.9045          -0.1960            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.75, learning_rate=0.05, score=-1.502142, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         270.2257          -2.1484            0.00s\n",
      "         2         243.3628           2.6208            0.00s\n",
      "         3         215.3946          -0.6160            0.00s\n",
      "         4         202.2680           2.5267            0.00s\n",
      "         5         125.4237           3.5690            0.00s\n",
      "         6         148.8767          11.1782            0.00s\n",
      "         7         164.0276           2.8294            0.00s\n",
      "         8         131.4368           8.4987            0.00s\n",
      "         9         148.9505           1.6405            0.00s\n",
      "        10         120.9108          -0.2270            0.00s\n",
      "        20          75.2901           0.4504            0.00s\n",
      "        30          32.6026           0.2156            0.00s\n",
      "        40          27.9272          -0.9515            0.01s\n",
      "        50          21.3200          -0.1229            0.00s\n",
      "        60          10.9514          -0.5580            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.75, learning_rate=0.05, score=0.050321, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         264.1448           0.1533            0.00s\n",
      "         2         235.6200           1.7001            0.00s\n",
      "         3         209.5950          -0.2452            0.00s\n",
      "         4         199.3489           1.1566            0.00s\n",
      "         5         123.2049           1.4258            0.00s\n",
      "         6         143.4356          13.9860            0.00s\n",
      "         7         163.0826           1.6629            0.00s\n",
      "         8         124.5009          12.2335            0.00s\n",
      "         9         144.0616           2.7077            0.00s\n",
      "        10         113.1198           8.5316            0.00s\n",
      "        20          67.3918           0.6146            0.00s\n",
      "        30          30.7386           0.4788            0.00s\n",
      "        40          28.5621          -0.6870            0.01s\n",
      "        50          22.5626          -0.1401            0.00s\n",
      "        60           8.8148          -0.5147            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.75, learning_rate=0.05, score=0.129066, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         204.1192          -0.1469            0.89s\n",
      "         2         183.1465           2.2665            0.44s\n",
      "         3         168.4147          -0.4337            0.29s\n",
      "         4         157.8817          -0.1274            0.21s\n",
      "         5          76.3381           5.4371            0.17s\n",
      "         6         137.9097          -0.4105            0.14s\n",
      "         7         125.8014          -0.1604            0.11s\n",
      "         8         114.1897          -0.5995            0.10s\n",
      "         9         115.8158          -0.9644            0.09s\n",
      "        10          85.9593           8.3826            0.08s\n",
      "        20          51.9370           0.5252            0.03s\n",
      "        30          26.7198           0.7155            0.02s\n",
      "        40          19.4742          -0.3531            0.02s\n",
      "        50          15.5695           0.0011            0.01s\n",
      "        60           9.7061          -0.4186            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.75, learning_rate=0.05, score=-0.480281, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         209.8049          18.1789            0.00s\n",
      "         2         197.5415          19.2881            0.00s\n",
      "         3         215.5563           0.0675            0.00s\n",
      "         4         187.7647           0.9669            0.00s\n",
      "         5         122.7889           1.6851            0.00s\n",
      "         6         175.1053          -1.5282            0.00s\n",
      "         7         135.6874          11.3252            0.00s\n",
      "         8         147.2330           0.9615            0.00s\n",
      "         9         135.0989          -0.4004            0.09s\n",
      "        10         116.2827           8.4709            0.08s\n",
      "        20          71.3483           0.5402            0.03s\n",
      "        30          37.1323           0.1841            0.02s\n",
      "        40          27.5912           0.5038            0.01s\n",
      "        50          14.7195          -0.2992            0.00s\n",
      "        60          14.4043          -0.1232            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.75, learning_rate=0.05, score=-1.013033, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         126.5477           0.1852            0.06s\n",
      "         2         120.4698           2.2887            0.03s\n",
      "         3         164.1207           0.6620            0.04s\n",
      "         4         141.7157          -0.6886            0.03s\n",
      "         5         134.4763           0.0972            0.03s\n",
      "         6         134.7302          -0.2956            0.04s\n",
      "         7          83.9601          10.3598            0.03s\n",
      "         8         116.0170          -0.0490            0.03s\n",
      "         9         103.4701           0.9350            0.03s\n",
      "        10          85.0517           7.7244            0.03s\n",
      "        20          56.0271          -0.2888            0.02s\n",
      "        30          37.7032          -0.1053            0.01s\n",
      "        40          19.5174           0.3494            0.01s\n",
      "        50          11.7854          -0.1743            0.00s\n",
      "        60           9.5625          -0.0731            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.75, learning_rate=0.05, score=0.175156, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         216.0023          22.7936            0.06s\n",
      "         2         202.2616          16.5841            0.03s\n",
      "         3         226.9424           1.5440            0.04s\n",
      "         4         194.8489           2.1965            0.03s\n",
      "         5         130.0177           1.6237            0.03s\n",
      "         6         187.2252          -0.0906            0.04s\n",
      "         7         140.4913          12.1321            0.03s\n",
      "         8         156.3404          -0.0501            0.03s\n",
      "         9         100.6794           1.9714            0.03s\n",
      "        10         120.3175          -1.5733            0.03s\n",
      "        20          74.9823           0.0094            0.02s\n",
      "        30          48.0922           0.0381            0.01s\n",
      "        40          31.3057           0.2311            0.01s\n",
      "        50          17.4502          -0.6286            0.00s\n",
      "        60          14.4383          -0.1131            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.75, learning_rate=0.05, score=-4.610658, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         153.9567          37.6070            0.06s\n",
      "         2         227.4605           0.6571            0.06s\n",
      "         3         182.3300          15.1226            0.06s\n",
      "         4         178.1178          -0.2921            0.04s\n",
      "         5         180.9259           0.0589            0.04s\n",
      "         6         161.0233          -0.0041            0.04s\n",
      "         7         122.5322          12.7934            0.04s\n",
      "         8         135.2936           0.3861            0.04s\n",
      "         9          91.2823          -0.7171            0.03s\n",
      "        10         103.3137           5.7727            0.03s\n",
      "        20          59.4061          -1.1133            0.02s\n",
      "        30          40.5768          -0.0332            0.01s\n",
      "        40          19.4983          -0.6226            0.01s\n",
      "        50          20.6462          -0.2445            0.00s\n",
      "        60          12.7243          -0.0414            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.75, learning_rate=0.05, score=0.263953, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         163.7241          21.2369            0.06s\n",
      "         2         200.1829           0.9624            0.03s\n",
      "         3         196.6305           0.5399            0.04s\n",
      "         4         163.8048           0.8524            0.03s\n",
      "         5         162.3932           0.1074            0.03s\n",
      "         6         141.2258           1.2252            0.03s\n",
      "         7         111.0067          13.2590            0.03s\n",
      "         8         126.8180          -0.7288            0.03s\n",
      "         9          78.6346          -1.4484            0.03s\n",
      "        10         105.1129           0.9564            0.03s\n",
      "        20          56.6228          -1.0033            0.02s\n",
      "        30          39.2170          -1.1407            0.01s\n",
      "        40          23.7424          -0.2411            0.01s\n",
      "        50          21.2572          -0.1544            0.00s\n",
      "        60          13.0738          -0.5458            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.75, learning_rate=0.05, score=0.563414, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         257.4776          -2.3388            0.00s\n",
      "         2         241.7770           1.4257            0.00s\n",
      "         3         209.0030           0.4755            0.00s\n",
      "         4         200.7384           2.3963            0.00s\n",
      "         5         132.2427           2.0073            0.00s\n",
      "         6         141.7269          16.8199            0.00s\n",
      "         7         154.8332           1.6629            0.00s\n",
      "         8         130.6981          10.2961            0.00s\n",
      "         9         143.8746           1.6707            0.00s\n",
      "        10         118.3874          -1.7671            0.00s\n",
      "        20          77.2480          -0.7091            0.03s\n",
      "        30          35.0579          -0.1444            0.02s\n",
      "        40          32.1287          -0.4230            0.01s\n",
      "        50          24.5360          -0.2195            0.00s\n",
      "        60          12.8231          -0.4412            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.8, learning_rate=0.05, score=0.147925, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         258.8168          -2.8023            0.00s\n",
      "         2         244.5659           0.9362            0.00s\n",
      "         3         209.1942           0.2687            0.00s\n",
      "         4         197.9320           2.5709            0.00s\n",
      "         5         129.5730          -0.7873            0.00s\n",
      "         6         139.9396          15.3070            0.00s\n",
      "         7         155.3602           0.3441            0.00s\n",
      "         8         130.4724          12.9007            0.00s\n",
      "         9         142.3373           1.9727            0.00s\n",
      "        10         118.9281          10.6039            0.00s\n",
      "        20          73.8965          -0.8558            0.00s\n",
      "        30          36.6930           0.7108            0.02s\n",
      "        40          28.3404          -0.4593            0.01s\n",
      "        50          20.5258          -0.3272            0.00s\n",
      "        60          12.2139          -0.4173            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.8, learning_rate=0.05, score=-1.778014, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         257.8732          -2.3651            0.89s\n",
      "         2         241.8607           1.0871            0.44s\n",
      "         3         209.9834          -0.5204            0.29s\n",
      "         4         198.1589           1.9131            0.21s\n",
      "         5         124.3352           1.9173            0.17s\n",
      "         6         141.2271          17.1872            0.14s\n",
      "         7         155.8790           0.4138            0.11s\n",
      "         8         124.3954          12.6757            0.10s\n",
      "         9         141.2854           1.1341            0.09s\n",
      "        10         114.0630           0.1947            0.08s\n",
      "        20          76.0996          -0.2641            0.03s\n",
      "        30          31.8498          -0.2164            0.02s\n",
      "        40          29.1867          -0.0737            0.02s\n",
      "        50          21.0118          -0.2004            0.01s\n",
      "        60          11.5226          -0.4792            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.8, learning_rate=0.05, score=0.003283, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         252.0375           0.6366            0.00s\n",
      "         2         234.8903           1.0437            0.00s\n",
      "         3         203.2993          -1.0737            0.00s\n",
      "         4         196.3459           1.3811            0.00s\n",
      "         5         123.4720           0.9504            0.00s\n",
      "         6         136.7778          12.2434            0.00s\n",
      "         7         158.0998           1.4039            0.12s\n",
      "         8         119.2789          11.0843            0.10s\n",
      "         9         139.9259           2.2259            0.09s\n",
      "        10         109.6036          10.3356            0.08s\n",
      "        20          68.0858           0.5082            0.03s\n",
      "        30          29.7749           0.7168            0.02s\n",
      "        40          29.5987          -0.2540            0.01s\n",
      "        50          21.8601           0.0100            0.00s\n",
      "        60           9.0597          -0.4910            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.8, learning_rate=0.05, score=-0.087282, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         200.1416          -0.0133            0.06s\n",
      "         2         186.6225           0.5539            0.06s\n",
      "         3         163.5990          -0.0425            0.06s\n",
      "         4         156.0444           0.4311            0.06s\n",
      "         5          77.2701           2.6414            0.04s\n",
      "         6         131.0229          -2.2096            0.04s\n",
      "         7         121.7491          -0.8032            0.04s\n",
      "         8         111.0033          -1.0983            0.04s\n",
      "         9         114.1929          -0.2507            0.04s\n",
      "        10          84.6760          10.9160            0.03s\n",
      "        20          53.8036           0.2805            0.02s\n",
      "        30          26.0121          -0.4607            0.01s\n",
      "        40          20.7414          -0.4223            0.01s\n",
      "        50          15.2931           0.0791            0.00s\n",
      "        60           9.2186          -0.4608            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.8, learning_rate=0.05, score=-0.472555, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         205.5813          22.2638            0.06s\n",
      "         2         198.9332          22.4691            0.03s\n",
      "         3         209.9556          -0.8094            0.04s\n",
      "         4         185.5978           1.7812            0.04s\n",
      "         5         117.9231           2.2885            0.04s\n",
      "         6         168.1631           0.1056            0.04s\n",
      "         7         131.8074          13.2168            0.04s\n",
      "         8         142.5929           1.0783            0.03s\n",
      "         9         130.3075          -0.8416            0.03s\n",
      "        10         112.0629          11.4218            0.03s\n",
      "        20          72.9578          -0.1754            0.02s\n",
      "        30          36.9837          -0.4933            0.01s\n",
      "        40          29.2648           0.4016            0.01s\n",
      "        50          21.0315           0.0438            0.00s\n",
      "        60          13.4065          -0.1252            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.8, learning_rate=0.05, score=-1.548226, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         127.4067           3.7214            0.06s\n",
      "         2         127.5733           2.2292            0.06s\n",
      "         3         159.2033          -0.4973            0.04s\n",
      "         4         140.2239          -0.0732            0.04s\n",
      "         5         128.8219           1.9968            0.04s\n",
      "         6         127.8568          -0.4449            0.05s\n",
      "         7          80.7699          11.8783            0.05s\n",
      "         8         111.7349          -1.0014            0.05s\n",
      "         9         100.8145          -0.2198            0.05s\n",
      "        10          82.1460           9.1513            0.05s\n",
      "        20          54.1039          -0.4034            0.02s\n",
      "        30          34.4313          -0.2560            0.01s\n",
      "        40          19.8102           0.1104            0.01s\n",
      "        50          15.6699           0.0224            0.00s\n",
      "        60           9.6937           0.1264            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.8, learning_rate=0.05, score=0.098745, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         210.7542          27.7115            0.06s\n",
      "         2         202.2091          22.4318            0.03s\n",
      "         3         218.3298           0.5161            0.04s\n",
      "         4         189.7704           3.1958            0.03s\n",
      "         5         124.2552           2.1012            0.03s\n",
      "         6         177.1254          -0.0853            0.03s\n",
      "         7         136.7902          15.5484            0.03s\n",
      "         8         148.7874          -0.5806            0.03s\n",
      "         9          95.9382           3.9840            0.03s\n",
      "        10         114.8695           1.8370            0.02s\n",
      "        20          74.3273          -0.2584            0.02s\n",
      "        30          45.7374          -0.6486            0.01s\n",
      "        40          30.5957           0.4334            0.01s\n",
      "        50          22.5067          -0.4684            0.00s\n",
      "        60          14.4044          -0.1308            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.8, learning_rate=0.05, score=-6.687576, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         147.9161          49.6953            0.00s\n",
      "         2         218.0749          -0.9812            0.00s\n",
      "         3         170.0834          19.4873            0.28s\n",
      "         4         167.1435          -0.5983            0.21s\n",
      "         5         168.3374          -0.4309            0.16s\n",
      "         6         150.4835           0.1109            0.13s\n",
      "         7         116.4094          15.9285            0.11s\n",
      "         8         127.3297           1.1379            0.10s\n",
      "         9         117.8359           1.1663            0.08s\n",
      "        10          92.6741           4.0742            0.07s\n",
      "        20          58.4540          -1.2477            0.03s\n",
      "        30          35.5772          -0.1097            0.01s\n",
      "        40          18.8754          -0.4059            0.01s\n",
      "        50          19.2066          -0.0673            0.01s\n",
      "        60          11.0323          -0.2191            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.8, learning_rate=0.05, score=0.212463, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         158.3255          27.5288            0.00s\n",
      "         2         192.3097          -2.0664            0.00s\n",
      "         3         184.0155           0.5617            0.00s\n",
      "         4         154.1330           0.5367            0.00s\n",
      "         5         156.1989          -0.0544            0.00s\n",
      "         6         131.8712           0.5963            0.00s\n",
      "         7         107.6108          16.4488            0.00s\n",
      "         8         120.8746           1.2283            0.00s\n",
      "         9         111.8588          -0.9314            0.00s\n",
      "        10          95.2026          -0.3503            0.00s\n",
      "        20          52.1071          -0.1867            0.03s\n",
      "        30          35.0050          -0.9010            0.02s\n",
      "        40          21.6973          -0.4732            0.01s\n",
      "        50          19.7562          -0.3959            0.00s\n",
      "        60          11.4069          -0.6065            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.8, learning_rate=0.05, score=0.532822, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         287.9736          -0.7565            0.00s\n",
      "         2         261.5520           2.2923            0.00s\n",
      "         3         229.4453          -0.0105            0.00s\n",
      "         4         216.3591           0.8768            0.00s\n",
      "         5         136.2679           2.7670            0.00s\n",
      "         6         102.3316          12.7564            0.00s\n",
      "         7         174.8256           2.0569            0.00s\n",
      "         8         150.2438           8.8975            0.00s\n",
      "         9         162.6161           1.1299            0.00s\n",
      "        10         114.8951          -0.1415            0.00s\n",
      "        20          78.6247          -0.7271            0.00s\n",
      "        30          37.5994           0.2667            0.02s\n",
      "        40          36.9691          -0.8229            0.01s\n",
      "        50          23.1494          -0.5878            0.01s\n",
      "        60          12.8760          -0.6862            0.00s\n",
      "        70          13.5760          -0.1151            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.7, learning_rate=0.05, score=0.035209, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         289.8912          -1.1790            0.00s\n",
      "         2         264.0664          -0.3385            0.00s\n",
      "         3         231.1540          -0.0936            0.00s\n",
      "         4         213.5986           1.8984            0.00s\n",
      "         5         132.1037           0.6387            0.00s\n",
      "         6          99.9696          11.0747            0.00s\n",
      "         7         176.3750           1.1742            0.00s\n",
      "         8         148.8401           8.8957            0.00s\n",
      "         9         159.0204           3.5621            0.00s\n",
      "        10         118.8041           7.1564            0.00s\n",
      "        20          76.0601          -0.2070            0.00s\n",
      "        30          36.9563           0.4483            0.00s\n",
      "        40          32.2758          -1.2277            0.01s\n",
      "        50          19.8651          -1.2161            0.01s\n",
      "        60          12.7640          -0.8902            0.00s\n",
      "        70          11.5390           0.0519            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.7, learning_rate=0.05, score=-1.588703, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         288.7676          -0.4958            0.07s\n",
      "         2         260.8576           2.3372            0.03s\n",
      "         3         229.2588           0.0750            0.04s\n",
      "         4         213.8526           0.7059            0.03s\n",
      "         5         127.8188           1.4648            0.04s\n",
      "         6         100.9612           7.1176            0.03s\n",
      "         7         178.5623           2.5173            0.04s\n",
      "         8         144.3274           7.8547            0.03s\n",
      "         9         162.8372           2.0646            0.03s\n",
      "        10         117.9719           7.0554            0.03s\n",
      "        20          76.2296          -2.3826            0.02s\n",
      "        30          34.6612           0.8876            0.02s\n",
      "        40          32.8047          -0.7608            0.01s\n",
      "        50          22.0184          -0.3413            0.01s\n",
      "        60          11.5588          -0.4660            0.00s\n",
      "        70          12.8714          -0.3397            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.7, learning_rate=0.05, score=0.019832, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         282.2828          -0.0102            0.00s\n",
      "         2         253.5370           1.6543            0.03s\n",
      "         3         223.2478           0.2454            0.02s\n",
      "         4         209.8703           0.5862            0.03s\n",
      "         5         125.9980           0.9530            0.03s\n",
      "         6          93.2883          10.1961            0.03s\n",
      "         7         173.7415           1.4318            0.03s\n",
      "         8         135.1072          10.4558            0.03s\n",
      "         9         153.5216           2.6928            0.03s\n",
      "        10         109.4107           7.0141            0.03s\n",
      "        20          70.8742          -1.9218            0.02s\n",
      "        30          33.8144           0.3714            0.01s\n",
      "        40          33.3849           0.0600            0.01s\n",
      "        50          21.9482          -0.8878            0.01s\n",
      "        60          10.2359          -0.5246            0.00s\n",
      "        70          11.0619          -0.3421            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.7, learning_rate=0.05, score=0.225272, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         218.2648           0.4686            0.07s\n",
      "         2         193.4615           2.0600            0.07s\n",
      "         3         179.8763          -0.1774            0.07s\n",
      "         4         159.6389           1.1099            0.05s\n",
      "         5          77.2999           1.1221            0.05s\n",
      "         6          87.1573           7.1577            0.04s\n",
      "         7         136.2369           0.6059            0.05s\n",
      "         8         126.6066           0.1578            0.04s\n",
      "         9         124.5734          -0.0968            0.04s\n",
      "        10          93.3076           8.4527            0.04s\n",
      "        20          57.1697           0.0664            0.02s\n",
      "        30          26.5903           1.7657            0.02s\n",
      "        40          21.3004           0.0212            0.01s\n",
      "        50          15.4694          -0.4036            0.01s\n",
      "        60           9.6476          -0.2568            0.00s\n",
      "        70           7.8061          -0.0789            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.7, learning_rate=0.05, score=-0.494956, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         225.1204          17.0315            0.00s\n",
      "         2         207.3429          16.9920            0.00s\n",
      "         3         229.4716           1.3476            0.00s\n",
      "         4         193.4812           1.6320            0.00s\n",
      "         5         126.0808           1.2106            0.00s\n",
      "         6         131.6346           2.7756            0.00s\n",
      "         7         133.3527           9.5769            0.00s\n",
      "         8         163.2346           0.4488            0.00s\n",
      "         9         143.3374           0.6792            0.00s\n",
      "        10         124.4394           7.0784            0.00s\n",
      "        20          76.6747          -1.0176            0.00s\n",
      "        30          40.2286           0.0542            0.00s\n",
      "        40          30.0616           1.1584            0.00s\n",
      "        50          14.7093          -0.8203            0.01s\n",
      "        60          12.5212          -0.2473            0.00s\n",
      "        70          11.5009          -0.3461            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.7, learning_rate=0.05, score=-1.599027, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         133.9842           0.9055            0.00s\n",
      "         2         123.8410          15.3338            0.00s\n",
      "         3         171.8981           1.6232            0.33s\n",
      "         4         138.3225           1.2471            0.25s\n",
      "         5         134.5724          -0.8331            0.19s\n",
      "         6         141.8770          -0.5574            0.16s\n",
      "         7          73.2841           1.3067            0.13s\n",
      "         8         127.2879          -0.7810            0.12s\n",
      "         9         110.1483           1.5023            0.10s\n",
      "        10          91.3234           6.2794            0.09s\n",
      "        20          60.3283           0.5448            0.04s\n",
      "        30          39.4301          -0.4026            0.02s\n",
      "        40          23.3527           0.2605            0.01s\n",
      "        50          11.8372           0.0361            0.01s\n",
      "        60           8.4997          -0.3663            0.01s\n",
      "        70           7.5939          -0.0283            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.7, learning_rate=0.05, score=0.156904, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         228.4113          16.0948            0.00s\n",
      "         2         208.2246          15.9924            0.00s\n",
      "         3         240.6272           1.1782            0.00s\n",
      "         4         202.7495           2.5096            0.00s\n",
      "         5         129.8965           0.5696            0.00s\n",
      "         6         196.2444          -0.3975            0.17s\n",
      "         7         132.1608           9.5669            0.14s\n",
      "         8         165.4871          -0.1151            0.12s\n",
      "         9         103.9404           3.2202            0.11s\n",
      "        10         125.6503           6.3469            0.10s\n",
      "        20          77.0482           0.0663            0.04s\n",
      "        30          49.1315          -0.4225            0.02s\n",
      "        40          31.2053           0.2877            0.01s\n",
      "        50          17.1307          -0.0683            0.01s\n",
      "        60          12.4441           0.0003            0.01s\n",
      "        70          10.6414          -0.2573            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.7, learning_rate=0.05, score=-2.689544, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         156.9905          35.8122            0.00s\n",
      "         2         230.4978          -1.0397            0.00s\n",
      "         3         185.0656          13.8384            0.00s\n",
      "         4         152.1994           8.4696            0.00s\n",
      "         5         185.1336           0.8325            0.00s\n",
      "         6         167.6584          -0.2808            0.17s\n",
      "         7         124.7295          11.6066            0.14s\n",
      "         8         138.4362           0.9995            0.12s\n",
      "         9          90.8820          -0.7740            0.11s\n",
      "        10         105.7159           7.3629            0.10s\n",
      "        20          56.7881           0.9323            0.04s\n",
      "        30          39.8741           0.0546            0.02s\n",
      "        40          20.5276          -0.3138            0.01s\n",
      "        50          20.6773          -0.2903            0.01s\n",
      "        60          12.8600          -0.6354            0.01s\n",
      "        70          10.6873          -0.1704            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.7, learning_rate=0.05, score=0.260008, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         166.7912          19.1280            0.00s\n",
      "         2         201.3738          -1.0168            0.03s\n",
      "         3         202.3122           1.6514            0.02s\n",
      "         4         168.0097           0.0956            0.03s\n",
      "         5         168.4248           0.5394            0.03s\n",
      "         6         147.4937           1.5592            0.03s\n",
      "         7         113.1946          10.3537            0.04s\n",
      "         8         130.4427          -0.0372            0.03s\n",
      "         9          79.6994          -0.4040            0.03s\n",
      "        10         107.6369           1.1828            0.03s\n",
      "        20          52.2437          -0.0602            0.02s\n",
      "        30          39.8847          -0.2959            0.01s\n",
      "        40          25.9608          -0.0217            0.01s\n",
      "        50          22.4357          -0.1229            0.01s\n",
      "        60          12.9579          -0.2207            0.00s\n",
      "        70          10.3403           0.0135            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.7, learning_rate=0.05, score=0.704573, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         268.0527          -1.5883            0.00s\n",
      "         2         241.9591           1.0539            0.03s\n",
      "         3         214.6580          -0.2809            0.02s\n",
      "         4         204.7294           1.1407            0.03s\n",
      "         5         133.0443           2.8846            0.03s\n",
      "         6         149.3782          13.3313            0.03s\n",
      "         7         162.4382           1.6519            0.03s\n",
      "         8         136.6754           8.7842            0.03s\n",
      "         9         149.1879           1.3127            0.03s\n",
      "        10         122.7701          -0.3590            0.03s\n",
      "        20          76.8949           0.6460            0.02s\n",
      "        30          37.3772          -0.1253            0.01s\n",
      "        40          30.2933          -0.3243            0.01s\n",
      "        50          23.1466          -0.7874            0.01s\n",
      "        60          12.1141          -0.3245            0.00s\n",
      "        70          12.5360          -0.3918            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.75, learning_rate=0.05, score=0.065954, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         269.8733          -2.2693            0.07s\n",
      "         2         244.5319          -0.2242            0.07s\n",
      "         3         215.6269           0.1733            0.07s\n",
      "         4         201.7632           2.4753            0.05s\n",
      "         5         129.0312           0.4536            0.05s\n",
      "         6         146.6481          14.7172            0.05s\n",
      "         7         162.4356           0.9133            0.06s\n",
      "         8         133.9593           9.4031            0.06s\n",
      "         9         145.4613           2.1809            0.06s\n",
      "        10         123.0340           8.6540            0.05s\n",
      "        20          72.2249           0.8441            0.03s\n",
      "        30          35.9153           1.2181            0.02s\n",
      "        40          27.6550          -1.5833            0.01s\n",
      "        50          20.7931          -0.1686            0.01s\n",
      "        60          10.9045          -0.1960            0.00s\n",
      "        70          10.3888          -0.1948            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.75, learning_rate=0.05, score=-1.607495, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         270.2257          -2.1484            0.00s\n",
      "         2         243.3628           2.6208            0.03s\n",
      "         3         215.3946          -0.6160            0.04s\n",
      "         4         202.2680           2.5267            0.05s\n",
      "         5         125.4237           3.5690            0.04s\n",
      "         6         148.8767          11.1782            0.04s\n",
      "         7         164.0276           2.8294            0.04s\n",
      "         8         131.4368           8.4987            0.04s\n",
      "         9         148.9505           1.6405            0.03s\n",
      "        10         120.9108          -0.2270            0.04s\n",
      "        20          75.2901           0.4504            0.02s\n",
      "        30          32.6026           0.2156            0.02s\n",
      "        40          27.9272          -0.9515            0.01s\n",
      "        50          21.3200          -0.1229            0.01s\n",
      "        60          10.9514          -0.5580            0.00s\n",
      "        70          12.6630          -0.0680            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.75, learning_rate=0.05, score=0.019984, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         264.1448           0.1533            0.00s\n",
      "         2         235.6200           1.7001            0.00s\n",
      "         3         209.5950          -0.2452            0.00s\n",
      "         4         199.3489           1.1566            0.00s\n",
      "         5         123.2049           1.4258            0.00s\n",
      "         6         143.4356          13.9860            0.00s\n",
      "         7         163.0826           1.6629            0.00s\n",
      "         8         124.5009          12.2335            0.00s\n",
      "         9         144.0616           2.7077            0.00s\n",
      "        10         113.1198           8.5316            0.09s\n",
      "        20          67.3918           0.6146            0.04s\n",
      "        30          30.7386           0.4788            0.02s\n",
      "        40          28.5621          -0.6870            0.01s\n",
      "        50          22.5626          -0.1401            0.01s\n",
      "        60           8.8148          -0.5147            0.01s\n",
      "        70          12.0062          -0.0365            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.75, learning_rate=0.05, score=0.121697, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         204.1192          -0.1469            0.00s\n",
      "         2         183.1465           2.2665            0.00s\n",
      "         3         168.4147          -0.4337            0.00s\n",
      "         4         157.8817          -0.1274            0.00s\n",
      "         5          76.3381           5.4371            0.00s\n",
      "         6         137.9097          -0.4105            0.00s\n",
      "         7         125.8014          -0.1604            0.00s\n",
      "         8         114.1897          -0.5995            0.00s\n",
      "         9         115.8158          -0.9644            0.00s\n",
      "        10          85.9593           8.3826            0.00s\n",
      "        20          51.9370           0.5252            0.04s\n",
      "        30          26.7198           0.7155            0.02s\n",
      "        40          19.4742          -0.3531            0.01s\n",
      "        50          15.5695           0.0011            0.01s\n",
      "        60           9.7061          -0.4186            0.00s\n",
      "        70           8.3893          -0.0353            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.75, learning_rate=0.05, score=-0.534091, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         209.8049          18.1789            0.00s\n",
      "         2         197.5415          19.2881            0.00s\n",
      "         3         215.5563           0.0675            0.00s\n",
      "         4         187.7647           0.9669            0.00s\n",
      "         5         122.7889           1.6851            0.00s\n",
      "         6         175.1053          -1.5282            0.00s\n",
      "         7         135.6874          11.3252            0.00s\n",
      "         8         147.2330           0.9615            0.00s\n",
      "         9         135.0989          -0.4004            0.00s\n",
      "        10         116.2827           8.4709            0.00s\n",
      "        20          71.3483           0.5402            0.00s\n",
      "        30          37.1323           0.1841            0.02s\n",
      "        40          27.5912           0.5038            0.01s\n",
      "        50          14.7195          -0.2992            0.01s\n",
      "        60          14.4043          -0.1232            0.00s\n",
      "        70          11.6203          -0.2452            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.75, learning_rate=0.05, score=-0.955615, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         126.5477           0.1852            0.07s\n",
      "         2         120.4698           2.2887            0.07s\n",
      "         3         164.1207           0.6620            0.04s\n",
      "         4         141.7157          -0.6886            0.05s\n",
      "         5         134.4763           0.0972            0.04s\n",
      "         6         134.7302          -0.2956            0.04s\n",
      "         7          83.9601          10.3598            0.05s\n",
      "         8         116.0170          -0.0490            0.05s\n",
      "         9         103.4701           0.9350            0.04s\n",
      "        10          85.0517           7.7244            0.04s\n",
      "        20          56.0271          -0.2888            0.02s\n",
      "        30          37.7032          -0.1053            0.02s\n",
      "        40          19.5174           0.3494            0.01s\n",
      "        50          11.7854          -0.1743            0.01s\n",
      "        60           9.5625          -0.0731            0.00s\n",
      "        70           7.4553          -0.0969            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.75, learning_rate=0.05, score=0.181617, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         216.0023          22.7936            0.07s\n",
      "         2         202.2616          16.5841            0.03s\n",
      "         3         226.9424           1.5440            0.04s\n",
      "         4         194.8489           2.1965            0.03s\n",
      "         5         130.0177           1.6237            0.04s\n",
      "         6         187.2252          -0.0906            0.04s\n",
      "         7         140.4913          12.1321            0.04s\n",
      "         8         156.3404          -0.0501            0.04s\n",
      "         9         100.6794           1.9714            0.03s\n",
      "        10         120.3175          -1.5733            0.04s\n",
      "        20          74.9823           0.0094            0.02s\n",
      "        30          48.0922           0.0381            0.02s\n",
      "        40          31.3057           0.2311            0.01s\n",
      "        50          17.4502          -0.6286            0.01s\n",
      "        60          14.4383          -0.1131            0.00s\n",
      "        70          12.1543          -0.2881            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.75, learning_rate=0.05, score=-4.602241, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         153.9567          37.6070            0.07s\n",
      "         2         227.4605           0.6571            0.07s\n",
      "         3         182.3300          15.1226            0.07s\n",
      "         4         178.1178          -0.2921            0.05s\n",
      "         5         180.9259           0.0589            0.05s\n",
      "         6         161.0233          -0.0041            0.04s\n",
      "         7         122.5322          12.7934            0.04s\n",
      "         8         135.2936           0.3861            0.05s\n",
      "         9          91.2823          -0.7171            0.04s\n",
      "        10         103.3137           5.7727            0.04s\n",
      "        20          59.4061          -1.1133            0.02s\n",
      "        30          40.5768          -0.0332            0.02s\n",
      "        40          19.4983          -0.6226            0.01s\n",
      "        50          20.6462          -0.2445            0.01s\n",
      "        60          12.7243          -0.0414            0.00s\n",
      "        70           9.4605          -0.0205            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.75, learning_rate=0.05, score=0.267807, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         163.7241          21.2369            0.00s\n",
      "         2         200.1829           0.9624            0.07s\n",
      "         3         196.6305           0.5399            0.07s\n",
      "         4         163.8048           0.8524            0.05s\n",
      "         5         162.3932           0.1074            0.05s\n",
      "         6         141.2258           1.2252            0.04s\n",
      "         7         111.0067          13.2590            0.04s\n",
      "         8         126.8180          -0.7288            0.04s\n",
      "         9          78.6346          -1.4484            0.04s\n",
      "        10         105.1129           0.9564            0.04s\n",
      "        20          56.6228          -1.0033            0.02s\n",
      "        30          39.2170          -1.1407            0.02s\n",
      "        40          23.7424          -0.2411            0.01s\n",
      "        50          21.2572          -0.1544            0.01s\n",
      "        60          13.0738          -0.5458            0.00s\n",
      "        70          10.9238          -0.0215            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.75, learning_rate=0.05, score=0.581888, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         257.4776          -2.3388            0.00s\n",
      "         2         241.7770           1.4257            0.03s\n",
      "         3         209.0030           0.4755            0.04s\n",
      "         4         200.7384           2.3963            0.03s\n",
      "         5         132.2427           2.0073            0.04s\n",
      "         6         141.7269          16.8199            0.03s\n",
      "         7         154.8332           1.6629            0.04s\n",
      "         8         130.6981          10.2961            0.03s\n",
      "         9         143.8746           1.6707            0.03s\n",
      "        10         118.3874          -1.7671            0.02s\n",
      "        20          77.2480          -0.7091            0.01s\n",
      "        30          35.0579          -0.1444            0.01s\n",
      "        40          32.1287          -0.4230            0.00s\n",
      "        50          24.5360          -0.2195            0.00s\n",
      "        60          12.8231          -0.4412            0.00s\n",
      "        70          12.1171          -0.5181            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.8, learning_rate=0.05, score=0.060015, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         258.8168          -2.8023            0.00s\n",
      "         2         244.5659           0.9362            0.00s\n",
      "         3         209.1942           0.2687            0.00s\n",
      "         4         197.9320           2.5709            0.00s\n",
      "         5         129.5730          -0.7873            0.00s\n",
      "         6         139.9396          15.3070            0.00s\n",
      "         7         155.3602           0.3441            0.00s\n",
      "         8         130.4724          12.9007            0.00s\n",
      "         9         142.3373           1.9727            0.00s\n",
      "        10         118.9281          10.6039            0.00s\n",
      "        20          73.8965          -0.8558            0.04s\n",
      "        30          36.6930           0.7108            0.02s\n",
      "        40          28.3404          -0.4593            0.01s\n",
      "        50          20.5258          -0.3272            0.01s\n",
      "        60          12.2139          -0.4173            0.01s\n",
      "        70          10.5701           0.2233            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.8, learning_rate=0.05, score=-1.972725, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         257.8732          -2.3651            0.00s\n",
      "         2         241.8607           1.0871            0.00s\n",
      "         3         209.9834          -0.5204            0.00s\n",
      "         4         198.1589           1.9131            0.00s\n",
      "         5         124.3352           1.9173            0.00s\n",
      "         6         141.2271          17.1872            0.00s\n",
      "         7         155.8790           0.4138            0.00s\n",
      "         8         124.3954          12.6757            0.00s\n",
      "         9         141.2854           1.1341            0.00s\n",
      "        10         114.0630           0.1947            0.00s\n",
      "        20          76.0996          -0.2641            0.04s\n",
      "        30          31.8498          -0.2164            0.03s\n",
      "        40          29.1867          -0.0737            0.02s\n",
      "        50          21.0118          -0.2004            0.01s\n",
      "        60          11.5226          -0.4792            0.01s\n",
      "        70          11.8175          -0.0884            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.8, learning_rate=0.05, score=0.007712, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         252.0375           0.6366            0.00s\n",
      "         2         234.8903           1.0437            0.03s\n",
      "         3         203.2993          -1.0737            0.02s\n",
      "         4         196.3459           1.3811            0.05s\n",
      "         5         123.4720           0.9504            0.05s\n",
      "         6         136.7778          12.2434            0.04s\n",
      "         7         158.0998           1.4039            0.05s\n",
      "         8         119.2789          11.0843            0.05s\n",
      "         9         139.9259           2.2259            0.04s\n",
      "        10         109.6036          10.3356            0.04s\n",
      "        20          68.0858           0.5082            0.02s\n",
      "        30          29.7749           0.7168            0.02s\n",
      "        40          29.5987          -0.2540            0.01s\n",
      "        50          21.8601           0.0100            0.01s\n",
      "        60           9.0597          -0.4910            0.00s\n",
      "        70          10.4469          -0.0446            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.8, learning_rate=0.05, score=-0.052953, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         200.1416          -0.0133            0.00s\n",
      "         2         186.6225           0.5539            0.03s\n",
      "         3         163.5990          -0.0425            0.02s\n",
      "         4         156.0444           0.4311            0.03s\n",
      "         5          77.2701           2.6414            0.04s\n",
      "         6         131.0229          -2.2096            0.03s\n",
      "         7         121.7491          -0.8032            0.04s\n",
      "         8         111.0033          -1.0983            0.03s\n",
      "         9         114.1929          -0.2507            0.03s\n",
      "        10          84.6760          10.9160            0.03s\n",
      "        20          53.8036           0.2805            0.02s\n",
      "        30          26.0121          -0.4607            0.01s\n",
      "        40          20.7414          -0.4223            0.01s\n",
      "        50          15.2931           0.0791            0.01s\n",
      "        60           9.2186          -0.4608            0.00s\n",
      "        70           8.2820          -0.0264            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.8, learning_rate=0.05, score=-0.544702, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         205.5813          22.2638            0.07s\n",
      "         2         198.9332          22.4691            0.07s\n",
      "         3         209.9556          -0.8094            0.04s\n",
      "         4         185.5978           1.7812            0.05s\n",
      "         5         117.9231           2.2885            0.06s\n",
      "         6         168.1631           0.1056            0.05s\n",
      "         7         131.8074          13.2168            0.04s\n",
      "         8         142.5929           1.0783            0.04s\n",
      "         9         130.3075          -0.8416            0.05s\n",
      "        10         112.0629          11.4218            0.05s\n",
      "        20          72.9578          -0.1754            0.03s\n",
      "        30          36.9837          -0.4933            0.02s\n",
      "        40          29.2648           0.4016            0.01s\n",
      "        50          21.0315           0.0438            0.01s\n",
      "        60          13.4065          -0.1252            0.00s\n",
      "        70          10.0555          -0.3488            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.8, learning_rate=0.05, score=-1.542153, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         127.4067           3.7214            0.00s\n",
      "         2         127.5733           2.2292            0.03s\n",
      "         3         159.2033          -0.4973            0.02s\n",
      "         4         140.2239          -0.0732            0.03s\n",
      "         5         128.8219           1.9968            0.04s\n",
      "         6         127.8568          -0.4449            0.03s\n",
      "         7          80.7699          11.8783            0.04s\n",
      "         8         111.7349          -1.0014            0.04s\n",
      "         9         100.8145          -0.2198            0.03s\n",
      "        10          82.1460           9.1513            0.04s\n",
      "        20          54.1039          -0.4034            0.02s\n",
      "        30          34.4313          -0.2560            0.02s\n",
      "        40          19.8102           0.1104            0.01s\n",
      "        50          15.6699           0.0224            0.01s\n",
      "        60           9.6937           0.1264            0.00s\n",
      "        70           6.8930          -0.1023            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.8, learning_rate=0.05, score=0.094570, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         210.7542          27.7115            0.00s\n",
      "         2         202.2091          22.4318            0.00s\n",
      "         3         218.3298           0.5161            0.00s\n",
      "         4         189.7704           3.1958            0.00s\n",
      "         5         124.2552           2.1012            0.00s\n",
      "         6         177.1254          -0.0853            0.00s\n",
      "         7         136.7902          15.5484            0.00s\n",
      "         8         148.7874          -0.5806            0.00s\n",
      "         9          95.9382           3.9840            0.00s\n",
      "        10         114.8695           1.8370            0.00s\n",
      "        20          74.3273          -0.2584            0.04s\n",
      "        30          45.7374          -0.6486            0.02s\n",
      "        40          30.5957           0.4334            0.01s\n",
      "        50          22.5067          -0.4684            0.01s\n",
      "        60          14.4044          -0.1308            0.01s\n",
      "        70          10.1910          -0.3412            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.8, learning_rate=0.05, score=-6.766020, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         147.9161          49.6953            0.00s\n",
      "         2         218.0749          -0.9812            0.00s\n",
      "         3         170.0834          19.4873            0.00s\n",
      "         4         167.1435          -0.5983            0.00s\n",
      "         5         168.3374          -0.4309            0.00s\n",
      "         6         150.4835           0.1109            0.00s\n",
      "         7         116.4094          15.9285            0.00s\n",
      "         8         127.3297           1.1379            0.00s\n",
      "         9         117.8359           1.1663            0.00s\n",
      "        10          92.6741           4.0742            0.00s\n",
      "        20          58.4540          -1.2477            0.04s\n",
      "        30          35.5772          -0.1097            0.02s\n",
      "        40          18.8754          -0.4059            0.01s\n",
      "        50          19.2066          -0.0673            0.01s\n",
      "        60          11.0323          -0.2191            0.00s\n",
      "        70           8.6651           0.0377            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.8, learning_rate=0.05, score=0.192553, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         158.3255          27.5288            0.00s\n",
      "         2         192.3097          -2.0664            0.00s\n",
      "         3         184.0155           0.5617            0.00s\n",
      "         4         154.1330           0.5367            0.00s\n",
      "         5         156.1989          -0.0544            0.00s\n",
      "         6         131.8712           0.5963            0.00s\n",
      "         7         107.6108          16.4488            0.00s\n",
      "         8         120.8746           1.2283            0.00s\n",
      "         9         111.8588          -0.9314            0.00s\n",
      "        10          95.2026          -0.3503            0.00s\n",
      "        20          52.1071          -0.1867            0.04s\n",
      "        30          35.0050          -0.9010            0.03s\n",
      "        40          21.6973          -0.4732            0.02s\n",
      "        50          19.7562          -0.3959            0.01s\n",
      "        60          11.4069          -0.6065            0.01s\n",
      "        70          10.0372          -0.2365            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.8, learning_rate=0.05, score=0.542866, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         287.9736          -0.7565            0.00s\n",
      "         2         261.5520           2.2923            0.04s\n",
      "         3         229.4453          -0.0105            0.03s\n",
      "         4         216.3591           0.8768            0.04s\n",
      "         5         136.2679           2.7670            0.05s\n",
      "         6         102.3316          12.7564            0.04s\n",
      "         7         174.8256           2.0569            0.04s\n",
      "         8         150.2438           8.8975            0.04s\n",
      "         9         162.6161           1.1299            0.04s\n",
      "        10         114.8951          -0.1415            0.04s\n",
      "        20          78.6247          -0.7271            0.02s\n",
      "        30          37.5994           0.2667            0.02s\n",
      "        40          36.9691          -0.8229            0.01s\n",
      "        50          23.1494          -0.5878            0.01s\n",
      "        60          12.8760          -0.6862            0.01s\n",
      "        70          13.5760          -0.1151            0.00s\n",
      "        80           8.8398          -0.5253            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.7, learning_rate=0.05, score=-0.050215, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         289.8912          -1.1790            0.08s\n",
      "         2         264.0664          -0.3385            0.08s\n",
      "         3         231.1540          -0.0936            0.05s\n",
      "         4         213.5986           1.8984            0.06s\n",
      "         5         132.1037           0.6387            0.05s\n",
      "         6          99.9696          11.0747            0.05s\n",
      "         7         176.3750           1.1742            0.04s\n",
      "         8         148.8401           8.8957            0.05s\n",
      "         9         159.0204           3.5621            0.04s\n",
      "        10         118.8041           7.1564            0.04s\n",
      "        20          76.0601          -0.2070            0.03s\n",
      "        30          36.9563           0.4483            0.02s\n",
      "        40          32.2758          -1.2277            0.02s\n",
      "        50          19.8651          -1.2161            0.01s\n",
      "        60          12.7640          -0.8902            0.01s\n",
      "        70          11.5390           0.0519            0.00s\n",
      "        80           8.5777          -0.3289            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.7, learning_rate=0.05, score=-1.864949, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         288.7676          -0.4958            0.08s\n",
      "         2         260.8576           2.3372            0.08s\n",
      "         3         229.2588           0.0750            0.05s\n",
      "         4         213.8526           0.7059            0.06s\n",
      "         5         127.8188           1.4648            0.05s\n",
      "         6         100.9612           7.1176            0.05s\n",
      "         7         178.5623           2.5173            0.05s\n",
      "         8         144.3274           7.8547            0.05s\n",
      "         9         162.8372           2.0646            0.05s\n",
      "        10         117.9719           7.0554            0.04s\n",
      "        20          76.2296          -2.3826            0.03s\n",
      "        30          34.6612           0.8876            0.02s\n",
      "        40          32.8047          -0.7608            0.02s\n",
      "        50          22.0184          -0.3413            0.01s\n",
      "        60          11.5588          -0.4660            0.01s\n",
      "        70          12.8714          -0.3397            0.00s\n",
      "        80           8.8225          -0.4063            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.7, learning_rate=0.05, score=-0.059582, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         282.2828          -0.0102            0.00s\n",
      "         2         253.5370           1.6543            0.04s\n",
      "         3         223.2478           0.2454            0.03s\n",
      "         4         209.8703           0.5862            0.04s\n",
      "         5         125.9980           0.9530            0.03s\n",
      "         6          93.2883          10.1961            0.04s\n",
      "         7         173.7415           1.4318            0.03s\n",
      "         8         135.1072          10.4558            0.04s\n",
      "         9         153.5216           2.6928            0.03s\n",
      "        10         109.4107           7.0141            0.03s\n",
      "        20          70.8742          -1.9218            0.02s\n",
      "        30          33.8144           0.3714            0.01s\n",
      "        40          33.3849           0.0600            0.01s\n",
      "        50          21.9482          -0.8878            0.00s\n",
      "        60          10.2359          -0.5246            0.00s\n",
      "        70          11.0619          -0.3421            0.00s\n",
      "        80           7.2119          -0.3180            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.7, learning_rate=0.05, score=0.199325, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         218.2648           0.4686            0.00s\n",
      "         2         193.4615           2.0600            0.00s\n",
      "         3         179.8763          -0.1774            0.00s\n",
      "         4         159.6389           1.1099            0.00s\n",
      "         5          77.2999           1.1221            0.00s\n",
      "         6          87.1573           7.1577            0.00s\n",
      "         7         136.2369           0.6059            0.00s\n",
      "         8         126.6066           0.1578            0.00s\n",
      "         9         124.5734          -0.0968            0.00s\n",
      "        10          93.3076           8.4527            0.00s\n",
      "        20          57.1697           0.0664            0.00s\n",
      "        30          26.5903           1.7657            0.02s\n",
      "        40          21.3004           0.0212            0.01s\n",
      "        50          15.4694          -0.4036            0.01s\n",
      "        60           9.6476          -0.2568            0.00s\n",
      "        70           7.8061          -0.0789            0.00s\n",
      "        80           6.5346          -0.1968            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.7, learning_rate=0.05, score=-0.519500, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         225.1204          17.0315            0.00s\n",
      "         2         207.3429          16.9920            0.00s\n",
      "         3         229.4716           1.3476            0.00s\n",
      "         4         193.4812           1.6320            0.00s\n",
      "         5         126.0808           1.2106            0.00s\n",
      "         6         131.6346           2.7756            0.00s\n",
      "         7         133.3527           9.5769            0.00s\n",
      "         8         163.2346           0.4488            0.00s\n",
      "         9         143.3374           0.6792            0.00s\n",
      "        10         124.4394           7.0784            0.00s\n",
      "        20          76.6747          -1.0176            0.05s\n",
      "        30          40.2286           0.0542            0.04s\n",
      "        40          30.0616           1.1584            0.03s\n",
      "        50          14.7093          -0.8203            0.02s\n",
      "        60          12.5212          -0.2473            0.01s\n",
      "        70          11.5009          -0.3461            0.01s\n",
      "        80           8.7676          -0.1245            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.7, learning_rate=0.05, score=-1.625465, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         133.9842           0.9055            0.08s\n",
      "         2         123.8410          15.3338            0.04s\n",
      "         3         171.8981           1.6232            0.05s\n",
      "         4         138.3225           1.2471            0.04s\n",
      "         5         134.5724          -0.8331            0.05s\n",
      "         6         141.8770          -0.5574            0.04s\n",
      "         7          73.2841           1.3067            0.04s\n",
      "         8         127.2879          -0.7810            0.04s\n",
      "         9         110.1483           1.5023            0.04s\n",
      "        10          91.3234           6.2794            0.04s\n",
      "        20          60.3283           0.5448            0.03s\n",
      "        30          39.4301          -0.4026            0.02s\n",
      "        40          23.3527           0.2605            0.01s\n",
      "        50          11.8372           0.0361            0.01s\n",
      "        60           8.4997          -0.3663            0.01s\n",
      "        70           7.5939          -0.0283            0.00s\n",
      "        80           5.9132          -0.0685            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.7, learning_rate=0.05, score=0.153027, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         228.4113          16.0948            0.00s\n",
      "         2         208.2246          15.9924            0.04s\n",
      "         3         240.6272           1.1782            0.03s\n",
      "         4         202.7495           2.5096            0.04s\n",
      "         5         129.8965           0.5696            0.05s\n",
      "         6         196.2444          -0.3975            0.04s\n",
      "         7         132.1608           9.5669            0.04s\n",
      "         8         165.4871          -0.1151            0.04s\n",
      "         9         103.9404           3.2202            0.04s\n",
      "        10         125.6503           6.3469            0.03s\n",
      "        20          77.0482           0.0663            0.02s\n",
      "        30          49.1315          -0.4225            0.02s\n",
      "        40          31.2053           0.2877            0.01s\n",
      "        50          17.1307          -0.0683            0.01s\n",
      "        60          12.4441           0.0003            0.01s\n",
      "        70          10.6414          -0.2573            0.00s\n",
      "        80           6.7104          -0.2638            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.7, learning_rate=0.05, score=-2.930086, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         156.9905          35.8122            0.08s\n",
      "         2         230.4978          -1.0397            0.08s\n",
      "         3         185.0656          13.8384            0.08s\n",
      "         4         152.1994           8.4696            0.08s\n",
      "         5         185.1336           0.8325            0.07s\n",
      "         6         167.6584          -0.2808            0.06s\n",
      "         7         124.7295          11.6066            0.06s\n",
      "         8         138.4362           0.9995            0.06s\n",
      "         9          90.8820          -0.7740            0.06s\n",
      "        10         105.7159           7.3629            0.06s\n",
      "        20          56.7881           0.9323            0.04s\n",
      "        30          39.8741           0.0546            0.03s\n",
      "        40          20.5276          -0.3138            0.02s\n",
      "        50          20.6773          -0.2903            0.01s\n",
      "        60          12.8600          -0.6354            0.01s\n",
      "        70          10.6873          -0.1704            0.00s\n",
      "        80           7.5249          -0.0272            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.7, learning_rate=0.05, score=0.286778, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         166.7912          19.1280            0.00s\n",
      "         2         201.3738          -1.0168            0.04s\n",
      "         3         202.3122           1.6514            0.03s\n",
      "         4         168.0097           0.0956            0.04s\n",
      "         5         168.4248           0.5394            0.03s\n",
      "         6         147.4937           1.5592            0.04s\n",
      "         7         113.1946          10.3537            0.03s\n",
      "         8         130.4427          -0.0372            0.04s\n",
      "         9          79.6994          -0.4040            0.03s\n",
      "        10         107.6369           1.1828            0.04s\n",
      "        20          52.2437          -0.0602            0.02s\n",
      "        30          39.8847          -0.2959            0.01s\n",
      "        40          25.9608          -0.0217            0.01s\n",
      "        50          22.4357          -0.1229            0.00s\n",
      "        60          12.9579          -0.2207            0.00s\n",
      "        70          10.3403           0.0135            0.00s\n",
      "        80           7.2722          -0.0448            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.7, learning_rate=0.05, score=0.698780, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         268.0527          -1.5883            0.00s\n",
      "         2         241.9591           1.0539            0.00s\n",
      "         3         214.6580          -0.2809            0.00s\n",
      "         4         204.7294           1.1407            0.00s\n",
      "         5         133.0443           2.8846            0.00s\n",
      "         6         149.3782          13.3313            0.00s\n",
      "         7         162.4382           1.6519            0.00s\n",
      "         8         136.6754           8.7842            0.00s\n",
      "         9         149.1879           1.3127            0.00s\n",
      "        10         122.7701          -0.3590            0.00s\n",
      "        20          76.8949           0.6460            0.00s\n",
      "        30          37.3772          -0.1253            0.03s\n",
      "        40          30.2933          -0.3243            0.02s\n",
      "        50          23.1466          -0.7874            0.01s\n",
      "        60          12.1141          -0.3245            0.01s\n",
      "        70          12.5360          -0.3918            0.00s\n",
      "        80           7.6479          -0.4812            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.75, learning_rate=0.05, score=-0.022946, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         269.8733          -2.2693            0.00s\n",
      "         2         244.5319          -0.2242            0.00s\n",
      "         3         215.6269           0.1733            0.00s\n",
      "         4         201.7632           2.4753            0.00s\n",
      "         5         129.0312           0.4536            0.00s\n",
      "         6         146.6481          14.7172            0.00s\n",
      "         7         162.4356           0.9133            0.00s\n",
      "         8         133.9593           9.4031            0.00s\n",
      "         9         145.4613           2.1809            0.00s\n",
      "        10         123.0340           8.6540            0.00s\n",
      "        20          72.2249           0.8441            0.05s\n",
      "        30          35.9153           1.2181            0.04s\n",
      "        40          27.6550          -1.5833            0.03s\n",
      "        50          20.7931          -0.1686            0.02s\n",
      "        60          10.9045          -0.1960            0.01s\n",
      "        70          10.3888          -0.1948            0.01s\n",
      "        80           6.7925          -0.3749            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.75, learning_rate=0.05, score=-1.888717, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         270.2257          -2.1484            0.00s\n",
      "         2         243.3628           2.6208            0.00s\n",
      "         3         215.3946          -0.6160            0.03s\n",
      "         4         202.2680           2.5267            0.02s\n",
      "         5         125.4237           3.5690            0.03s\n",
      "         6         148.8767          11.1782            0.02s\n",
      "         7         164.0276           2.8294            0.03s\n",
      "         8         131.4368           8.4987            0.03s\n",
      "         9         148.9505           1.6405            0.03s\n",
      "        10         120.9108          -0.2270            0.03s\n",
      "        20          75.2901           0.4504            0.02s\n",
      "        30          32.6026           0.2156            0.02s\n",
      "        40          27.9272          -0.9515            0.01s\n",
      "        50          21.3200          -0.1229            0.01s\n",
      "        60          10.9514          -0.5580            0.01s\n",
      "        70          12.6630          -0.0680            0.00s\n",
      "        80           7.3013          -0.1042            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.75, learning_rate=0.05, score=-0.002638, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         264.1448           0.1533            0.00s\n",
      "         2         235.6200           1.7001            0.04s\n",
      "         3         209.5950          -0.2452            0.03s\n",
      "         4         199.3489           1.1566            0.04s\n",
      "         5         123.2049           1.4258            0.03s\n",
      "         6         143.4356          13.9860            0.04s\n",
      "         7         163.0826           1.6629            0.03s\n",
      "         8         124.5009          12.2335            0.04s\n",
      "         9         144.0616           2.7077            0.03s\n",
      "        10         113.1198           8.5316            0.03s\n",
      "        20          67.3918           0.6146            0.02s\n",
      "        30          30.7386           0.4788            0.02s\n",
      "        40          28.5621          -0.6870            0.01s\n",
      "        50          22.5626          -0.1401            0.01s\n",
      "        60           8.8148          -0.5147            0.01s\n",
      "        70          12.0062          -0.0365            0.00s\n",
      "        80           6.0375          -0.3250            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.75, learning_rate=0.05, score=0.109656, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         204.1192          -0.1469            0.08s\n",
      "         2         183.1465           2.2665            0.04s\n",
      "         3         168.4147          -0.4337            0.05s\n",
      "         4         157.8817          -0.1274            0.04s\n",
      "         5          76.3381           5.4371            0.05s\n",
      "         6         137.9097          -0.4105            0.05s\n",
      "         7         125.8014          -0.1604            0.04s\n",
      "         8         114.1897          -0.5995            0.04s\n",
      "         9         115.8158          -0.9644            0.05s\n",
      "        10          85.9593           8.3826            0.04s\n",
      "        20          51.9370           0.5252            0.03s\n",
      "        30          26.7198           0.7155            0.02s\n",
      "        40          19.4742          -0.3531            0.02s\n",
      "        50          15.5695           0.0011            0.01s\n",
      "        60           9.7061          -0.4186            0.01s\n",
      "        70           8.3893          -0.0353            0.00s\n",
      "        80           5.5438          -0.0884            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.75, learning_rate=0.05, score=-0.576418, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         209.8049          18.1789            0.00s\n",
      "         2         197.5415          19.2881            0.00s\n",
      "         3         215.5563           0.0675            0.03s\n",
      "         4         187.7647           0.9669            0.02s\n",
      "         5         122.7889           1.6851            0.03s\n",
      "         6         175.1053          -1.5282            0.02s\n",
      "         7         135.6874          11.3252            0.03s\n",
      "         8         147.2330           0.9615            0.03s\n",
      "         9         135.0989          -0.4004            0.03s\n",
      "        10         116.2827           8.4709            0.03s\n",
      "        20          71.3483           0.5402            0.02s\n",
      "        30          37.1323           0.1841            0.02s\n",
      "        40          27.5912           0.5038            0.01s\n",
      "        50          14.7195          -0.2992            0.01s\n",
      "        60          14.4043          -0.1232            0.01s\n",
      "        70          11.6203          -0.2452            0.00s\n",
      "        80           8.4590          -0.1027            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.75, learning_rate=0.05, score=-1.052718, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         126.5477           0.1852            0.00s\n",
      "         2         120.4698           2.2887            0.00s\n",
      "         3         164.1207           0.6620            0.00s\n",
      "         4         141.7157          -0.6886            0.00s\n",
      "         5         134.4763           0.0972            0.00s\n",
      "         6         134.7302          -0.2956            0.00s\n",
      "         7          83.9601          10.3598            0.00s\n",
      "         8         116.0170          -0.0490            0.00s\n",
      "         9         103.4701           0.9350            0.00s\n",
      "        10          85.0517           7.7244            0.00s\n",
      "        20          56.0271          -0.2888            0.00s\n",
      "        30          37.7032          -0.1053            0.03s\n",
      "        40          19.5174           0.3494            0.02s\n",
      "        50          11.7854          -0.1743            0.01s\n",
      "        60           9.5625          -0.0731            0.01s\n",
      "        70           7.4553          -0.0969            0.00s\n",
      "        80           5.0484          -0.3482            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.75, learning_rate=0.05, score=0.187867, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         216.0023          22.7936            0.00s\n",
      "         2         202.2616          16.5841            0.00s\n",
      "         3         226.9424           1.5440            0.00s\n",
      "         4         194.8489           2.1965            0.00s\n",
      "         5         130.0177           1.6237            0.00s\n",
      "         6         187.2252          -0.0906            0.00s\n",
      "         7         140.4913          12.1321            0.00s\n",
      "         8         156.3404          -0.0501            0.00s\n",
      "         9         100.6794           1.9714            0.00s\n",
      "        10         120.3175          -1.5733            0.00s\n",
      "        20          74.9823           0.0094            0.00s\n",
      "        30          48.0922           0.0381            0.03s\n",
      "        40          31.3057           0.2311            0.02s\n",
      "        50          17.4502          -0.6286            0.01s\n",
      "        60          14.4383          -0.1131            0.01s\n",
      "        70          12.1543          -0.2881            0.00s\n",
      "        80           6.9197          -0.6076            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.75, learning_rate=0.05, score=-4.779866, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         153.9567          37.6070            0.08s\n",
      "         2         227.4605           0.6571            0.04s\n",
      "         3         182.3300          15.1226            0.05s\n",
      "         4         178.1178          -0.2921            0.06s\n",
      "         5         180.9259           0.0589            0.05s\n",
      "         6         161.0233          -0.0041            0.05s\n",
      "         7         122.5322          12.7934            0.05s\n",
      "         8         135.2936           0.3861            0.04s\n",
      "         9          91.2823          -0.7171            0.05s\n",
      "        10         103.3137           5.7727            0.04s\n",
      "        20          59.4061          -1.1133            0.03s\n",
      "        30          40.5768          -0.0332            0.02s\n",
      "        40          19.4983          -0.6226            0.02s\n",
      "        50          20.6462          -0.2445            0.01s\n",
      "        60          12.7243          -0.0414            0.01s\n",
      "        70           9.4605          -0.0205            0.00s\n",
      "        80           6.4730          -0.2273            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.75, learning_rate=0.05, score=0.284234, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         163.7241          21.2369            0.08s\n",
      "         2         200.1829           0.9624            0.08s\n",
      "         3         196.6305           0.5399            0.05s\n",
      "         4         163.8048           0.8524            0.06s\n",
      "         5         162.3932           0.1074            0.05s\n",
      "         6         141.2258           1.2252            0.05s\n",
      "         7         111.0067          13.2590            0.05s\n",
      "         8         126.8180          -0.7288            0.05s\n",
      "         9          78.6346          -1.4484            0.05s\n",
      "        10         105.1129           0.9564            0.04s\n",
      "        20          56.6228          -1.0033            0.03s\n",
      "        30          39.2170          -1.1407            0.02s\n",
      "        40          23.7424          -0.2411            0.02s\n",
      "        50          21.2572          -0.1544            0.01s\n",
      "        60          13.0738          -0.5458            0.01s\n",
      "        70          10.9238          -0.0215            0.00s\n",
      "        80           7.4219          -0.0535            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.75, learning_rate=0.05, score=0.596265, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         257.4776          -2.3388            0.08s\n",
      "         2         241.7770           1.4257            0.04s\n",
      "         3         209.0030           0.4755            0.05s\n",
      "         4         200.7384           2.3963            0.06s\n",
      "         5         132.2427           2.0073            0.05s\n",
      "         6         141.7269          16.8199            0.05s\n",
      "         7         154.8332           1.6629            0.05s\n",
      "         8         130.6981          10.2961            0.05s\n",
      "         9         143.8746           1.6707            0.05s\n",
      "        10         118.3874          -1.7671            0.04s\n",
      "        20          77.2480          -0.7091            0.03s\n",
      "        30          35.0579          -0.1444            0.02s\n",
      "        40          32.1287          -0.4230            0.02s\n",
      "        50          24.5360          -0.2195            0.01s\n",
      "        60          12.8231          -0.4412            0.01s\n",
      "        70          12.1171          -0.5181            0.00s\n",
      "        80           8.0590          -0.5514            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.8, learning_rate=0.05, score=-0.092266, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         258.8168          -2.8023            0.08s\n",
      "         2         244.5659           0.9362            0.08s\n",
      "         3         209.1942           0.2687            0.08s\n",
      "         4         197.9320           2.5709            0.06s\n",
      "         5         129.5730          -0.7873            0.06s\n",
      "         6         139.9396          15.3070            0.05s\n",
      "         7         155.3602           0.3441            0.05s\n",
      "         8         130.4724          12.9007            0.05s\n",
      "         9         142.3373           1.9727            0.05s\n",
      "        10         118.9281          10.6039            0.05s\n",
      "        20          73.8965          -0.8558            0.03s\n",
      "        30          36.6930           0.7108            0.02s\n",
      "        40          28.3404          -0.4593            0.02s\n",
      "        50          20.5258          -0.3272            0.01s\n",
      "        60          12.2139          -0.4173            0.01s\n",
      "        70          10.5701           0.2233            0.00s\n",
      "        80           7.2258          -0.4642            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.8, learning_rate=0.05, score=-1.859267, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         257.8732          -2.3651            0.08s\n",
      "         2         241.8607           1.0871            0.04s\n",
      "         3         209.9834          -0.5204            0.05s\n",
      "         4         198.1589           1.9131            0.06s\n",
      "         5         124.3352           1.9173            0.05s\n",
      "         6         141.2271          17.1872            0.05s\n",
      "         7         155.8790           0.4138            0.04s\n",
      "         8         124.3954          12.6757            0.05s\n",
      "         9         141.2854           1.1341            0.04s\n",
      "        10         114.0630           0.1947            0.04s\n",
      "        20          76.0996          -0.2641            0.03s\n",
      "        30          31.8498          -0.2164            0.02s\n",
      "        40          29.1867          -0.0737            0.01s\n",
      "        50          21.0118          -0.2004            0.01s\n",
      "        60          11.5226          -0.4792            0.00s\n",
      "        70          11.8175          -0.0884            0.00s\n",
      "        80           7.2891          -0.3147            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.8, learning_rate=0.05, score=-0.014163, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         252.0375           0.6366            0.00s\n",
      "         2         234.8903           1.0437            0.00s\n",
      "         3         203.2993          -1.0737            0.00s\n",
      "         4         196.3459           1.3811            0.00s\n",
      "         5         123.4720           0.9504            0.00s\n",
      "         6         136.7778          12.2434            0.00s\n",
      "         7         158.0998           1.4039            0.00s\n",
      "         8         119.2789          11.0843            0.00s\n",
      "         9         139.9259           2.2259            0.00s\n",
      "        10         109.6036          10.3356            0.00s\n",
      "        20          68.0858           0.5082            0.00s\n",
      "        30          29.7749           0.7168            0.03s\n",
      "        40          29.5987          -0.2540            0.02s\n",
      "        50          21.8601           0.0100            0.02s\n",
      "        60           9.0597          -0.4910            0.01s\n",
      "        70          10.4469          -0.0446            0.00s\n",
      "        80           5.4742          -0.4522            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.8, learning_rate=0.05, score=-0.064443, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         200.1416          -0.0133            0.00s\n",
      "         2         186.6225           0.5539            0.04s\n",
      "         3         163.5990          -0.0425            0.03s\n",
      "         4         156.0444           0.4311            0.04s\n",
      "         5          77.2701           2.6414            0.03s\n",
      "         6         131.0229          -2.2096            0.04s\n",
      "         7         121.7491          -0.8032            0.04s\n",
      "         8         111.0033          -1.0983            0.05s\n",
      "         9         114.1929          -0.2507            0.04s\n",
      "        10          84.6760          10.9160            0.04s\n",
      "        20          53.8036           0.2805            0.03s\n",
      "        30          26.0121          -0.4607            0.02s\n",
      "        40          20.7414          -0.4223            0.02s\n",
      "        50          15.2931           0.0791            0.01s\n",
      "        60           9.2186          -0.4608            0.01s\n",
      "        70           8.2820          -0.0264            0.00s\n",
      "        80           6.2186          -0.1630            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.8, learning_rate=0.05, score=-0.584761, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         205.5813          22.2638            0.08s\n",
      "         2         198.9332          22.4691            0.04s\n",
      "         3         209.9556          -0.8094            0.05s\n",
      "         4         185.5978           1.7812            0.04s\n",
      "         5         117.9231           2.2885            0.05s\n",
      "         6         168.1631           0.1056            0.04s\n",
      "         7         131.8074          13.2168            0.04s\n",
      "         8         142.5929           1.0783            0.04s\n",
      "         9         130.3075          -0.8416            0.04s\n",
      "        10         112.0629          11.4218            0.04s\n",
      "        20          72.9578          -0.1754            0.03s\n",
      "        30          36.9837          -0.4933            0.02s\n",
      "        40          29.2648           0.4016            0.02s\n",
      "        50          21.0315           0.0438            0.01s\n",
      "        60          13.4065          -0.1252            0.01s\n",
      "        70          10.0555          -0.3488            0.00s\n",
      "        80           8.1804          -0.1234            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.8, learning_rate=0.05, score=-1.408049, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         127.4067           3.7214            0.08s\n",
      "         2         127.5733           2.2292            0.04s\n",
      "         3         159.2033          -0.4973            0.05s\n",
      "         4         140.2239          -0.0732            0.04s\n",
      "         5         128.8219           1.9968            0.05s\n",
      "         6         127.8568          -0.4449            0.04s\n",
      "         7          80.7699          11.8783            0.04s\n",
      "         8         111.7349          -1.0014            0.04s\n",
      "         9         100.8145          -0.2198            0.04s\n",
      "        10          82.1460           9.1513            0.04s\n",
      "        20          54.1039          -0.4034            0.03s\n",
      "        30          34.4313          -0.2560            0.02s\n",
      "        40          19.8102           0.1104            0.02s\n",
      "        50          15.6699           0.0224            0.01s\n",
      "        60           9.6937           0.1264            0.01s\n",
      "        70           6.8930          -0.1023            0.00s\n",
      "        80           4.7575          -0.1539            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.8, learning_rate=0.05, score=0.105627, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         210.7542          27.7115            0.08s\n",
      "         2         202.2091          22.4318            0.04s\n",
      "         3         218.3298           0.5161            0.05s\n",
      "         4         189.7704           3.1958            0.04s\n",
      "         5         124.2552           2.1012            0.05s\n",
      "         6         177.1254          -0.0853            0.04s\n",
      "         7         136.7902          15.5484            0.04s\n",
      "         8         148.7874          -0.5806            0.04s\n",
      "         9          95.9382           3.9840            0.04s\n",
      "        10         114.8695           1.8370            0.04s\n",
      "        20          74.3273          -0.2584            0.03s\n",
      "        30          45.7374          -0.6486            0.02s\n",
      "        40          30.5957           0.4334            0.02s\n",
      "        50          22.5067          -0.4684            0.01s\n",
      "        60          14.4044          -0.1308            0.01s\n",
      "        70          10.1910          -0.3412            0.00s\n",
      "        80           7.1859          -0.0601            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.8, learning_rate=0.05, score=-7.000906, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         147.9161          49.6953            0.00s\n",
      "         2         218.0749          -0.9812            0.00s\n",
      "         3         170.0834          19.4873            0.00s\n",
      "         4         167.1435          -0.5983            0.00s\n",
      "         5         168.3374          -0.4309            0.24s\n",
      "         6         150.4835           0.1109            0.20s\n",
      "         7         116.4094          15.9285            0.17s\n",
      "         8         127.3297           1.1379            0.14s\n",
      "         9         117.8359           1.1663            0.13s\n",
      "        10          92.6741           4.0742            0.11s\n",
      "        20          58.4540          -1.2477            0.05s\n",
      "        30          35.5772          -0.1097            0.03s\n",
      "        40          18.8754          -0.4059            0.02s\n",
      "        50          19.2066          -0.0673            0.02s\n",
      "        60          11.0323          -0.2191            0.01s\n",
      "        70           8.6651           0.0377            0.00s\n",
      "        80           5.6065          -0.0063            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.8, learning_rate=0.05, score=0.223493, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         158.3255          27.5288            0.00s\n",
      "         2         192.3097          -2.0664            0.00s\n",
      "         3         184.0155           0.5617            0.38s\n",
      "         4         154.1330           0.5367            0.28s\n",
      "         5         156.1989          -0.0544            0.22s\n",
      "         6         131.8712           0.5963            0.18s\n",
      "         7         107.6108          16.4488            0.16s\n",
      "         8         120.8746           1.2283            0.13s\n",
      "         9         111.8588          -0.9314            0.12s\n",
      "        10          95.2026          -0.3503            0.10s\n",
      "        20          52.1071          -0.1867            0.04s\n",
      "        30          35.0050          -0.9010            0.02s\n",
      "        40          21.6973          -0.4732            0.01s\n",
      "        50          19.7562          -0.3959            0.02s\n",
      "        60          11.4069          -0.6065            0.01s\n",
      "        70          10.0372          -0.2365            0.01s\n",
      "        80           7.0070          -0.0134            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.8, learning_rate=0.05, score=0.550185, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         287.9736          -0.7565            0.09s\n",
      "         2         261.5520           2.2923            0.09s\n",
      "         3         229.4453          -0.0105            0.09s\n",
      "         4         216.3591           0.8768            0.06s\n",
      "         5         136.2679           2.7670            0.07s\n",
      "         6         102.3316          12.7564            0.07s\n",
      "         7         174.8256           2.0569            0.07s\n",
      "         8         150.2438           8.8975            0.07s\n",
      "         9         162.6161           1.1299            0.06s\n",
      "        10         114.8951          -0.1415            0.06s\n",
      "        20          78.6247          -0.7271            0.04s\n",
      "        30          37.5994           0.2667            0.03s\n",
      "        40          36.9691          -0.8229            0.02s\n",
      "        50          23.1494          -0.5878            0.02s\n",
      "        60          12.8760          -0.6862            0.01s\n",
      "        70          13.5760          -0.1151            0.01s\n",
      "        80           8.8398          -0.5253            0.00s\n",
      "        90           7.1346          -0.3031            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.7, learning_rate=0.05, score=-0.220010, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         289.8912          -1.1790            0.09s\n",
      "         2         264.0664          -0.3385            0.09s\n",
      "         3         231.1540          -0.0936            0.06s\n",
      "         4         213.5986           1.8984            0.06s\n",
      "         5         132.1037           0.6387            0.07s\n",
      "         6          99.9696          11.0747            0.06s\n",
      "         7         176.3750           1.1742            0.06s\n",
      "         8         148.8401           8.8957            0.05s\n",
      "         9         159.0204           3.5621            0.05s\n",
      "        10         118.8041           7.1564            0.05s\n",
      "        20          76.0601          -0.2070            0.03s\n",
      "        30          36.9563           0.4483            0.03s\n",
      "        40          32.2758          -1.2277            0.02s\n",
      "        50          19.8651          -1.2161            0.02s\n",
      "        60          12.7640          -0.8902            0.01s\n",
      "        70          11.5390           0.0519            0.01s\n",
      "        80           8.5777          -0.3289            0.00s\n",
      "        90           6.7940          -0.1051            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.7, learning_rate=0.05, score=-1.964640, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         288.7676          -0.4958            0.00s\n",
      "         2         260.8576           2.3372            0.04s\n",
      "         3         229.2588           0.0750            0.06s\n",
      "         4         213.8526           0.7059            0.04s\n",
      "         5         127.8188           1.4648            0.05s\n",
      "         6         100.9612           7.1176            0.06s\n",
      "         7         178.5623           2.5173            0.05s\n",
      "         8         144.3274           7.8547            0.05s\n",
      "         9         162.8372           2.0646            0.04s\n",
      "        10         117.9719           7.0554            0.05s\n",
      "        20          76.2296          -2.3826            0.03s\n",
      "        30          34.6612           0.8876            0.03s\n",
      "        40          32.8047          -0.7608            0.02s\n",
      "        50          22.0184          -0.3413            0.02s\n",
      "        60          11.5588          -0.4660            0.01s\n",
      "        70          12.8714          -0.3397            0.01s\n",
      "        80           8.8225          -0.4063            0.00s\n",
      "        90           7.1812          -0.2018            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.7, learning_rate=0.05, score=-0.120619, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         282.2828          -0.0102            0.00s\n",
      "         2         253.5370           1.6543            0.04s\n",
      "         3         223.2478           0.2454            0.03s\n",
      "         4         209.8703           0.5862            0.02s\n",
      "         5         125.9980           0.9530            0.03s\n",
      "         6          93.2883          10.1961            0.03s\n",
      "         7         173.7415           1.4318            0.04s\n",
      "         8         135.1072          10.4558            0.03s\n",
      "         9         153.5216           2.6928            0.04s\n",
      "        10         109.4107           7.0141            0.03s\n",
      "        20          70.8742          -1.9218            0.02s\n",
      "        30          33.8144           0.3714            0.02s\n",
      "        40          33.3849           0.0600            0.01s\n",
      "        50          21.9482          -0.8878            0.01s\n",
      "        60          10.2359          -0.5246            0.01s\n",
      "        70          11.0619          -0.3421            0.00s\n",
      "        80           7.2119          -0.3180            0.00s\n",
      "        90           5.6569          -0.2460            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.7, learning_rate=0.05, score=0.228186, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         218.2648           0.4686            0.00s\n",
      "         2         193.4615           2.0600            0.00s\n",
      "         3         179.8763          -0.1774            0.00s\n",
      "         4         159.6389           1.1099            0.00s\n",
      "         5          77.2999           1.1221            0.00s\n",
      "         6          87.1573           7.1577            0.00s\n",
      "         7         136.2369           0.6059            0.00s\n",
      "         8         126.6066           0.1578            0.00s\n",
      "         9         124.5734          -0.0968            0.00s\n",
      "        10          93.3076           8.4527            0.00s\n",
      "        20          57.1697           0.0664            0.05s\n",
      "        30          26.5903           1.7657            0.03s\n",
      "        40          21.3004           0.0212            0.02s\n",
      "        50          15.4694          -0.4036            0.01s\n",
      "        60           9.6476          -0.2568            0.01s\n",
      "        70           7.8061          -0.0789            0.01s\n",
      "        80           6.5346          -0.1968            0.00s\n",
      "        90           5.0102          -0.2107            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.7, learning_rate=0.05, score=-0.575386, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         225.1204          17.0315            0.00s\n",
      "         2         207.3429          16.9920            0.00s\n",
      "         3         229.4716           1.3476            0.00s\n",
      "         4         193.4812           1.6320            0.00s\n",
      "         5         126.0808           1.2106            0.00s\n",
      "         6         131.6346           2.7756            0.00s\n",
      "         7         133.3527           9.5769            0.00s\n",
      "         8         163.2346           0.4488            0.16s\n",
      "         9         143.3374           0.6792            0.14s\n",
      "        10         124.4394           7.0784            0.13s\n",
      "        20          76.6747          -1.0176            0.08s\n",
      "        30          40.2286           0.0542            0.05s\n",
      "        40          30.0616           1.1584            0.04s\n",
      "        50          14.7093          -0.8203            0.03s\n",
      "        60          12.5212          -0.2473            0.02s\n",
      "        70          11.5009          -0.3461            0.01s\n",
      "        80           8.7676          -0.1245            0.01s\n",
      "        90           6.4381          -0.2707            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.7, learning_rate=0.05, score=-1.729431, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         133.9842           0.9055            0.09s\n",
      "         2         123.8410          15.3338            0.04s\n",
      "         3         171.8981           1.6232            0.06s\n",
      "         4         138.3225           1.2471            0.04s\n",
      "         5         134.5724          -0.8331            0.05s\n",
      "         6         141.8770          -0.5574            0.06s\n",
      "         7          73.2841           1.3067            0.05s\n",
      "         8         127.2879          -0.7810            0.05s\n",
      "         9         110.1483           1.5023            0.05s\n",
      "        10          91.3234           6.2794            0.05s\n",
      "        20          60.3283           0.5448            0.03s\n",
      "        30          39.4301          -0.4026            0.02s\n",
      "        40          23.3527           0.2605            0.02s\n",
      "        50          11.8372           0.0361            0.02s\n",
      "        60           8.4997          -0.3663            0.01s\n",
      "        70           7.5939          -0.0283            0.01s\n",
      "        80           5.9132          -0.0685            0.00s\n",
      "        90           4.4219          -0.1250            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.7, learning_rate=0.05, score=0.160112, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         228.4113          16.0948            0.00s\n",
      "         2         208.2246          15.9924            0.04s\n",
      "         3         240.6272           1.1782            0.03s\n",
      "         4         202.7495           2.5096            0.04s\n",
      "         5         129.8965           0.5696            0.05s\n",
      "         6         196.2444          -0.3975            0.04s\n",
      "         7         132.1608           9.5669            0.05s\n",
      "         8         165.4871          -0.1151            0.04s\n",
      "         9         103.9404           3.2202            0.04s\n",
      "        10         125.6503           6.3469            0.04s\n",
      "        20          77.0482           0.0663            0.03s\n",
      "        30          49.1315          -0.4225            0.03s\n",
      "        40          31.2053           0.2877            0.02s\n",
      "        50          17.1307          -0.0683            0.02s\n",
      "        60          12.4441           0.0003            0.01s\n",
      "        70          10.6414          -0.2573            0.01s\n",
      "        80           6.7104          -0.2638            0.00s\n",
      "        90           6.1395          -0.0627            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.7, learning_rate=0.05, score=-3.097045, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         156.9905          35.8122            0.00s\n",
      "         2         230.4978          -1.0397            0.04s\n",
      "         3         185.0656          13.8384            0.03s\n",
      "         4         152.1994           8.4696            0.04s\n",
      "         5         185.1336           0.8325            0.05s\n",
      "         6         167.6584          -0.2808            0.06s\n",
      "         7         124.7295          11.6066            0.06s\n",
      "         8         138.4362           0.9995            0.05s\n",
      "         9          90.8820          -0.7740            0.05s\n",
      "        10         105.7159           7.3629            0.05s\n",
      "        20          56.7881           0.9323            0.03s\n",
      "        30          39.8741           0.0546            0.03s\n",
      "        40          20.5276          -0.3138            0.02s\n",
      "        50          20.6773          -0.2903            0.02s\n",
      "        60          12.8600          -0.6354            0.01s\n",
      "        70          10.6873          -0.1704            0.01s\n",
      "        80           7.5249          -0.0272            0.00s\n",
      "        90           5.3867          -0.2278            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.7, learning_rate=0.05, score=0.315442, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.7, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         166.7912          19.1280            0.00s\n",
      "         2         201.3738          -1.0168            0.04s\n",
      "         3         202.3122           1.6514            0.03s\n",
      "         4         168.0097           0.0956            0.04s\n",
      "         5         168.4248           0.5394            0.03s\n",
      "         6         147.4937           1.5592            0.04s\n",
      "         7         113.1946          10.3537            0.04s\n",
      "         8         130.4427          -0.0372            0.04s\n",
      "         9          79.6994          -0.4040            0.04s\n",
      "        10         107.6369           1.1828            0.04s\n",
      "        20          52.2437          -0.0602            0.03s\n",
      "        30          39.8847          -0.2959            0.02s\n",
      "        40          25.9608          -0.0217            0.02s\n",
      "        50          22.4357          -0.1229            0.01s\n",
      "        60          12.9579          -0.2207            0.01s\n",
      "        70          10.3403           0.0135            0.01s\n",
      "        80           7.2722          -0.0448            0.00s\n",
      "        90           5.9201          -0.1576            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.7, learning_rate=0.05, score=0.705754, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         268.0527          -1.5883            0.00s\n",
      "         2         241.9591           1.0539            0.00s\n",
      "         3         214.6580          -0.2809            0.00s\n",
      "         4         204.7294           1.1407            0.00s\n",
      "         5         133.0443           2.8846            0.00s\n",
      "         6         149.3782          13.3313            0.00s\n",
      "         7         162.4382           1.6519            0.00s\n",
      "         8         136.6754           8.7842            0.16s\n",
      "         9         149.1879           1.3127            0.14s\n",
      "        10         122.7701          -0.3590            0.13s\n",
      "        20          76.8949           0.6460            0.07s\n",
      "        30          37.3772          -0.1253            0.05s\n",
      "        40          30.2933          -0.3243            0.04s\n",
      "        50          23.1466          -0.7874            0.02s\n",
      "        60          12.1141          -0.3245            0.02s\n",
      "        70          12.5360          -0.3918            0.01s\n",
      "        80           7.6479          -0.4812            0.01s\n",
      "        90           5.7757          -0.2838            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.75, learning_rate=0.05, score=-0.174004, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         269.8733          -2.2693            0.09s\n",
      "         2         244.5319          -0.2242            0.04s\n",
      "         3         215.6269           0.1733            0.06s\n",
      "         4         201.7632           2.4753            0.06s\n",
      "         5         129.0312           0.4536            0.05s\n",
      "         6         146.6481          14.7172            0.06s\n",
      "         7         162.4356           0.9133            0.05s\n",
      "         8         133.9593           9.4031            0.05s\n",
      "         9         145.4613           2.1809            0.05s\n",
      "        10         123.0340           8.6540            0.05s\n",
      "        20          72.2249           0.8441            0.03s\n",
      "        30          35.9153           1.2181            0.03s\n",
      "        40          27.6550          -1.5833            0.02s\n",
      "        50          20.7931          -0.1686            0.02s\n",
      "        60          10.9045          -0.1960            0.01s\n",
      "        70          10.3888          -0.1948            0.01s\n",
      "        80           6.7925          -0.3749            0.00s\n",
      "        90           4.7893          -0.1168            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.75, learning_rate=0.05, score=-1.927193, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         270.2257          -2.1484            0.09s\n",
      "         2         243.3628           2.6208            0.09s\n",
      "         3         215.3946          -0.6160            0.06s\n",
      "         4         202.2680           2.5267            0.06s\n",
      "         5         125.4237           3.5690            0.05s\n",
      "         6         148.8767          11.1782            0.06s\n",
      "         7         164.0276           2.8294            0.05s\n",
      "         8         131.4368           8.4987            0.05s\n",
      "         9         148.9505           1.6405            0.05s\n",
      "        10         120.9108          -0.2270            0.05s\n",
      "        20          75.2901           0.4504            0.03s\n",
      "        30          32.6026           0.2156            0.02s\n",
      "        40          27.9272          -0.9515            0.02s\n",
      "        50          21.3200          -0.1229            0.02s\n",
      "        60          10.9514          -0.5580            0.01s\n",
      "        70          12.6630          -0.0680            0.01s\n",
      "        80           7.3013          -0.1042            0.00s\n",
      "        90           5.2023          -0.2440            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.75, learning_rate=0.05, score=-0.043966, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         264.1448           0.1533            0.09s\n",
      "         2         235.6200           1.7001            0.04s\n",
      "         3         209.5950          -0.2452            0.06s\n",
      "         4         199.3489           1.1566            0.04s\n",
      "         5         123.2049           1.4258            0.05s\n",
      "         6         143.4356          13.9860            0.04s\n",
      "         7         163.0826           1.6629            0.05s\n",
      "         8         124.5009          12.2335            0.04s\n",
      "         9         144.0616           2.7077            0.05s\n",
      "        10         113.1198           8.5316            0.04s\n",
      "        20          67.3918           0.6146            0.03s\n",
      "        30          30.7386           0.4788            0.03s\n",
      "        40          28.5621          -0.6870            0.02s\n",
      "        50          22.5626          -0.1401            0.02s\n",
      "        60           8.8148          -0.5147            0.01s\n",
      "        70          12.0062          -0.0365            0.01s\n",
      "        80           6.0375          -0.3250            0.00s\n",
      "        90           4.7740          -0.4178            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.75, learning_rate=0.05, score=0.141975, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         204.1192          -0.1469            0.09s\n",
      "         2         183.1465           2.2665            0.04s\n",
      "         3         168.4147          -0.4337            0.06s\n",
      "         4         157.8817          -0.1274            0.06s\n",
      "         5          76.3381           5.4371            0.05s\n",
      "         6         137.9097          -0.4105            0.06s\n",
      "         7         125.8014          -0.1604            0.05s\n",
      "         8         114.1897          -0.5995            0.04s\n",
      "         9         115.8158          -0.9644            0.05s\n",
      "        10          85.9593           8.3826            0.05s\n",
      "        20          51.9370           0.5252            0.03s\n",
      "        30          26.7198           0.7155            0.03s\n",
      "        40          19.4742          -0.3531            0.02s\n",
      "        50          15.5695           0.0011            0.01s\n",
      "        60           9.7061          -0.4186            0.01s\n",
      "        70           8.3893          -0.0353            0.01s\n",
      "        80           5.5438          -0.0884            0.00s\n",
      "        90           3.8575          -0.2248            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.75, learning_rate=0.05, score=-0.599152, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         209.8049          18.1789            0.00s\n",
      "         2         197.5415          19.2881            0.00s\n",
      "         3         215.5563           0.0675            0.00s\n",
      "         4         187.7647           0.9669            0.00s\n",
      "         5         122.7889           1.6851            0.00s\n",
      "         6         175.1053          -1.5282            0.00s\n",
      "         7         135.6874          11.3252            0.00s\n",
      "         8         147.2330           0.9615            0.00s\n",
      "         9         135.0989          -0.4004            0.00s\n",
      "        10         116.2827           8.4709            0.00s\n",
      "        20          71.3483           0.5402            0.00s\n",
      "        30          37.1323           0.1841            0.00s\n",
      "        40          27.5912           0.5038            0.02s\n",
      "        50          14.7195          -0.2992            0.02s\n",
      "        60          14.4043          -0.1232            0.01s\n",
      "        70          11.6203          -0.2452            0.01s\n",
      "        80           8.4590          -0.1027            0.00s\n",
      "        90           5.8115          -0.2172            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.75, learning_rate=0.05, score=-0.973173, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         126.5477           0.1852            0.00s\n",
      "         2         120.4698           2.2887            0.04s\n",
      "         3         164.1207           0.6620            0.06s\n",
      "         4         141.7157          -0.6886            0.06s\n",
      "         5         134.4763           0.0972            0.05s\n",
      "         6         134.7302          -0.2956            0.06s\n",
      "         7          83.9601          10.3598            0.06s\n",
      "         8         116.0170          -0.0490            0.05s\n",
      "         9         103.4701           0.9350            0.05s\n",
      "        10          85.0517           7.7244            0.05s\n",
      "        20          56.0271          -0.2888            0.03s\n",
      "        30          37.7032          -0.1053            0.03s\n",
      "        40          19.5174           0.3494            0.02s\n",
      "        50          11.7854          -0.1743            0.02s\n",
      "        60           9.5625          -0.0731            0.01s\n",
      "        70           7.4553          -0.0969            0.01s\n",
      "        80           5.0484          -0.3482            0.00s\n",
      "        90           4.1241          -0.1431            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.75, learning_rate=0.05, score=0.170624, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         216.0023          22.7936            0.09s\n",
      "         2         202.2616          16.5841            0.13s\n",
      "         3         226.9424           1.5440            0.12s\n",
      "         4         194.8489           2.1965            0.11s\n",
      "         5         130.0177           1.6237            0.09s\n",
      "         6         187.2252          -0.0906            0.08s\n",
      "         7         140.4913          12.1321            0.08s\n",
      "         8         156.3404          -0.0501            0.07s\n",
      "         9         100.6794           1.9714            0.07s\n",
      "        10         120.3175          -1.5733            0.06s\n",
      "        20          74.9823           0.0094            0.04s\n",
      "        30          48.0922           0.0381            0.03s\n",
      "        40          31.3057           0.2311            0.02s\n",
      "        50          17.4502          -0.6286            0.02s\n",
      "        60          14.4383          -0.1131            0.01s\n",
      "        70          12.1543          -0.2881            0.01s\n",
      "        80           6.9197          -0.6076            0.00s\n",
      "        90           6.2642          -0.1282            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.75, learning_rate=0.05, score=-5.252459, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         153.9567          37.6070            0.09s\n",
      "         2         227.4605           0.6571            0.09s\n",
      "         3         182.3300          15.1226            0.06s\n",
      "         4         178.1178          -0.2921            0.06s\n",
      "         5         180.9259           0.0589            0.07s\n",
      "         6         161.0233          -0.0041            0.06s\n",
      "         7         122.5322          12.7934            0.06s\n",
      "         8         135.2936           0.3861            0.05s\n",
      "         9          91.2823          -0.7171            0.05s\n",
      "        10         103.3137           5.7727            0.05s\n",
      "        20          59.4061          -1.1133            0.03s\n",
      "        30          40.5768          -0.0332            0.03s\n",
      "        40          19.4983          -0.6226            0.02s\n",
      "        50          20.6462          -0.2445            0.02s\n",
      "        60          12.7243          -0.0414            0.01s\n",
      "        70           9.4605          -0.0205            0.01s\n",
      "        80           6.4730          -0.2273            0.00s\n",
      "        90           4.8016          -0.0613            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.75, learning_rate=0.05, score=0.299716, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.75, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         163.7241          21.2369            0.00s\n",
      "         2         200.1829           0.9624            0.04s\n",
      "         3         196.6305           0.5399            0.03s\n",
      "         4         163.8048           0.8524            0.02s\n",
      "         5         162.3932           0.1074            0.03s\n",
      "         6         141.2258           1.2252            0.03s\n",
      "         7         111.0067          13.2590            0.04s\n",
      "         8         126.8180          -0.7288            0.03s\n",
      "         9          78.6346          -1.4484            0.04s\n",
      "        10         105.1129           0.9564            0.04s\n",
      "        20          56.6228          -1.0033            0.03s\n",
      "        30          39.2170          -1.1407            0.02s\n",
      "        40          23.7424          -0.2411            0.02s\n",
      "        50          21.2572          -0.1544            0.01s\n",
      "        60          13.0738          -0.5458            0.01s\n",
      "        70          10.9238          -0.0215            0.01s\n",
      "        80           7.4219          -0.0535            0.00s\n",
      "        90           5.2263          -0.3014            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.75, learning_rate=0.05, score=0.609590, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         257.4776          -2.3388            0.00s\n",
      "         2         241.7770           1.4257            0.00s\n",
      "         3         209.0030           0.4755            0.00s\n",
      "         4         200.7384           2.3963            0.00s\n",
      "         5         132.2427           2.0073            0.00s\n",
      "         6         141.7269          16.8199            0.00s\n",
      "         7         154.8332           1.6629            0.00s\n",
      "         8         130.6981          10.2961            0.00s\n",
      "         9         143.8746           1.6707            0.00s\n",
      "        10         118.3874          -1.7671            0.00s\n",
      "        20          77.2480          -0.7091            0.05s\n",
      "        30          35.0579          -0.1444            0.03s\n",
      "        40          32.1287          -0.4230            0.02s\n",
      "        50          24.5360          -0.2195            0.01s\n",
      "        60          12.8231          -0.4412            0.01s\n",
      "        70          12.1171          -0.5181            0.01s\n",
      "        80           8.0590          -0.5514            0.00s\n",
      "        90           5.8047          -0.3325            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.8, learning_rate=0.05, score=-0.254633, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         258.8168          -2.8023            0.00s\n",
      "         2         244.5659           0.9362            0.00s\n",
      "         3         209.1942           0.2687            0.00s\n",
      "         4         197.9320           2.5709            0.00s\n",
      "         5         129.5730          -0.7873            0.00s\n",
      "         6         139.9396          15.3070            0.00s\n",
      "         7         155.3602           0.3441            0.19s\n",
      "         8         130.4724          12.9007            0.16s\n",
      "         9         142.3373           1.9727            0.14s\n",
      "        10         118.9281          10.6039            0.13s\n",
      "        20          73.8965          -0.8558            0.08s\n",
      "        30          36.6930           0.7108            0.05s\n",
      "        40          28.3404          -0.4593            0.04s\n",
      "        50          20.5258          -0.3272            0.03s\n",
      "        60          12.2139          -0.4173            0.02s\n",
      "        70          10.5701           0.2233            0.01s\n",
      "        80           7.2258          -0.4642            0.01s\n",
      "        90           5.1927          -0.0988            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.8, learning_rate=0.05, score=-2.057140, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         257.8732          -2.3651            0.09s\n",
      "         2         241.8607           1.0871            0.09s\n",
      "         3         209.9834          -0.5204            0.09s\n",
      "         4         198.1589           1.9131            0.06s\n",
      "         5         124.3352           1.9173            0.07s\n",
      "         6         141.2271          17.1872            0.06s\n",
      "         7         155.8790           0.4138            0.06s\n",
      "         8         124.3954          12.6757            0.05s\n",
      "         9         141.2854           1.1341            0.05s\n",
      "        10         114.0630           0.1947            0.05s\n",
      "        20          76.0996          -0.2641            0.03s\n",
      "        30          31.8498          -0.2164            0.03s\n",
      "        40          29.1867          -0.0737            0.02s\n",
      "        50          21.0118          -0.2004            0.02s\n",
      "        60          11.5226          -0.4792            0.01s\n",
      "        70          11.8175          -0.0884            0.01s\n",
      "        80           7.2891          -0.3147            0.00s\n",
      "        90           5.0089          -0.0514            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.8, learning_rate=0.05, score=-0.027205, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         252.0375           0.6366            0.00s\n",
      "         2         234.8903           1.0437            0.04s\n",
      "         3         203.2993          -1.0737            0.03s\n",
      "         4         196.3459           1.3811            0.04s\n",
      "         5         123.4720           0.9504            0.03s\n",
      "         6         136.7778          12.2434            0.04s\n",
      "         7         158.0998           1.4039            0.04s\n",
      "         8         119.2789          11.0843            0.04s\n",
      "         9         139.9259           2.2259            0.04s\n",
      "        10         109.6036          10.3356            0.04s\n",
      "        20          68.0858           0.5082            0.03s\n",
      "        30          29.7749           0.7168            0.02s\n",
      "        40          29.5987          -0.2540            0.02s\n",
      "        50          21.8601           0.0100            0.01s\n",
      "        60           9.0597          -0.4910            0.01s\n",
      "        70          10.4469          -0.0446            0.01s\n",
      "        80           5.4742          -0.4522            0.00s\n",
      "        90           3.9269          -0.3217            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.8, learning_rate=0.05, score=-0.032356, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         200.1416          -0.0133            0.09s\n",
      "         2         186.6225           0.5539            0.09s\n",
      "         3         163.5990          -0.0425            0.06s\n",
      "         4         156.0444           0.4311            0.06s\n",
      "         5          77.2701           2.6414            0.05s\n",
      "         6         131.0229          -2.2096            0.06s\n",
      "         7         121.7491          -0.8032            0.06s\n",
      "         8         111.0033          -1.0983            0.05s\n",
      "         9         114.1929          -0.2507            0.05s\n",
      "        10          84.6760          10.9160            0.05s\n",
      "        20          53.8036           0.2805            0.03s\n",
      "        30          26.0121          -0.4607            0.03s\n",
      "        40          20.7414          -0.4223            0.02s\n",
      "        50          15.2931           0.0791            0.02s\n",
      "        60           9.2186          -0.4608            0.01s\n",
      "        70           8.2820          -0.0264            0.01s\n",
      "        80           6.2186          -0.1630            0.00s\n",
      "        90           4.1991          -0.1920            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.8, learning_rate=0.05, score=-0.638140, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         205.5813          22.2638            0.09s\n",
      "         2         198.9332          22.4691            0.04s\n",
      "         3         209.9556          -0.8094            0.06s\n",
      "         4         185.5978           1.7812            0.06s\n",
      "         5         117.9231           2.2885            0.05s\n",
      "         6         168.1631           0.1056            0.06s\n",
      "         7         131.8074          13.2168            0.05s\n",
      "         8         142.5929           1.0783            0.05s\n",
      "         9         130.3075          -0.8416            0.04s\n",
      "        10         112.0629          11.4218            0.05s\n",
      "        20          72.9578          -0.1754            0.03s\n",
      "        30          36.9837          -0.4933            0.02s\n",
      "        40          29.2648           0.4016            0.02s\n",
      "        50          21.0315           0.0438            0.02s\n",
      "        60          13.4065          -0.1252            0.01s\n",
      "        70          10.0555          -0.3488            0.01s\n",
      "        80           8.1804          -0.1234            0.00s\n",
      "        90           5.4834          -0.1158            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.8, learning_rate=0.05, score=-1.310360, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         127.4067           3.7214            0.00s\n",
      "         2         127.5733           2.2292            0.00s\n",
      "         3         159.2033          -0.4973            0.00s\n",
      "         4         140.2239          -0.0732            0.00s\n",
      "         5         128.8219           1.9968            0.00s\n",
      "         6         127.8568          -0.4449            0.00s\n",
      "         7          80.7699          11.8783            0.00s\n",
      "         8         111.7349          -1.0014            0.00s\n",
      "         9         100.8145          -0.2198            0.00s\n",
      "        10          82.1460           9.1513            0.00s\n",
      "        20          54.1039          -0.4034            0.00s\n",
      "        30          34.4313          -0.2560            0.00s\n",
      "        40          19.8102           0.1104            0.02s\n",
      "        50          15.6699           0.0224            0.02s\n",
      "        60           9.6937           0.1264            0.01s\n",
      "        70           6.8930          -0.1023            0.01s\n",
      "        80           4.7575          -0.1539            0.00s\n",
      "        90           3.5495          -0.1859            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.8, learning_rate=0.05, score=0.098872, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         210.7542          27.7115            0.00s\n",
      "         2         202.2091          22.4318            0.04s\n",
      "         3         218.3298           0.5161            0.06s\n",
      "         4         189.7704           3.1958            0.06s\n",
      "         5         124.2552           2.1012            0.05s\n",
      "         6         177.1254          -0.0853            0.06s\n",
      "         7         136.7902          15.5484            0.05s\n",
      "         8         148.7874          -0.5806            0.05s\n",
      "         9          95.9382           3.9840            0.05s\n",
      "        10         114.8695           1.8370            0.05s\n",
      "        20          74.3273          -0.2584            0.03s\n",
      "        30          45.7374          -0.6486            0.03s\n",
      "        40          30.5957           0.4334            0.02s\n",
      "        50          22.5067          -0.4684            0.02s\n",
      "        60          14.4044          -0.1308            0.01s\n",
      "        70          10.1910          -0.3412            0.01s\n",
      "        80           7.1859          -0.0601            0.00s\n",
      "        90           5.5851          -0.2457            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.8, learning_rate=0.05, score=-7.756038, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         147.9161          49.6953            0.09s\n",
      "         2         218.0749          -0.9812            0.04s\n",
      "         3         170.0834          19.4873            0.09s\n",
      "         4         167.1435          -0.5983            0.06s\n",
      "         5         168.3374          -0.4309            0.07s\n",
      "         6         150.4835           0.1109            0.06s\n",
      "         7         116.4094          15.9285            0.06s\n",
      "         8         127.3297           1.1379            0.05s\n",
      "         9         117.8359           1.1663            0.05s\n",
      "        10          92.6741           4.0742            0.05s\n",
      "        20          58.4540          -1.2477            0.03s\n",
      "        30          35.5772          -0.1097            0.03s\n",
      "        40          18.8754          -0.4059            0.02s\n",
      "        50          19.2066          -0.0673            0.02s\n",
      "        60          11.0323          -0.2191            0.01s\n",
      "        70           8.6651           0.0377            0.01s\n",
      "        80           5.6065          -0.0063            0.00s\n",
      "        90           4.4880           0.0165            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.8, learning_rate=0.05, score=0.236255, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.8, learning_rate=0.05 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         158.3255          27.5288            0.09s\n",
      "         2         192.3097          -2.0664            0.04s\n",
      "         3         184.0155           0.5617            0.06s\n",
      "         4         154.1330           0.5367            0.04s\n",
      "         5         156.1989          -0.0544            0.05s\n",
      "         6         131.8712           0.5963            0.04s\n",
      "         7         107.6108          16.4488            0.05s\n",
      "         8         120.8746           1.2283            0.05s\n",
      "         9         111.8588          -0.9314            0.04s\n",
      "        10          95.2026          -0.3503            0.05s\n",
      "        20          52.1071          -0.1867            0.03s\n",
      "        30          35.0050          -0.9010            0.02s\n",
      "        40          21.6973          -0.4732            0.02s\n",
      "        50          19.7562          -0.3959            0.02s\n",
      "        60          11.4069          -0.6065            0.01s\n",
      "        70          10.0372          -0.2365            0.01s\n",
      "        80           7.0070          -0.0134            0.00s\n",
      "        90           5.6783          -0.3289            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.8, learning_rate=0.05, score=0.561493, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.7, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         287.9736          -0.7565            0.10s\n",
      "         2         261.5520           2.2923            0.05s\n",
      "         3         229.4453          -0.0105            0.06s\n",
      "         4         216.3591           0.8768            0.07s\n",
      "         5         136.2679           2.7670            0.08s\n",
      "         6         102.3316          12.7564            0.06s\n",
      "         7         174.8256           2.0569            0.07s\n",
      "         8         150.2438           8.8975            0.06s\n",
      "         9         162.6161           1.1299            0.06s\n",
      "        10         114.8951          -0.1415            0.05s\n",
      "        20          78.6247          -0.7271            0.04s\n",
      "        30          37.5994           0.2667            0.03s\n",
      "        40          36.9691          -0.8229            0.02s\n",
      "        50          23.1494          -0.5878            0.02s\n",
      "        60          12.8760          -0.6862            0.02s\n",
      "        70          13.5760          -0.1151            0.01s\n",
      "        80           8.8398          -0.5253            0.01s\n",
      "        90           7.1346          -0.3031            0.00s\n",
      "       100           4.6849          -0.1112            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.7, learning_rate=0.05, score=-0.246498, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.7, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         289.8912          -1.1790            0.00s\n",
      "         2         264.0664          -0.3385            0.00s\n",
      "         3         231.1540          -0.0936            0.00s\n",
      "         4         213.5986           1.8984            0.00s\n",
      "         5         132.1037           0.6387            0.00s\n",
      "         6          99.9696          11.0747            0.00s\n",
      "         7         176.3750           1.1742            0.00s\n",
      "         8         148.8401           8.8957            0.18s\n",
      "         9         159.0204           3.5621            0.16s\n",
      "        10         118.8041           7.1564            0.14s\n",
      "        20          76.0601          -0.2070            0.06s\n",
      "        30          36.9563           0.4483            0.04s\n",
      "        40          32.2758          -1.2277            0.02s\n",
      "        50          19.8651          -1.2161            0.04s\n",
      "        60          12.7640          -0.8902            0.03s\n",
      "        70          11.5390           0.0519            0.02s\n",
      "        80           8.5777          -0.3289            0.01s\n",
      "        90           6.7940          -0.1051            0.01s\n",
      "       100           4.2508          -0.2276            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.7, learning_rate=0.05, score=-2.279382, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.7, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         288.7676          -0.4958            0.00s\n",
      "         2         260.8576           2.3372            0.05s\n",
      "         3         229.2588           0.0750            0.03s\n",
      "         4         213.8526           0.7059            0.05s\n",
      "         5         127.8188           1.4648            0.04s\n",
      "         6         100.9612           7.1176            0.05s\n",
      "         7         178.5623           2.5173            0.04s\n",
      "         8         144.3274           7.8547            0.06s\n",
      "         9         162.8372           2.0646            0.06s\n",
      "        10         117.9719           7.0554            0.05s\n",
      "        20          76.2296          -2.3826            0.04s\n",
      "        30          34.6612           0.8876            0.03s\n",
      "        40          32.8047          -0.7608            0.02s\n",
      "        50          22.0184          -0.3413            0.02s\n",
      "        60          11.5588          -0.4660            0.02s\n",
      "        70          12.8714          -0.3397            0.01s\n",
      "        80           8.8225          -0.4063            0.01s\n",
      "        90           7.1812          -0.2018            0.00s\n",
      "       100           5.0523          -0.0213            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.7, learning_rate=0.05, score=-0.160143, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.7, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         282.2828          -0.0102            0.10s\n",
      "         2         253.5370           1.6543            0.10s\n",
      "         3         223.2478           0.2454            0.10s\n",
      "         4         209.8703           0.5862            0.07s\n",
      "         5         125.9980           0.9530            0.08s\n",
      "         6          93.2883          10.1961            0.08s\n",
      "         7         173.7415           1.4318            0.07s\n",
      "         8         135.1072          10.4558            0.07s\n",
      "         9         153.5216           2.6928            0.06s\n",
      "        10         109.4107           7.0141            0.06s\n",
      "        20          70.8742          -1.9218            0.04s\n",
      "        30          33.8144           0.3714            0.03s\n",
      "        40          33.3849           0.0600            0.02s\n",
      "        50          21.9482          -0.8878            0.02s\n",
      "        60          10.2359          -0.5246            0.02s\n",
      "        70          11.0619          -0.3421            0.01s\n",
      "        80           7.2119          -0.3180            0.01s\n",
      "        90           5.6569          -0.2460            0.00s\n",
      "       100           4.4301          -0.0164            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.7, learning_rate=0.05, score=0.238765, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.7, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         218.2648           0.4686            0.10s\n",
      "         2         193.4615           2.0600            0.05s\n",
      "         3         179.8763          -0.1774            0.06s\n",
      "         4         159.6389           1.1099            0.05s\n",
      "         5          77.2999           1.1221            0.06s\n",
      "         6          87.1573           7.1577            0.05s\n",
      "         7         136.2369           0.6059            0.05s\n",
      "         8         126.6066           0.1578            0.05s\n",
      "         9         124.5734          -0.0968            0.05s\n",
      "        10          93.3076           8.4527            0.05s\n",
      "        20          57.1697           0.0664            0.04s\n",
      "        30          26.5903           1.7657            0.03s\n",
      "        40          21.3004           0.0212            0.02s\n",
      "        50          15.4694          -0.4036            0.02s\n",
      "        60           9.6476          -0.2568            0.02s\n",
      "        70           7.8061          -0.0789            0.01s\n",
      "        80           6.5346          -0.1968            0.01s\n",
      "        90           5.0102          -0.2107            0.00s\n",
      "       100           3.8915          -0.1047            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.7, learning_rate=0.05, score=-0.586688, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.7, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         225.1204          17.0315            0.10s\n",
      "         2         207.3429          16.9920            0.10s\n",
      "         3         229.4716           1.3476            0.06s\n",
      "         4         193.4812           1.6320            0.07s\n",
      "         5         126.0808           1.2106            0.06s\n",
      "         6         131.6346           2.7756            0.06s\n",
      "         7         133.3527           9.5769            0.05s\n",
      "         8         163.2346           0.4488            0.06s\n",
      "         9         143.3374           0.6792            0.05s\n",
      "        10         124.4394           7.0784            0.05s\n",
      "        20          76.6747          -1.0176            0.03s\n",
      "        30          40.2286           0.0542            0.03s\n",
      "        40          30.0616           1.1584            0.02s\n",
      "        50          14.7093          -0.8203            0.02s\n",
      "        60          12.5212          -0.2473            0.01s\n",
      "        70          11.5009          -0.3461            0.01s\n",
      "        80           8.7676          -0.1245            0.01s\n",
      "        90           6.4381          -0.2707            0.00s\n",
      "       100           5.4358          -0.2604            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.7, learning_rate=0.05, score=-1.717086, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.7, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         133.9842           0.9055            0.00s\n",
      "         2         123.8410          15.3338            0.00s\n",
      "         3         171.8981           1.6232            0.00s\n",
      "         4         138.3225           1.2471            0.00s\n",
      "         5         134.5724          -0.8331            0.00s\n",
      "         6         141.8770          -0.5574            0.00s\n",
      "         7          73.2841           1.3067            0.00s\n",
      "         8         127.2879          -0.7810            0.00s\n",
      "         9         110.1483           1.5023            0.00s\n",
      "        10          91.3234           6.2794            0.00s\n",
      "        20          60.3283           0.5448            0.06s\n",
      "        30          39.4301          -0.4026            0.04s\n",
      "        40          23.3527           0.2605            0.02s\n",
      "        50          11.8372           0.0361            0.02s\n",
      "        60           8.4997          -0.3663            0.01s\n",
      "        70           7.5939          -0.0283            0.02s\n",
      "        80           5.9132          -0.0685            0.01s\n",
      "        90           4.4219          -0.1250            0.00s\n",
      "       100           3.6106          -0.1696            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.7, learning_rate=0.05, score=0.159626, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.7, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         228.4113          16.0948            0.10s\n",
      "         2         208.2246          15.9924            0.05s\n",
      "         3         240.6272           1.1782            0.06s\n",
      "         4         202.7495           2.5096            0.05s\n",
      "         5         129.8965           0.5696            0.06s\n",
      "         6         196.2444          -0.3975            0.05s\n",
      "         7         132.1608           9.5669            0.05s\n",
      "         8         165.4871          -0.1151            0.05s\n",
      "         9         103.9404           3.2202            0.05s\n",
      "        10         125.6503           6.3469            0.04s\n",
      "        20          77.0482           0.0663            0.04s\n",
      "        30          49.1315          -0.4225            0.03s\n",
      "        40          31.2053           0.2877            0.02s\n",
      "        50          17.1307          -0.0683            0.02s\n",
      "        60          12.4441           0.0003            0.02s\n",
      "        70          10.6414          -0.2573            0.01s\n",
      "        80           6.7104          -0.2638            0.01s\n",
      "        90           6.1395          -0.0627            0.00s\n",
      "       100           4.2234          -0.2327            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.7, learning_rate=0.05, score=-3.183889, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.7, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         156.9905          35.8122            0.10s\n",
      "         2         230.4978          -1.0397            0.05s\n",
      "         3         185.0656          13.8384            0.06s\n",
      "         4         152.1994           8.4696            0.05s\n",
      "         5         185.1336           0.8325            0.08s\n",
      "         6         167.6584          -0.2808            0.06s\n",
      "         7         124.7295          11.6066            0.07s\n",
      "         8         138.4362           0.9995            0.07s\n",
      "         9          90.8820          -0.7740            0.06s\n",
      "        10         105.7159           7.3629            0.06s\n",
      "        20          56.7881           0.9323            0.04s\n",
      "        30          39.8741           0.0546            0.03s\n",
      "        40          20.5276          -0.3138            0.02s\n",
      "        50          20.6773          -0.2903            0.02s\n",
      "        60          12.8600          -0.6354            0.02s\n",
      "        70          10.6873          -0.1704            0.01s\n",
      "        80           7.5249          -0.0272            0.01s\n",
      "        90           5.3867          -0.2278            0.00s\n",
      "       100           4.5054          -0.2316            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.7, learning_rate=0.05, score=0.330310, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.7, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         166.7912          19.1280            0.10s\n",
      "         2         201.3738          -1.0168            0.05s\n",
      "         3         202.3122           1.6514            0.06s\n",
      "         4         168.0097           0.0956            0.05s\n",
      "         5         168.4248           0.5394            0.06s\n",
      "         6         147.4937           1.5592            0.06s\n",
      "         7         113.1946          10.3537            0.05s\n",
      "         8         130.4427          -0.0372            0.06s\n",
      "         9          79.6994          -0.4040            0.05s\n",
      "        10         107.6369           1.1828            0.05s\n",
      "        20          52.2437          -0.0602            0.04s\n",
      "        30          39.8847          -0.2959            0.03s\n",
      "        40          25.9608          -0.0217            0.02s\n",
      "        50          22.4357          -0.1229            0.02s\n",
      "        60          12.9579          -0.2207            0.01s\n",
      "        70          10.3403           0.0135            0.01s\n",
      "        80           7.2722          -0.0448            0.01s\n",
      "        90           5.9201          -0.1576            0.00s\n",
      "       100           4.2096           0.0205            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.7, learning_rate=0.05, score=0.719292, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.75, learning_rate=0.05 ............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         268.0527          -1.5883            0.10s\n",
      "         2         241.9591           1.0539            0.05s\n",
      "         3         214.6580          -0.2809            0.06s\n",
      "         4         204.7294           1.1407            0.07s\n",
      "         5         133.0443           2.8846            0.08s\n",
      "         6         149.3782          13.3313            0.06s\n",
      "         7         162.4382           1.6519            0.07s\n",
      "         8         136.6754           8.7842            0.06s\n",
      "         9         149.1879           1.3127            0.06s\n",
      "        10         122.7701          -0.3590            0.05s\n",
      "        20          76.8949           0.6460            0.04s\n",
      "        30          37.3772          -0.1253            0.03s\n",
      "        40          30.2933          -0.3243            0.02s\n",
      "        50          23.1466          -0.7874            0.02s\n",
      "        60          12.1141          -0.3245            0.02s\n",
      "        70          12.5360          -0.3918            0.01s\n",
      "        80           7.6479          -0.4812            0.01s\n",
      "        90           5.7757          -0.2838            0.00s\n",
      "       100           4.1766          -0.2890            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.75, learning_rate=0.05, score=-0.185979, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.75, learning_rate=0.05 ............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         269.8733          -2.2693            0.00s\n",
      "         2         244.5319          -0.2242            0.00s\n",
      "         3         215.6269           0.1733            0.00s\n",
      "         4         201.7632           2.4753            0.00s\n",
      "         5         129.0312           0.4536            0.00s\n",
      "         6         146.6481          14.7172            0.00s\n",
      "         7         162.4356           0.9133            0.00s\n",
      "         8         133.9593           9.4031            0.00s\n",
      "         9         145.4613           2.1809            0.00s\n",
      "        10         123.0340           8.6540            0.00s\n",
      "        20          72.2249           0.8441            0.06s\n",
      "        30          35.9153           1.2181            0.03s\n",
      "        40          27.6550          -1.5833            0.02s\n",
      "        50          20.7931          -0.1686            0.01s\n",
      "        60          10.9045          -0.1960            0.01s\n",
      "        70          10.3888          -0.1948            0.01s\n",
      "        80           6.7925          -0.3749            0.01s\n",
      "        90           4.7893          -0.1168            0.00s\n",
      "       100           3.3951          -0.2488            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.75, learning_rate=0.05, score=-2.105136, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.75, learning_rate=0.05 ............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         270.2257          -2.1484            0.10s\n",
      "         2         243.3628           2.6208            0.05s\n",
      "         3         215.3946          -0.6160            0.06s\n",
      "         4         202.2680           2.5267            0.07s\n",
      "         5         125.4237           3.5690            0.08s\n",
      "         6         148.8767          11.1782            0.08s\n",
      "         7         164.0276           2.8294            0.07s\n",
      "         8         131.4368           8.4987            0.07s\n",
      "         9         148.9505           1.6405            0.07s\n",
      "        10         120.9108          -0.2270            0.07s\n",
      "        20          75.2901           0.4504            0.04s\n",
      "        30          32.6026           0.2156            0.03s\n",
      "        40          27.9272          -0.9515            0.03s\n",
      "        50          21.3200          -0.1229            0.02s\n",
      "        60          10.9514          -0.5580            0.02s\n",
      "        70          12.6630          -0.0680            0.01s\n",
      "        80           7.3013          -0.1042            0.01s\n",
      "        90           5.2023          -0.2440            0.00s\n",
      "       100           4.3345          -0.0945            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.75, learning_rate=0.05, score=-0.060380, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.75, learning_rate=0.05 ............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         264.1448           0.1533            0.10s\n",
      "         2         235.6200           1.7001            0.05s\n",
      "         3         209.5950          -0.2452            0.06s\n",
      "         4         199.3489           1.1566            0.07s\n",
      "         5         123.2049           1.4258            0.06s\n",
      "         6         143.4356          13.9860            0.06s\n",
      "         7         163.0826           1.6629            0.05s\n",
      "         8         124.5009          12.2335            0.06s\n",
      "         9         144.0616           2.7077            0.05s\n",
      "        10         113.1198           8.5316            0.05s\n",
      "        20          67.3918           0.6146            0.04s\n",
      "        30          30.7386           0.4788            0.03s\n",
      "        40          28.5621          -0.6870            0.03s\n",
      "        50          22.5626          -0.1401            0.02s\n",
      "        60           8.8148          -0.5147            0.02s\n",
      "        70          12.0062          -0.0365            0.01s\n",
      "        80           6.0375          -0.3250            0.01s\n",
      "        90           4.7740          -0.4178            0.00s\n",
      "       100           3.9162           0.0069            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.75, learning_rate=0.05, score=0.103227, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.75, learning_rate=0.05 ............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         204.1192          -0.1469            0.00s\n",
      "         2         183.1465           2.2665            0.05s\n",
      "         3         168.4147          -0.4337            0.06s\n",
      "         4         157.8817          -0.1274            0.05s\n",
      "         5          76.3381           5.4371            0.06s\n",
      "         6         137.9097          -0.4105            0.05s\n",
      "         7         125.8014          -0.1604            0.05s\n",
      "         8         114.1897          -0.5995            0.05s\n",
      "         9         115.8158          -0.9644            0.05s\n",
      "        10          85.9593           8.3826            0.04s\n",
      "        20          51.9370           0.5252            0.04s\n",
      "        30          26.7198           0.7155            0.03s\n",
      "        40          19.4742          -0.3531            0.03s\n",
      "        50          15.5695           0.0011            0.02s\n",
      "        60           9.7061          -0.4186            0.02s\n",
      "        70           8.3893          -0.0353            0.01s\n",
      "        80           5.5438          -0.0884            0.01s\n",
      "        90           3.8575          -0.2248            0.00s\n",
      "       100           3.4736          -0.0665            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.75, learning_rate=0.05, score=-0.619920, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.75, learning_rate=0.05 ............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         209.8049          18.1789            0.10s\n",
      "         2         197.5415          19.2881            0.05s\n",
      "         3         215.5563           0.0675            0.06s\n",
      "         4         187.7647           0.9669            0.05s\n",
      "         5         122.7889           1.6851            0.06s\n",
      "         6         175.1053          -1.5282            0.06s\n",
      "         7         135.6874          11.3252            0.05s\n",
      "         8         147.2330           0.9615            0.06s\n",
      "         9         135.0989          -0.4004            0.05s\n",
      "        10         116.2827           8.4709            0.05s\n",
      "        20          71.3483           0.5402            0.04s\n",
      "        30          37.1323           0.1841            0.03s\n",
      "        40          27.5912           0.5038            0.03s\n",
      "        50          14.7195          -0.2992            0.02s\n",
      "        60          14.4043          -0.1232            0.02s\n",
      "        70          11.6203          -0.2452            0.01s\n",
      "        80           8.4590          -0.1027            0.01s\n",
      "        90           5.8115          -0.2172            0.00s\n",
      "       100           5.1463          -0.2234            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.75, learning_rate=0.05, score=-1.064973, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.75, learning_rate=0.05 ............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         126.5477           0.1852            0.00s\n",
      "         2         120.4698           2.2887            0.00s\n",
      "         3         164.1207           0.6620            0.00s\n",
      "         4         141.7157          -0.6886            0.00s\n",
      "         5         134.4763           0.0972            0.00s\n",
      "         6         134.7302          -0.2956            0.00s\n",
      "         7          83.9601          10.3598            0.00s\n",
      "         8         116.0170          -0.0490            0.00s\n",
      "         9         103.4701           0.9350            0.00s\n",
      "        10          85.0517           7.7244            0.00s\n",
      "        20          56.0271          -0.2888            0.08s\n",
      "        30          37.7032          -0.1053            0.06s\n",
      "        40          19.5174           0.3494            0.04s\n",
      "        50          11.7854          -0.1743            0.03s\n",
      "        60           9.5625          -0.0731            0.02s\n",
      "        70           7.4553          -0.0969            0.02s\n",
      "        80           5.0484          -0.3482            0.01s\n",
      "        90           4.1241          -0.1431            0.01s\n",
      "       100           3.7319          -0.0262            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.75, learning_rate=0.05, score=0.178675, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.75, learning_rate=0.05 ............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         216.0023          22.7936            0.10s\n",
      "         2         202.2616          16.5841            0.05s\n",
      "         3         226.9424           1.5440            0.06s\n",
      "         4         194.8489           2.1965            0.07s\n",
      "         5         130.0177           1.6237            0.08s\n",
      "         6         187.2252          -0.0906            0.06s\n",
      "         7         140.4913          12.1321            0.07s\n",
      "         8         156.3404          -0.0501            0.06s\n",
      "         9         100.6794           1.9714            0.06s\n",
      "        10         120.3175          -1.5733            0.05s\n",
      "        20          74.9823           0.0094            0.04s\n",
      "        30          48.0922           0.0381            0.03s\n",
      "        40          31.3057           0.2311            0.02s\n",
      "        50          17.4502          -0.6286            0.02s\n",
      "        60          14.4383          -0.1131            0.02s\n",
      "        70          12.1543          -0.2881            0.01s\n",
      "        80           6.9197          -0.6076            0.01s\n",
      "        90           6.2642          -0.1282            0.00s\n",
      "       100           4.7052          -0.2408            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.75, learning_rate=0.05, score=-5.154685, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.75, learning_rate=0.05 ............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         153.9567          37.6070            0.00s\n",
      "         2         227.4605           0.6571            0.10s\n",
      "         3         182.3300          15.1226            0.06s\n",
      "         4         178.1178          -0.2921            0.07s\n",
      "         5         180.9259           0.0589            0.06s\n",
      "         6         161.0233          -0.0041            0.06s\n",
      "         7         122.5322          12.7934            0.05s\n",
      "         8         135.2936           0.3861            0.06s\n",
      "         9          91.2823          -0.7171            0.06s\n",
      "        10         103.3137           5.7727            0.06s\n",
      "        20          59.4061          -1.1133            0.04s\n",
      "        30          40.5768          -0.0332            0.03s\n",
      "        40          19.4983          -0.6226            0.03s\n",
      "        50          20.6462          -0.2445            0.02s\n",
      "        60          12.7243          -0.0414            0.02s\n",
      "        70           9.4605          -0.0205            0.01s\n",
      "        80           6.4730          -0.2273            0.01s\n",
      "        90           4.8016          -0.0613            0.00s\n",
      "       100           4.0732          -0.0840            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.75, learning_rate=0.05, score=0.320426, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.75, learning_rate=0.05 ............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         163.7241          21.2369            0.10s\n",
      "         2         200.1829           0.9624            0.05s\n",
      "         3         196.6305           0.5399            0.06s\n",
      "         4         163.8048           0.8524            0.07s\n",
      "         5         162.3932           0.1074            0.08s\n",
      "         6         141.2258           1.2252            0.06s\n",
      "         7         111.0067          13.2590            0.07s\n",
      "         8         126.8180          -0.7288            0.06s\n",
      "         9          78.6346          -1.4484            0.06s\n",
      "        10         105.1129           0.9564            0.05s\n",
      "        20          56.6228          -1.0033            0.04s\n",
      "        30          39.2170          -1.1407            0.03s\n",
      "        40          23.7424          -0.2411            0.03s\n",
      "        50          21.2572          -0.1544            0.02s\n",
      "        60          13.0738          -0.5458            0.02s\n",
      "        70          10.9238          -0.0215            0.01s\n",
      "        80           7.4219          -0.0535            0.01s\n",
      "        90           5.2263          -0.3014            0.00s\n",
      "       100           4.1526          -0.1749            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.75, learning_rate=0.05, score=0.615256, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.8, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         257.4776          -2.3388            0.10s\n",
      "         2         241.7770           1.4257            0.05s\n",
      "         3         209.0030           0.4755            0.06s\n",
      "         4         200.7384           2.3963            0.05s\n",
      "         5         132.2427           2.0073            0.06s\n",
      "         6         141.7269          16.8199            0.05s\n",
      "         7         154.8332           1.6629            0.05s\n",
      "         8         130.6981          10.2961            0.05s\n",
      "         9         143.8746           1.6707            0.05s\n",
      "        10         118.3874          -1.7671            0.05s\n",
      "        20          77.2480          -0.7091            0.03s\n",
      "        30          35.0579          -0.1444            0.03s\n",
      "        40          32.1287          -0.4230            0.02s\n",
      "        50          24.5360          -0.2195            0.02s\n",
      "        60          12.8231          -0.4412            0.02s\n",
      "        70          12.1171          -0.5181            0.01s\n",
      "        80           8.0590          -0.5514            0.01s\n",
      "        90           5.8047          -0.3325            0.00s\n",
      "       100           4.4857          -0.1852            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.8, learning_rate=0.05, score=-0.388512, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.8, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         258.8168          -2.8023            0.40s\n",
      "         2         244.5659           0.9362            0.25s\n",
      "         3         209.1942           0.2687            0.19s\n",
      "         4         197.9320           2.5709            0.17s\n",
      "         5         129.5730          -0.7873            0.15s\n",
      "         6         139.9396          15.3070            0.13s\n",
      "         7         155.3602           0.3441            0.12s\n",
      "         8         130.4724          12.9007            0.11s\n",
      "         9         142.3373           1.9727            0.10s\n",
      "        10         118.9281          10.6039            0.10s\n",
      "        20          73.8965          -0.8558            0.06s\n",
      "        30          36.6930           0.7108            0.04s\n",
      "        40          28.3404          -0.4593            0.03s\n",
      "        50          20.5258          -0.3272            0.03s\n",
      "        60          12.2139          -0.4173            0.02s\n",
      "        70          10.5701           0.2233            0.01s\n",
      "        80           7.2258          -0.4642            0.01s\n",
      "        90           5.1927          -0.0988            0.00s\n",
      "       100           4.1107          -0.0957            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.8, learning_rate=0.05, score=-2.175075, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.8, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         257.8732          -2.3651            0.00s\n",
      "         2         241.8607           1.0871            0.05s\n",
      "         3         209.9834          -0.5204            0.06s\n",
      "         4         198.1589           1.9131            0.05s\n",
      "         5         124.3352           1.9173            0.06s\n",
      "         6         141.2271          17.1872            0.05s\n",
      "         7         155.8790           0.4138            0.05s\n",
      "         8         124.3954          12.6757            0.06s\n",
      "         9         141.2854           1.1341            0.06s\n",
      "        10         114.0630           0.1947            0.05s\n",
      "        20          76.0996          -0.2641            0.04s\n",
      "        30          31.8498          -0.2164            0.03s\n",
      "        40          29.1867          -0.0737            0.03s\n",
      "        50          21.0118          -0.2004            0.02s\n",
      "        60          11.5226          -0.4792            0.02s\n",
      "        70          11.8175          -0.0884            0.01s\n",
      "        80           7.2891          -0.3147            0.01s\n",
      "        90           5.0089          -0.0514            0.00s\n",
      "       100           3.8752          -0.1255            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.8, learning_rate=0.05, score=-0.051042, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.8, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         252.0375           0.6366            0.10s\n",
      "         2         234.8903           1.0437            0.10s\n",
      "         3         203.2993          -1.0737            0.10s\n",
      "         4         196.3459           1.3811            0.10s\n",
      "         5         123.4720           0.9504            0.08s\n",
      "         6         136.7778          12.2434            0.08s\n",
      "         7         158.0998           1.4039            0.08s\n",
      "         8         119.2789          11.0843            0.07s\n",
      "         9         139.9259           2.2259            0.07s\n",
      "        10         109.6036          10.3356            0.06s\n",
      "        20          68.0858           0.5082            0.04s\n",
      "        30          29.7749           0.7168            0.03s\n",
      "        40          29.5987          -0.2540            0.03s\n",
      "        50          21.8601           0.0100            0.02s\n",
      "        60           9.0597          -0.4910            0.02s\n",
      "        70          10.4469          -0.0446            0.01s\n",
      "        80           5.4742          -0.4522            0.01s\n",
      "        90           3.9269          -0.3217            0.00s\n",
      "       100           3.4985          -0.1015            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.8, learning_rate=0.05, score=-0.050028, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.8, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         200.1416          -0.0133            0.10s\n",
      "         2         186.6225           0.5539            0.10s\n",
      "         3         163.5990          -0.0425            0.06s\n",
      "         4         156.0444           0.4311            0.07s\n",
      "         5          77.2701           2.6414            0.08s\n",
      "         6         131.0229          -2.2096            0.06s\n",
      "         7         121.7491          -0.8032            0.07s\n",
      "         8         111.0033          -1.0983            0.06s\n",
      "         9         114.1929          -0.2507            0.06s\n",
      "        10          84.6760          10.9160            0.05s\n",
      "        20          53.8036           0.2805            0.04s\n",
      "        30          26.0121          -0.4607            0.03s\n",
      "        40          20.7414          -0.4223            0.03s\n",
      "        50          15.2931           0.0791            0.02s\n",
      "        60           9.2186          -0.4608            0.02s\n",
      "        70           8.2820          -0.0264            0.01s\n",
      "        80           6.2186          -0.1630            0.01s\n",
      "        90           4.1991          -0.1920            0.00s\n",
      "       100           3.6774          -0.1047            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.8, learning_rate=0.05, score=-0.656866, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.8, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         205.5813          22.2638            0.00s\n",
      "         2         198.9332          22.4691            0.05s\n",
      "         3         209.9556          -0.8094            0.06s\n",
      "         4         185.5978           1.7812            0.07s\n",
      "         5         117.9231           2.2885            0.06s\n",
      "         6         168.1631           0.1056            0.06s\n",
      "         7         131.8074          13.2168            0.05s\n",
      "         8         142.5929           1.0783            0.06s\n",
      "         9         130.3075          -0.8416            0.05s\n",
      "        10         112.0629          11.4218            0.05s\n",
      "        20          72.9578          -0.1754            0.04s\n",
      "        30          36.9837          -0.4933            0.03s\n",
      "        40          29.2648           0.4016            0.03s\n",
      "        50          21.0315           0.0438            0.02s\n",
      "        60          13.4065          -0.1252            0.02s\n",
      "        70          10.0555          -0.3488            0.01s\n",
      "        80           8.1804          -0.1234            0.01s\n",
      "        90           5.4834          -0.1158            0.00s\n",
      "       100           4.6416          -0.1991            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.8, learning_rate=0.05, score=-1.253108, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.8, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         127.4067           3.7214            0.10s\n",
      "         2         127.5733           2.2292            0.05s\n",
      "         3         159.2033          -0.4973            0.06s\n",
      "         4         140.2239          -0.0732            0.05s\n",
      "         5         128.8219           1.9968            0.06s\n",
      "         6         127.8568          -0.4449            0.05s\n",
      "         7          80.7699          11.8783            0.05s\n",
      "         8         111.7349          -1.0014            0.05s\n",
      "         9         100.8145          -0.2198            0.05s\n",
      "        10          82.1460           9.1513            0.04s\n",
      "        20          54.1039          -0.4034            0.03s\n",
      "        30          34.4313          -0.2560            0.03s\n",
      "        40          19.8102           0.1104            0.02s\n",
      "        50          15.6699           0.0224            0.02s\n",
      "        60           9.6937           0.1264            0.02s\n",
      "        70           6.8930          -0.1023            0.01s\n",
      "        80           4.7575          -0.1539            0.01s\n",
      "        90           3.5495          -0.1859            0.00s\n",
      "       100           3.2475          -0.0190            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.8, learning_rate=0.05, score=0.109111, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.8, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         210.7542          27.7115            0.10s\n",
      "         2         202.2091          22.4318            0.05s\n",
      "         3         218.3298           0.5161            0.06s\n",
      "         4         189.7704           3.1958            0.07s\n",
      "         5         124.2552           2.1012            0.06s\n",
      "         6         177.1254          -0.0853            0.06s\n",
      "         7         136.7902          15.5484            0.05s\n",
      "         8         148.7874          -0.5806            0.06s\n",
      "         9          95.9382           3.9840            0.05s\n",
      "        10         114.8695           1.8370            0.05s\n",
      "        20          74.3273          -0.2584            0.04s\n",
      "        30          45.7374          -0.6486            0.03s\n",
      "        40          30.5957           0.4334            0.03s\n",
      "        50          22.5067          -0.4684            0.02s\n",
      "        60          14.4044          -0.1308            0.02s\n",
      "        70          10.1910          -0.3412            0.01s\n",
      "        80           7.1859          -0.0601            0.01s\n",
      "        90           5.5851          -0.2457            0.00s\n",
      "       100           4.5602          -0.1831            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.8, learning_rate=0.05, score=-7.734615, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.8, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         147.9161          49.6953            0.10s\n",
      "         2         218.0749          -0.9812            0.10s\n",
      "         3         170.0834          19.4873            0.10s\n",
      "         4         167.1435          -0.5983            0.07s\n",
      "         5         168.3374          -0.4309            0.08s\n",
      "         6         150.4835           0.1109            0.06s\n",
      "         7         116.4094          15.9285            0.07s\n",
      "         8         127.3297           1.1379            0.06s\n",
      "         9         117.8359           1.1663            0.06s\n",
      "        10          92.6741           4.0742            0.05s\n",
      "        20          58.4540          -1.2477            0.04s\n",
      "        30          35.5772          -0.1097            0.03s\n",
      "        40          18.8754          -0.4059            0.03s\n",
      "        50          19.2066          -0.0673            0.02s\n",
      "        60          11.0323          -0.2191            0.02s\n",
      "        70           8.6651           0.0377            0.01s\n",
      "        80           5.6065          -0.0063            0.01s\n",
      "        90           4.4880           0.0165            0.00s\n",
      "       100           3.5269          -0.0885            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.8, learning_rate=0.05, score=0.236406, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.8, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         158.3255          27.5288            0.10s\n",
      "         2         192.3097          -2.0664            0.10s\n",
      "         3         184.0155           0.5617            0.06s\n",
      "         4         154.1330           0.5367            0.07s\n",
      "         5         156.1989          -0.0544            0.08s\n",
      "         6         131.8712           0.5963            0.06s\n",
      "         7         107.6108          16.4488            0.07s\n",
      "         8         120.8746           1.2283            0.06s\n",
      "         9         111.8588          -0.9314            0.06s\n",
      "        10          95.2026          -0.3503            0.06s\n",
      "        20          52.1071          -0.1867            0.04s\n",
      "        30          35.0050          -0.9010            0.03s\n",
      "        40          21.6973          -0.4732            0.03s\n",
      "        50          19.7562          -0.3959            0.02s\n",
      "        60          11.4069          -0.6065            0.02s\n",
      "        70          10.0372          -0.2365            0.01s\n",
      "        80           7.0070          -0.0134            0.01s\n",
      "        90           5.6783          -0.3289            0.00s\n",
      "       100           4.3444          -0.1800            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.8, learning_rate=0.05, score=0.580765, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.7, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         287.9736          -0.7565            0.20s\n",
      "         2         261.5520           2.2923            0.20s\n",
      "         3         229.4453          -0.0105            0.20s\n",
      "         4         216.3591           0.8768            0.15s\n",
      "         5         136.2679           2.7670            0.16s\n",
      "         6         102.3316          12.7564            0.13s\n",
      "         7         174.8256           2.0569            0.14s\n",
      "         8         150.2438           8.8975            0.12s\n",
      "         9         162.6161           1.1299            0.13s\n",
      "        10         114.8951          -0.1415            0.11s\n",
      "        20          78.6247          -0.7271            0.09s\n",
      "        30          37.5994           0.2667            0.07s\n",
      "        40          36.9691          -0.8229            0.05s\n",
      "        50          23.1494          -0.5878            0.04s\n",
      "        60          12.8760          -0.6862            0.03s\n",
      "        70          13.5760          -0.1151            0.02s\n",
      "        80           8.8398          -0.5253            0.05s\n",
      "        90           7.1346          -0.3031            0.05s\n",
      "       100           4.6849          -0.1112            0.04s\n",
      "       200           0.5824          -0.0146            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.7, learning_rate=0.05, score=-0.514983, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.7, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         289.8912          -1.1790            0.20s\n",
      "         2         264.0664          -0.3385            0.10s\n",
      "         3         231.1540          -0.0936            0.13s\n",
      "         4         213.5986           1.8984            0.15s\n",
      "         5         132.1037           0.6387            0.12s\n",
      "         6          99.9696          11.0747            0.13s\n",
      "         7         176.3750           1.1742            0.11s\n",
      "         8         148.8401           8.8957            0.12s\n",
      "         9         159.0204           3.5621            0.11s\n",
      "        10         118.8041           7.1564            0.11s\n",
      "        20          76.0601          -0.2070            0.09s\n",
      "        30          36.9563           0.4483            0.09s\n",
      "        40          32.2758          -1.2277            0.07s\n",
      "        50          19.8651          -1.2161            0.07s\n",
      "        60          12.7640          -0.8902            0.06s\n",
      "        70          11.5390           0.0519            0.06s\n",
      "        80           8.5777          -0.3289            0.05s\n",
      "        90           6.7940          -0.1051            0.05s\n",
      "       100           4.2508          -0.2276            0.04s\n",
      "       200           0.5925          -0.0323            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.7, learning_rate=0.05, score=-2.582933, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.7, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         288.7676          -0.4958            0.20s\n",
      "         2         260.8576           2.3372            0.10s\n",
      "         3         229.2588           0.0750            0.13s\n",
      "         4         213.8526           0.7059            0.10s\n",
      "         5         127.8188           1.4648            0.12s\n",
      "         6         100.9612           7.1176            0.10s\n",
      "         7         178.5623           2.5173            0.11s\n",
      "         8         144.3274           7.8547            0.10s\n",
      "         9         162.8372           2.0646            0.11s\n",
      "        10         117.9719           7.0554            0.10s\n",
      "        20          76.2296          -2.3826            0.07s\n",
      "        30          34.6612           0.8876            0.07s\n",
      "        40          32.8047          -0.7608            0.06s\n",
      "        50          22.0184          -0.3413            0.06s\n",
      "        60          11.5588          -0.4660            0.06s\n",
      "        70          12.8714          -0.3397            0.05s\n",
      "        80           8.8225          -0.4063            0.05s\n",
      "        90           7.1812          -0.2018            0.04s\n",
      "       100           5.0523          -0.0213            0.04s\n",
      "       200           0.6067          -0.0133            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.7, learning_rate=0.05, score=-0.276152, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.7, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         282.2828          -0.0102            0.00s\n",
      "         2         253.5370           1.6543            0.00s\n",
      "         3         223.2478           0.2454            0.00s\n",
      "         4         209.8703           0.5862            0.00s\n",
      "         5         125.9980           0.9530            0.00s\n",
      "         6          93.2883          10.1961            0.00s\n",
      "         7         173.7415           1.4318            0.00s\n",
      "         8         135.1072          10.4558            0.00s\n",
      "         9         153.5216           2.6928            0.00s\n",
      "        10         109.4107           7.0141            0.00s\n",
      "        20          70.8742          -1.9218            0.00s\n",
      "        30          33.8144           0.3714            0.00s\n",
      "        40          33.3849           0.0600            0.00s\n",
      "        50          21.9482          -0.8878            0.06s\n",
      "        60          10.2359          -0.5246            0.05s\n",
      "        70          11.0619          -0.3421            0.05s\n",
      "        80           7.2119          -0.3180            0.05s\n",
      "        90           5.6569          -0.2460            0.04s\n",
      "       100           4.4301          -0.0164            0.04s\n",
      "       200           0.4155          -0.0129            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.7, learning_rate=0.05, score=0.176356, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.7, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         218.2648           0.4686            0.20s\n",
      "         2         193.4615           2.0600            0.30s\n",
      "         3         179.8763          -0.1774            0.20s\n",
      "         4         159.6389           1.1099            0.20s\n",
      "         5          77.2999           1.1221            0.16s\n",
      "         6          87.1573           7.1577            0.16s\n",
      "         7         136.2369           0.6059            0.14s\n",
      "         8         126.6066           0.1578            0.14s\n",
      "         9         124.5734          -0.0968            0.15s\n",
      "        10          93.3076           8.4527            0.13s\n",
      "        20          57.1697           0.0664            0.09s\n",
      "        30          26.5903           1.7657            0.07s\n",
      "        40          21.3004           0.0212            0.07s\n",
      "        50          15.4694          -0.4036            0.06s\n",
      "        60           9.6476          -0.2568            0.06s\n",
      "        70           7.8061          -0.0789            0.05s\n",
      "        80           6.5346          -0.1968            0.05s\n",
      "        90           5.0102          -0.2107            0.04s\n",
      "       100           3.8915          -0.1047            0.04s\n",
      "       200           0.4003          -0.0100            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.7, learning_rate=0.05, score=-0.721563, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.7, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         225.1204          17.0315            0.20s\n",
      "         2         207.3429          16.9920            0.20s\n",
      "         3         229.4716           1.3476            0.20s\n",
      "         4         193.4812           1.6320            0.15s\n",
      "         5         126.0808           1.2106            0.16s\n",
      "         6         131.6346           2.7756            0.16s\n",
      "         7         133.3527           9.5769            0.17s\n",
      "         8         163.2346           0.4488            0.17s\n",
      "         9         143.3374           0.6792            0.15s\n",
      "        10         124.4394           7.0784            0.15s\n",
      "        20          76.6747          -1.0176            0.11s\n",
      "        30          40.2286           0.0542            0.08s\n",
      "        40          30.0616           1.1584            0.08s\n",
      "        50          14.7093          -0.8203            0.07s\n",
      "        60          12.5212          -0.2473            0.06s\n",
      "        70          11.5009          -0.3461            0.06s\n",
      "        80           8.7676          -0.1245            0.05s\n",
      "        90           6.4381          -0.2707            0.05s\n",
      "       100           5.4358          -0.2604            0.04s\n",
      "       200           0.6054          -0.0174            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.7, learning_rate=0.05, score=-2.164301, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.7, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         133.9842           0.9055            0.00s\n",
      "         2         123.8410          15.3338            0.00s\n",
      "         3         171.8981           1.6232            0.00s\n",
      "         4         138.3225           1.2471            0.00s\n",
      "         5         134.5724          -0.8331            0.00s\n",
      "         6         141.8770          -0.5574            0.00s\n",
      "         7          73.2841           1.3067            0.00s\n",
      "         8         127.2879          -0.7810            0.00s\n",
      "         9         110.1483           1.5023            0.00s\n",
      "        10          91.3234           6.2794            0.28s\n",
      "        20          60.3283           0.5448            0.18s\n",
      "        30          39.4301          -0.4026            0.13s\n",
      "        40          23.3527           0.2605            0.11s\n",
      "        50          11.8372           0.0361            0.09s\n",
      "        60           8.4997          -0.3663            0.08s\n",
      "        70           7.5939          -0.0283            0.07s\n",
      "        80           5.9132          -0.0685            0.07s\n",
      "        90           4.4219          -0.1250            0.06s\n",
      "       100           3.6106          -0.1696            0.05s\n",
      "       200           0.2939          -0.0040            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.7, learning_rate=0.05, score=0.134484, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.7, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         228.4113          16.0948            0.00s\n",
      "         2         208.2246          15.9924            0.10s\n",
      "         3         240.6272           1.1782            0.13s\n",
      "         4         202.7495           2.5096            0.10s\n",
      "         5         129.8965           0.5696            0.12s\n",
      "         6         196.2444          -0.3975            0.13s\n",
      "         7         132.1608           9.5669            0.11s\n",
      "         8         165.4871          -0.1151            0.12s\n",
      "         9         103.9404           3.2202            0.11s\n",
      "        10         125.6503           6.3469            0.11s\n",
      "        20          77.0482           0.0663            0.08s\n",
      "        30          49.1315          -0.4225            0.07s\n",
      "        40          31.2053           0.2877            0.06s\n",
      "        50          17.1307          -0.0683            0.06s\n",
      "        60          12.4441           0.0003            0.05s\n",
      "        70          10.6414          -0.2573            0.05s\n",
      "        80           6.7104          -0.2638            0.04s\n",
      "        90           6.1395          -0.0627            0.04s\n",
      "       100           4.2234          -0.2327            0.04s\n",
      "       200           0.5192          -0.0211            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.7, learning_rate=0.05, score=-3.439959, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.7, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         156.9905          35.8122            0.20s\n",
      "         2         230.4978          -1.0397            0.20s\n",
      "         3         185.0656          13.8384            0.13s\n",
      "         4         152.1994           8.4696            0.15s\n",
      "         5         185.1336           0.8325            0.12s\n",
      "         6         167.6584          -0.2808            0.13s\n",
      "         7         124.7295          11.6066            0.11s\n",
      "         8         138.4362           0.9995            0.12s\n",
      "         9          90.8820          -0.7740            0.13s\n",
      "        10         105.7159           7.3629            0.11s\n",
      "        20          56.7881           0.9323            0.09s\n",
      "        30          39.8741           0.0546            0.07s\n",
      "        40          20.5276          -0.3138            0.06s\n",
      "        50          20.6773          -0.2903            0.06s\n",
      "        60          12.8600          -0.6354            0.06s\n",
      "        70          10.6873          -0.1704            0.05s\n",
      "        80           7.5249          -0.0272            0.05s\n",
      "        90           5.3867          -0.2278            0.04s\n",
      "       100           4.5054          -0.2316            0.04s\n",
      "       200           0.5895          -0.0196            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.7, learning_rate=0.05, score=0.338226, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.7, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         166.7912          19.1280            2.98s\n",
      "         2         201.3738          -1.0168            1.48s\n",
      "         3         202.3122           1.6514            1.31s\n",
      "         4         168.0097           0.0956            1.03s\n",
      "         5         168.4248           0.5394            0.86s\n",
      "         6         147.4937           1.5592            0.71s\n",
      "         7         113.1946          10.3537            0.63s\n",
      "         8         130.4427          -0.0372            0.55s\n",
      "         9          79.6994          -0.4040            0.51s\n",
      "        10         107.6369           1.1828            0.46s\n",
      "        20          52.2437          -0.0602            0.24s\n",
      "        30          39.8847          -0.2959            0.18s\n",
      "        40          25.9608          -0.0217            0.14s\n",
      "        50          22.4357          -0.1229            0.12s\n",
      "        60          12.9579          -0.2207            0.10s\n",
      "        70          10.3403           0.0135            0.09s\n",
      "        80           7.2722          -0.0448            0.08s\n",
      "        90           5.9201          -0.1576            0.07s\n",
      "       100           4.2096           0.0205            0.06s\n",
      "       200           0.5888          -0.0168            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.7, learning_rate=0.05, score=0.761894, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.75, learning_rate=0.05 ............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         268.0527          -1.5883            0.20s\n",
      "         2         241.9591           1.0539            0.20s\n",
      "         3         214.6580          -0.2809            0.13s\n",
      "         4         204.7294           1.1407            0.15s\n",
      "         5         133.0443           2.8846            0.12s\n",
      "         6         149.3782          13.3313            0.13s\n",
      "         7         162.4382           1.6519            0.14s\n",
      "         8         136.6754           8.7842            0.12s\n",
      "         9         149.1879           1.3127            0.13s\n",
      "        10         122.7701          -0.3590            0.11s\n",
      "        20          76.8949           0.6460            0.09s\n",
      "        30          37.3772          -0.1253            0.07s\n",
      "        40          30.2933          -0.3243            0.06s\n",
      "        50          23.1466          -0.7874            0.06s\n",
      "        60          12.1141          -0.3245            0.05s\n",
      "        70          12.5360          -0.3918            0.05s\n",
      "        80           7.6479          -0.4812            0.04s\n",
      "        90           5.7757          -0.2838            0.04s\n",
      "       100           4.1766          -0.2890            0.04s\n",
      "       200           0.4505          -0.0140            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.75, learning_rate=0.05, score=-0.259634, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.75, learning_rate=0.05 ............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         269.8733          -2.2693            0.20s\n",
      "         2         244.5319          -0.2242            0.20s\n",
      "         3         215.6269           0.1733            0.20s\n",
      "         4         201.7632           2.4753            0.20s\n",
      "         5         129.0312           0.4536            0.19s\n",
      "         6         146.6481          14.7172            0.16s\n",
      "         7         162.4356           0.9133            0.17s\n",
      "         8         133.9593           9.4031            0.14s\n",
      "         9         145.4613           2.1809            0.15s\n",
      "        10         123.0340           8.6540            0.15s\n",
      "        20          72.2249           0.8441            0.10s\n",
      "        30          35.9153           1.2181            0.08s\n",
      "        40          27.6550          -1.5833            0.08s\n",
      "        50          20.7931          -0.1686            0.07s\n",
      "        60          10.9045          -0.1960            0.06s\n",
      "        70          10.3888          -0.1948            0.06s\n",
      "        80           6.7925          -0.3749            0.05s\n",
      "        90           4.7893          -0.1168            0.05s\n",
      "       100           3.3951          -0.2488            0.04s\n",
      "       200           0.3719          -0.0053            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.75, learning_rate=0.05, score=-2.459457, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.75, learning_rate=0.05 ............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         270.2257          -2.1484            0.20s\n",
      "         2         243.3628           2.6208            0.20s\n",
      "         3         215.3946          -0.6160            0.13s\n",
      "         4         202.2680           2.5267            0.20s\n",
      "         5         125.4237           3.5690            0.16s\n",
      "         6         148.8767          11.1782            0.16s\n",
      "         7         164.0276           2.8294            0.17s\n",
      "         8         131.4368           8.4987            0.17s\n",
      "         9         148.9505           1.6405            0.17s\n",
      "        10         120.9108          -0.2270            0.17s\n",
      "        20          75.2901           0.4504            0.12s\n",
      "        30          32.6026           0.2156            0.10s\n",
      "        40          27.9272          -0.9515            0.08s\n",
      "        50          21.3200          -0.1229            0.07s\n",
      "        60          10.9514          -0.5580            0.06s\n",
      "        70          12.6630          -0.0680            0.06s\n",
      "        80           7.3013          -0.1042            0.05s\n",
      "        90           5.2023          -0.2440            0.05s\n",
      "       100           4.3345          -0.0945            0.04s\n",
      "       200           0.4588          -0.0229            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.75, learning_rate=0.05, score=-0.134688, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.75, learning_rate=0.05 ............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         264.1448           0.1533            0.20s\n",
      "         2         235.6200           1.7001            0.20s\n",
      "         3         209.5950          -0.2452            0.13s\n",
      "         4         199.3489           1.1566            0.20s\n",
      "         5         123.2049           1.4258            0.16s\n",
      "         6         143.4356          13.9860            0.16s\n",
      "         7         163.0826           1.6629            0.17s\n",
      "         8         124.5009          12.2335            0.14s\n",
      "         9         144.0616           2.7077            0.15s\n",
      "        10         113.1198           8.5316            0.13s\n",
      "        20          67.3918           0.6146            0.09s\n",
      "        30          30.7386           0.4788            0.08s\n",
      "        40          28.5621          -0.6870            0.07s\n",
      "        50          22.5626          -0.1401            0.06s\n",
      "        60           8.8148          -0.5147            0.06s\n",
      "        70          12.0062          -0.0365            0.05s\n",
      "        80           6.0375          -0.3250            0.05s\n",
      "        90           4.7740          -0.4178            0.04s\n",
      "       100           3.9162           0.0069            0.04s\n",
      "       200           0.3264          -0.0117            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.75, learning_rate=0.05, score=0.018283, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.75, learning_rate=0.05 ............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         204.1192          -0.1469            0.20s\n",
      "         2         183.1465           2.2665            0.20s\n",
      "         3         168.4147          -0.4337            0.13s\n",
      "         4         157.8817          -0.1274            0.15s\n",
      "         5          76.3381           5.4371            0.12s\n",
      "         6         137.9097          -0.4105            0.10s\n",
      "         7         125.8014          -0.1604            0.11s\n",
      "         8         114.1897          -0.5995            0.10s\n",
      "         9         115.8158          -0.9644            0.11s\n",
      "        10          85.9593           8.3826            0.10s\n",
      "        20          51.9370           0.5252            0.07s\n",
      "        30          26.7198           0.7155            0.07s\n",
      "        40          19.4742          -0.3531            0.06s\n",
      "        50          15.5695           0.0011            0.06s\n",
      "        60           9.7061          -0.4186            0.05s\n",
      "        70           8.3893          -0.0353            0.05s\n",
      "        80           5.5438          -0.0884            0.04s\n",
      "        90           3.8575          -0.2248            0.04s\n",
      "       100           3.4736          -0.0665            0.03s\n",
      "       200           0.2785          -0.0018            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.75, learning_rate=0.05, score=-0.694640, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.75, learning_rate=0.05 ............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         209.8049          18.1789            0.20s\n",
      "         2         197.5415          19.2881            0.20s\n",
      "         3         215.5563           0.0675            0.13s\n",
      "         4         187.7647           0.9669            0.15s\n",
      "         5         122.7889           1.6851            0.16s\n",
      "         6         175.1053          -1.5282            0.16s\n",
      "         7         135.6874          11.3252            0.14s\n",
      "         8         147.2330           0.9615            0.14s\n",
      "         9         135.0989          -0.4004            0.13s\n",
      "        10         116.2827           8.4709            0.13s\n",
      "        20          71.3483           0.5402            0.09s\n",
      "        30          37.1323           0.1841            0.08s\n",
      "        40          27.5912           0.5038            0.07s\n",
      "        50          14.7195          -0.2992            0.06s\n",
      "        60          14.4043          -0.1232            0.06s\n",
      "        70          11.6203          -0.2452            0.05s\n",
      "        80           8.4590          -0.1027            0.05s\n",
      "        90           5.8115          -0.2172            0.05s\n",
      "       100           5.1463          -0.2234            0.04s\n",
      "       200           0.5308          -0.0142            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.75, learning_rate=0.05, score=-1.500614, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.75, learning_rate=0.05 ............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         126.5477           0.1852            0.20s\n",
      "         2         120.4698           2.2887            0.30s\n",
      "         3         164.1207           0.6620            0.26s\n",
      "         4         141.7157          -0.6886            0.20s\n",
      "         5         134.4763           0.0972            0.19s\n",
      "         6         134.7302          -0.2956            0.19s\n",
      "         7          83.9601          10.3598            0.17s\n",
      "         8         116.0170          -0.0490            0.17s\n",
      "         9         103.4701           0.9350            0.15s\n",
      "        10          85.0517           7.7244            0.15s\n",
      "        20          56.0271          -0.2888            0.10s\n",
      "        30          37.7032          -0.1053            0.08s\n",
      "        40          19.5174           0.3494            0.08s\n",
      "        50          11.7854          -0.1743            0.07s\n",
      "        60           9.5625          -0.0731            0.07s\n",
      "        70           7.4553          -0.0969            0.06s\n",
      "        80           5.0484          -0.3482            0.05s\n",
      "        90           4.1241          -0.1431            0.05s\n",
      "       100           3.7319          -0.0262            0.04s\n",
      "       200           0.2766          -0.0061            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.75, learning_rate=0.05, score=0.159993, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.75, learning_rate=0.05 ............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         216.0023          22.7936            0.00s\n",
      "         2         202.2616          16.5841            0.10s\n",
      "         3         226.9424           1.5440            0.13s\n",
      "         4         194.8489           2.1965            0.10s\n",
      "         5         130.0177           1.6237            0.12s\n",
      "         6         187.2252          -0.0906            0.10s\n",
      "         7         140.4913          12.1321            0.11s\n",
      "         8         156.3404          -0.0501            0.10s\n",
      "         9         100.6794           1.9714            0.11s\n",
      "        10         120.3175          -1.5733            0.10s\n",
      "        20          74.9823           0.0094            0.07s\n",
      "        30          48.0922           0.0381            0.07s\n",
      "        40          31.3057           0.2311            0.06s\n",
      "        50          17.4502          -0.6286            0.06s\n",
      "        60          14.4383          -0.1131            0.05s\n",
      "        70          12.1543          -0.2881            0.05s\n",
      "        80           6.9197          -0.6076            0.04s\n",
      "        90           6.2642          -0.1282            0.04s\n",
      "       100           4.7052          -0.2408            0.04s\n",
      "       200           0.4510          -0.0130            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.75, learning_rate=0.05, score=-5.288247, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.75, learning_rate=0.05 ............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         153.9567          37.6070            0.00s\n",
      "         2         227.4605           0.6571            0.10s\n",
      "         3         182.3300          15.1226            0.13s\n",
      "         4         178.1178          -0.2921            0.10s\n",
      "         5         180.9259           0.0589            0.12s\n",
      "         6         161.0233          -0.0041            0.10s\n",
      "         7         122.5322          12.7934            0.11s\n",
      "         8         135.2936           0.3861            0.10s\n",
      "         9          91.2823          -0.7171            0.11s\n",
      "        10         103.3137           5.7727            0.11s\n",
      "        20          59.4061          -1.1133            0.07s\n",
      "        30          40.5768          -0.0332            0.07s\n",
      "        40          19.4983          -0.6226            0.06s\n",
      "        50          20.6462          -0.2445            0.05s\n",
      "        60          12.7243          -0.0414            0.05s\n",
      "        70           9.4605          -0.0205            0.05s\n",
      "        80           6.4730          -0.2273            0.04s\n",
      "        90           4.8016          -0.0613            0.04s\n",
      "       100           4.0732          -0.0840            0.04s\n",
      "       200           0.4148          -0.0041            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.75, learning_rate=0.05, score=0.357660, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.75, learning_rate=0.05 ............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         163.7241          21.2369            0.20s\n",
      "         2         200.1829           0.9624            0.20s\n",
      "         3         196.6305           0.5399            0.20s\n",
      "         4         163.8048           0.8524            0.20s\n",
      "         5         162.3932           0.1074            0.16s\n",
      "         6         141.2258           1.2252            0.16s\n",
      "         7         111.0067          13.2590            0.14s\n",
      "         8         126.8180          -0.7288            0.14s\n",
      "         9          78.6346          -1.4484            0.13s\n",
      "        10         105.1129           0.9564            0.13s\n",
      "        20          56.6228          -1.0033            0.09s\n",
      "        30          39.2170          -1.1407            0.07s\n",
      "        40          23.7424          -0.2411            0.07s\n",
      "        50          21.2572          -0.1544            0.07s\n",
      "        60          13.0738          -0.5458            0.06s\n",
      "        70          10.9238          -0.0215            0.05s\n",
      "        80           7.4219          -0.0535            0.05s\n",
      "        90           5.2263          -0.3014            0.04s\n",
      "       100           4.1526          -0.1749            0.04s\n",
      "       200           0.5214          -0.0092            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.75, learning_rate=0.05, score=0.656451, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.8, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         257.4776          -2.3388            0.20s\n",
      "         2         241.7770           1.4257            0.20s\n",
      "         3         209.0030           0.4755            0.20s\n",
      "         4         200.7384           2.3963            0.20s\n",
      "         5         132.2427           2.0073            0.16s\n",
      "         6         141.7269          16.8199            0.16s\n",
      "         7         154.8332           1.6629            0.17s\n",
      "         8         130.6981          10.2961            0.17s\n",
      "         9         143.8746           1.6707            0.17s\n",
      "        10         118.3874          -1.7671            0.15s\n",
      "        20          77.2480          -0.7091            0.11s\n",
      "        30          35.0579          -0.1444            0.09s\n",
      "        40          32.1287          -0.4230            0.08s\n",
      "        50          24.5360          -0.2195            0.07s\n",
      "        60          12.8231          -0.4412            0.06s\n",
      "        70          12.1171          -0.5181            0.06s\n",
      "        80           8.0590          -0.5514            0.05s\n",
      "        90           5.8047          -0.3325            0.05s\n",
      "       100           4.4857          -0.1852            0.04s\n",
      "       200           0.5061          -0.0111            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.8, learning_rate=0.05, score=-0.525302, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.8, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         258.8168          -2.8023            0.20s\n",
      "         2         244.5659           0.9362            0.20s\n",
      "         3         209.1942           0.2687            0.13s\n",
      "         4         197.9320           2.5709            0.15s\n",
      "         5         129.5730          -0.7873            0.12s\n",
      "         6         139.9396          15.3070            0.13s\n",
      "         7         155.3602           0.3441            0.11s\n",
      "         8         130.4724          12.9007            0.12s\n",
      "         9         142.3373           1.9727            0.13s\n",
      "        10         118.9281          10.6039            0.13s\n",
      "        20          73.8965          -0.8558            0.09s\n",
      "        30          36.6930           0.7108            0.07s\n",
      "        40          28.3404          -0.4593            0.06s\n",
      "        50          20.5258          -0.3272            0.06s\n",
      "        60          12.2139          -0.4173            0.05s\n",
      "        70          10.5701           0.2233            0.05s\n",
      "        80           7.2258          -0.4642            0.04s\n",
      "        90           5.1927          -0.0988            0.04s\n",
      "       100           4.1107          -0.0957            0.04s\n",
      "       200           0.3810          -0.0079            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.8, learning_rate=0.05, score=-2.554326, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.8, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         257.8732          -2.3651            0.20s\n",
      "         2         241.8607           1.0871            0.10s\n",
      "         3         209.9834          -0.5204            0.13s\n",
      "         4         198.1589           1.9131            0.15s\n",
      "         5         124.3352           1.9173            0.12s\n",
      "         6         141.2271          17.1872            0.13s\n",
      "         7         155.8790           0.4138            0.14s\n",
      "         8         124.3954          12.6757            0.12s\n",
      "         9         141.2854           1.1341            0.13s\n",
      "        10         114.0630           0.1947            0.11s\n",
      "        20          76.0996          -0.2641            0.08s\n",
      "        30          31.8498          -0.2164            0.07s\n",
      "        40          29.1867          -0.0737            0.07s\n",
      "        50          21.0118          -0.2004            0.06s\n",
      "        60          11.5226          -0.4792            0.06s\n",
      "        70          11.8175          -0.0884            0.05s\n",
      "        80           7.2891          -0.3147            0.05s\n",
      "        90           5.0089          -0.0514            0.05s\n",
      "       100           3.8752          -0.1255            0.04s\n",
      "       200           0.3912          -0.0044            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.8, learning_rate=0.05, score=-0.126386, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.8, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         252.0375           0.6366            0.00s\n",
      "         2         234.8903           1.0437            0.10s\n",
      "         3         203.2993          -1.0737            0.07s\n",
      "         4         196.3459           1.3811            0.10s\n",
      "         5         123.4720           0.9504            0.08s\n",
      "         6         136.7778          12.2434            0.10s\n",
      "         7         158.0998           1.4039            0.08s\n",
      "         8         119.2789          11.0843            0.10s\n",
      "         9         139.9259           2.2259            0.08s\n",
      "        10         109.6036          10.3356            0.09s\n",
      "        20          68.0858           0.5082            0.07s\n",
      "        30          29.7749           0.7168            0.07s\n",
      "        40          29.5987          -0.2540            0.06s\n",
      "        50          21.8601           0.0100            0.06s\n",
      "        60           9.0597          -0.4910            0.05s\n",
      "        70          10.4469          -0.0446            0.05s\n",
      "        80           5.4742          -0.4522            0.05s\n",
      "        90           3.9269          -0.3217            0.04s\n",
      "       100           3.4985          -0.1015            0.04s\n",
      "       200           0.3227          -0.0098            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.8, learning_rate=0.05, score=-0.109641, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.8, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         200.1416          -0.0133            0.00s\n",
      "         2         186.6225           0.5539            0.10s\n",
      "         3         163.5990          -0.0425            0.07s\n",
      "         4         156.0444           0.4311            0.10s\n",
      "         5          77.2701           2.6414            0.08s\n",
      "         6         131.0229          -2.2096            0.10s\n",
      "         7         121.7491          -0.8032            0.08s\n",
      "         8         111.0033          -1.0983            0.10s\n",
      "         9         114.1929          -0.2507            0.08s\n",
      "        10          84.6760          10.9160            0.09s\n",
      "        20          53.8036           0.2805            0.06s\n",
      "        30          26.0121          -0.4607            0.06s\n",
      "        40          20.7414          -0.4223            0.06s\n",
      "        50          15.2931           0.0791            0.05s\n",
      "        60           9.2186          -0.4608            0.05s\n",
      "        70           8.2820          -0.0264            0.05s\n",
      "        80           6.2186          -0.1630            0.04s\n",
      "        90           4.1991          -0.1920            0.04s\n",
      "       100           3.6774          -0.1047            0.04s\n",
      "       200           0.2960          -0.0076            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.8, learning_rate=0.05, score=-0.753731, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.8, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         205.5813          22.2638            0.20s\n",
      "         2         198.9332          22.4691            0.10s\n",
      "         3         209.9556          -0.8094            0.13s\n",
      "         4         185.5978           1.7812            0.15s\n",
      "         5         117.9231           2.2885            0.12s\n",
      "         6         168.1631           0.1056            0.13s\n",
      "         7         131.8074          13.2168            0.14s\n",
      "         8         142.5929           1.0783            0.12s\n",
      "         9         130.3075          -0.8416            0.13s\n",
      "        10         112.0629          11.4218            0.11s\n",
      "        20          72.9578          -0.1754            0.09s\n",
      "        30          36.9837          -0.4933            0.07s\n",
      "        40          29.2648           0.4016            0.06s\n",
      "        50          21.0315           0.0438            0.06s\n",
      "        60          13.4065          -0.1252            0.06s\n",
      "        70          10.0555          -0.3488            0.05s\n",
      "        80           8.1804          -0.1234            0.05s\n",
      "        90           5.4834          -0.1158            0.04s\n",
      "       100           4.6416          -0.1991            0.04s\n",
      "       200           0.4566          -0.0128            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.8, learning_rate=0.05, score=-1.531277, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.8, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         127.4067           3.7214            0.00s\n",
      "         2         127.5733           2.2292            0.10s\n",
      "         3         159.2033          -0.4973            0.07s\n",
      "         4         140.2239          -0.0732            0.10s\n",
      "         5         128.8219           1.9968            0.08s\n",
      "         6         127.8568          -0.4449            0.10s\n",
      "         7          80.7699          11.8783            0.08s\n",
      "         8         111.7349          -1.0014            0.10s\n",
      "         9         100.8145          -0.2198            0.08s\n",
      "        10          82.1460           9.1513            0.11s\n",
      "        20          54.1039          -0.4034            0.08s\n",
      "        30          34.4313          -0.2560            0.07s\n",
      "        40          19.8102           0.1104            0.06s\n",
      "        50          15.6699           0.0224            0.06s\n",
      "        60           9.6937           0.1264            0.06s\n",
      "        70           6.8930          -0.1023            0.05s\n",
      "        80           4.7575          -0.1539            0.05s\n",
      "        90           3.5495          -0.1859            0.04s\n",
      "       100           3.2475          -0.0190            0.04s\n",
      "       200           0.2465          -0.0053            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.8, learning_rate=0.05, score=0.104946, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.8, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         210.7542          27.7115            0.20s\n",
      "         2         202.2091          22.4318            0.20s\n",
      "         3         218.3298           0.5161            0.20s\n",
      "         4         189.7704           3.1958            0.15s\n",
      "         5         124.2552           2.1012            0.16s\n",
      "         6         177.1254          -0.0853            0.16s\n",
      "         7         136.7902          15.5484            0.14s\n",
      "         8         148.7874          -0.5806            0.14s\n",
      "         9          95.9382           3.9840            0.13s\n",
      "        10         114.8695           1.8370            0.13s\n",
      "        20          74.3273          -0.2584            0.09s\n",
      "        30          45.7374          -0.6486            0.07s\n",
      "        40          30.5957           0.4334            0.07s\n",
      "        50          22.5067          -0.4684            0.06s\n",
      "        60          14.4044          -0.1308            0.06s\n",
      "        70          10.1910          -0.3412            0.05s\n",
      "        80           7.1859          -0.0601            0.05s\n",
      "        90           5.5851          -0.2457            0.04s\n",
      "       100           4.5602          -0.1831            0.04s\n",
      "       200           0.3679          -0.0189            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.8, learning_rate=0.05, score=-7.861414, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.8, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         147.9161          49.6953            0.20s\n",
      "         2         218.0749          -0.9812            0.10s\n",
      "         3         170.0834          19.4873            0.13s\n",
      "         4         167.1435          -0.5983            0.15s\n",
      "         5         168.3374          -0.4309            0.12s\n",
      "         6         150.4835           0.1109            0.13s\n",
      "         7         116.4094          15.9285            0.14s\n",
      "         8         127.3297           1.1379            0.12s\n",
      "         9         117.8359           1.1663            0.13s\n",
      "        10          92.6741           4.0742            0.11s\n",
      "        20          58.4540          -1.2477            0.08s\n",
      "        30          35.5772          -0.1097            0.07s\n",
      "        40          18.8754          -0.4059            0.07s\n",
      "        50          19.2066          -0.0673            0.06s\n",
      "        60          11.0323          -0.2191            0.06s\n",
      "        70           8.6651           0.0377            0.05s\n",
      "        80           5.6065          -0.0063            0.05s\n",
      "        90           4.4880           0.0165            0.05s\n",
      "       100           3.5269          -0.0885            0.04s\n",
      "       200           0.3414          -0.0060            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.8, learning_rate=0.05, score=0.285034, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.8, learning_rate=0.05 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         158.3255          27.5288            0.00s\n",
      "         2         192.3097          -2.0664            0.10s\n",
      "         3         184.0155           0.5617            0.13s\n",
      "         4         154.1330           0.5367            0.10s\n",
      "         5         156.1989          -0.0544            0.12s\n",
      "         6         131.8712           0.5963            0.10s\n",
      "         7         107.6108          16.4488            0.11s\n",
      "         8         120.8746           1.2283            0.12s\n",
      "         9         111.8588          -0.9314            0.13s\n",
      "        10          95.2026          -0.3503            0.11s\n",
      "        20          52.1071          -0.1867            0.09s\n",
      "        30          35.0050          -0.9010            0.09s\n",
      "        40          21.6973          -0.4732            0.08s\n",
      "        50          19.7562          -0.3959            0.07s\n",
      "        60          11.4069          -0.6065            0.07s\n",
      "        70          10.0372          -0.2365            0.06s\n",
      "        80           7.0070          -0.0134            0.05s\n",
      "        90           5.6783          -0.3289            0.05s\n",
      "       100           4.3444          -0.1800            0.04s\n",
      "       200           0.4941          -0.0091            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.8, learning_rate=0.05, score=0.626511, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         262.8658          -2.9054            0.00s\n",
      "         2         220.9964           4.0227            0.01s\n",
      "         3         175.4706          -0.2296            0.01s\n",
      "         4         155.9681           2.3634            0.01s\n",
      "         5          93.0879           1.1133            0.01s\n",
      "         6          73.2691          17.2805            0.01s\n",
      "         7         106.9451           0.6327            0.01s\n",
      "         8          90.4306           6.0374            0.01s\n",
      "         9          90.6089           0.5271            0.01s\n",
      "        10          61.4069           6.2804            0.01s\n",
      "        20          27.3549          -2.3446            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.7, learning_rate=0.1, score=0.339317, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         264.5848          -3.7668            0.02s\n",
      "         2         222.3572          -1.0804            0.01s\n",
      "         3         178.0437          -0.3488            0.01s\n",
      "         4         153.9776           2.2977            0.01s\n",
      "         5          89.1182           1.1180            0.01s\n",
      "         6          70.7960          15.3296            0.01s\n",
      "         7         106.9559           3.3278            0.01s\n",
      "         8          90.7802           9.7359            0.01s\n",
      "         9          88.9477           1.8940            0.01s\n",
      "        10          61.5709           0.9214            0.01s\n",
      "        20          28.5320          -0.6776            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.7, learning_rate=0.1, score=-1.453880, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         262.8065          -2.4396            0.02s\n",
      "         2         218.9041           3.7570            0.02s\n",
      "         3         174.2150          -1.5867            0.02s\n",
      "         4         153.3974           0.4726            0.02s\n",
      "         5          87.8555           1.7901            0.01s\n",
      "         6          71.5664           9.2502            0.01s\n",
      "         7         108.5677           3.3918            0.01s\n",
      "         8          86.8464           9.0799            0.01s\n",
      "         9          89.7808           1.5033            0.01s\n",
      "        10          60.7715          -1.1748            0.01s\n",
      "        20          30.1439          -4.5142            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.7, learning_rate=0.1, score=0.125979, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         256.1238          -0.3836            0.02s\n",
      "         2         211.7803           2.6240            0.01s\n",
      "         3         169.0250           0.0708            0.01s\n",
      "         4         148.4681           0.5472            0.01s\n",
      "         5          87.5807           0.3824            0.01s\n",
      "         6          64.5821           4.7040            0.01s\n",
      "         7         107.5384           2.2573            0.01s\n",
      "         8          78.2253           8.2995            0.01s\n",
      "         9          84.3936           2.3927            0.01s\n",
      "        10          57.3567          -0.9504            0.01s\n",
      "        20          26.6672          -2.7083            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.7, learning_rate=0.1, score=0.036579, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         198.0329          -0.0243            0.02s\n",
      "         2         161.7336           3.4997            0.02s\n",
      "         3         137.5545          -0.1031            0.01s\n",
      "         4         111.2589           1.4515            0.01s\n",
      "         5          54.1124           0.7492            0.01s\n",
      "         6          58.8313           5.8361            0.01s\n",
      "         7          83.1991          -0.5532            0.01s\n",
      "         8          73.7525          -1.5827            0.01s\n",
      "         9          70.2469          -0.0856            0.01s\n",
      "        10          53.4014          -1.4817            0.01s\n",
      "        20          21.7508           0.3439            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.7, learning_rate=0.1, score=-0.128014, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         204.1237          30.8578            0.02s\n",
      "         2         176.2616          28.1649            0.02s\n",
      "         3         174.6204           2.2035            0.01s\n",
      "         4         132.3285           0.3386            0.01s\n",
      "         5          87.6627           0.8449            0.01s\n",
      "         6          86.9300          -2.1871            0.01s\n",
      "         7          85.0056          11.4036            0.01s\n",
      "         8          92.4498          -0.4039            0.01s\n",
      "         9          77.0537          -0.0198            0.01s\n",
      "        10          69.9551           6.5173            0.01s\n",
      "        20          30.4621          -1.8251            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.7, learning_rate=0.1, score=-0.918086, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         123.7072           1.5255            0.04s\n",
      "         2         107.3706          28.2098            0.03s\n",
      "         3         139.4616           0.7118            0.02s\n",
      "         4         101.6939           1.9011            0.02s\n",
      "         5          94.7211          -1.5840            0.01s\n",
      "         6          95.5368           0.9291            0.01s\n",
      "         7          46.8264           8.6758            0.01s\n",
      "         8          75.9240          -0.4583            0.01s\n",
      "         9          60.5617           1.5385            0.01s\n",
      "        10          52.8697          -0.9924            0.01s\n",
      "        20          24.8743           0.2826            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.7, learning_rate=0.1, score=0.017749, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         208.0202          30.0677            0.00s\n",
      "         2         175.4719          25.9461            0.01s\n",
      "         3         183.9487           0.2350            0.01s\n",
      "         4         140.4071           2.5427            0.01s\n",
      "         5          88.6856           0.3884            0.01s\n",
      "         6         124.3057           0.2204            0.01s\n",
      "         7          78.6821          12.0933            0.01s\n",
      "         8          89.8906          -2.7397            0.01s\n",
      "         9          57.7148           0.5756            0.01s\n",
      "        10          68.9297           4.1508            0.00s\n",
      "        20          31.8865           0.3512            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.7, learning_rate=0.1, score=-5.603966, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         144.2561          67.0223            0.02s\n",
      "         2         187.6820          -3.7931            0.01s\n",
      "         3         144.9588          21.1933            0.01s\n",
      "         4         107.1331          13.7385            0.01s\n",
      "         5         120.0382           0.9391            0.01s\n",
      "         6         101.0801          -0.3243            0.01s\n",
      "         7          74.4217           8.9459            0.01s\n",
      "         8          72.5340           0.9129            0.01s\n",
      "         9          47.2228          -0.9725            0.01s\n",
      "        10          54.3601           0.3420            0.01s\n",
      "        20          24.1906           0.1054            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.7, learning_rate=0.1, score=0.198488, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         152.3957          34.5125            0.02s\n",
      "         2         166.4078          -6.6912            0.02s\n",
      "         3         160.8578           1.3137            0.01s\n",
      "         4         123.6751           0.6482            0.01s\n",
      "         5         116.3182           0.9625            0.01s\n",
      "         6          94.8785           1.5927            0.01s\n",
      "         7          73.5657           7.7550            0.01s\n",
      "         8          75.5867          -0.2429            0.01s\n",
      "         9          44.8079           3.5097            0.01s\n",
      "        10          52.9112          -2.0431            0.01s\n",
      "        20          22.5081          -0.8693            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.7, learning_rate=0.1, score=0.633182, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         244.9091          -4.7851            0.00s\n",
      "         2         204.8047           1.7528            0.01s\n",
      "         3         165.3122          -0.7743            0.02s\n",
      "         4         150.0433           2.3150            0.02s\n",
      "         5          94.9605           4.1643            0.01s\n",
      "         6         100.9927          17.7065            0.01s\n",
      "         7          99.5158           0.1175            0.01s\n",
      "         8          82.8676           4.2680            0.01s\n",
      "         9          85.1565           0.8391            0.01s\n",
      "        10          69.0982           1.0308            0.01s\n",
      "        20          30.0836          -0.4102            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.75, learning_rate=0.1, score=0.571264, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         246.5297          -6.1481            0.00s\n",
      "         2         206.5334          -0.4408            0.01s\n",
      "         3         166.6904          -1.0804            0.01s\n",
      "         4         146.5628           3.5243            0.01s\n",
      "         5          88.8836           0.3732            0.01s\n",
      "         6          97.6289          15.4687            0.01s\n",
      "         7          97.8836          -3.5274            0.01s\n",
      "         8          82.9149          10.8805            0.01s\n",
      "         9          83.8288           3.1215            0.00s\n",
      "        10          69.5891          -1.3278            0.01s\n",
      "        20          32.2921          -0.0855            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.75, learning_rate=0.1, score=-0.624163, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         247.6843          -5.9155            0.00s\n",
      "         2         206.6658           4.6904            0.01s\n",
      "         3         164.5391          -1.8892            0.01s\n",
      "         4         146.6786           4.5077            0.01s\n",
      "         5          88.9411           8.2152            0.01s\n",
      "         6          99.9737          13.6023            0.01s\n",
      "         7          99.8886           2.9253            0.01s\n",
      "         8          79.0966          10.5812            0.01s\n",
      "         9          81.2340           0.7805            0.01s\n",
      "        10          66.3535          -0.5691            0.01s\n",
      "        20          32.7656          -0.1217            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.75, learning_rate=0.1, score=0.074918, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         241.3760           0.1692            0.00s\n",
      "         2         198.1967           2.7898            0.01s\n",
      "         3         159.3101          -0.7978            0.01s\n",
      "         4         143.5937           1.5462            0.01s\n",
      "         5          87.5214           1.9932            0.01s\n",
      "         6          96.7593          15.7438            0.01s\n",
      "         7          99.8412          -1.0981            0.01s\n",
      "         8          72.9228           8.1512            0.01s\n",
      "         9          79.8875           2.0719            0.01s\n",
      "        10          63.0211           5.0942            0.01s\n",
      "        20          28.8266          -0.2679            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.75, learning_rate=0.1, score=-0.101749, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         186.3867          -1.1701            0.00s\n",
      "         2         154.0178           3.8243            0.01s\n",
      "         3         129.5736          -0.5592            0.01s\n",
      "         4         112.2960          -0.7840            0.01s\n",
      "         5          54.4220           7.8209            0.01s\n",
      "         6          87.8630          -1.8935            0.01s\n",
      "         7          74.6408          -2.0772            0.01s\n",
      "         8          64.4901          -2.5314            0.01s\n",
      "         9          64.2275          -1.2492            0.01s\n",
      "        10          47.7917          -1.3823            0.01s\n",
      "        20          22.4049           0.0228            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.75, learning_rate=0.1, score=-0.222743, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         190.6566          33.8868            0.02s\n",
      "         2         170.6149          30.9591            0.01s\n",
      "         3         167.5426           0.0545            0.01s\n",
      "         4         132.3537          -1.1084            0.01s\n",
      "         5          85.4612           2.4108            0.01s\n",
      "         6         112.3850          -2.1312            0.01s\n",
      "         7          86.1611           9.0458            0.01s\n",
      "         8          82.7949          -2.9607            0.01s\n",
      "         9          71.8612          -2.3986            0.01s\n",
      "        10          67.1836           5.8593            0.01s\n",
      "        20          30.9319          -0.0504            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.75, learning_rate=0.1, score=-0.749231, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         117.0397           0.1609            0.02s\n",
      "         2         104.4567           4.1667            0.02s\n",
      "         3         139.6583           1.3361            0.02s\n",
      "         4         108.3229          -1.9874            0.02s\n",
      "         5          99.8879          -0.6580            0.01s\n",
      "         6          92.9491          -0.8423            0.01s\n",
      "         7          57.3517           9.7576            0.01s\n",
      "         8          71.2306           0.9487            0.01s\n",
      "         9          57.7076           1.2155            0.01s\n",
      "        10          52.8153           6.2931            0.01s\n",
      "        20          24.1345          -0.0577            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.75, learning_rate=0.1, score=-0.013565, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         198.0561          43.9576            0.00s\n",
      "         2         172.4489          27.4678            0.01s\n",
      "         3         175.6636           2.2493            0.01s\n",
      "         4         136.1155           1.1267            0.01s\n",
      "         5          91.3650           1.6835            0.01s\n",
      "         6         122.2101          -1.0514            0.01s\n",
      "         7          91.1172          11.7353            0.01s\n",
      "         8          90.9978          -1.4523            0.01s\n",
      "         9          56.7388           0.4585            0.01s\n",
      "        10          68.2205           5.4793            0.01s\n",
      "        20          32.6598           0.6124            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.75, learning_rate=0.1, score=-6.153976, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         142.6835          71.2680            0.02s\n",
      "         2         189.0696           0.9837            0.02s\n",
      "         3         143.4282          22.9831            0.01s\n",
      "         4         122.4720          -0.7270            0.01s\n",
      "         5         119.0424           0.8025            0.01s\n",
      "         6          98.2204           0.2950            0.01s\n",
      "         7          73.7368          12.0137            0.01s\n",
      "         8          70.8693           1.2037            0.01s\n",
      "         9          48.2885          -0.8560            0.01s\n",
      "        10          52.8030           2.8342            0.01s\n",
      "        20          22.3888          -2.5022            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.75, learning_rate=0.1, score=0.221842, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         151.3252          41.1125            0.02s\n",
      "         2         167.9958           3.5696            0.01s\n",
      "         3         153.3046           0.3679            0.01s\n",
      "         4         117.9798           1.0669            0.01s\n",
      "         5         110.2722          -0.0815            0.01s\n",
      "         6          90.0852           1.0381            0.01s\n",
      "         7          71.3803          11.8296            0.01s\n",
      "         8          72.6838           0.8961            0.01s\n",
      "         9          42.6973           2.0138            0.01s\n",
      "        10          48.3787          -1.9061            0.01s\n",
      "        20          22.7478          -1.9083            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.75, learning_rate=0.1, score=0.645634, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         236.5202          -6.5556            0.02s\n",
      "         2         206.0829           2.4892            0.02s\n",
      "         3         161.6424           0.3191            0.01s\n",
      "         4         147.4986           3.0073            0.01s\n",
      "         5          95.8493           3.2118            0.01s\n",
      "         6          96.7498          21.3187            0.01s\n",
      "         7          95.6117          -0.1053            0.01s\n",
      "         8          80.3913           7.6684            0.01s\n",
      "         9          81.4958           1.1355            0.01s\n",
      "        10          67.3661           6.5160            0.01s\n",
      "        20          29.8975           0.0603            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.8, learning_rate=0.1, score=0.234978, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         237.7680          -7.4811            0.04s\n",
      "         2         208.4878           1.3715            0.03s\n",
      "         3         161.8860          -0.0891            0.02s\n",
      "         4         144.6101           2.8569            0.02s\n",
      "         5          92.2313          -1.3031            0.01s\n",
      "         6          93.7766          19.0260            0.01s\n",
      "         7          93.8149           1.3667            0.01s\n",
      "         8          79.4476          12.0193            0.01s\n",
      "         9          78.8401           1.9034            0.01s\n",
      "        10          65.9160          -1.2967            0.01s\n",
      "        20          31.2080          -0.1639            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.8, learning_rate=0.1, score=-1.049950, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         236.4401          -6.6425            0.02s\n",
      "         2         205.5058           1.6582            0.01s\n",
      "         3         161.2724          -1.6024            0.01s\n",
      "         4         143.9889           2.2850            0.01s\n",
      "         5          89.0190           4.2659            0.01s\n",
      "         6          95.0057          20.6741            0.01s\n",
      "         7          93.6789           3.6990            0.01s\n",
      "         8          74.9801          11.2001            0.01s\n",
      "         9          77.8527          -0.0749            0.01s\n",
      "        10          64.1170          -1.1040            0.01s\n",
      "        20          29.3921           0.3342            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.8, learning_rate=0.1, score=0.240145, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         230.3734           1.1228            0.02s\n",
      "         2         198.0328           1.6821            0.01s\n",
      "         3         154.5906          -2.4774            0.01s\n",
      "         4         141.3734          -0.2815            0.01s\n",
      "         5          88.0733           1.2910            0.01s\n",
      "         6          92.0782          18.8025            0.01s\n",
      "         7          95.0809           1.6771            0.01s\n",
      "         8          70.1894           8.0632            0.01s\n",
      "         9          73.8739           2.7558            0.01s\n",
      "        10          57.9961           0.0827            0.00s\n",
      "        20          26.7782          -2.2641            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.8, learning_rate=0.1, score=-0.020680, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         182.1397          -1.9354            0.02s\n",
      "         2         157.5296          -0.0847            0.02s\n",
      "         3         126.0536          -1.6761            0.02s\n",
      "         4         112.6346           0.3971            0.02s\n",
      "         5          55.9613           4.0620            0.01s\n",
      "         6          82.9701          -5.1848            0.01s\n",
      "         7          73.1678          -3.5716            0.01s\n",
      "         8          62.6832          -4.1683            0.01s\n",
      "         9          66.0019          -1.9104            0.01s\n",
      "        10          49.3426           0.1143            0.01s\n",
      "        20          22.4788           0.6244            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.8, learning_rate=0.1, score=-0.210319, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         187.9873          41.7830            0.00s\n",
      "         2         171.9537          37.4702            0.01s\n",
      "         3         161.0043          -1.7492            0.01s\n",
      "         4         132.5319          -0.4276            0.01s\n",
      "         5          83.7036           3.4274            0.01s\n",
      "         6         108.0456          -1.5220            0.01s\n",
      "         7          84.8802          10.2830            0.01s\n",
      "         8          82.6213           0.3530            0.01s\n",
      "         9          70.1084          -1.6202            0.01s\n",
      "        10          64.2965           7.8351            0.01s\n",
      "        20          27.9639           0.7302            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.8, learning_rate=0.1, score=-0.977757, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         118.4191           7.2077            0.02s\n",
      "         2         111.4162          34.7246            0.02s\n",
      "         3         128.4961          -1.2471            0.02s\n",
      "         4         101.9903           0.0780            0.01s\n",
      "         5          90.5179          -0.2382            0.01s\n",
      "         6          84.1471          -0.9777            0.01s\n",
      "         7          55.0324          10.6068            0.01s\n",
      "         8          67.7334          -0.3540            0.01s\n",
      "         9          55.3630           1.6033            0.01s\n",
      "        10          49.1757          -0.2559            0.01s\n",
      "        20          21.8009          -0.2318            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.8, learning_rate=0.1, score=0.028048, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         193.2021          53.5973            0.00s\n",
      "         2         171.7450          37.9446            0.01s\n",
      "         3         167.3416           0.6678            0.01s\n",
      "         4         131.5012           2.9652            0.01s\n",
      "         5          86.9403           2.2613            0.01s\n",
      "         6         113.4580          -3.5376            0.01s\n",
      "         7          88.0329          16.0978            0.01s\n",
      "         8          86.4696          -0.7687            0.01s\n",
      "         9          52.3169           3.3993            0.01s\n",
      "        10          65.2144           8.5409            0.01s\n",
      "        20          29.6667          -0.3534            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.8, learning_rate=0.1, score=-2.440081, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         136.6496          95.9320            0.02s\n",
      "         2         180.2674          -2.4761            0.02s\n",
      "         3         132.6954          29.7444            0.02s\n",
      "         4         113.7503           0.7629            0.02s\n",
      "         5         110.0132           0.1133            0.02s\n",
      "         6          91.4702          -0.3071            0.01s\n",
      "         7          70.0900          15.0178            0.01s\n",
      "         8          68.4053           1.2771            0.01s\n",
      "         9          58.6432          -0.7747            0.01s\n",
      "        10          47.6259           2.3104            0.01s\n",
      "        20          22.4320          -0.8196            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.8, learning_rate=0.1, score=0.182915, total=   0.0s\n",
      "[CV] n_estimators=20, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         146.7422          53.3235            0.00s\n",
      "         2         161.7998          -4.6665            0.01s\n",
      "         3         145.2594           0.4953            0.01s\n",
      "         4         112.4802           0.5597            0.01s\n",
      "         5         108.4693          -0.3235            0.01s\n",
      "         6          84.3720           2.2330            0.01s\n",
      "         7          69.9517          15.9506            0.01s\n",
      "         8          68.6523          -0.9784            0.01s\n",
      "         9          58.5079          -5.0482            0.00s\n",
      "        10          47.8218          -1.6201            0.00s\n",
      "        20          23.9498          -0.6134            0.00s\n",
      "[CV]  n_estimators=20, subsample=0.8, learning_rate=0.1, score=0.695394, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         262.8658          -2.9054            0.03s\n",
      "         2         220.9964           4.0227            0.03s\n",
      "         3         175.4706          -0.2296            0.03s\n",
      "         4         155.9681           2.3634            0.03s\n",
      "         5          93.0879           1.1133            0.02s\n",
      "         6          73.2691          17.2805            0.02s\n",
      "         7         106.9451           0.6327            0.02s\n",
      "         8          90.4306           6.0374            0.02s\n",
      "         9          90.6089           0.5271            0.01s\n",
      "        10          61.4069           6.2804            0.01s\n",
      "        20          27.3549          -2.3446            0.00s\n",
      "        30          13.3452          -0.3527            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.7, learning_rate=0.1, score=0.092354, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         264.5848          -3.7668            0.03s\n",
      "         2         222.3572          -1.0804            0.03s\n",
      "         3         178.0437          -0.3488            0.02s\n",
      "         4         153.9776           2.2977            0.02s\n",
      "         5          89.1182           1.1180            0.02s\n",
      "         6          70.7960          15.3296            0.02s\n",
      "         7         106.9559           3.3278            0.01s\n",
      "         8          90.7802           9.7359            0.01s\n",
      "         9          88.9477           1.8940            0.01s\n",
      "        10          61.5709           0.9214            0.01s\n",
      "        20          28.5320          -0.6776            0.00s\n",
      "        30          13.5926          -0.4935            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.7, learning_rate=0.1, score=-1.460660, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         262.8065          -2.4396            0.03s\n",
      "         2         218.9041           3.7570            0.03s\n",
      "         3         174.2150          -1.5867            0.03s\n",
      "         4         153.3974           0.4726            0.02s\n",
      "         5          87.8555           1.7901            0.02s\n",
      "         6          71.5664           9.2502            0.02s\n",
      "         7         108.5677           3.3918            0.02s\n",
      "         8          86.8464           9.0799            0.02s\n",
      "         9          89.7808           1.5033            0.01s\n",
      "        10          60.7715          -1.1748            0.01s\n",
      "        20          30.1439          -4.5142            0.00s\n",
      "        30          13.0760          -0.6942            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.7, learning_rate=0.1, score=-0.006869, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         256.1238          -0.3836            0.03s\n",
      "         2         211.7803           2.6240            0.03s\n",
      "         3         169.0250           0.0708            0.02s\n",
      "         4         148.4681           0.5472            0.02s\n",
      "         5          87.5807           0.3824            0.02s\n",
      "         6          64.5821           4.7040            0.02s\n",
      "         7         107.5384           2.2573            0.02s\n",
      "         8          78.2253           8.2995            0.01s\n",
      "         9          84.3936           2.3927            0.01s\n",
      "        10          57.3567          -0.9504            0.01s\n",
      "        20          26.6672          -2.7083            0.00s\n",
      "        30          13.1692          -0.8021            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.7, learning_rate=0.1, score=0.064800, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         198.0329          -0.0243            0.00s\n",
      "         2         161.7336           3.4997            0.00s\n",
      "         3         137.5545          -0.1031            0.01s\n",
      "         4         111.2589           1.4515            0.01s\n",
      "         5          54.1124           0.7492            0.01s\n",
      "         6          58.8313           5.8361            0.01s\n",
      "         7          83.1991          -0.5532            0.01s\n",
      "         8          73.7525          -1.5827            0.01s\n",
      "         9          70.2469          -0.0856            0.01s\n",
      "        10          53.4014          -1.4817            0.01s\n",
      "        20          21.7508           0.3439            0.00s\n",
      "        30          11.1034          -0.1016            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.7, learning_rate=0.1, score=-0.377874, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         204.1237          30.8578            0.06s\n",
      "         2         176.2616          28.1649            0.06s\n",
      "         3         174.6204           2.2035            0.05s\n",
      "         4         132.3285           0.3386            0.05s\n",
      "         5          87.6627           0.8449            0.04s\n",
      "         6          86.9300          -2.1871            0.03s\n",
      "         7          85.0056          11.4036            0.03s\n",
      "         8          92.4498          -0.4039            0.02s\n",
      "         9          77.0537          -0.0198            0.02s\n",
      "        10          69.9551           6.5173            0.02s\n",
      "        20          30.4621          -1.8251            0.01s\n",
      "        30          17.7524           0.2619            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.7, learning_rate=0.1, score=-0.345159, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         123.7072           1.5255            0.03s\n",
      "         2         107.3706          28.2098            0.01s\n",
      "         3         139.4616           0.7118            0.02s\n",
      "         4         101.6939           1.9011            0.01s\n",
      "         5          94.7211          -1.5840            0.02s\n",
      "         6          95.5368           0.9291            0.01s\n",
      "         7          46.8264           8.6758            0.01s\n",
      "         8          75.9240          -0.4583            0.01s\n",
      "         9          60.5617           1.5385            0.01s\n",
      "        10          52.8697          -0.9924            0.01s\n",
      "        20          24.8743           0.2826            0.00s\n",
      "        30          14.0894           0.0077            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.7, learning_rate=0.1, score=0.105940, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         208.0202          30.0677            0.00s\n",
      "         2         175.4719          25.9461            0.01s\n",
      "         3         183.9487           0.2350            0.02s\n",
      "         4         140.4071           2.5427            0.01s\n",
      "         5          88.6856           0.3884            0.02s\n",
      "         6         124.3057           0.2204            0.01s\n",
      "         7          78.6821          12.0933            0.01s\n",
      "         8          89.8906          -2.7397            0.01s\n",
      "         9          57.7148           0.5756            0.01s\n",
      "        10          68.9297           4.1508            0.01s\n",
      "        20          31.8865           0.3512            0.00s\n",
      "        30          14.8773          -2.0780            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.7, learning_rate=0.1, score=-5.031455, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         144.2561          67.0223            0.03s\n",
      "         2         187.6820          -3.7931            0.03s\n",
      "         3         144.9588          21.1933            0.02s\n",
      "         4         107.1331          13.7385            0.02s\n",
      "         5         120.0382           0.9391            0.02s\n",
      "         6         101.0801          -0.3243            0.02s\n",
      "         7          74.4217           8.9459            0.01s\n",
      "         8          72.5340           0.9129            0.01s\n",
      "         9          47.2228          -0.9725            0.01s\n",
      "        10          54.3601           0.3420            0.01s\n",
      "        20          24.1906           0.1054            0.00s\n",
      "        30          13.3715          -1.8196            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.7, learning_rate=0.1, score=0.181191, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         152.3957          34.5125            0.03s\n",
      "         2         166.4078          -6.6912            0.03s\n",
      "         3         160.8578           1.3137            0.03s\n",
      "         4         123.6751           0.6482            0.02s\n",
      "         5         116.3182           0.9625            0.02s\n",
      "         6          94.8785           1.5927            0.02s\n",
      "         7          73.5657           7.7550            0.02s\n",
      "         8          75.5867          -0.2429            0.02s\n",
      "         9          44.8079           3.5097            0.02s\n",
      "        10          52.9112          -2.0431            0.01s\n",
      "        20          22.5081          -0.8693            0.01s\n",
      "        30          13.8569          -1.3059            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.7, learning_rate=0.1, score=0.637039, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         244.9091          -4.7851            0.00s\n",
      "         2         204.8047           1.7528            0.01s\n",
      "         3         165.3122          -0.7743            0.01s\n",
      "         4         150.0433           2.3150            0.01s\n",
      "         5          94.9605           4.1643            0.01s\n",
      "         6         100.9927          17.7065            0.01s\n",
      "         7          99.5158           0.1175            0.01s\n",
      "         8          82.8676           4.2680            0.01s\n",
      "         9          85.1565           0.8391            0.01s\n",
      "        10          69.0982           1.0308            0.01s\n",
      "        20          30.0836          -0.4102            0.00s\n",
      "        30          13.6969          -0.0936            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.75, learning_rate=0.1, score=0.295671, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         246.5297          -6.1481            0.00s\n",
      "         2         206.5334          -0.4408            0.01s\n",
      "         3         166.6904          -1.0804            0.01s\n",
      "         4         146.5628           3.5243            0.01s\n",
      "         5          88.8836           0.3732            0.01s\n",
      "         6          97.6289          15.4687            0.01s\n",
      "         7          97.8836          -3.5274            0.02s\n",
      "         8          82.9149          10.8805            0.01s\n",
      "         9          83.8288           3.1215            0.01s\n",
      "        10          69.5891          -1.3278            0.01s\n",
      "        20          32.2921          -0.0855            0.00s\n",
      "        30          13.7299          -0.4531            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.75, learning_rate=0.1, score=-0.895133, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         247.6843          -5.9155            0.03s\n",
      "         2         206.6658           4.6904            0.03s\n",
      "         3         164.5391          -1.8892            0.02s\n",
      "         4         146.6786           4.5077            0.02s\n",
      "         5          88.9411           8.2152            0.02s\n",
      "         6          99.9737          13.6023            0.02s\n",
      "         7          99.8886           2.9253            0.02s\n",
      "         8          79.0966          10.5812            0.01s\n",
      "         9          81.2340           0.7805            0.01s\n",
      "        10          66.3535          -0.5691            0.01s\n",
      "        20          32.7656          -0.1217            0.01s\n",
      "        30          10.5839          -0.7432            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.75, learning_rate=0.1, score=-0.016822, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         241.3760           0.1692            0.00s\n",
      "         2         198.1967           2.7898            0.01s\n",
      "         3         159.3101          -0.7978            0.01s\n",
      "         4         143.5937           1.5462            0.01s\n",
      "         5          87.5214           1.9932            0.02s\n",
      "         6          96.7593          15.7438            0.02s\n",
      "         7          99.8412          -1.0981            0.02s\n",
      "         8          72.9228           8.1512            0.01s\n",
      "         9          79.8875           2.0719            0.01s\n",
      "        10          63.0211           5.0942            0.01s\n",
      "        20          28.8266          -0.2679            0.00s\n",
      "        30           9.9541          -0.6890            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.75, learning_rate=0.1, score=-0.106767, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         186.3867          -1.1701            0.00s\n",
      "         2         154.0178           3.8243            0.01s\n",
      "         3         129.5736          -0.5592            0.01s\n",
      "         4         112.2960          -0.7840            0.01s\n",
      "         5          54.4220           7.8209            0.01s\n",
      "         6          87.8630          -1.8935            0.01s\n",
      "         7          74.6408          -2.0772            0.01s\n",
      "         8          64.4901          -2.5314            0.01s\n",
      "         9          64.2275          -1.2492            0.01s\n",
      "        10          47.7917          -1.3823            0.01s\n",
      "        20          22.4049           0.0228            0.00s\n",
      "        30          11.6620          -0.1287            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.75, learning_rate=0.1, score=-0.480752, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         190.6566          33.8868            0.03s\n",
      "         2         170.6149          30.9591            0.03s\n",
      "         3         167.5426           0.0545            0.02s\n",
      "         4         132.3537          -1.1084            0.02s\n",
      "         5          85.4612           2.4108            0.02s\n",
      "         6         112.3850          -2.1312            0.02s\n",
      "         7          86.1611           9.0458            0.02s\n",
      "         8          82.7949          -2.9607            0.01s\n",
      "         9          71.8612          -2.3986            0.01s\n",
      "        10          67.1836           5.8593            0.01s\n",
      "        20          30.9319          -0.0504            0.00s\n",
      "        30          14.1479          -0.7589            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.75, learning_rate=0.1, score=-1.029659, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         117.0397           0.1609            0.03s\n",
      "         2         104.4567           4.1667            0.03s\n",
      "         3         139.6583           1.3361            0.03s\n",
      "         4         108.3229          -1.9874            0.02s\n",
      "         5          99.8879          -0.6580            0.02s\n",
      "         6          92.9491          -0.8423            0.02s\n",
      "         7          57.3517           9.7576            0.02s\n",
      "         8          71.2306           0.9487            0.02s\n",
      "         9          57.7076           1.2155            0.01s\n",
      "        10          52.8153           6.2931            0.01s\n",
      "        20          24.1345          -0.0577            0.00s\n",
      "        30          12.5556          -0.2512            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.75, learning_rate=0.1, score=0.115850, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         198.0561          43.9576            0.03s\n",
      "         2         172.4489          27.4678            0.01s\n",
      "         3         175.6636           2.2493            0.02s\n",
      "         4         136.1155           1.1267            0.02s\n",
      "         5          91.3650           1.6835            0.02s\n",
      "         6         122.2101          -1.0514            0.02s\n",
      "         7          91.1172          11.7353            0.01s\n",
      "         8          90.9978          -1.4523            0.01s\n",
      "         9          56.7388           0.4585            0.01s\n",
      "        10          68.2205           5.4793            0.01s\n",
      "        20          32.6598           0.6124            0.00s\n",
      "        30          15.1800          -0.8281            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.75, learning_rate=0.1, score=-6.696295, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         142.6835          71.2680            0.03s\n",
      "         2         189.0696           0.9837            0.03s\n",
      "         3         143.4282          22.9831            0.03s\n",
      "         4         122.4720          -0.7270            0.02s\n",
      "         5         119.0424           0.8025            0.02s\n",
      "         6          98.2204           0.2950            0.02s\n",
      "         7          73.7368          12.0137            0.02s\n",
      "         8          70.8693           1.2037            0.02s\n",
      "         9          48.2885          -0.8560            0.02s\n",
      "        10          52.8030           2.8342            0.02s\n",
      "        20          22.3888          -2.5022            0.01s\n",
      "        30          12.5633          -0.2258            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.75, learning_rate=0.1, score=0.273008, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         151.3252          41.1125            0.00s\n",
      "         2         167.9958           3.5696            0.01s\n",
      "         3         153.3046           0.3679            0.01s\n",
      "         4         117.9798           1.0669            0.01s\n",
      "         5         110.2722          -0.0815            0.01s\n",
      "         6          90.0852           1.0381            0.01s\n",
      "         7          71.3803          11.8296            0.01s\n",
      "         8          72.6838           0.8961            0.01s\n",
      "         9          42.6973           2.0138            0.01s\n",
      "        10          48.3787          -1.9061            0.01s\n",
      "        20          22.7478          -1.9083            0.00s\n",
      "        30          11.6458          -1.6155            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.75, learning_rate=0.1, score=0.676450, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         236.5202          -6.5556            0.03s\n",
      "         2         206.0829           2.4892            0.03s\n",
      "         3         161.6424           0.3191            0.02s\n",
      "         4         147.4986           3.0073            0.02s\n",
      "         5          95.8493           3.2118            0.02s\n",
      "         6          96.7498          21.3187            0.02s\n",
      "         7          95.6117          -0.1053            0.02s\n",
      "         8          80.3913           7.6684            0.02s\n",
      "         9          81.4958           1.1355            0.01s\n",
      "        10          67.3661           6.5160            0.01s\n",
      "        20          29.8975           0.0603            0.00s\n",
      "        30          10.9573           0.1072            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.8, learning_rate=0.1, score=-0.088321, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         237.7680          -7.4811            0.03s\n",
      "         2         208.4878           1.3715            0.01s\n",
      "         3         161.8860          -0.0891            0.02s\n",
      "         4         144.6101           2.8569            0.02s\n",
      "         5          92.2313          -1.3031            0.02s\n",
      "         6          93.7766          19.0260            0.02s\n",
      "         7          93.8149           1.3667            0.01s\n",
      "         8          79.4476          12.0193            0.01s\n",
      "         9          78.8401           1.9034            0.01s\n",
      "        10          65.9160          -1.2967            0.01s\n",
      "        20          31.2080          -0.1639            0.00s\n",
      "        30          12.1865          -0.7915            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.8, learning_rate=0.1, score=-1.190096, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         236.4401          -6.6425            0.00s\n",
      "         2         205.5058           1.6582            0.01s\n",
      "         3         161.2724          -1.6024            0.02s\n",
      "         4         143.9889           2.2850            0.02s\n",
      "         5          89.0190           4.2659            0.02s\n",
      "         6          95.0057          20.6741            0.02s\n",
      "         7          93.6789           3.6990            0.01s\n",
      "         8          74.9801          11.2001            0.01s\n",
      "         9          77.8527          -0.0749            0.01s\n",
      "        10          64.1170          -1.1040            0.01s\n",
      "        20          29.3921           0.3342            0.00s\n",
      "        30          10.0306          -0.7254            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.8, learning_rate=0.1, score=0.176933, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         230.3734           1.1228            0.00s\n",
      "         2         198.0328           1.6821            0.01s\n",
      "         3         154.5906          -2.4774            0.01s\n",
      "         4         141.3734          -0.2815            0.01s\n",
      "         5          88.0733           1.2910            0.02s\n",
      "         6          92.0782          18.8025            0.02s\n",
      "         7          95.0809           1.6771            0.01s\n",
      "         8          70.1894           8.0632            0.01s\n",
      "         9          73.8739           2.7558            0.01s\n",
      "        10          57.9961           0.0827            0.01s\n",
      "        20          26.7782          -2.2641            0.00s\n",
      "        30           9.4275          -0.6672            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.8, learning_rate=0.1, score=-0.089786, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         182.1397          -1.9354            0.00s\n",
      "         2         157.5296          -0.0847            0.01s\n",
      "         3         126.0536          -1.6761            0.01s\n",
      "         4         112.6346           0.3971            0.01s\n",
      "         5          55.9613           4.0620            0.01s\n",
      "         6          82.9701          -5.1848            0.01s\n",
      "         7          73.1678          -3.5716            0.01s\n",
      "         8          62.6832          -4.1683            0.01s\n",
      "         9          66.0019          -1.9104            0.01s\n",
      "        10          49.3426           0.1143            0.01s\n",
      "        20          22.4788           0.6244            0.00s\n",
      "        30          10.1968           0.1914            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.8, learning_rate=0.1, score=-0.457476, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         187.9873          41.7830            0.03s\n",
      "         2         171.9537          37.4702            0.03s\n",
      "         3         161.0043          -1.7492            0.03s\n",
      "         4         132.5319          -0.4276            0.03s\n",
      "         5          83.7036           3.4274            0.03s\n",
      "         6         108.0456          -1.5220            0.02s\n",
      "         7          84.8802          10.2830            0.02s\n",
      "         8          82.6213           0.3530            0.02s\n",
      "         9          70.1084          -1.6202            0.02s\n",
      "        10          64.2965           7.8351            0.02s\n",
      "        20          27.9639           0.7302            0.01s\n",
      "        30          12.1517          -0.3748            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.8, learning_rate=0.1, score=-1.472097, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         118.4191           7.2077            0.03s\n",
      "         2         111.4162          34.7246            0.03s\n",
      "         3         128.4961          -1.2471            0.02s\n",
      "         4         101.9903           0.0780            0.02s\n",
      "         5          90.5179          -0.2382            0.02s\n",
      "         6          84.1471          -0.9777            0.02s\n",
      "         7          55.0324          10.6068            0.02s\n",
      "         8          67.7334          -0.3540            0.01s\n",
      "         9          55.3630           1.6033            0.01s\n",
      "        10          49.1757          -0.2559            0.01s\n",
      "        20          21.8009          -0.2318            0.00s\n",
      "        30          11.1556          -0.1374            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.8, learning_rate=0.1, score=0.095424, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         193.2021          53.5973            0.06s\n",
      "         2         171.7450          37.9446            0.03s\n",
      "         3         167.3416           0.6678            0.03s\n",
      "         4         131.5012           2.9652            0.02s\n",
      "         5          86.9403           2.2613            0.02s\n",
      "         6         113.4580          -3.5376            0.02s\n",
      "         7          88.0329          16.0978            0.02s\n",
      "         8          86.4696          -0.7687            0.02s\n",
      "         9          52.3169           3.3993            0.01s\n",
      "        10          65.2144           8.5409            0.01s\n",
      "        20          29.6667          -0.3534            0.00s\n",
      "        30          13.2457          -1.3142            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.8, learning_rate=0.1, score=-3.560008, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         136.6496          95.9320            0.03s\n",
      "         2         180.2674          -2.4761            0.01s\n",
      "         3         132.6954          29.7444            0.02s\n",
      "         4         113.7503           0.7629            0.02s\n",
      "         5         110.0132           0.1133            0.02s\n",
      "         6          91.4702          -0.3071            0.02s\n",
      "         7          70.0900          15.0178            0.01s\n",
      "         8          68.4053           1.2771            0.01s\n",
      "         9          58.6432          -0.7747            0.01s\n",
      "        10          47.6259           2.3104            0.01s\n",
      "        20          22.4320          -0.8196            0.00s\n",
      "        30          11.1800          -1.4659            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.8, learning_rate=0.1, score=0.199390, total=   0.0s\n",
      "[CV] n_estimators=30, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         146.7422          53.3235            0.00s\n",
      "         2         161.7998          -4.6665            0.01s\n",
      "         3         145.2594           0.4953            0.01s\n",
      "         4         112.4802           0.5597            0.01s\n",
      "         5         108.4693          -0.3235            0.01s\n",
      "         6          84.3720           2.2330            0.01s\n",
      "         7          69.9517          15.9506            0.01s\n",
      "         8          68.6523          -0.9784            0.01s\n",
      "         9          58.5079          -5.0482            0.01s\n",
      "        10          47.8218          -1.6201            0.01s\n",
      "        20          23.9498          -0.6134            0.00s\n",
      "        30          11.5019          -0.2085            0.00s\n",
      "[CV]  n_estimators=30, subsample=0.8, learning_rate=0.1, score=0.736140, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         262.8658          -2.9054            0.00s\n",
      "         2         220.9964           4.0227            0.02s\n",
      "         3         175.4706          -0.2296            0.02s\n",
      "         4         155.9681           2.3634            0.02s\n",
      "         5          93.0879           1.1133            0.03s\n",
      "         6          73.2691          17.2805            0.02s\n",
      "         7         106.9451           0.6327            0.02s\n",
      "         8          90.4306           6.0374            0.02s\n",
      "         9          90.6089           0.5271            0.02s\n",
      "        10          61.4069           6.2804            0.02s\n",
      "        20          27.3549          -2.3446            0.01s\n",
      "        30          13.3452          -0.3527            0.01s\n",
      "        40          10.7186          -0.6676            0.00s\n",
      "        50           5.4114          -0.0995            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.7, learning_rate=0.1, score=-0.071298, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         264.5848          -3.7668            0.05s\n",
      "         2         222.3572          -1.0804            0.05s\n",
      "         3         178.0437          -0.3488            0.03s\n",
      "         4         153.9776           2.2977            0.03s\n",
      "         5          89.1182           1.1180            0.04s\n",
      "         6          70.7960          15.3296            0.03s\n",
      "         7         106.9559           3.3278            0.03s\n",
      "         8          90.7802           9.7359            0.03s\n",
      "         9          88.9477           1.8940            0.03s\n",
      "        10          61.5709           0.9214            0.02s\n",
      "        20          28.5320          -0.6776            0.01s\n",
      "        30          13.5926          -0.4935            0.01s\n",
      "        40           8.5681          -0.8864            0.00s\n",
      "        50           4.4795          -0.2587            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.7, learning_rate=0.1, score=-1.710251, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         262.8065          -2.4396            0.05s\n",
      "         2         218.9041           3.7570            0.02s\n",
      "         3         174.2150          -1.5867            0.05s\n",
      "         4         153.3974           0.4726            0.05s\n",
      "         5          87.8555           1.7901            0.04s\n",
      "         6          71.5664           9.2502            0.04s\n",
      "         7         108.5677           3.3918            0.03s\n",
      "         8          86.8464           9.0799            0.03s\n",
      "         9          89.7808           1.5033            0.03s\n",
      "        10          60.7715          -1.1748            0.03s\n",
      "        20          30.1439          -4.5142            0.01s\n",
      "        30          13.0760          -0.6942            0.01s\n",
      "        40           9.3088          -0.7189            0.00s\n",
      "        50           4.9462          -0.3992            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.7, learning_rate=0.1, score=-0.133902, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         256.1238          -0.3836            0.05s\n",
      "         2         211.7803           2.6240            0.05s\n",
      "         3         169.0250           0.0708            0.03s\n",
      "         4         148.4681           0.5472            0.03s\n",
      "         5          87.5807           0.3824            0.03s\n",
      "         6          64.5821           4.7040            0.03s\n",
      "         7         107.5384           2.2573            0.02s\n",
      "         8          78.2253           8.2995            0.03s\n",
      "         9          84.3936           2.3927            0.02s\n",
      "        10          57.3567          -0.9504            0.02s\n",
      "        20          26.6672          -2.7083            0.01s\n",
      "        30          13.1692          -0.8021            0.01s\n",
      "        40           8.9818          -0.1215            0.00s\n",
      "        50           4.5713          -0.2173            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.7, learning_rate=0.1, score=0.129514, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         198.0329          -0.0243            0.05s\n",
      "         2         161.7336           3.4997            0.05s\n",
      "         3         137.5545          -0.1031            0.03s\n",
      "         4         111.2589           1.4515            0.03s\n",
      "         5          54.1124           0.7492            0.03s\n",
      "         6          58.8313           5.8361            0.03s\n",
      "         7          83.1991          -0.5532            0.03s\n",
      "         8          73.7525          -1.5827            0.03s\n",
      "         9          70.2469          -0.0856            0.03s\n",
      "        10          53.4014          -1.4817            0.03s\n",
      "        20          21.7508           0.3439            0.01s\n",
      "        30          11.1034          -0.1016            0.01s\n",
      "        40           5.6875          -0.1346            0.00s\n",
      "        50           4.4160          -0.0298            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.7, learning_rate=0.1, score=-0.574714, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         204.1237          30.8578            0.00s\n",
      "         2         176.2616          28.1649            0.02s\n",
      "         3         174.6204           2.2035            0.02s\n",
      "         4         132.3285           0.3386            0.02s\n",
      "         5          87.6627           0.8449            0.02s\n",
      "         6          86.9300          -2.1871            0.02s\n",
      "         7          85.0056          11.4036            0.02s\n",
      "         8          92.4498          -0.4039            0.02s\n",
      "         9          77.0537          -0.0198            0.02s\n",
      "        10          69.9551           6.5173            0.02s\n",
      "        20          30.4621          -1.8251            0.01s\n",
      "        30          17.7524           0.2619            0.01s\n",
      "        40           9.5849          -0.2988            0.00s\n",
      "        50           4.2173          -0.2147            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.7, learning_rate=0.1, score=-0.438807, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         123.7072           1.5255            0.05s\n",
      "         2         107.3706          28.2098            0.05s\n",
      "         3         139.4616           0.7118            0.05s\n",
      "         4         101.6939           1.9011            0.03s\n",
      "         5          94.7211          -1.5840            0.04s\n",
      "         6          95.5368           0.9291            0.03s\n",
      "         7          46.8264           8.6758            0.03s\n",
      "         8          75.9240          -0.4583            0.03s\n",
      "         9          60.5617           1.5385            0.03s\n",
      "        10          52.8697          -0.9924            0.02s\n",
      "        20          24.8743           0.2826            0.01s\n",
      "        30          14.0894           0.0077            0.01s\n",
      "        40           7.1751          -0.5242            0.00s\n",
      "        50           3.6592          -0.1535            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.7, learning_rate=0.1, score=0.184612, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         208.0202          30.0677            0.00s\n",
      "         2         175.4719          25.9461            0.02s\n",
      "         3         183.9487           0.2350            0.02s\n",
      "         4         140.4071           2.5427            0.02s\n",
      "         5          88.6856           0.3884            0.03s\n",
      "         6         124.3057           0.2204            0.04s\n",
      "         7          78.6821          12.0933            0.04s\n",
      "         8          89.8906          -2.7397            0.03s\n",
      "         9          57.7148           0.5756            0.03s\n",
      "        10          68.9297           4.1508            0.03s\n",
      "        20          31.8865           0.3512            0.02s\n",
      "        30          14.8773          -2.0780            0.01s\n",
      "        40           8.4074           0.1711            0.00s\n",
      "        50           3.8872          -0.3233            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.7, learning_rate=0.1, score=-4.719346, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         144.2561          67.0223            0.05s\n",
      "         2         187.6820          -3.7931            0.02s\n",
      "         3         144.9588          21.1933            0.03s\n",
      "         4         107.1331          13.7385            0.02s\n",
      "         5         120.0382           0.9391            0.03s\n",
      "         6         101.0801          -0.3243            0.02s\n",
      "         7          74.4217           8.9459            0.02s\n",
      "         8          72.5340           0.9129            0.02s\n",
      "         9          47.2228          -0.9725            0.02s\n",
      "        10          54.3601           0.3420            0.02s\n",
      "        20          24.1906           0.1054            0.01s\n",
      "        30          13.3715          -1.8196            0.01s\n",
      "        40           5.8459          -0.0281            0.00s\n",
      "        50           3.8378          -0.3121            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.7, learning_rate=0.1, score=0.224669, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         152.3957          34.5125            0.00s\n",
      "         2         166.4078          -6.6912            0.02s\n",
      "         3         160.8578           1.3137            0.02s\n",
      "         4         123.6751           0.6482            0.02s\n",
      "         5         116.3182           0.9625            0.02s\n",
      "         6          94.8785           1.5927            0.02s\n",
      "         7          73.5657           7.7550            0.02s\n",
      "         8          75.5867          -0.2429            0.02s\n",
      "         9          44.8079           3.5097            0.02s\n",
      "        10          52.9112          -2.0431            0.02s\n",
      "        20          22.5081          -0.8693            0.01s\n",
      "        30          13.8569          -1.3059            0.01s\n",
      "        40           8.3869          -0.4379            0.00s\n",
      "        50           5.4156          -0.2633            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.7, learning_rate=0.1, score=0.673615, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         244.9091          -4.7851            0.05s\n",
      "         2         204.8047           1.7528            0.02s\n",
      "         3         165.3122          -0.7743            0.03s\n",
      "         4         150.0433           2.3150            0.02s\n",
      "         5          94.9605           4.1643            0.03s\n",
      "         6         100.9927          17.7065            0.02s\n",
      "         7          99.5158           0.1175            0.02s\n",
      "         8          82.8676           4.2680            0.03s\n",
      "         9          85.1565           0.8391            0.02s\n",
      "        10          69.0982           1.0308            0.02s\n",
      "        20          30.0836          -0.4102            0.01s\n",
      "        30          13.6969          -0.0936            0.01s\n",
      "        40           8.6332          -0.8593            0.00s\n",
      "        50           5.2889          -0.3394            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.75, learning_rate=0.1, score=0.146106, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         246.5297          -6.1481            0.00s\n",
      "         2         206.5334          -0.4408            0.05s\n",
      "         3         166.6904          -1.0804            0.03s\n",
      "         4         146.5628           3.5243            0.03s\n",
      "         5          88.8836           0.3732            0.04s\n",
      "         6          97.6289          15.4687            0.04s\n",
      "         7          97.8836          -3.5274            0.03s\n",
      "         8          82.9149          10.8805            0.03s\n",
      "         9          83.8288           3.1215            0.03s\n",
      "        10          69.5891          -1.3278            0.03s\n",
      "        20          32.2921          -0.0855            0.02s\n",
      "        30          13.7299          -0.4531            0.01s\n",
      "        40           8.8591           0.0329            0.01s\n",
      "        50           4.4111          -0.3667            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.75, learning_rate=0.1, score=-1.002737, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         247.6843          -5.9155            0.05s\n",
      "         2         206.6658           4.6904            0.02s\n",
      "         3         164.5391          -1.8892            0.03s\n",
      "         4         146.6786           4.5077            0.03s\n",
      "         5          88.9411           8.2152            0.04s\n",
      "         6          99.9737          13.6023            0.04s\n",
      "         7          99.8886           2.9253            0.04s\n",
      "         8          79.0966          10.5812            0.04s\n",
      "         9          81.2340           0.7805            0.03s\n",
      "        10          66.3535          -0.5691            0.03s\n",
      "        20          32.7656          -0.1217            0.02s\n",
      "        30          10.5839          -0.7432            0.01s\n",
      "        40           7.2422          -0.0295            0.00s\n",
      "        50           4.0204          -0.0575            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.75, learning_rate=0.1, score=-0.127303, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         241.3760           0.1692            0.05s\n",
      "         2         198.1967           2.7898            0.02s\n",
      "         3         159.3101          -0.7978            0.03s\n",
      "         4         143.5937           1.5462            0.03s\n",
      "         5          87.5214           1.9932            0.04s\n",
      "         6          96.7593          15.7438            0.03s\n",
      "         7          99.8412          -1.0981            0.03s\n",
      "         8          72.9228           8.1512            0.03s\n",
      "         9          79.8875           2.0719            0.03s\n",
      "        10          63.0211           5.0942            0.03s\n",
      "        20          28.8266          -0.2679            0.02s\n",
      "        30           9.9541          -0.6890            0.01s\n",
      "        40           7.6987          -0.0051            0.00s\n",
      "        50           3.7230           0.0512            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.75, learning_rate=0.1, score=-0.093267, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         186.3867          -1.1701            0.05s\n",
      "         2         154.0178           3.8243            0.05s\n",
      "         3         129.5736          -0.5592            0.03s\n",
      "         4         112.2960          -0.7840            0.03s\n",
      "         5          54.4220           7.8209            0.03s\n",
      "         6          87.8630          -1.8935            0.03s\n",
      "         7          74.6408          -2.0772            0.02s\n",
      "         8          64.4901          -2.5314            0.03s\n",
      "         9          64.2275          -1.2492            0.02s\n",
      "        10          47.7917          -1.3823            0.02s\n",
      "        20          22.4049           0.0228            0.01s\n",
      "        30          11.6620          -0.1287            0.01s\n",
      "        40           6.1861          -0.1299            0.00s\n",
      "        50           4.3740          -0.0734            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.75, learning_rate=0.1, score=-0.625247, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         190.6566          33.8868            0.05s\n",
      "         2         170.6149          30.9591            0.05s\n",
      "         3         167.5426           0.0545            0.05s\n",
      "         4         132.3537          -1.1084            0.03s\n",
      "         5          85.4612           2.4108            0.04s\n",
      "         6         112.3850          -2.1312            0.03s\n",
      "         7          86.1611           9.0458            0.03s\n",
      "         8          82.7949          -2.9607            0.03s\n",
      "         9          71.8612          -2.3986            0.03s\n",
      "        10          67.1836           5.8593            0.03s\n",
      "        20          30.9319          -0.0504            0.02s\n",
      "        30          14.1479          -0.7589            0.01s\n",
      "        40           7.6120          -0.0206            0.00s\n",
      "        50           3.8695          -0.4833            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.75, learning_rate=0.1, score=-1.309555, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         117.0397           0.1609            0.05s\n",
      "         2         104.4567           4.1667            0.02s\n",
      "         3         139.6583           1.3361            0.03s\n",
      "         4         108.3229          -1.9874            0.02s\n",
      "         5          99.8879          -0.6580            0.03s\n",
      "         6          92.9491          -0.8423            0.03s\n",
      "         7          57.3517           9.7576            0.03s\n",
      "         8          71.2306           0.9487            0.03s\n",
      "         9          57.7076           1.2155            0.03s\n",
      "        10          52.8153           6.2931            0.02s\n",
      "        20          24.1345          -0.0577            0.01s\n",
      "        30          12.5556          -0.2512            0.01s\n",
      "        40           5.1996           0.2031            0.00s\n",
      "        50           2.4617          -0.0543            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.75, learning_rate=0.1, score=0.179612, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         198.0561          43.9576            0.05s\n",
      "         2         172.4489          27.4678            0.05s\n",
      "         3         175.6636           2.2493            0.05s\n",
      "         4         136.1155           1.1267            0.05s\n",
      "         5          91.3650           1.6835            0.05s\n",
      "         6         122.2101          -1.0514            0.04s\n",
      "         7          91.1172          11.7353            0.04s\n",
      "         8          90.9978          -1.4523            0.03s\n",
      "         9          56.7388           0.4585            0.03s\n",
      "        10          68.2205           5.4793            0.03s\n",
      "        20          32.6598           0.6124            0.02s\n",
      "        30          15.1800          -0.8281            0.01s\n",
      "        40           6.9259          -0.4930            0.00s\n",
      "        50           3.1232          -0.1682            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.75, learning_rate=0.1, score=-7.062663, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         142.6835          71.2680            0.05s\n",
      "         2         189.0696           0.9837            0.05s\n",
      "         3         143.4282          22.9831            0.03s\n",
      "         4         122.4720          -0.7270            0.03s\n",
      "         5         119.0424           0.8025            0.04s\n",
      "         6          98.2204           0.2950            0.04s\n",
      "         7          73.7368          12.0137            0.03s\n",
      "         8          70.8693           1.2037            0.03s\n",
      "         9          48.2885          -0.8560            0.03s\n",
      "        10          52.8030           2.8342            0.03s\n",
      "        20          22.3888          -2.5022            0.02s\n",
      "        30          12.5633          -0.2258            0.01s\n",
      "        40           5.3020          -0.5017            0.00s\n",
      "        50           3.6867          -0.0364            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.75, learning_rate=0.1, score=0.268995, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         151.3252          41.1125            0.05s\n",
      "         2         167.9958           3.5696            0.05s\n",
      "         3         153.3046           0.3679            0.03s\n",
      "         4         117.9798           1.0669            0.03s\n",
      "         5         110.2722          -0.0815            0.04s\n",
      "         6          90.0852           1.0381            0.04s\n",
      "         7          71.3803          11.8296            0.03s\n",
      "         8          72.6838           0.8961            0.03s\n",
      "         9          42.6973           2.0138            0.03s\n",
      "        10          48.3787          -1.9061            0.03s\n",
      "        20          22.7478          -1.9083            0.02s\n",
      "        30          11.6458          -1.6155            0.01s\n",
      "        40           6.9165          -0.5915            0.00s\n",
      "        50           4.9428           0.0119            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.75, learning_rate=0.1, score=0.708940, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         236.5202          -6.5556            0.05s\n",
      "         2         206.0829           2.4892            0.05s\n",
      "         3         161.6424           0.3191            0.03s\n",
      "         4         147.4986           3.0073            0.03s\n",
      "         5          95.8493           3.2118            0.04s\n",
      "         6          96.7498          21.3187            0.04s\n",
      "         7          95.6117          -0.1053            0.04s\n",
      "         8          80.3913           7.6684            0.04s\n",
      "         9          81.4958           1.1355            0.04s\n",
      "        10          67.3661           6.5160            0.03s\n",
      "        20          29.8975           0.0603            0.02s\n",
      "        30          10.9573           0.1072            0.01s\n",
      "        40           7.1681          -0.2610            0.00s\n",
      "        50           3.6195          -0.3069            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.8, learning_rate=0.1, score=-0.264058, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         237.7680          -7.4811            0.05s\n",
      "         2         208.4878           1.3715            0.02s\n",
      "         3         161.8860          -0.0891            0.03s\n",
      "         4         144.6101           2.8569            0.02s\n",
      "         5          92.2313          -1.3031            0.03s\n",
      "         6          93.7766          19.0260            0.02s\n",
      "         7          93.8149           1.3667            0.02s\n",
      "         8          79.4476          12.0193            0.03s\n",
      "         9          78.8401           1.9034            0.02s\n",
      "        10          65.9160          -1.2967            0.02s\n",
      "        20          31.2080          -0.1639            0.01s\n",
      "        30          12.1865          -0.7915            0.01s\n",
      "        40           7.0650           0.0128            0.00s\n",
      "        50           3.8679          -0.4162            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.8, learning_rate=0.1, score=-0.494783, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         236.4401          -6.6425            0.05s\n",
      "         2         205.5058           1.6582            0.02s\n",
      "         3         161.2724          -1.6024            0.03s\n",
      "         4         143.9889           2.2850            0.02s\n",
      "         5          89.0190           4.2659            0.03s\n",
      "         6          95.0057          20.6741            0.03s\n",
      "         7          93.6789           3.6990            0.02s\n",
      "         8          74.9801          11.2001            0.03s\n",
      "         9          77.8527          -0.0749            0.02s\n",
      "        10          64.1170          -1.1040            0.02s\n",
      "        20          29.3921           0.3342            0.01s\n",
      "        30          10.0306          -0.7254            0.01s\n",
      "        40           7.4300          -0.0728            0.00s\n",
      "        50           3.9377          -0.3611            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.8, learning_rate=0.1, score=0.017249, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         230.3734           1.1228            0.05s\n",
      "         2         198.0328           1.6821            0.05s\n",
      "         3         154.5906          -2.4774            0.03s\n",
      "         4         141.3734          -0.2815            0.03s\n",
      "         5          88.0733           1.2910            0.04s\n",
      "         6          92.0782          18.8025            0.04s\n",
      "         7          95.0809           1.6771            0.04s\n",
      "         8          70.1894           8.0632            0.03s\n",
      "         9          73.8739           2.7558            0.03s\n",
      "        10          57.9961           0.0827            0.03s\n",
      "        20          26.7782          -2.2641            0.02s\n",
      "        30           9.4275          -0.6672            0.01s\n",
      "        40           6.7577          -0.0043            0.00s\n",
      "        50           3.5351          -0.0092            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.8, learning_rate=0.1, score=-0.104588, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         182.1397          -1.9354            0.05s\n",
      "         2         157.5296          -0.0847            0.05s\n",
      "         3         126.0536          -1.6761            0.03s\n",
      "         4         112.6346           0.3971            0.03s\n",
      "         5          55.9613           4.0620            0.03s\n",
      "         6          82.9701          -5.1848            0.03s\n",
      "         7          73.1678          -3.5716            0.03s\n",
      "         8          62.6832          -4.1683            0.03s\n",
      "         9          66.0019          -1.9104            0.03s\n",
      "        10          49.3426           0.1143            0.03s\n",
      "        20          22.4788           0.6244            0.01s\n",
      "        30          10.1968           0.1914            0.01s\n",
      "        40           6.0474          -0.1280            0.00s\n",
      "        50           2.9843          -0.0751            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.8, learning_rate=0.1, score=-0.645438, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         187.9873          41.7830            0.05s\n",
      "         2         171.9537          37.4702            0.05s\n",
      "         3         161.0043          -1.7492            0.05s\n",
      "         4         132.5319          -0.4276            0.03s\n",
      "         5          83.7036           3.4274            0.04s\n",
      "         6         108.0456          -1.5220            0.04s\n",
      "         7          84.8802          10.2830            0.03s\n",
      "         8          82.6213           0.3530            0.03s\n",
      "         9          70.1084          -1.6202            0.03s\n",
      "        10          64.2965           7.8351            0.03s\n",
      "        20          27.9639           0.7302            0.01s\n",
      "        30          12.1517          -0.3748            0.01s\n",
      "        40           6.6993          -0.2320            0.00s\n",
      "        50           3.8244          -0.2816            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.8, learning_rate=0.1, score=-1.952226, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         118.4191           7.2077            0.00s\n",
      "         2         111.4162          34.7246            0.02s\n",
      "         3         128.4961          -1.2471            0.03s\n",
      "         4         101.9903           0.0780            0.02s\n",
      "         5          90.5179          -0.2382            0.03s\n",
      "         6          84.1471          -0.9777            0.02s\n",
      "         7          55.0324          10.6068            0.02s\n",
      "         8          67.7334          -0.3540            0.02s\n",
      "         9          55.3630           1.6033            0.02s\n",
      "        10          49.1757          -0.2559            0.02s\n",
      "        20          21.8009          -0.2318            0.01s\n",
      "        30          11.1556          -0.1374            0.01s\n",
      "        40           5.0889          -0.0484            0.00s\n",
      "        50           3.3043          -0.1897            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.8, learning_rate=0.1, score=0.167163, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         193.2021          53.5973            0.05s\n",
      "         2         171.7450          37.9446            0.07s\n",
      "         3         167.3416           0.6678            0.06s\n",
      "         4         131.5012           2.9652            0.06s\n",
      "         5          86.9403           2.2613            0.06s\n",
      "         6         113.4580          -3.5376            0.06s\n",
      "         7          88.0329          16.0978            0.05s\n",
      "         8          86.4696          -0.7687            0.05s\n",
      "         9          52.3169           3.3993            0.05s\n",
      "        10          65.2144           8.5409            0.04s\n",
      "        20          29.6667          -0.3534            0.02s\n",
      "        30          13.2457          -1.3142            0.01s\n",
      "        40           6.8857          -0.3391            0.01s\n",
      "        50           4.1882          -0.3036            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.8, learning_rate=0.1, score=-3.618679, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         136.6496          95.9320            0.05s\n",
      "         2         180.2674          -2.4761            0.07s\n",
      "         3         132.6954          29.7444            0.06s\n",
      "         4         113.7503           0.7629            0.06s\n",
      "         5         110.0132           0.1133            0.05s\n",
      "         6          91.4702          -0.3071            0.04s\n",
      "         7          70.0900          15.0178            0.04s\n",
      "         8          68.4053           1.2771            0.04s\n",
      "         9          58.6432          -0.7747            0.04s\n",
      "        10          47.6259           2.3104            0.03s\n",
      "        20          22.4320          -0.8196            0.02s\n",
      "        30          11.1800          -1.4659            0.01s\n",
      "        40           5.1423          -0.2741            0.01s\n",
      "        50           3.8472          -0.1251            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.8, learning_rate=0.1, score=0.274709, total=   0.0s\n",
      "[CV] n_estimators=50, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         146.7422          53.3235            0.00s\n",
      "         2         161.7998          -4.6665            0.02s\n",
      "         3         145.2594           0.4953            0.02s\n",
      "         4         112.4802           0.5597            0.02s\n",
      "         5         108.4693          -0.3235            0.02s\n",
      "         6          84.3720           2.2330            0.02s\n",
      "         7          69.9517          15.9506            0.02s\n",
      "         8          68.6523          -0.9784            0.02s\n",
      "         9          58.5079          -5.0482            0.02s\n",
      "        10          47.8218          -1.6201            0.02s\n",
      "        20          23.9498          -0.6134            0.01s\n",
      "        30          11.5019          -0.2085            0.01s\n",
      "        40           5.3056          -0.6555            0.00s\n",
      "        50           3.5691          -0.1247            0.00s\n",
      "[CV]  n_estimators=50, subsample=0.8, learning_rate=0.1, score=0.748059, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         262.8658          -2.9054            0.06s\n",
      "         2         220.9964           4.0227            0.03s\n",
      "         3         175.4706          -0.2296            0.04s\n",
      "         4         155.9681           2.3634            0.03s\n",
      "         5          93.0879           1.1133            0.03s\n",
      "         6          73.2691          17.2805            0.03s\n",
      "         7         106.9451           0.6327            0.03s\n",
      "         8          90.4306           6.0374            0.03s\n",
      "         9          90.6089           0.5271            0.03s\n",
      "        10          61.4069           6.2804            0.03s\n",
      "        20          27.3549          -2.3446            0.02s\n",
      "        30          13.3452          -0.3527            0.01s\n",
      "        40          10.7186          -0.6676            0.01s\n",
      "        50           5.4114          -0.0995            0.00s\n",
      "        60           2.6889          -0.2712            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.7, learning_rate=0.1, score=-0.248264, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         264.5848          -3.7668            0.06s\n",
      "         2         222.3572          -1.0804            0.03s\n",
      "         3         178.0437          -0.3488            0.04s\n",
      "         4         153.9776           2.2977            0.04s\n",
      "         5          89.1182           1.1180            0.03s\n",
      "         6          70.7960          15.3296            0.04s\n",
      "         7         106.9559           3.3278            0.03s\n",
      "         8          90.7802           9.7359            0.03s\n",
      "         9          88.9477           1.8940            0.03s\n",
      "        10          61.5709           0.9214            0.03s\n",
      "        20          28.5320          -0.6776            0.02s\n",
      "        30          13.5926          -0.4935            0.01s\n",
      "        40           8.5681          -0.8864            0.01s\n",
      "        50           4.4795          -0.2587            0.00s\n",
      "        60           2.3636          -0.5981            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.7, learning_rate=0.1, score=-1.552673, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         262.8065          -2.4396            0.06s\n",
      "         2         218.9041           3.7570            0.03s\n",
      "         3         174.2150          -1.5867            0.04s\n",
      "         4         153.3974           0.4726            0.03s\n",
      "         5          87.8555           1.7901            0.03s\n",
      "         6          71.5664           9.2502            0.03s\n",
      "         7         108.5677           3.3918            0.03s\n",
      "         8          86.8464           9.0799            0.03s\n",
      "         9          89.7808           1.5033            0.03s\n",
      "        10          60.7715          -1.1748            0.03s\n",
      "        20          30.1439          -4.5142            0.02s\n",
      "        30          13.0760          -0.6942            0.01s\n",
      "        40           9.3088          -0.7189            0.01s\n",
      "        50           4.9462          -0.3992            0.00s\n",
      "        60           2.1532          -0.5493            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.7, learning_rate=0.1, score=-0.144130, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         256.1238          -0.3836            0.00s\n",
      "         2         211.7803           2.6240            0.03s\n",
      "         3         169.0250           0.0708            0.04s\n",
      "         4         148.4681           0.5472            0.04s\n",
      "         5          87.5807           0.3824            0.03s\n",
      "         6          64.5821           4.7040            0.04s\n",
      "         7         107.5384           2.2573            0.04s\n",
      "         8          78.2253           8.2995            0.04s\n",
      "         9          84.3936           2.3927            0.03s\n",
      "        10          57.3567          -0.9504            0.03s\n",
      "        20          26.6672          -2.7083            0.02s\n",
      "        30          13.1692          -0.8021            0.02s\n",
      "        40           8.9818          -0.1215            0.01s\n",
      "        50           4.5713          -0.2173            0.00s\n",
      "        60           1.8095          -0.2416            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.7, learning_rate=0.1, score=0.125152, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         198.0329          -0.0243            0.06s\n",
      "         2         161.7336           3.4997            0.06s\n",
      "         3         137.5545          -0.1031            0.06s\n",
      "         4         111.2589           1.4515            0.04s\n",
      "         5          54.1124           0.7492            0.04s\n",
      "         6          58.8313           5.8361            0.04s\n",
      "         7          83.1991          -0.5532            0.04s\n",
      "         8          73.7525          -1.5827            0.03s\n",
      "         9          70.2469          -0.0856            0.03s\n",
      "        10          53.4014          -1.4817            0.03s\n",
      "        20          21.7508           0.3439            0.02s\n",
      "        30          11.1034          -0.1016            0.01s\n",
      "        40           5.6875          -0.1346            0.01s\n",
      "        50           4.4160          -0.0298            0.00s\n",
      "        60           1.9120          -0.1330            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.7, learning_rate=0.1, score=-0.599454, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         204.1237          30.8578            0.06s\n",
      "         2         176.2616          28.1649            0.06s\n",
      "         3         174.6204           2.2035            0.06s\n",
      "         4         132.3285           0.3386            0.06s\n",
      "         5          87.6627           0.8449            0.05s\n",
      "         6          86.9300          -2.1871            0.04s\n",
      "         7          85.0056          11.4036            0.05s\n",
      "         8          92.4498          -0.4039            0.04s\n",
      "         9          77.0537          -0.0198            0.04s\n",
      "        10          69.9551           6.5173            0.03s\n",
      "        20          30.4621          -1.8251            0.02s\n",
      "        30          17.7524           0.2619            0.01s\n",
      "        40           9.5849          -0.2988            0.01s\n",
      "        50           4.2173          -0.2147            0.00s\n",
      "        60           2.3130          -0.1748            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.7, learning_rate=0.1, score=-0.484164, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         123.7072           1.5255            0.06s\n",
      "         2         107.3706          28.2098            0.06s\n",
      "         3         139.4616           0.7118            0.04s\n",
      "         4         101.6939           1.9011            0.04s\n",
      "         5          94.7211          -1.5840            0.04s\n",
      "         6          95.5368           0.9291            0.04s\n",
      "         7          46.8264           8.6758            0.04s\n",
      "         8          75.9240          -0.4583            0.04s\n",
      "         9          60.5617           1.5385            0.03s\n",
      "        10          52.8697          -0.9924            0.03s\n",
      "        20          24.8743           0.2826            0.02s\n",
      "        30          14.0894           0.0077            0.01s\n",
      "        40           7.1751          -0.5242            0.01s\n",
      "        50           3.6592          -0.1535            0.00s\n",
      "        60           2.4073          -0.2283            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.7, learning_rate=0.1, score=0.205710, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         208.0202          30.0677            0.06s\n",
      "         2         175.4719          25.9461            0.09s\n",
      "         3         183.9487           0.2350            0.08s\n",
      "         4         140.4071           2.5427            0.08s\n",
      "         5          88.6856           0.3884            0.08s\n",
      "         6         124.3057           0.2204            0.07s\n",
      "         7          78.6821          12.0933            0.08s\n",
      "         8          89.8906          -2.7397            0.08s\n",
      "         9          57.7148           0.5756            0.07s\n",
      "        10          68.9297           4.1508            0.07s\n",
      "        20          31.8865           0.3512            0.03s\n",
      "        30          14.8773          -2.0780            0.02s\n",
      "        40           8.4074           0.1711            0.01s\n",
      "        50           3.8872          -0.3233            0.01s\n",
      "        60           2.3021          -0.0918            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.7, learning_rate=0.1, score=-5.049459, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         144.2561          67.0223            0.06s\n",
      "         2         187.6820          -3.7931            0.06s\n",
      "         3         144.9588          21.1933            0.06s\n",
      "         4         107.1331          13.7385            0.06s\n",
      "         5         120.0382           0.9391            0.05s\n",
      "         6         101.0801          -0.3243            0.05s\n",
      "         7          74.4217           8.9459            0.05s\n",
      "         8          72.5340           0.9129            0.05s\n",
      "         9          47.2228          -0.9725            0.04s\n",
      "        10          54.3601           0.3420            0.04s\n",
      "        20          24.1906           0.1054            0.03s\n",
      "        30          13.3715          -1.8196            0.02s\n",
      "        40           5.8459          -0.0281            0.01s\n",
      "        50           3.8378          -0.3121            0.01s\n",
      "        60           2.0764          -0.1366            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.7, learning_rate=0.1, score=0.261881, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         152.3957          34.5125            0.00s\n",
      "         2         166.4078          -6.6912            0.03s\n",
      "         3         160.8578           1.3137            0.02s\n",
      "         4         123.6751           0.6482            0.03s\n",
      "         5         116.3182           0.9625            0.02s\n",
      "         6          94.8785           1.5927            0.03s\n",
      "         7          73.5657           7.7550            0.03s\n",
      "         8          75.5867          -0.2429            0.03s\n",
      "         9          44.8079           3.5097            0.03s\n",
      "        10          52.9112          -2.0431            0.03s\n",
      "        20          22.5081          -0.8693            0.02s\n",
      "        30          13.8569          -1.3059            0.01s\n",
      "        40           8.3869          -0.4379            0.01s\n",
      "        50           5.4156          -0.2633            0.00s\n",
      "        60           2.8133          -0.1942            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.7, learning_rate=0.1, score=0.698547, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         244.9091          -4.7851            0.06s\n",
      "         2         204.8047           1.7528            0.06s\n",
      "         3         165.3122          -0.7743            0.06s\n",
      "         4         150.0433           2.3150            0.04s\n",
      "         5          94.9605           4.1643            0.04s\n",
      "         6         100.9927          17.7065            0.05s\n",
      "         7          99.5158           0.1175            0.04s\n",
      "         8          82.8676           4.2680            0.04s\n",
      "         9          85.1565           0.8391            0.03s\n",
      "        10          69.0982           1.0308            0.04s\n",
      "        20          30.0836          -0.4102            0.02s\n",
      "        30          13.6969          -0.0936            0.01s\n",
      "        40           8.6332          -0.8593            0.01s\n",
      "        50           5.2889          -0.3394            0.00s\n",
      "        60           2.5368          -0.0959            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.75, learning_rate=0.1, score=0.097216, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         246.5297          -6.1481            0.06s\n",
      "         2         206.5334          -0.4408            0.03s\n",
      "         3         166.6904          -1.0804            0.04s\n",
      "         4         146.5628           3.5243            0.04s\n",
      "         5          88.8836           0.3732            0.04s\n",
      "         6          97.6289          15.4687            0.05s\n",
      "         7          97.8836          -3.5274            0.05s\n",
      "         8          82.9149          10.8805            0.04s\n",
      "         9          83.8288           3.1215            0.04s\n",
      "        10          69.5891          -1.3278            0.03s\n",
      "        20          32.2921          -0.0855            0.02s\n",
      "        30          13.7299          -0.4531            0.01s\n",
      "        40           8.8591           0.0329            0.01s\n",
      "        50           4.4111          -0.3667            0.00s\n",
      "        60           2.2717          -0.2322            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.75, learning_rate=0.1, score=-1.019561, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         247.6843          -5.9155            0.06s\n",
      "         2         206.6658           4.6904            0.03s\n",
      "         3         164.5391          -1.8892            0.04s\n",
      "         4         146.6786           4.5077            0.03s\n",
      "         5          88.9411           8.2152            0.03s\n",
      "         6          99.9737          13.6023            0.03s\n",
      "         7          99.8886           2.9253            0.03s\n",
      "         8          79.0966          10.5812            0.03s\n",
      "         9          81.2340           0.7805            0.03s\n",
      "        10          66.3535          -0.5691            0.03s\n",
      "        20          32.7656          -0.1217            0.02s\n",
      "        30          10.5839          -0.7432            0.01s\n",
      "        40           7.2422          -0.0295            0.01s\n",
      "        50           4.0204          -0.0575            0.00s\n",
      "        60           1.8403          -0.5365            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.75, learning_rate=0.1, score=-0.129632, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         241.3760           0.1692            0.06s\n",
      "         2         198.1967           2.7898            0.06s\n",
      "         3         159.3101          -0.7978            0.06s\n",
      "         4         143.5937           1.5462            0.06s\n",
      "         5          87.5214           1.9932            0.05s\n",
      "         6          96.7593          15.7438            0.05s\n",
      "         7          99.8412          -1.0981            0.06s\n",
      "         8          72.9228           8.1512            0.06s\n",
      "         9          79.8875           2.0719            0.05s\n",
      "        10          63.0211           5.0942            0.05s\n",
      "        20          28.8266          -0.2679            0.03s\n",
      "        30           9.9541          -0.6890            0.02s\n",
      "        40           7.6987          -0.0051            0.01s\n",
      "        50           3.7230           0.0512            0.00s\n",
      "        60           1.3225          -0.1323            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.75, learning_rate=0.1, score=-0.083967, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         186.3867          -1.1701            0.06s\n",
      "         2         154.0178           3.8243            0.06s\n",
      "         3         129.5736          -0.5592            0.04s\n",
      "         4         112.2960          -0.7840            0.04s\n",
      "         5          54.4220           7.8209            0.03s\n",
      "         6          87.8630          -1.8935            0.04s\n",
      "         7          74.6408          -2.0772            0.03s\n",
      "         8          64.4901          -2.5314            0.03s\n",
      "         9          64.2275          -1.2492            0.03s\n",
      "        10          47.7917          -1.3823            0.03s\n",
      "        20          22.4049           0.0228            0.02s\n",
      "        30          11.6620          -0.1287            0.01s\n",
      "        40           6.1861          -0.1299            0.01s\n",
      "        50           4.3740          -0.0734            0.00s\n",
      "        60           2.1731          -0.2737            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.75, learning_rate=0.1, score=-0.670010, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         190.6566          33.8868            0.06s\n",
      "         2         170.6149          30.9591            0.06s\n",
      "         3         167.5426           0.0545            0.06s\n",
      "         4         132.3537          -1.1084            0.06s\n",
      "         5          85.4612           2.4108            0.04s\n",
      "         6         112.3850          -2.1312            0.04s\n",
      "         7          86.1611           9.0458            0.05s\n",
      "         8          82.7949          -2.9607            0.05s\n",
      "         9          71.8612          -2.3986            0.04s\n",
      "        10          67.1836           5.8593            0.04s\n",
      "        20          30.9319          -0.0504            0.02s\n",
      "        30          14.1479          -0.7589            0.02s\n",
      "        40           7.6120          -0.0206            0.01s\n",
      "        50           3.8695          -0.4833            0.00s\n",
      "        60           2.7551          -0.3473            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.75, learning_rate=0.1, score=-1.302516, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         117.0397           0.1609            0.00s\n",
      "         2         104.4567           4.1667            0.03s\n",
      "         3         139.6583           1.3361            0.04s\n",
      "         4         108.3229          -1.9874            0.04s\n",
      "         5          99.8879          -0.6580            0.04s\n",
      "         6          92.9491          -0.8423            0.04s\n",
      "         7          57.3517           9.7576            0.04s\n",
      "         8          71.2306           0.9487            0.04s\n",
      "         9          57.7076           1.2155            0.03s\n",
      "        10          52.8153           6.2931            0.03s\n",
      "        20          24.1345          -0.0577            0.02s\n",
      "        30          12.5556          -0.2512            0.01s\n",
      "        40           5.1996           0.2031            0.01s\n",
      "        50           2.4617          -0.0543            0.00s\n",
      "        60           1.6969          -0.0651            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.75, learning_rate=0.1, score=0.177781, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         198.0561          43.9576            0.00s\n",
      "         2         172.4489          27.4678            0.03s\n",
      "         3         175.6636           2.2493            0.04s\n",
      "         4         136.1155           1.1267            0.03s\n",
      "         5          91.3650           1.6835            0.03s\n",
      "         6         122.2101          -1.0514            0.03s\n",
      "         7          91.1172          11.7353            0.03s\n",
      "         8          90.9978          -1.4523            0.03s\n",
      "         9          56.7388           0.4585            0.03s\n",
      "        10          68.2205           5.4793            0.03s\n",
      "        20          32.6598           0.6124            0.02s\n",
      "        30          15.1800          -0.8281            0.01s\n",
      "        40           6.9259          -0.4930            0.01s\n",
      "        50           3.1232          -0.1682            0.00s\n",
      "        60           2.0481          -0.1856            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.75, learning_rate=0.1, score=-7.240080, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         142.6835          71.2680            0.06s\n",
      "         2         189.0696           0.9837            0.03s\n",
      "         3         143.4282          22.9831            0.04s\n",
      "         4         122.4720          -0.7270            0.04s\n",
      "         5         119.0424           0.8025            0.03s\n",
      "         6          98.2204           0.2950            0.04s\n",
      "         7          73.7368          12.0137            0.03s\n",
      "         8          70.8693           1.2037            0.03s\n",
      "         9          48.2885          -0.8560            0.03s\n",
      "        10          52.8030           2.8342            0.03s\n",
      "        20          22.3888          -2.5022            0.02s\n",
      "        30          12.5633          -0.2258            0.01s\n",
      "        40           5.3020          -0.5017            0.01s\n",
      "        50           3.6867          -0.0364            0.00s\n",
      "        60           2.0083          -0.1133            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.75, learning_rate=0.1, score=0.294434, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         151.3252          41.1125            0.06s\n",
      "         2         167.9958           3.5696            0.03s\n",
      "         3         153.3046           0.3679            0.04s\n",
      "         4         117.9798           1.0669            0.03s\n",
      "         5         110.2722          -0.0815            0.03s\n",
      "         6          90.0852           1.0381            0.03s\n",
      "         7          71.3803          11.8296            0.03s\n",
      "         8          72.6838           0.8961            0.03s\n",
      "         9          42.6973           2.0138            0.03s\n",
      "        10          48.3787          -1.9061            0.03s\n",
      "        20          22.7478          -1.9083            0.02s\n",
      "        30          11.6458          -1.6155            0.01s\n",
      "        40           6.9165          -0.5915            0.01s\n",
      "        50           4.9428           0.0119            0.00s\n",
      "        60           2.1780          -0.2291            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.75, learning_rate=0.1, score=0.725275, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         236.5202          -6.5556            0.06s\n",
      "         2         206.0829           2.4892            0.03s\n",
      "         3         161.6424           0.3191            0.04s\n",
      "         4         147.4986           3.0073            0.04s\n",
      "         5          95.8493           3.2118            0.03s\n",
      "         6          96.7498          21.3187            0.04s\n",
      "         7          95.6117          -0.1053            0.03s\n",
      "         8          80.3913           7.6684            0.03s\n",
      "         9          81.4958           1.1355            0.03s\n",
      "        10          67.3661           6.5160            0.03s\n",
      "        20          29.8975           0.0603            0.02s\n",
      "        30          10.9573           0.1072            0.01s\n",
      "        40           7.1681          -0.2610            0.01s\n",
      "        50           3.6195          -0.3069            0.00s\n",
      "        60           1.6530          -0.3201            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.8, learning_rate=0.1, score=-0.369715, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         237.7680          -7.4811            0.06s\n",
      "         2         208.4878           1.3715            0.06s\n",
      "         3         161.8860          -0.0891            0.06s\n",
      "         4         144.6101           2.8569            0.04s\n",
      "         5          92.2313          -1.3031            0.04s\n",
      "         6          93.7766          19.0260            0.04s\n",
      "         7          93.8149           1.3667            0.04s\n",
      "         8          79.4476          12.0193            0.03s\n",
      "         9          78.8401           1.9034            0.03s\n",
      "        10          65.9160          -1.2967            0.04s\n",
      "        20          31.2080          -0.1639            0.02s\n",
      "        30          12.1865          -0.7915            0.01s\n",
      "        40           7.0650           0.0128            0.01s\n",
      "        50           3.8679          -0.4162            0.00s\n",
      "        60           1.8699          -0.4532            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.8, learning_rate=0.1, score=-0.454436, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         236.4401          -6.6425            0.00s\n",
      "         2         205.5058           1.6582            0.03s\n",
      "         3         161.2724          -1.6024            0.02s\n",
      "         4         143.9889           2.2850            0.03s\n",
      "         5          89.0190           4.2659            0.02s\n",
      "         6          95.0057          20.6741            0.03s\n",
      "         7          93.6789           3.6990            0.02s\n",
      "         8          74.9801          11.2001            0.03s\n",
      "         9          77.8527          -0.0749            0.02s\n",
      "        10          64.1170          -1.1040            0.03s\n",
      "        20          29.3921           0.3342            0.02s\n",
      "        30          10.0306          -0.7254            0.01s\n",
      "        40           7.4300          -0.0728            0.01s\n",
      "        50           3.9377          -0.3611            0.00s\n",
      "        60           2.0240          -0.4218            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.8, learning_rate=0.1, score=0.040784, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         230.3734           1.1228            0.06s\n",
      "         2         198.0328           1.6821            0.06s\n",
      "         3         154.5906          -2.4774            0.04s\n",
      "         4         141.3734          -0.2815            0.04s\n",
      "         5          88.0733           1.2910            0.04s\n",
      "         6          92.0782          18.8025            0.04s\n",
      "         7          95.0809           1.6771            0.04s\n",
      "         8          70.1894           8.0632            0.03s\n",
      "         9          73.8739           2.7558            0.03s\n",
      "        10          57.9961           0.0827            0.03s\n",
      "        20          26.7782          -2.2641            0.02s\n",
      "        30           9.4275          -0.6672            0.01s\n",
      "        40           6.7577          -0.0043            0.01s\n",
      "        50           3.5351          -0.0092            0.00s\n",
      "        60           1.3930          -0.2216            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.8, learning_rate=0.1, score=-0.149516, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         182.1397          -1.9354            0.12s\n",
      "         2         157.5296          -0.0847            0.09s\n",
      "         3         126.0536          -1.6761            0.08s\n",
      "         4         112.6346           0.3971            0.07s\n",
      "         5          55.9613           4.0620            0.06s\n",
      "         6          82.9701          -5.1848            0.05s\n",
      "         7          73.1678          -3.5716            0.05s\n",
      "         8          62.6832          -4.1683            0.05s\n",
      "         9          66.0019          -1.9104            0.04s\n",
      "        10          49.3426           0.1143            0.04s\n",
      "        20          22.4788           0.6244            0.02s\n",
      "        30          10.1968           0.1914            0.01s\n",
      "        40           6.0474          -0.1280            0.01s\n",
      "        50           2.9843          -0.0751            0.00s\n",
      "        60           1.6181          -0.2566            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.8, learning_rate=0.1, score=-0.682601, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         187.9873          41.7830            0.00s\n",
      "         2         171.9537          37.4702            0.03s\n",
      "         3         161.0043          -1.7492            0.02s\n",
      "         4         132.5319          -0.4276            0.03s\n",
      "         5          83.7036           3.4274            0.02s\n",
      "         6         108.0456          -1.5220            0.03s\n",
      "         7          84.8802          10.2830            0.02s\n",
      "         8          82.6213           0.3530            0.03s\n",
      "         9          70.1084          -1.6202            0.03s\n",
      "        10          64.2965           7.8351            0.03s\n",
      "        20          27.9639           0.7302            0.02s\n",
      "        30          12.1517          -0.3748            0.01s\n",
      "        40           6.6993          -0.2320            0.01s\n",
      "        50           3.8244          -0.2816            0.00s\n",
      "        60           2.2081          -0.1196            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.8, learning_rate=0.1, score=-1.761243, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         118.4191           7.2077            0.00s\n",
      "         2         111.4162          34.7246            0.03s\n",
      "         3         128.4961          -1.2471            0.02s\n",
      "         4         101.9903           0.0780            0.03s\n",
      "         5          90.5179          -0.2382            0.02s\n",
      "         6          84.1471          -0.9777            0.03s\n",
      "         7          55.0324          10.6068            0.02s\n",
      "         8          67.7334          -0.3540            0.03s\n",
      "         9          55.3630           1.6033            0.03s\n",
      "        10          49.1757          -0.2559            0.03s\n",
      "        20          21.8009          -0.2318            0.02s\n",
      "        30          11.1556          -0.1374            0.01s\n",
      "        40           5.0889          -0.0484            0.01s\n",
      "        50           3.3043          -0.1897            0.00s\n",
      "        60           1.7803          -0.1126            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.8, learning_rate=0.1, score=0.149646, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         193.2021          53.5973            0.06s\n",
      "         2         171.7450          37.9446            0.03s\n",
      "         3         167.3416           0.6678            0.04s\n",
      "         4         131.5012           2.9652            0.04s\n",
      "         5          86.9403           2.2613            0.03s\n",
      "         6         113.4580          -3.5376            0.04s\n",
      "         7          88.0329          16.0978            0.03s\n",
      "         8          86.4696          -0.7687            0.03s\n",
      "         9          52.3169           3.3993            0.03s\n",
      "        10          65.2144           8.5409            0.03s\n",
      "        20          29.6667          -0.3534            0.02s\n",
      "        30          13.2457          -1.3142            0.01s\n",
      "        40           6.8857          -0.3391            0.01s\n",
      "        50           4.1882          -0.3036            0.00s\n",
      "        60           2.2326          -0.1642            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.8, learning_rate=0.1, score=-3.983151, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         136.6496          95.9320            0.00s\n",
      "         2         180.2674          -2.4761            0.03s\n",
      "         3         132.6954          29.7444            0.02s\n",
      "         4         113.7503           0.7629            0.03s\n",
      "         5         110.0132           0.1133            0.03s\n",
      "         6          91.4702          -0.3071            0.04s\n",
      "         7          70.0900          15.0178            0.03s\n",
      "         8          68.4053           1.2771            0.03s\n",
      "         9          58.6432          -0.7747            0.03s\n",
      "        10          47.6259           2.3104            0.03s\n",
      "        20          22.4320          -0.8196            0.02s\n",
      "        30          11.1800          -1.4659            0.01s\n",
      "        40           5.1423          -0.2741            0.01s\n",
      "        50           3.8472          -0.1251            0.00s\n",
      "        60           2.0987          -0.1041            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.8, learning_rate=0.1, score=0.298665, total=   0.0s\n",
      "[CV] n_estimators=60, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         146.7422          53.3235            0.06s\n",
      "         2         161.7998          -4.6665            0.03s\n",
      "         3         145.2594           0.4953            0.04s\n",
      "         4         112.4802           0.5597            0.03s\n",
      "         5         108.4693          -0.3235            0.03s\n",
      "         6          84.3720           2.2330            0.03s\n",
      "         7          69.9517          15.9506            0.03s\n",
      "         8          68.6523          -0.9784            0.03s\n",
      "         9          58.5079          -5.0482            0.03s\n",
      "        10          47.8218          -1.6201            0.02s\n",
      "        20          23.9498          -0.6134            0.02s\n",
      "        30          11.5019          -0.2085            0.01s\n",
      "        40           5.3056          -0.6555            0.01s\n",
      "        50           3.5691          -0.1247            0.00s\n",
      "        60           1.8081          -0.0877            0.00s\n",
      "[CV]  n_estimators=60, subsample=0.8, learning_rate=0.1, score=0.766298, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         262.8658          -2.9054            0.00s\n",
      "         2         220.9964           4.0227            0.03s\n",
      "         3         175.4706          -0.2296            0.02s\n",
      "         4         155.9681           2.3634            0.03s\n",
      "         5          93.0879           1.1133            0.04s\n",
      "         6          73.2691          17.2805            0.03s\n",
      "         7         106.9451           0.6327            0.04s\n",
      "         8          90.4306           6.0374            0.04s\n",
      "         9          90.6089           0.5271            0.03s\n",
      "        10          61.4069           6.2804            0.04s\n",
      "        20          27.3549          -2.3446            0.02s\n",
      "        30          13.3452          -0.3527            0.02s\n",
      "        40          10.7186          -0.6676            0.01s\n",
      "        50           5.4114          -0.0995            0.01s\n",
      "        60           2.6889          -0.2712            0.00s\n",
      "        70           2.2101          -0.0189            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.7, learning_rate=0.1, score=-0.252317, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         264.5848          -3.7668            0.00s\n",
      "         2         222.3572          -1.0804            0.03s\n",
      "         3         178.0437          -0.3488            0.02s\n",
      "         4         153.9776           2.2977            0.03s\n",
      "         5          89.1182           1.1180            0.03s\n",
      "         6          70.7960          15.3296            0.03s\n",
      "         7         106.9559           3.3278            0.03s\n",
      "         8          90.7802           9.7359            0.03s\n",
      "         9          88.9477           1.8940            0.03s\n",
      "        10          61.5709           0.9214            0.03s\n",
      "        20          28.5320          -0.6776            0.02s\n",
      "        30          13.5926          -0.4935            0.01s\n",
      "        40           8.5681          -0.8864            0.01s\n",
      "        50           4.4795          -0.2587            0.01s\n",
      "        60           2.3636          -0.5981            0.00s\n",
      "        70           1.8063          -0.0357            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.7, learning_rate=0.1, score=-1.768361, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         262.8065          -2.4396            0.00s\n",
      "         2         218.9041           3.7570            0.03s\n",
      "         3         174.2150          -1.5867            0.02s\n",
      "         4         153.3974           0.4726            0.03s\n",
      "         5          87.8555           1.7901            0.04s\n",
      "         6          71.5664           9.2502            0.03s\n",
      "         7         108.5677           3.3918            0.04s\n",
      "         8          86.8464           9.0799            0.04s\n",
      "         9          89.7808           1.5033            0.04s\n",
      "        10          60.7715          -1.1748            0.04s\n",
      "        20          30.1439          -4.5142            0.02s\n",
      "        30          13.0760          -0.6942            0.02s\n",
      "        40           9.3088          -0.7189            0.01s\n",
      "        50           4.9462          -0.3992            0.01s\n",
      "        60           2.1532          -0.5493            0.00s\n",
      "        70           2.0892          -0.1252            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.7, learning_rate=0.1, score=-0.132496, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         256.1238          -0.3836            0.00s\n",
      "         2         211.7803           2.6240            0.03s\n",
      "         3         169.0250           0.0708            0.04s\n",
      "         4         148.4681           0.5472            0.03s\n",
      "         5          87.5807           0.3824            0.04s\n",
      "         6          64.5821           4.7040            0.03s\n",
      "         7         107.5384           2.2573            0.04s\n",
      "         8          78.2253           8.2995            0.03s\n",
      "         9          84.3936           2.3927            0.03s\n",
      "        10          57.3567          -0.9504            0.04s\n",
      "        20          26.6672          -2.7083            0.02s\n",
      "        30          13.1692          -0.8021            0.02s\n",
      "        40           8.9818          -0.1215            0.01s\n",
      "        50           4.5713          -0.2173            0.01s\n",
      "        60           1.8095          -0.2416            0.00s\n",
      "        70           1.4665          -0.0358            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.7, learning_rate=0.1, score=0.137579, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         198.0329          -0.0243            0.00s\n",
      "         2         161.7336           3.4997            0.03s\n",
      "         3         137.5545          -0.1031            0.04s\n",
      "         4         111.2589           1.4515            0.03s\n",
      "         5          54.1124           0.7492            0.04s\n",
      "         6          58.8313           5.8361            0.03s\n",
      "         7          83.1991          -0.5532            0.04s\n",
      "         8          73.7525          -1.5827            0.03s\n",
      "         9          70.2469          -0.0856            0.03s\n",
      "        10          53.4014          -1.4817            0.03s\n",
      "        20          21.7508           0.3439            0.02s\n",
      "        30          11.1034          -0.1016            0.02s\n",
      "        40           5.6875          -0.1346            0.01s\n",
      "        50           4.4160          -0.0298            0.01s\n",
      "        60           1.9120          -0.1330            0.00s\n",
      "        70           1.4304           0.0246            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.7, learning_rate=0.1, score=-0.605792, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         204.1237          30.8578            0.07s\n",
      "         2         176.2616          28.1649            0.03s\n",
      "         3         174.6204           2.2035            0.04s\n",
      "         4         132.3285           0.3386            0.05s\n",
      "         5          87.6627           0.8449            0.04s\n",
      "         6          86.9300          -2.1871            0.04s\n",
      "         7          85.0056          11.4036            0.04s\n",
      "         8          92.4498          -0.4039            0.04s\n",
      "         9          77.0537          -0.0198            0.03s\n",
      "        10          69.9551           6.5173            0.04s\n",
      "        20          30.4621          -1.8251            0.02s\n",
      "        30          17.7524           0.2619            0.02s\n",
      "        40           9.5849          -0.2988            0.01s\n",
      "        50           4.2173          -0.2147            0.01s\n",
      "        60           2.3130          -0.1748            0.00s\n",
      "        70           1.7250          -0.0905            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.7, learning_rate=0.1, score=-0.512459, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         123.7072           1.5255            0.07s\n",
      "         2         107.3706          28.2098            0.03s\n",
      "         3         139.4616           0.7118            0.04s\n",
      "         4         101.6939           1.9011            0.03s\n",
      "         5          94.7211          -1.5840            0.04s\n",
      "         6          95.5368           0.9291            0.03s\n",
      "         7          46.8264           8.6758            0.04s\n",
      "         8          75.9240          -0.4583            0.04s\n",
      "         9          60.5617           1.5385            0.03s\n",
      "        10          52.8697          -0.9924            0.04s\n",
      "        20          24.8743           0.2826            0.02s\n",
      "        30          14.0894           0.0077            0.02s\n",
      "        40           7.1751          -0.5242            0.01s\n",
      "        50           3.6592          -0.1535            0.01s\n",
      "        60           2.4073          -0.2283            0.00s\n",
      "        70           1.5628          -0.0877            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.7, learning_rate=0.1, score=0.205496, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         208.0202          30.0677            0.00s\n",
      "         2         175.4719          25.9461            0.03s\n",
      "         3         183.9487           0.2350            0.02s\n",
      "         4         140.4071           2.5427            0.03s\n",
      "         5          88.6856           0.3884            0.03s\n",
      "         6         124.3057           0.2204            0.03s\n",
      "         7          78.6821          12.0933            0.03s\n",
      "         8          89.8906          -2.7397            0.03s\n",
      "         9          57.7148           0.5756            0.03s\n",
      "        10          68.9297           4.1508            0.03s\n",
      "        20          31.8865           0.3512            0.02s\n",
      "        30          14.8773          -2.0780            0.02s\n",
      "        40           8.4074           0.1711            0.01s\n",
      "        50           3.8872          -0.3233            0.01s\n",
      "        60           2.3021          -0.0918            0.00s\n",
      "        70           1.6735          -0.0649            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.7, learning_rate=0.1, score=-5.153679, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         144.2561          67.0223            0.00s\n",
      "         2         187.6820          -3.7931            0.03s\n",
      "         3         144.9588          21.1933            0.02s\n",
      "         4         107.1331          13.7385            0.03s\n",
      "         5         120.0382           0.9391            0.04s\n",
      "         6         101.0801          -0.3243            0.03s\n",
      "         7          74.4217           8.9459            0.03s\n",
      "         8          72.5340           0.9129            0.03s\n",
      "         9          47.2228          -0.9725            0.03s\n",
      "        10          54.3601           0.3420            0.03s\n",
      "        20          24.1906           0.1054            0.02s\n",
      "        30          13.3715          -1.8196            0.02s\n",
      "        40           5.8459          -0.0281            0.01s\n",
      "        50           3.8378          -0.3121            0.01s\n",
      "        60           2.0764          -0.1366            0.00s\n",
      "        70           1.7798          -0.0225            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.7, learning_rate=0.1, score=0.262989, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         152.3957          34.5125            0.00s\n",
      "         2         166.4078          -6.6912            0.03s\n",
      "         3         160.8578           1.3137            0.04s\n",
      "         4         123.6751           0.6482            0.03s\n",
      "         5         116.3182           0.9625            0.04s\n",
      "         6          94.8785           1.5927            0.03s\n",
      "         7          73.5657           7.7550            0.04s\n",
      "         8          75.5867          -0.2429            0.04s\n",
      "         9          44.8079           3.5097            0.03s\n",
      "        10          52.9112          -2.0431            0.04s\n",
      "        20          22.5081          -0.8693            0.02s\n",
      "        30          13.8569          -1.3059            0.02s\n",
      "        40           8.3869          -0.4379            0.01s\n",
      "        50           5.4156          -0.2633            0.01s\n",
      "        60           2.8133          -0.1942            0.00s\n",
      "        70           2.0319          -0.0381            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.7, learning_rate=0.1, score=0.696971, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         244.9091          -4.7851            0.00s\n",
      "         2         204.8047           1.7528            0.03s\n",
      "         3         165.3122          -0.7743            0.04s\n",
      "         4         150.0433           2.3150            0.03s\n",
      "         5          94.9605           4.1643            0.04s\n",
      "         6         100.9927          17.7065            0.04s\n",
      "         7          99.5158           0.1175            0.04s\n",
      "         8          82.8676           4.2680            0.04s\n",
      "         9          85.1565           0.8391            0.03s\n",
      "        10          69.0982           1.0308            0.04s\n",
      "        20          30.0836          -0.4102            0.02s\n",
      "        30          13.6969          -0.0936            0.02s\n",
      "        40           8.6332          -0.8593            0.01s\n",
      "        50           5.2889          -0.3394            0.01s\n",
      "        60           2.5368          -0.0959            0.00s\n",
      "        70           2.6759          -0.2530            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.75, learning_rate=0.1, score=0.078761, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         246.5297          -6.1481            0.07s\n",
      "         2         206.5334          -0.4408            0.03s\n",
      "         3         166.6904          -1.0804            0.04s\n",
      "         4         146.5628           3.5243            0.05s\n",
      "         5          88.8836           0.3732            0.04s\n",
      "         6          97.6289          15.4687            0.04s\n",
      "         7          97.8836          -3.5274            0.04s\n",
      "         8          82.9149          10.8805            0.04s\n",
      "         9          83.8288           3.1215            0.04s\n",
      "        10          69.5891          -1.3278            0.04s\n",
      "        20          32.2921          -0.0855            0.02s\n",
      "        30          13.7299          -0.4531            0.02s\n",
      "        40           8.8591           0.0329            0.01s\n",
      "        50           4.4111          -0.3667            0.01s\n",
      "        60           2.2717          -0.2322            0.00s\n",
      "        70           1.9045          -0.0337            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.75, learning_rate=0.1, score=-0.983430, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         247.6843          -5.9155            0.00s\n",
      "         2         206.6658           4.6904            0.03s\n",
      "         3         164.5391          -1.8892            0.04s\n",
      "         4         146.6786           4.5077            0.03s\n",
      "         5          88.9411           8.2152            0.04s\n",
      "         6          99.9737          13.6023            0.04s\n",
      "         7          99.8886           2.9253            0.04s\n",
      "         8          79.0966          10.5812            0.04s\n",
      "         9          81.2340           0.7805            0.04s\n",
      "        10          66.3535          -0.5691            0.04s\n",
      "        20          32.7656          -0.1217            0.02s\n",
      "        30          10.5839          -0.7432            0.02s\n",
      "        40           7.2422          -0.0295            0.01s\n",
      "        50           4.0204          -0.0575            0.01s\n",
      "        60           1.8403          -0.5365            0.00s\n",
      "        70           1.8852          -0.0092            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.75, learning_rate=0.1, score=-0.120925, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         241.3760           0.1692            0.07s\n",
      "         2         198.1967           2.7898            0.03s\n",
      "         3         159.3101          -0.7978            0.04s\n",
      "         4         143.5937           1.5462            0.05s\n",
      "         5          87.5214           1.9932            0.04s\n",
      "         6          96.7593          15.7438            0.04s\n",
      "         7          99.8412          -1.0981            0.05s\n",
      "         8          72.9228           8.1512            0.04s\n",
      "         9          79.8875           2.0719            0.04s\n",
      "        10          63.0211           5.0942            0.04s\n",
      "        20          28.8266          -0.2679            0.02s\n",
      "        30           9.9541          -0.6890            0.02s\n",
      "        40           7.6987          -0.0051            0.01s\n",
      "        50           3.7230           0.0512            0.01s\n",
      "        60           1.3225          -0.1323            0.00s\n",
      "        70           1.1714          -0.0116            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.75, learning_rate=0.1, score=-0.107669, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         186.3867          -1.1701            0.00s\n",
      "         2         154.0178           3.8243            0.03s\n",
      "         3         129.5736          -0.5592            0.02s\n",
      "         4         112.2960          -0.7840            0.03s\n",
      "         5          54.4220           7.8209            0.03s\n",
      "         6          87.8630          -1.8935            0.03s\n",
      "         7          74.6408          -2.0772            0.04s\n",
      "         8          64.4901          -2.5314            0.03s\n",
      "         9          64.2275          -1.2492            0.03s\n",
      "        10          47.7917          -1.3823            0.04s\n",
      "        20          22.4049           0.0228            0.02s\n",
      "        30          11.6620          -0.1287            0.02s\n",
      "        40           6.1861          -0.1299            0.01s\n",
      "        50           4.3740          -0.0734            0.01s\n",
      "        60           2.1731          -0.2737            0.00s\n",
      "        70           1.5243          -0.0220            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.75, learning_rate=0.1, score=-0.673417, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         190.6566          33.8868            0.07s\n",
      "         2         170.6149          30.9591            0.03s\n",
      "         3         167.5426           0.0545            0.07s\n",
      "         4         132.3537          -1.1084            0.05s\n",
      "         5          85.4612           2.4108            0.05s\n",
      "         6         112.3850          -2.1312            0.05s\n",
      "         7          86.1611           9.0458            0.04s\n",
      "         8          82.7949          -2.9607            0.05s\n",
      "         9          71.8612          -2.3986            0.04s\n",
      "        10          67.1836           5.8593            0.04s\n",
      "        20          30.9319          -0.0504            0.02s\n",
      "        30          14.1479          -0.7589            0.02s\n",
      "        40           7.6120          -0.0206            0.01s\n",
      "        50           3.8695          -0.4833            0.01s\n",
      "        60           2.7551          -0.3473            0.00s\n",
      "        70           1.8251          -0.1026            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.75, learning_rate=0.1, score=-1.494724, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         117.0397           0.1609            0.07s\n",
      "         2         104.4567           4.1667            0.07s\n",
      "         3         139.6583           1.3361            0.04s\n",
      "         4         108.3229          -1.9874            0.07s\n",
      "         5          99.8879          -0.6580            0.07s\n",
      "         6          92.9491          -0.8423            0.05s\n",
      "         7          57.3517           9.7576            0.05s\n",
      "         8          71.2306           0.9487            0.05s\n",
      "         9          57.7076           1.2155            0.05s\n",
      "        10          52.8153           6.2931            0.05s\n",
      "        20          24.1345          -0.0577            0.03s\n",
      "        30          12.5556          -0.2512            0.02s\n",
      "        40           5.1996           0.2031            0.01s\n",
      "        50           2.4617          -0.0543            0.01s\n",
      "        60           1.6969          -0.0651            0.00s\n",
      "        70           1.1247          -0.0042            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.75, learning_rate=0.1, score=0.172995, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         198.0561          43.9576            0.07s\n",
      "         2         172.4489          27.4678            0.03s\n",
      "         3         175.6636           2.2493            0.04s\n",
      "         4         136.1155           1.1267            0.03s\n",
      "         5          91.3650           1.6835            0.04s\n",
      "         6         122.2101          -1.0514            0.03s\n",
      "         7          91.1172          11.7353            0.04s\n",
      "         8          90.9978          -1.4523            0.04s\n",
      "         9          56.7388           0.4585            0.04s\n",
      "        10          68.2205           5.4793            0.05s\n",
      "        20          32.6598           0.6124            0.03s\n",
      "        30          15.1800          -0.8281            0.02s\n",
      "        40           6.9259          -0.4930            0.01s\n",
      "        50           3.1232          -0.1682            0.01s\n",
      "        60           2.0481          -0.1856            0.00s\n",
      "        70           1.5368          -0.0863            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.75, learning_rate=0.1, score=-7.243290, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         142.6835          71.2680            0.07s\n",
      "         2         189.0696           0.9837            0.03s\n",
      "         3         143.4282          22.9831            0.04s\n",
      "         4         122.4720          -0.7270            0.03s\n",
      "         5         119.0424           0.8025            0.04s\n",
      "         6          98.2204           0.2950            0.03s\n",
      "         7          73.7368          12.0137            0.04s\n",
      "         8          70.8693           1.2037            0.04s\n",
      "         9          48.2885          -0.8560            0.03s\n",
      "        10          52.8030           2.8342            0.04s\n",
      "        20          22.3888          -2.5022            0.02s\n",
      "        30          12.5633          -0.2258            0.02s\n",
      "        40           5.3020          -0.5017            0.01s\n",
      "        50           3.6867          -0.0364            0.01s\n",
      "        60           2.0083          -0.1133            0.00s\n",
      "        70           1.4393          -0.0710            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.75, learning_rate=0.1, score=0.293749, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         151.3252          41.1125            0.07s\n",
      "         2         167.9958           3.5696            0.03s\n",
      "         3         153.3046           0.3679            0.04s\n",
      "         4         117.9798           1.0669            0.03s\n",
      "         5         110.2722          -0.0815            0.04s\n",
      "         6          90.0852           1.0381            0.04s\n",
      "         7          71.3803          11.8296            0.04s\n",
      "         8          72.6838           0.8961            0.04s\n",
      "         9          42.6973           2.0138            0.03s\n",
      "        10          48.3787          -1.9061            0.04s\n",
      "        20          22.7478          -1.9083            0.02s\n",
      "        30          11.6458          -1.6155            0.02s\n",
      "        40           6.9165          -0.5915            0.01s\n",
      "        50           4.9428           0.0119            0.01s\n",
      "        60           2.1780          -0.2291            0.00s\n",
      "        70           1.7922          -0.0271            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.75, learning_rate=0.1, score=0.731312, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         236.5202          -6.5556            0.07s\n",
      "         2         206.0829           2.4892            0.07s\n",
      "         3         161.6424           0.3191            0.07s\n",
      "         4         147.4986           3.0073            0.05s\n",
      "         5          95.8493           3.2118            0.05s\n",
      "         6          96.7498          21.3187            0.05s\n",
      "         7          95.6117          -0.1053            0.04s\n",
      "         8          80.3913           7.6684            0.05s\n",
      "         9          81.4958           1.1355            0.04s\n",
      "        10          67.3661           6.5160            0.04s\n",
      "        20          29.8975           0.0603            0.02s\n",
      "        30          10.9573           0.1072            0.02s\n",
      "        40           7.1681          -0.2610            0.01s\n",
      "        50           3.6195          -0.3069            0.01s\n",
      "        60           1.6530          -0.3201            0.00s\n",
      "        70           1.3471          -0.0463            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.8, learning_rate=0.1, score=-0.529147, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         237.7680          -7.4811            0.00s\n",
      "         2         208.4878           1.3715            0.03s\n",
      "         3         161.8860          -0.0891            0.02s\n",
      "         4         144.6101           2.8569            0.03s\n",
      "         5          92.2313          -1.3031            0.03s\n",
      "         6          93.7766          19.0260            0.03s\n",
      "         7          93.8149           1.3667            0.04s\n",
      "         8          79.4476          12.0193            0.03s\n",
      "         9          78.8401           1.9034            0.03s\n",
      "        10          65.9160          -1.2967            0.04s\n",
      "        20          31.2080          -0.1639            0.02s\n",
      "        30          12.1865          -0.7915            0.02s\n",
      "        40           7.0650           0.0128            0.01s\n",
      "        50           3.8679          -0.4162            0.01s\n",
      "        60           1.8699          -0.4532            0.00s\n",
      "        70           1.5845          -0.0690            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.8, learning_rate=0.1, score=-0.524257, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         236.4401          -6.6425            0.07s\n",
      "         2         205.5058           1.6582            0.03s\n",
      "         3         161.2724          -1.6024            0.04s\n",
      "         4         143.9889           2.2850            0.05s\n",
      "         5          89.0190           4.2659            0.04s\n",
      "         6          95.0057          20.6741            0.04s\n",
      "         7          93.6789           3.6990            0.05s\n",
      "         8          74.9801          11.2001            0.04s\n",
      "         9          77.8527          -0.0749            0.04s\n",
      "        10          64.1170          -1.1040            0.04s\n",
      "        20          29.3921           0.3342            0.02s\n",
      "        30          10.0306          -0.7254            0.02s\n",
      "        40           7.4300          -0.0728            0.01s\n",
      "        50           3.9377          -0.3611            0.01s\n",
      "        60           2.0240          -0.4218            0.00s\n",
      "        70           1.7748          -0.0333            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.8, learning_rate=0.1, score=0.011782, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         230.3734           1.1228            0.00s\n",
      "         2         198.0328           1.6821            0.03s\n",
      "         3         154.5906          -2.4774            0.02s\n",
      "         4         141.3734          -0.2815            0.03s\n",
      "         5          88.0733           1.2910            0.03s\n",
      "         6          92.0782          18.8025            0.03s\n",
      "         7          95.0809           1.6771            0.04s\n",
      "         8          70.1894           8.0632            0.04s\n",
      "         9          73.8739           2.7558            0.04s\n",
      "        10          57.9961           0.0827            0.04s\n",
      "        20          26.7782          -2.2641            0.02s\n",
      "        30           9.4275          -0.6672            0.02s\n",
      "        40           6.7577          -0.0043            0.01s\n",
      "        50           3.5351          -0.0092            0.01s\n",
      "        60           1.3930          -0.2216            0.00s\n",
      "        70           0.9987           0.0212            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.8, learning_rate=0.1, score=-0.141017, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         182.1397          -1.9354            0.07s\n",
      "         2         157.5296          -0.0847            0.03s\n",
      "         3         126.0536          -1.6761            0.04s\n",
      "         4         112.6346           0.3971            0.05s\n",
      "         5          55.9613           4.0620            0.04s\n",
      "         6          82.9701          -5.1848            0.04s\n",
      "         7          73.1678          -3.5716            0.04s\n",
      "         8          62.6832          -4.1683            0.04s\n",
      "         9          66.0019          -1.9104            0.03s\n",
      "        10          49.3426           0.1143            0.04s\n",
      "        20          22.4788           0.6244            0.02s\n",
      "        30          10.1968           0.1914            0.02s\n",
      "        40           6.0474          -0.1280            0.01s\n",
      "        50           2.9843          -0.0751            0.01s\n",
      "        60           1.6181          -0.2566            0.00s\n",
      "        70           1.0421          -0.0097            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.8, learning_rate=0.1, score=-0.693960, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         187.9873          41.7830            0.07s\n",
      "         2         171.9537          37.4702            0.07s\n",
      "         3         161.0043          -1.7492            0.04s\n",
      "         4         132.5319          -0.4276            0.05s\n",
      "         5          83.7036           3.4274            0.05s\n",
      "         6         108.0456          -1.5220            0.05s\n",
      "         7          84.8802          10.2830            0.05s\n",
      "         8          82.6213           0.3530            0.05s\n",
      "         9          70.1084          -1.6202            0.05s\n",
      "        10          64.2965           7.8351            0.05s\n",
      "        20          27.9639           0.7302            0.03s\n",
      "        30          12.1517          -0.3748            0.02s\n",
      "        40           6.6993          -0.2320            0.01s\n",
      "        50           3.8244          -0.2816            0.01s\n",
      "        60           2.2081          -0.1196            0.00s\n",
      "        70           1.4550          -0.0662            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.8, learning_rate=0.1, score=-1.635635, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         118.4191           7.2077            0.07s\n",
      "         2         111.4162          34.7246            0.07s\n",
      "         3         128.4961          -1.2471            0.04s\n",
      "         4         101.9903           0.0780            0.05s\n",
      "         5          90.5179          -0.2382            0.04s\n",
      "         6          84.1471          -0.9777            0.04s\n",
      "         7          55.0324          10.6068            0.04s\n",
      "         8          67.7334          -0.3540            0.04s\n",
      "         9          55.3630           1.6033            0.04s\n",
      "        10          49.1757          -0.2559            0.04s\n",
      "        20          21.8009          -0.2318            0.02s\n",
      "        30          11.1556          -0.1374            0.02s\n",
      "        40           5.0889          -0.0484            0.01s\n",
      "        50           3.3043          -0.1897            0.01s\n",
      "        60           1.7803          -0.1126            0.00s\n",
      "        70           1.0669          -0.0406            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.8, learning_rate=0.1, score=0.145525, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         193.2021          53.5973            0.00s\n",
      "         2         171.7450          37.9446            0.03s\n",
      "         3         167.3416           0.6678            0.02s\n",
      "         4         131.5012           2.9652            0.03s\n",
      "         5          86.9403           2.2613            0.03s\n",
      "         6         113.4580          -3.5376            0.03s\n",
      "         7          88.0329          16.0978            0.03s\n",
      "         8          86.4696          -0.7687            0.03s\n",
      "         9          52.3169           3.3993            0.03s\n",
      "        10          65.2144           8.5409            0.03s\n",
      "        20          29.6667          -0.3534            0.02s\n",
      "        30          13.2457          -1.3142            0.02s\n",
      "        40           6.8857          -0.3391            0.01s\n",
      "        50           4.1882          -0.3036            0.01s\n",
      "        60           2.2326          -0.1642            0.00s\n",
      "        70           1.3692          -0.0830            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.8, learning_rate=0.1, score=-4.124843, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         136.6496          95.9320            0.07s\n",
      "         2         180.2674          -2.4761            0.07s\n",
      "         3         132.6954          29.7444            0.04s\n",
      "         4         113.7503           0.7629            0.05s\n",
      "         5         110.0132           0.1133            0.04s\n",
      "         6          91.4702          -0.3071            0.04s\n",
      "         7          70.0900          15.0178            0.04s\n",
      "         8          68.4053           1.2771            0.04s\n",
      "         9          58.6432          -0.7747            0.04s\n",
      "        10          47.6259           2.3104            0.04s\n",
      "        20          22.4320          -0.8196            0.02s\n",
      "        30          11.1800          -1.4659            0.02s\n",
      "        40           5.1423          -0.2741            0.01s\n",
      "        50           3.8472          -0.1251            0.01s\n",
      "        60           2.0987          -0.1041            0.00s\n",
      "        70           1.4384          -0.0481            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.8, learning_rate=0.1, score=0.304793, total=   0.0s\n",
      "[CV] n_estimators=70, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         146.7422          53.3235            0.00s\n",
      "         2         161.7998          -4.6665            0.03s\n",
      "         3         145.2594           0.4953            0.02s\n",
      "         4         112.4802           0.5597            0.03s\n",
      "         5         108.4693          -0.3235            0.04s\n",
      "         6          84.3720           2.2330            0.04s\n",
      "         7          69.9517          15.9506            0.05s\n",
      "         8          68.6523          -0.9784            0.05s\n",
      "         9          58.5079          -5.0482            0.05s\n",
      "        10          47.8218          -1.6201            0.04s\n",
      "        20          23.9498          -0.6134            0.02s\n",
      "        30          11.5019          -0.2085            0.02s\n",
      "        40           5.3056          -0.6555            0.01s\n",
      "        50           3.5691          -0.1247            0.01s\n",
      "        60           1.8081          -0.0877            0.00s\n",
      "        70           1.2804          -0.0736            0.00s\n",
      "[CV]  n_estimators=70, subsample=0.8, learning_rate=0.1, score=0.767126, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         262.8658          -2.9054            0.00s\n",
      "         2         220.9964           4.0227            0.04s\n",
      "         3         175.4706          -0.2296            0.05s\n",
      "         4         155.9681           2.3634            0.04s\n",
      "         5          93.0879           1.1133            0.05s\n",
      "         6          73.2691          17.2805            0.05s\n",
      "         7         106.9451           0.6327            0.05s\n",
      "         8          90.4306           6.0374            0.05s\n",
      "         9          90.6089           0.5271            0.06s\n",
      "        10          61.4069           6.2804            0.06s\n",
      "        20          27.3549          -2.3446            0.04s\n",
      "        30          13.3452          -0.3527            0.03s\n",
      "        40          10.7186          -0.6676            0.02s\n",
      "        50           5.4114          -0.0995            0.01s\n",
      "        60           2.6889          -0.2712            0.01s\n",
      "        70           2.2101          -0.0189            0.00s\n",
      "        80           1.2239          -0.1190            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.7, learning_rate=0.1, score=-0.293767, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         264.5848          -3.7668            0.08s\n",
      "         2         222.3572          -1.0804            0.08s\n",
      "         3         178.0437          -0.3488            0.05s\n",
      "         4         153.9776           2.2977            0.06s\n",
      "         5          89.1182           1.1180            0.04s\n",
      "         6          70.7960          15.3296            0.05s\n",
      "         7         106.9559           3.3278            0.05s\n",
      "         8          90.7802           9.7359            0.05s\n",
      "         9          88.9477           1.8940            0.05s\n",
      "        10          61.5709           0.9214            0.05s\n",
      "        20          28.5320          -0.6776            0.03s\n",
      "        30          13.5926          -0.4935            0.02s\n",
      "        40           8.5681          -0.8864            0.02s\n",
      "        50           4.4795          -0.2587            0.01s\n",
      "        60           2.3636          -0.5981            0.01s\n",
      "        70           1.8063          -0.0357            0.00s\n",
      "        80           1.1920          -0.0675            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.7, learning_rate=0.1, score=-1.820311, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         262.8065          -2.4396            0.16s\n",
      "         2         218.9041           3.7570            0.12s\n",
      "         3         174.2150          -1.5867            0.08s\n",
      "         4         153.3974           0.4726            0.08s\n",
      "         5          87.8555           1.7901            0.06s\n",
      "         6          71.5664           9.2502            0.06s\n",
      "         7         108.5677           3.3918            0.06s\n",
      "         8          86.8464           9.0799            0.05s\n",
      "         9          89.7808           1.5033            0.06s\n",
      "        10          60.7715          -1.1748            0.06s\n",
      "        20          30.1439          -4.5142            0.03s\n",
      "        30          13.0760          -0.6942            0.02s\n",
      "        40           9.3088          -0.7189            0.02s\n",
      "        50           4.9462          -0.3992            0.01s\n",
      "        60           2.1532          -0.5493            0.01s\n",
      "        70           2.0892          -0.1252            0.00s\n",
      "        80           1.4059          -0.1153            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.7, learning_rate=0.1, score=-0.186963, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         256.1238          -0.3836            0.00s\n",
      "         2         211.7803           2.6240            0.04s\n",
      "         3         169.0250           0.0708            0.03s\n",
      "         4         148.4681           0.5472            0.04s\n",
      "         5          87.5807           0.3824            0.03s\n",
      "         6          64.5821           4.7040            0.04s\n",
      "         7         107.5384           2.2573            0.03s\n",
      "         8          78.2253           8.2995            0.04s\n",
      "         9          84.3936           2.3927            0.04s\n",
      "        10          57.3567          -0.9504            0.03s\n",
      "        20          26.6672          -2.7083            0.02s\n",
      "        30          13.1692          -0.8021            0.02s\n",
      "        40           8.9818          -0.1215            0.02s\n",
      "        50           4.5713          -0.2173            0.01s\n",
      "        60           1.8095          -0.2416            0.01s\n",
      "        70           1.4665          -0.0358            0.00s\n",
      "        80           0.7710          -0.0586            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.7, learning_rate=0.1, score=0.123908, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         198.0329          -0.0243            0.08s\n",
      "         2         161.7336           3.4997            0.04s\n",
      "         3         137.5545          -0.1031            0.05s\n",
      "         4         111.2589           1.4515            0.04s\n",
      "         5          54.1124           0.7492            0.05s\n",
      "         6          58.8313           5.8361            0.05s\n",
      "         7          83.1991          -0.5532            0.05s\n",
      "         8          73.7525          -1.5827            0.05s\n",
      "         9          70.2469          -0.0856            0.06s\n",
      "        10          53.4014          -1.4817            0.05s\n",
      "        20          21.7508           0.3439            0.03s\n",
      "        30          11.1034          -0.1016            0.02s\n",
      "        40           5.6875          -0.1346            0.02s\n",
      "        50           4.4160          -0.0298            0.01s\n",
      "        60           1.9120          -0.1330            0.01s\n",
      "        70           1.4304           0.0246            0.00s\n",
      "        80           1.0048          -0.0601            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.7, learning_rate=0.1, score=-0.625548, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         204.1237          30.8578            0.08s\n",
      "         2         176.2616          28.1649            0.04s\n",
      "         3         174.6204           2.2035            0.05s\n",
      "         4         132.3285           0.3386            0.06s\n",
      "         5          87.6627           0.8449            0.05s\n",
      "         6          86.9300          -2.1871            0.05s\n",
      "         7          85.0056          11.4036            0.04s\n",
      "         8          92.4498          -0.4039            0.05s\n",
      "         9          77.0537          -0.0198            0.05s\n",
      "        10          69.9551           6.5173            0.05s\n",
      "        20          30.4621          -1.8251            0.03s\n",
      "        30          17.7524           0.2619            0.02s\n",
      "        40           9.5849          -0.2988            0.02s\n",
      "        50           4.2173          -0.2147            0.01s\n",
      "        60           2.3130          -0.1748            0.01s\n",
      "        70           1.7250          -0.0905            0.00s\n",
      "        80           1.0800          -0.0423            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.7, learning_rate=0.1, score=-0.520435, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         123.7072           1.5255            0.08s\n",
      "         2         107.3706          28.2098            0.08s\n",
      "         3         139.4616           0.7118            0.08s\n",
      "         4         101.6939           1.9011            0.08s\n",
      "         5          94.7211          -1.5840            0.07s\n",
      "         6          95.5368           0.9291            0.06s\n",
      "         7          46.8264           8.6758            0.06s\n",
      "         8          75.9240          -0.4583            0.05s\n",
      "         9          60.5617           1.5385            0.06s\n",
      "        10          52.8697          -0.9924            0.06s\n",
      "        20          24.8743           0.2826            0.03s\n",
      "        30          14.0894           0.0077            0.02s\n",
      "        40           7.1751          -0.5242            0.02s\n",
      "        50           3.6592          -0.1535            0.01s\n",
      "        60           2.4073          -0.2283            0.01s\n",
      "        70           1.5628          -0.0877            0.00s\n",
      "        80           0.8685          -0.0603            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.7, learning_rate=0.1, score=0.196511, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         208.0202          30.0677            0.00s\n",
      "         2         175.4719          25.9461            0.04s\n",
      "         3         183.9487           0.2350            0.05s\n",
      "         4         140.4071           2.5427            0.06s\n",
      "         5          88.6856           0.3884            0.05s\n",
      "         6         124.3057           0.2204            0.05s\n",
      "         7          78.6821          12.0933            0.05s\n",
      "         8          89.8906          -2.7397            0.05s\n",
      "         9          57.7148           0.5756            0.05s\n",
      "        10          68.9297           4.1508            0.05s\n",
      "        20          31.8865           0.3512            0.03s\n",
      "        30          14.8773          -2.0780            0.02s\n",
      "        40           8.4074           0.1711            0.02s\n",
      "        50           3.8872          -0.3233            0.01s\n",
      "        60           2.3021          -0.0918            0.01s\n",
      "        70           1.6735          -0.0649            0.00s\n",
      "        80           0.8396          -0.1053            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.7, learning_rate=0.1, score=-5.306303, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         144.2561          67.0223            0.08s\n",
      "         2         187.6820          -3.7931            0.08s\n",
      "         3         144.9588          21.1933            0.05s\n",
      "         4         107.1331          13.7385            0.06s\n",
      "         5         120.0382           0.9391            0.04s\n",
      "         6         101.0801          -0.3243            0.05s\n",
      "         7          74.4217           8.9459            0.05s\n",
      "         8          72.5340           0.9129            0.04s\n",
      "         9          47.2228          -0.9725            0.05s\n",
      "        10          54.3601           0.3420            0.04s\n",
      "        20          24.1906           0.1054            0.03s\n",
      "        30          13.3715          -1.8196            0.02s\n",
      "        40           5.8459          -0.0281            0.02s\n",
      "        50           3.8378          -0.3121            0.01s\n",
      "        60           2.0764          -0.1366            0.01s\n",
      "        70           1.7798          -0.0225            0.00s\n",
      "        80           0.9801          -0.0229            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.7, learning_rate=0.1, score=0.290461, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         152.3957          34.5125            0.16s\n",
      "         2         166.4078          -6.6912            0.16s\n",
      "         3         160.8578           1.3137            0.10s\n",
      "         4         123.6751           0.6482            0.09s\n",
      "         5         116.3182           0.9625            0.07s\n",
      "         6          94.8785           1.5927            0.07s\n",
      "         7          73.5657           7.7550            0.07s\n",
      "         8          75.5867          -0.2429            0.06s\n",
      "         9          44.8079           3.5097            0.06s\n",
      "        10          52.9112          -2.0431            0.06s\n",
      "        20          22.5081          -0.8693            0.04s\n",
      "        30          13.8569          -1.3059            0.02s\n",
      "        40           8.3869          -0.4379            0.02s\n",
      "        50           5.4156          -0.2633            0.01s\n",
      "        60           2.8133          -0.1942            0.01s\n",
      "        70           2.0319          -0.0381            0.00s\n",
      "        80           1.4464          -0.0309            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.7, learning_rate=0.1, score=0.707739, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         244.9091          -4.7851            0.08s\n",
      "         2         204.8047           1.7528            0.08s\n",
      "         3         165.3122          -0.7743            0.08s\n",
      "         4         150.0433           2.3150            0.06s\n",
      "         5          94.9605           4.1643            0.06s\n",
      "         6         100.9927          17.7065            0.06s\n",
      "         7          99.5158           0.1175            0.06s\n",
      "         8          82.8676           4.2680            0.06s\n",
      "         9          85.1565           0.8391            0.06s\n",
      "        10          69.0982           1.0308            0.06s\n",
      "        20          30.0836          -0.4102            0.04s\n",
      "        30          13.6969          -0.0936            0.03s\n",
      "        40           8.6332          -0.8593            0.02s\n",
      "        50           5.2889          -0.3394            0.02s\n",
      "        60           2.5368          -0.0959            0.01s\n",
      "        70           2.6759          -0.2530            0.01s\n",
      "        80           1.3745          -0.1105            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.75, learning_rate=0.1, score=-0.015179, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         246.5297          -6.1481            0.08s\n",
      "         2         206.5334          -0.4408            0.08s\n",
      "         3         166.6904          -1.0804            0.10s\n",
      "         4         146.5628           3.5243            0.09s\n",
      "         5          88.8836           0.3732            0.09s\n",
      "         6          97.6289          15.4687            0.09s\n",
      "         7          97.8836          -3.5274            0.08s\n",
      "         8          82.9149          10.8805            0.08s\n",
      "         9          83.8288           3.1215            0.09s\n",
      "        10          69.5891          -1.3278            0.08s\n",
      "        20          32.2921          -0.0855            0.05s\n",
      "        30          13.7299          -0.4531            0.03s\n",
      "        40           8.8591           0.0329            0.02s\n",
      "        50           4.4111          -0.3667            0.02s\n",
      "        60           2.2717          -0.2322            0.01s\n",
      "        70           1.9045          -0.0337            0.01s\n",
      "        80           1.1721          -0.1335            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.75, learning_rate=0.1, score=-0.992492, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         247.6843          -5.9155            0.08s\n",
      "         2         206.6658           4.6904            0.04s\n",
      "         3         164.5391          -1.8892            0.05s\n",
      "         4         146.6786           4.5077            0.04s\n",
      "         5          88.9411           8.2152            0.05s\n",
      "         6          99.9737          13.6023            0.04s\n",
      "         7          99.8886           2.9253            0.04s\n",
      "         8          79.0966          10.5812            0.04s\n",
      "         9          81.2340           0.7805            0.04s\n",
      "        10          66.3535          -0.5691            0.04s\n",
      "        20          32.7656          -0.1217            0.03s\n",
      "        30          10.5839          -0.7432            0.03s\n",
      "        40           7.2422          -0.0295            0.02s\n",
      "        50           4.0204          -0.0575            0.01s\n",
      "        60           1.8403          -0.5365            0.01s\n",
      "        70           1.8852          -0.0092            0.00s\n",
      "        80           1.0279          -0.1075            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.75, learning_rate=0.1, score=-0.148003, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         241.3760           0.1692            0.08s\n",
      "         2         198.1967           2.7898            0.04s\n",
      "         3         159.3101          -0.7978            0.05s\n",
      "         4         143.5937           1.5462            0.06s\n",
      "         5          87.5214           1.9932            0.06s\n",
      "         6          96.7593          15.7438            0.05s\n",
      "         7          99.8412          -1.0981            0.05s\n",
      "         8          72.9228           8.1512            0.05s\n",
      "         9          79.8875           2.0719            0.05s\n",
      "        10          63.0211           5.0942            0.05s\n",
      "        20          28.8266          -0.2679            0.03s\n",
      "        30           9.9541          -0.6890            0.03s\n",
      "        40           7.6987          -0.0051            0.02s\n",
      "        50           3.7230           0.0512            0.01s\n",
      "        60           1.3225          -0.1323            0.01s\n",
      "        70           1.1714          -0.0116            0.00s\n",
      "        80           0.5393          -0.0714            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.75, learning_rate=0.1, score=-0.133147, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         186.3867          -1.1701            0.08s\n",
      "         2         154.0178           3.8243            0.08s\n",
      "         3         129.5736          -0.5592            0.08s\n",
      "         4         112.2960          -0.7840            0.08s\n",
      "         5          54.4220           7.8209            0.07s\n",
      "         6          87.8630          -1.8935            0.07s\n",
      "         7          74.6408          -2.0772            0.06s\n",
      "         8          64.4901          -2.5314            0.06s\n",
      "         9          64.2275          -1.2492            0.06s\n",
      "        10          47.7917          -1.3823            0.06s\n",
      "        20          22.4049           0.0228            0.03s\n",
      "        30          11.6620          -0.1287            0.03s\n",
      "        40           6.1861          -0.1299            0.02s\n",
      "        50           4.3740          -0.0734            0.01s\n",
      "        60           2.1731          -0.2737            0.01s\n",
      "        70           1.5243          -0.0220            0.00s\n",
      "        80           0.8794          -0.0599            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.75, learning_rate=0.1, score=-0.684904, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         190.6566          33.8868            0.08s\n",
      "         2         170.6149          30.9591            0.04s\n",
      "         3         167.5426           0.0545            0.08s\n",
      "         4         132.3537          -1.1084            0.08s\n",
      "         5          85.4612           2.4108            0.06s\n",
      "         6         112.3850          -2.1312            0.06s\n",
      "         7          86.1611           9.0458            0.05s\n",
      "         8          82.7949          -2.9607            0.05s\n",
      "         9          71.8612          -2.3986            0.05s\n",
      "        10          67.1836           5.8593            0.05s\n",
      "        20          30.9319          -0.0504            0.03s\n",
      "        30          14.1479          -0.7589            0.02s\n",
      "        40           7.6120          -0.0206            0.02s\n",
      "        50           3.8695          -0.4833            0.01s\n",
      "        60           2.7551          -0.3473            0.01s\n",
      "        70           1.8251          -0.1026            0.00s\n",
      "        80           1.1472          -0.0631            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.75, learning_rate=0.1, score=-1.579275, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         117.0397           0.1609            0.00s\n",
      "         2         104.4567           4.1667            0.04s\n",
      "         3         139.6583           1.3361            0.05s\n",
      "         4         108.3229          -1.9874            0.04s\n",
      "         5          99.8879          -0.6580            0.05s\n",
      "         6          92.9491          -0.8423            0.04s\n",
      "         7          57.3517           9.7576            0.04s\n",
      "         8          71.2306           0.9487            0.04s\n",
      "         9          57.7076           1.2155            0.04s\n",
      "        10          52.8153           6.2931            0.04s\n",
      "        20          24.1345          -0.0577            0.03s\n",
      "        30          12.5556          -0.2512            0.02s\n",
      "        40           5.1996           0.2031            0.02s\n",
      "        50           2.4617          -0.0543            0.01s\n",
      "        60           1.6969          -0.0651            0.01s\n",
      "        70           1.1247          -0.0042            0.00s\n",
      "        80           0.5474          -0.0258            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.75, learning_rate=0.1, score=0.170975, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         198.0561          43.9576            0.08s\n",
      "         2         172.4489          27.4678            0.04s\n",
      "         3         175.6636           2.2493            0.05s\n",
      "         4         136.1155           1.1267            0.04s\n",
      "         5          91.3650           1.6835            0.05s\n",
      "         6         122.2101          -1.0514            0.04s\n",
      "         7          91.1172          11.7353            0.04s\n",
      "         8          90.9978          -1.4523            0.05s\n",
      "         9          56.7388           0.4585            0.04s\n",
      "        10          68.2205           5.4793            0.04s\n",
      "        20          32.6598           0.6124            0.03s\n",
      "        30          15.1800          -0.8281            0.02s\n",
      "        40           6.9259          -0.4930            0.02s\n",
      "        50           3.1232          -0.1682            0.01s\n",
      "        60           2.0481          -0.1856            0.01s\n",
      "        70           1.5368          -0.0863            0.00s\n",
      "        80           0.8316          -0.0802            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.75, learning_rate=0.1, score=-7.564012, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         142.6835          71.2680            0.00s\n",
      "         2         189.0696           0.9837            0.04s\n",
      "         3         143.4282          22.9831            0.05s\n",
      "         4         122.4720          -0.7270            0.04s\n",
      "         5         119.0424           0.8025            0.05s\n",
      "         6          98.2204           0.2950            0.04s\n",
      "         7          73.7368          12.0137            0.04s\n",
      "         8          70.8693           1.2037            0.05s\n",
      "         9          48.2885          -0.8560            0.04s\n",
      "        10          52.8030           2.8342            0.04s\n",
      "        20          22.3888          -2.5022            0.03s\n",
      "        30          12.5633          -0.2258            0.02s\n",
      "        40           5.3020          -0.5017            0.02s\n",
      "        50           3.6867          -0.0364            0.01s\n",
      "        60           2.0083          -0.1133            0.01s\n",
      "        70           1.4393          -0.0710            0.00s\n",
      "        80           0.8701          -0.0771            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.75, learning_rate=0.1, score=0.297122, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         151.3252          41.1125            0.00s\n",
      "         2         167.9958           3.5696            0.04s\n",
      "         3         153.3046           0.3679            0.03s\n",
      "         4         117.9798           1.0669            0.04s\n",
      "         5         110.2722          -0.0815            0.03s\n",
      "         6          90.0852           1.0381            0.04s\n",
      "         7          71.3803          11.8296            0.03s\n",
      "         8          72.6838           0.8961            0.04s\n",
      "         9          42.6973           2.0138            0.03s\n",
      "        10          48.3787          -1.9061            0.03s\n",
      "        20          22.7478          -1.9083            0.02s\n",
      "        30          11.6458          -1.6155            0.02s\n",
      "        40           6.9165          -0.5915            0.02s\n",
      "        50           4.9428           0.0119            0.01s\n",
      "        60           2.1780          -0.2291            0.01s\n",
      "        70           1.7922          -0.0271            0.00s\n",
      "        80           1.0614          -0.0748            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.75, learning_rate=0.1, score=0.737222, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         236.5202          -6.5556            0.08s\n",
      "         2         206.0829           2.4892            0.08s\n",
      "         3         161.6424           0.3191            0.05s\n",
      "         4         147.4986           3.0073            0.06s\n",
      "         5          95.8493           3.2118            0.06s\n",
      "         6          96.7498          21.3187            0.05s\n",
      "         7          95.6117          -0.1053            0.05s\n",
      "         8          80.3913           7.6684            0.04s\n",
      "         9          81.4958           1.1355            0.05s\n",
      "        10          67.3661           6.5160            0.04s\n",
      "        20          29.8975           0.0603            0.03s\n",
      "        30          10.9573           0.1072            0.02s\n",
      "        40           7.1681          -0.2610            0.02s\n",
      "        50           3.6195          -0.3069            0.01s\n",
      "        60           1.6530          -0.3201            0.01s\n",
      "        70           1.3471          -0.0463            0.00s\n",
      "        80           0.7892          -0.1588            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.8, learning_rate=0.1, score=-0.644913, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         237.7680          -7.4811            0.08s\n",
      "         2         208.4878           1.3715            0.08s\n",
      "         3         161.8860          -0.0891            0.08s\n",
      "         4         144.6101           2.8569            0.08s\n",
      "         5          92.2313          -1.3031            0.06s\n",
      "         6          93.7766          19.0260            0.06s\n",
      "         7          93.8149           1.3667            0.05s\n",
      "         8          79.4476          12.0193            0.05s\n",
      "         9          78.8401           1.9034            0.05s\n",
      "        10          65.9160          -1.2967            0.05s\n",
      "        20          31.2080          -0.1639            0.03s\n",
      "        30          12.1865          -0.7915            0.02s\n",
      "        40           7.0650           0.0128            0.02s\n",
      "        50           3.8679          -0.4162            0.01s\n",
      "        60           1.8699          -0.4532            0.01s\n",
      "        70           1.5845          -0.0690            0.00s\n",
      "        80           1.0757          -0.1789            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.8, learning_rate=0.1, score=-0.667038, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         236.4401          -6.6425            0.08s\n",
      "         2         205.5058           1.6582            0.04s\n",
      "         3         161.2724          -1.6024            0.05s\n",
      "         4         143.9889           2.2850            0.04s\n",
      "         5          89.0190           4.2659            0.05s\n",
      "         6          95.0057          20.6741            0.04s\n",
      "         7          93.6789           3.6990            0.04s\n",
      "         8          74.9801          11.2001            0.04s\n",
      "         9          77.8527          -0.0749            0.04s\n",
      "        10          64.1170          -1.1040            0.03s\n",
      "        20          29.3921           0.3342            0.03s\n",
      "        30          10.0306          -0.7254            0.02s\n",
      "        40           7.4300          -0.0728            0.02s\n",
      "        50           3.9377          -0.3611            0.01s\n",
      "        60           2.0240          -0.4218            0.01s\n",
      "        70           1.7748          -0.0333            0.00s\n",
      "        80           0.9935          -0.1209            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.8, learning_rate=0.1, score=-0.036770, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         230.3734           1.1228            0.08s\n",
      "         2         198.0328           1.6821            0.04s\n",
      "         3         154.5906          -2.4774            0.05s\n",
      "         4         141.3734          -0.2815            0.06s\n",
      "         5          88.0733           1.2910            0.05s\n",
      "         6          92.0782          18.8025            0.05s\n",
      "         7          95.0809           1.6771            0.05s\n",
      "         8          70.1894           8.0632            0.04s\n",
      "         9          73.8739           2.7558            0.05s\n",
      "        10          57.9961           0.0827            0.05s\n",
      "        20          26.7782          -2.2641            0.03s\n",
      "        30           9.4275          -0.6672            0.02s\n",
      "        40           6.7577          -0.0043            0.02s\n",
      "        50           3.5351          -0.0092            0.01s\n",
      "        60           1.3930          -0.2216            0.01s\n",
      "        70           0.9987           0.0212            0.00s\n",
      "        80           0.5434          -0.0899            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.8, learning_rate=0.1, score=-0.158715, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         182.1397          -1.9354            0.00s\n",
      "         2         157.5296          -0.0847            0.04s\n",
      "         3         126.0536          -1.6761            0.05s\n",
      "         4         112.6346           0.3971            0.06s\n",
      "         5          55.9613           4.0620            0.05s\n",
      "         6          82.9701          -5.1848            0.05s\n",
      "         7          73.1678          -3.5716            0.04s\n",
      "         8          62.6832          -4.1683            0.04s\n",
      "         9          66.0019          -1.9104            0.05s\n",
      "        10          49.3426           0.1143            0.04s\n",
      "        20          22.4788           0.6244            0.03s\n",
      "        30          10.1968           0.1914            0.02s\n",
      "        40           6.0474          -0.1280            0.02s\n",
      "        50           2.9843          -0.0751            0.01s\n",
      "        60           1.6181          -0.2566            0.01s\n",
      "        70           1.0421          -0.0097            0.00s\n",
      "        80           0.6708          -0.0438            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.8, learning_rate=0.1, score=-0.714259, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         187.9873          41.7830            0.00s\n",
      "         2         171.9537          37.4702            0.04s\n",
      "         3         161.0043          -1.7492            0.03s\n",
      "         4         132.5319          -0.4276            0.04s\n",
      "         5          83.7036           3.4274            0.03s\n",
      "         6         108.0456          -1.5220            0.04s\n",
      "         7          84.8802          10.2830            0.03s\n",
      "         8          82.6213           0.3530            0.04s\n",
      "         9          70.1084          -1.6202            0.03s\n",
      "        10          64.2965           7.8351            0.03s\n",
      "        20          27.9639           0.7302            0.02s\n",
      "        30          12.1517          -0.3748            0.02s\n",
      "        40           6.6993          -0.2320            0.02s\n",
      "        50           3.8244          -0.2816            0.01s\n",
      "        60           2.2081          -0.1196            0.01s\n",
      "        70           1.4550          -0.0662            0.00s\n",
      "        80           0.9976          -0.0397            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.8, learning_rate=0.1, score=-1.677309, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         118.4191           7.2077            0.00s\n",
      "         2         111.4162          34.7246            0.04s\n",
      "         3         128.4961          -1.2471            0.03s\n",
      "         4         101.9903           0.0780            0.04s\n",
      "         5          90.5179          -0.2382            0.03s\n",
      "         6          84.1471          -0.9777            0.04s\n",
      "         7          55.0324          10.6068            0.04s\n",
      "         8          67.7334          -0.3540            0.04s\n",
      "         9          55.3630           1.6033            0.04s\n",
      "        10          49.1757          -0.2559            0.04s\n",
      "        20          21.8009          -0.2318            0.03s\n",
      "        30          11.1556          -0.1374            0.02s\n",
      "        40           5.0889          -0.0484            0.02s\n",
      "        50           3.3043          -0.1897            0.01s\n",
      "        60           1.7803          -0.1126            0.01s\n",
      "        70           1.0669          -0.0406            0.00s\n",
      "        80           0.6983          -0.0174            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.8, learning_rate=0.1, score=0.142999, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         193.2021          53.5973            0.08s\n",
      "         2         171.7450          37.9446            0.04s\n",
      "         3         167.3416           0.6678            0.05s\n",
      "         4         131.5012           2.9652            0.04s\n",
      "         5          86.9403           2.2613            0.04s\n",
      "         6         113.4580          -3.5376            0.05s\n",
      "         7          88.0329          16.0978            0.04s\n",
      "         8          86.4696          -0.7687            0.04s\n",
      "         9          52.3169           3.3993            0.04s\n",
      "        10          65.2144           8.5409            0.04s\n",
      "        20          29.6667          -0.3534            0.03s\n",
      "        30          13.2457          -1.3142            0.02s\n",
      "        40           6.8857          -0.3391            0.02s\n",
      "        50           4.1882          -0.3036            0.01s\n",
      "        60           2.2326          -0.1642            0.01s\n",
      "        70           1.3692          -0.0830            0.00s\n",
      "        80           0.8741          -0.0857            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.8, learning_rate=0.1, score=-4.091411, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         136.6496          95.9320            0.00s\n",
      "         2         180.2674          -2.4761            0.04s\n",
      "         3         132.6954          29.7444            0.03s\n",
      "         4         113.7503           0.7629            0.04s\n",
      "         5         110.0132           0.1133            0.03s\n",
      "         6          91.4702          -0.3071            0.04s\n",
      "         7          70.0900          15.0178            0.03s\n",
      "         8          68.4053           1.2771            0.04s\n",
      "         9          58.6432          -0.7747            0.03s\n",
      "        10          47.6259           2.3104            0.04s\n",
      "        20          22.4320          -0.8196            0.02s\n",
      "        30          11.1800          -1.4659            0.02s\n",
      "        40           5.1423          -0.2741            0.02s\n",
      "        50           3.8472          -0.1251            0.01s\n",
      "        60           2.0987          -0.1041            0.01s\n",
      "        70           1.4384          -0.0481            0.00s\n",
      "        80           0.8831          -0.0498            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.8, learning_rate=0.1, score=0.305725, total=   0.0s\n",
      "[CV] n_estimators=80, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         146.7422          53.3235            0.16s\n",
      "         2         161.7998          -4.6665            0.12s\n",
      "         3         145.2594           0.4953            0.10s\n",
      "         4         112.4802           0.5597            0.08s\n",
      "         5         108.4693          -0.3235            0.08s\n",
      "         6          84.3720           2.2330            0.07s\n",
      "         7          69.9517          15.9506            0.06s\n",
      "         8          68.6523          -0.9784            0.06s\n",
      "         9          58.5079          -5.0482            0.06s\n",
      "        10          47.8218          -1.6201            0.06s\n",
      "        20          23.9498          -0.6134            0.03s\n",
      "        30          11.5019          -0.2085            0.03s\n",
      "        40           5.3056          -0.6555            0.02s\n",
      "        50           3.5691          -0.1247            0.01s\n",
      "        60           1.8081          -0.0877            0.01s\n",
      "        70           1.2804          -0.0736            0.00s\n",
      "        80           0.8933          -0.0127            0.00s\n",
      "[CV]  n_estimators=80, subsample=0.8, learning_rate=0.1, score=0.770863, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         262.8658          -2.9054            0.00s\n",
      "         2         220.9964           4.0227            0.04s\n",
      "         3         175.4706          -0.2296            0.06s\n",
      "         4         155.9681           2.3634            0.06s\n",
      "         5          93.0879           1.1133            0.05s\n",
      "         6          73.2691          17.2805            0.06s\n",
      "         7         106.9451           0.6327            0.06s\n",
      "         8          90.4306           6.0374            0.05s\n",
      "         9          90.6089           0.5271            0.05s\n",
      "        10          61.4069           6.2804            0.06s\n",
      "        20          27.3549          -2.3446            0.03s\n",
      "        30          13.3452          -0.3527            0.03s\n",
      "        40          10.7186          -0.6676            0.02s\n",
      "        50           5.4114          -0.0995            0.02s\n",
      "        60           2.6889          -0.2712            0.01s\n",
      "        70           2.2101          -0.0189            0.01s\n",
      "        80           1.2239          -0.1190            0.00s\n",
      "        90           0.8420          -0.0063            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.7, learning_rate=0.1, score=-0.366680, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         264.5848          -3.7668            0.09s\n",
      "         2         222.3572          -1.0804            0.09s\n",
      "         3         178.0437          -0.3488            0.06s\n",
      "         4         153.9776           2.2977            0.09s\n",
      "         5          89.1182           1.1180            0.07s\n",
      "         6          70.7960          15.3296            0.07s\n",
      "         7         106.9559           3.3278            0.06s\n",
      "         8          90.7802           9.7359            0.06s\n",
      "         9          88.9477           1.8940            0.06s\n",
      "        10          61.5709           0.9214            0.06s\n",
      "        20          28.5320          -0.6776            0.03s\n",
      "        30          13.5926          -0.4935            0.03s\n",
      "        40           8.5681          -0.8864            0.02s\n",
      "        50           4.4795          -0.2587            0.02s\n",
      "        60           2.3636          -0.5981            0.01s\n",
      "        70           1.8063          -0.0357            0.01s\n",
      "        80           1.1920          -0.0675            0.00s\n",
      "        90           0.8484          -0.0464            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.7, learning_rate=0.1, score=-1.694887, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         262.8065          -2.4396            0.09s\n",
      "         2         218.9041           3.7570            0.04s\n",
      "         3         174.2150          -1.5867            0.06s\n",
      "         4         153.3974           0.4726            0.06s\n",
      "         5          87.8555           1.7901            0.05s\n",
      "         6          71.5664           9.2502            0.06s\n",
      "         7         108.5677           3.3918            0.05s\n",
      "         8          86.8464           9.0799            0.05s\n",
      "         9          89.7808           1.5033            0.05s\n",
      "        10          60.7715          -1.1748            0.06s\n",
      "        20          30.1439          -4.5142            0.04s\n",
      "        30          13.0760          -0.6942            0.03s\n",
      "        40           9.3088          -0.7189            0.02s\n",
      "        50           4.9462          -0.3992            0.02s\n",
      "        60           2.1532          -0.5493            0.01s\n",
      "        70           2.0892          -0.1252            0.01s\n",
      "        80           1.4059          -0.1153            0.00s\n",
      "        90           0.9292          -0.0555            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.7, learning_rate=0.1, score=-0.204066, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         256.1238          -0.3836            0.18s\n",
      "         2         211.7803           2.6240            0.13s\n",
      "         3         169.0250           0.0708            0.12s\n",
      "         4         148.4681           0.5472            0.09s\n",
      "         5          87.5807           0.3824            0.09s\n",
      "         6          64.5821           4.7040            0.08s\n",
      "         7         107.5384           2.2573            0.08s\n",
      "         8          78.2253           8.2995            0.07s\n",
      "         9          84.3936           2.3927            0.07s\n",
      "        10          57.3567          -0.9504            0.06s\n",
      "        20          26.6672          -2.7083            0.04s\n",
      "        30          13.1692          -0.8021            0.03s\n",
      "        40           8.9818          -0.1215            0.02s\n",
      "        50           4.5713          -0.2173            0.02s\n",
      "        60           1.8095          -0.2416            0.01s\n",
      "        70           1.4665          -0.0358            0.01s\n",
      "        80           0.7710          -0.0586            0.00s\n",
      "        90           0.5281          -0.0129            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.7, learning_rate=0.1, score=0.109289, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         198.0329          -0.0243            0.18s\n",
      "         2         161.7336           3.4997            0.13s\n",
      "         3         137.5545          -0.1031            0.12s\n",
      "         4         111.2589           1.4515            0.09s\n",
      "         5          54.1124           0.7492            0.08s\n",
      "         6          58.8313           5.8361            0.07s\n",
      "         7          83.1991          -0.5532            0.07s\n",
      "         8          73.7525          -1.5827            0.07s\n",
      "         9          70.2469          -0.0856            0.06s\n",
      "        10          53.4014          -1.4817            0.06s\n",
      "        20          21.7508           0.3439            0.04s\n",
      "        30          11.1034          -0.1016            0.03s\n",
      "        40           5.6875          -0.1346            0.02s\n",
      "        50           4.4160          -0.0298            0.02s\n",
      "        60           1.9120          -0.1330            0.01s\n",
      "        70           1.4304           0.0246            0.01s\n",
      "        80           1.0048          -0.0601            0.00s\n",
      "        90           0.6576          -0.0464            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.7, learning_rate=0.1, score=-0.629742, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         204.1237          30.8578            0.00s\n",
      "         2         176.2616          28.1649            0.04s\n",
      "         3         174.6204           2.2035            0.03s\n",
      "         4         132.3285           0.3386            0.04s\n",
      "         5          87.6627           0.8449            0.05s\n",
      "         6          86.9300          -2.1871            0.04s\n",
      "         7          85.0056          11.4036            0.05s\n",
      "         8          92.4498          -0.4039            0.05s\n",
      "         9          77.0537          -0.0198            0.05s\n",
      "        10          69.9551           6.5173            0.05s\n",
      "        20          30.4621          -1.8251            0.03s\n",
      "        30          17.7524           0.2619            0.03s\n",
      "        40           9.5849          -0.2988            0.02s\n",
      "        50           4.2173          -0.2147            0.02s\n",
      "        60           2.3130          -0.1748            0.01s\n",
      "        70           1.7250          -0.0905            0.01s\n",
      "        80           1.0800          -0.0423            0.00s\n",
      "        90           0.6444          -0.0724            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.7, learning_rate=0.1, score=-0.589027, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         123.7072           1.5255            0.09s\n",
      "         2         107.3706          28.2098            0.04s\n",
      "         3         139.4616           0.7118            0.06s\n",
      "         4         101.6939           1.9011            0.04s\n",
      "         5          94.7211          -1.5840            0.05s\n",
      "         6          95.5368           0.9291            0.06s\n",
      "         7          46.8264           8.6758            0.06s\n",
      "         8          75.9240          -0.4583            0.06s\n",
      "         9          60.5617           1.5385            0.06s\n",
      "        10          52.8697          -0.9924            0.06s\n",
      "        20          24.8743           0.2826            0.04s\n",
      "        30          14.0894           0.0077            0.03s\n",
      "        40           7.1751          -0.5242            0.02s\n",
      "        50           3.6592          -0.1535            0.02s\n",
      "        60           2.4073          -0.2283            0.01s\n",
      "        70           1.5628          -0.0877            0.01s\n",
      "        80           0.8685          -0.0603            0.00s\n",
      "        90           0.6701          -0.0429            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.7, learning_rate=0.1, score=0.197570, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         208.0202          30.0677            0.00s\n",
      "         2         175.4719          25.9461            0.04s\n",
      "         3         183.9487           0.2350            0.06s\n",
      "         4         140.4071           2.5427            0.04s\n",
      "         5          88.6856           0.3884            0.05s\n",
      "         6         124.3057           0.2204            0.04s\n",
      "         7          78.6821          12.0933            0.05s\n",
      "         8          89.8906          -2.7397            0.05s\n",
      "         9          57.7148           0.5756            0.05s\n",
      "        10          68.9297           4.1508            0.05s\n",
      "        20          31.8865           0.3512            0.03s\n",
      "        30          14.8773          -2.0780            0.02s\n",
      "        40           8.4074           0.1711            0.02s\n",
      "        50           3.8872          -0.3233            0.02s\n",
      "        60           2.3021          -0.0918            0.01s\n",
      "        70           1.6735          -0.0649            0.01s\n",
      "        80           0.8396          -0.1053            0.00s\n",
      "        90           0.5531          -0.0812            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.7, learning_rate=0.1, score=-5.407867, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         144.2561          67.0223            0.09s\n",
      "         2         187.6820          -3.7931            0.09s\n",
      "         3         144.9588          21.1933            0.06s\n",
      "         4         107.1331          13.7385            0.06s\n",
      "         5         120.0382           0.9391            0.05s\n",
      "         6         101.0801          -0.3243            0.06s\n",
      "         7          74.4217           8.9459            0.05s\n",
      "         8          72.5340           0.9129            0.05s\n",
      "         9          47.2228          -0.9725            0.05s\n",
      "        10          54.3601           0.3420            0.06s\n",
      "        20          24.1906           0.1054            0.04s\n",
      "        30          13.3715          -1.8196            0.03s\n",
      "        40           5.8459          -0.0281            0.02s\n",
      "        50           3.8378          -0.3121            0.02s\n",
      "        60           2.0764          -0.1366            0.01s\n",
      "        70           1.7798          -0.0225            0.01s\n",
      "        80           0.9801          -0.0229            0.00s\n",
      "        90           0.5575          -0.0328            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.7, learning_rate=0.1, score=0.291682, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.7, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         152.3957          34.5125            0.09s\n",
      "         2         166.4078          -6.6912            0.04s\n",
      "         3         160.8578           1.3137            0.06s\n",
      "         4         123.6751           0.6482            0.06s\n",
      "         5         116.3182           0.9625            0.05s\n",
      "         6          94.8785           1.5927            0.06s\n",
      "         7          73.5657           7.7550            0.05s\n",
      "         8          75.5867          -0.2429            0.05s\n",
      "         9          44.8079           3.5097            0.05s\n",
      "        10          52.9112          -2.0431            0.05s\n",
      "        20          22.5081          -0.8693            0.03s\n",
      "        30          13.8569          -1.3059            0.03s\n",
      "        40           8.3869          -0.4379            0.02s\n",
      "        50           5.4156          -0.2633            0.02s\n",
      "        60           2.8133          -0.1942            0.01s\n",
      "        70           2.0319          -0.0381            0.01s\n",
      "        80           1.4464          -0.0309            0.00s\n",
      "        90           0.8056          -0.0742            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.7, learning_rate=0.1, score=0.713996, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         244.9091          -4.7851            0.09s\n",
      "         2         204.8047           1.7528            0.04s\n",
      "         3         165.3122          -0.7743            0.06s\n",
      "         4         150.0433           2.3150            0.04s\n",
      "         5          94.9605           4.1643            0.07s\n",
      "         6         100.9927          17.7065            0.07s\n",
      "         7          99.5158           0.1175            0.07s\n",
      "         8          82.8676           4.2680            0.08s\n",
      "         9          85.1565           0.8391            0.08s\n",
      "        10          69.0982           1.0308            0.08s\n",
      "        20          30.0836          -0.4102            0.05s\n",
      "        30          13.6969          -0.0936            0.04s\n",
      "        40           8.6332          -0.8593            0.03s\n",
      "        50           5.2889          -0.3394            0.03s\n",
      "        60           2.5368          -0.0959            0.02s\n",
      "        70           2.6759          -0.2530            0.01s\n",
      "        80           1.3745          -0.1105            0.01s\n",
      "        90           0.9375          -0.0731            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.75, learning_rate=0.1, score=-0.092561, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         246.5297          -6.1481            0.09s\n",
      "         2         206.5334          -0.4408            0.09s\n",
      "         3         166.6904          -1.0804            0.06s\n",
      "         4         146.5628           3.5243            0.06s\n",
      "         5          88.8836           0.3732            0.05s\n",
      "         6          97.6289          15.4687            0.06s\n",
      "         7          97.8836          -3.5274            0.05s\n",
      "         8          82.9149          10.8805            0.05s\n",
      "         9          83.8288           3.1215            0.05s\n",
      "        10          69.5891          -1.3278            0.06s\n",
      "        20          32.2921          -0.0855            0.03s\n",
      "        30          13.7299          -0.4531            0.03s\n",
      "        40           8.8591           0.0329            0.02s\n",
      "        50           4.4111          -0.3667            0.02s\n",
      "        60           2.2717          -0.2322            0.01s\n",
      "        70           1.9045          -0.0337            0.01s\n",
      "        80           1.1721          -0.1335            0.00s\n",
      "        90           0.7883          -0.0520            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.75, learning_rate=0.1, score=-0.972696, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         247.6843          -5.9155            0.09s\n",
      "         2         206.6658           4.6904            0.09s\n",
      "         3         164.5391          -1.8892            0.09s\n",
      "         4         146.6786           4.5077            0.06s\n",
      "         5          88.9411           8.2152            0.07s\n",
      "         6          99.9737          13.6023            0.07s\n",
      "         7          99.8886           2.9253            0.07s\n",
      "         8          79.0966          10.5812            0.07s\n",
      "         9          81.2340           0.7805            0.07s\n",
      "        10          66.3535          -0.5691            0.06s\n",
      "        20          32.7656          -0.1217            0.04s\n",
      "        30          10.5839          -0.7432            0.03s\n",
      "        40           7.2422          -0.0295            0.02s\n",
      "        50           4.0204          -0.0575            0.02s\n",
      "        60           1.8403          -0.5365            0.01s\n",
      "        70           1.8852          -0.0092            0.01s\n",
      "        80           1.0279          -0.1075            0.00s\n",
      "        90           0.6905          -0.0302            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.75, learning_rate=0.1, score=-0.118412, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         241.3760           0.1692            0.09s\n",
      "         2         198.1967           2.7898            0.09s\n",
      "         3         159.3101          -0.7978            0.06s\n",
      "         4         143.5937           1.5462            0.06s\n",
      "         5          87.5214           1.9932            0.05s\n",
      "         6          96.7593          15.7438            0.06s\n",
      "         7          99.8412          -1.0981            0.05s\n",
      "         8          72.9228           8.1512            0.05s\n",
      "         9          79.8875           2.0719            0.05s\n",
      "        10          63.0211           5.0942            0.06s\n",
      "        20          28.8266          -0.2679            0.03s\n",
      "        30           9.9541          -0.6890            0.03s\n",
      "        40           7.6987          -0.0051            0.02s\n",
      "        50           3.7230           0.0512            0.02s\n",
      "        60           1.3225          -0.1323            0.01s\n",
      "        70           1.1714          -0.0116            0.01s\n",
      "        80           0.5393          -0.0714            0.00s\n",
      "        90           0.3042          -0.0578            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.75, learning_rate=0.1, score=-0.121489, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         186.3867          -1.1701            0.09s\n",
      "         2         154.0178           3.8243            0.04s\n",
      "         3         129.5736          -0.5592            0.06s\n",
      "         4         112.2960          -0.7840            0.04s\n",
      "         5          54.4220           7.8209            0.05s\n",
      "         6          87.8630          -1.8935            0.04s\n",
      "         7          74.6408          -2.0772            0.05s\n",
      "         8          64.4901          -2.5314            0.04s\n",
      "         9          64.2275          -1.2492            0.04s\n",
      "        10          47.7917          -1.3823            0.05s\n",
      "        20          22.4049           0.0228            0.03s\n",
      "        30          11.6620          -0.1287            0.03s\n",
      "        40           6.1861          -0.1299            0.02s\n",
      "        50           4.3740          -0.0734            0.02s\n",
      "        60           2.1731          -0.2737            0.01s\n",
      "        70           1.5243          -0.0220            0.01s\n",
      "        80           0.8794          -0.0599            0.00s\n",
      "        90           0.4843          -0.0506            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.75, learning_rate=0.1, score=-0.700525, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         190.6566          33.8868            0.09s\n",
      "         2         170.6149          30.9591            0.04s\n",
      "         3         167.5426           0.0545            0.06s\n",
      "         4         132.3537          -1.1084            0.06s\n",
      "         5          85.4612           2.4108            0.05s\n",
      "         6         112.3850          -2.1312            0.06s\n",
      "         7          86.1611           9.0458            0.05s\n",
      "         8          82.7949          -2.9607            0.05s\n",
      "         9          71.8612          -2.3986            0.05s\n",
      "        10          67.1836           5.8593            0.05s\n",
      "        20          30.9319          -0.0504            0.03s\n",
      "        30          14.1479          -0.7589            0.03s\n",
      "        40           7.6120          -0.0206            0.02s\n",
      "        50           3.8695          -0.4833            0.02s\n",
      "        60           2.7551          -0.3473            0.01s\n",
      "        70           1.8251          -0.1026            0.01s\n",
      "        80           1.1472          -0.0631            0.00s\n",
      "        90           0.6874          -0.0560            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.75, learning_rate=0.1, score=-1.630942, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         117.0397           0.1609            0.18s\n",
      "         2         104.4567           4.1667            0.13s\n",
      "         3         139.6583           1.3361            0.12s\n",
      "         4         108.3229          -1.9874            0.09s\n",
      "         5          99.8879          -0.6580            0.08s\n",
      "         6          92.9491          -0.8423            0.08s\n",
      "         7          57.3517           9.7576            0.07s\n",
      "         8          71.2306           0.9487            0.07s\n",
      "         9          57.7076           1.2155            0.06s\n",
      "        10          52.8153           6.2931            0.06s\n",
      "        20          24.1345          -0.0577            0.04s\n",
      "        30          12.5556          -0.2512            0.03s\n",
      "        40           5.1996           0.2031            0.02s\n",
      "        50           2.4617          -0.0543            0.02s\n",
      "        60           1.6969          -0.0651            0.01s\n",
      "        70           1.1247          -0.0042            0.01s\n",
      "        80           0.5474          -0.0258            0.00s\n",
      "        90           0.3505          -0.0508            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.75, learning_rate=0.1, score=0.170712, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         198.0561          43.9576            0.09s\n",
      "         2         172.4489          27.4678            0.04s\n",
      "         3         175.6636           2.2493            0.06s\n",
      "         4         136.1155           1.1267            0.04s\n",
      "         5          91.3650           1.6835            0.05s\n",
      "         6         122.2101          -1.0514            0.06s\n",
      "         7          91.1172          11.7353            0.06s\n",
      "         8          90.9978          -1.4523            0.05s\n",
      "         9          56.7388           0.4585            0.05s\n",
      "        10          68.2205           5.4793            0.05s\n",
      "        20          32.6598           0.6124            0.03s\n",
      "        30          15.1800          -0.8281            0.03s\n",
      "        40           6.9259          -0.4930            0.02s\n",
      "        50           3.1232          -0.1682            0.02s\n",
      "        60           2.0481          -0.1856            0.01s\n",
      "        70           1.5368          -0.0863            0.01s\n",
      "        80           0.8316          -0.0802            0.00s\n",
      "        90           0.5944          -0.0291            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.75, learning_rate=0.1, score=-7.678271, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         142.6835          71.2680            0.09s\n",
      "         2         189.0696           0.9837            0.09s\n",
      "         3         143.4282          22.9831            0.09s\n",
      "         4         122.4720          -0.7270            0.09s\n",
      "         5         119.0424           0.8025            0.07s\n",
      "         6          98.2204           0.2950            0.07s\n",
      "         7          73.7368          12.0137            0.07s\n",
      "         8          70.8693           1.2037            0.07s\n",
      "         9          48.2885          -0.8560            0.06s\n",
      "        10          52.8030           2.8342            0.06s\n",
      "        20          22.3888          -2.5022            0.04s\n",
      "        30          12.5633          -0.2258            0.03s\n",
      "        40           5.3020          -0.5017            0.02s\n",
      "        50           3.6867          -0.0364            0.02s\n",
      "        60           2.0083          -0.1133            0.01s\n",
      "        70           1.4393          -0.0710            0.01s\n",
      "        80           0.8701          -0.0771            0.00s\n",
      "        90           0.5492          -0.0176            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.75, learning_rate=0.1, score=0.313935, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.75, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         151.3252          41.1125            0.00s\n",
      "         2         167.9958           3.5696            0.00s\n",
      "         3         153.3046           0.3679            0.00s\n",
      "         4         117.9798           1.0669            0.04s\n",
      "         5         110.2722          -0.0815            0.03s\n",
      "         6          90.0852           1.0381            0.03s\n",
      "         7          71.3803          11.8296            0.05s\n",
      "         8          72.6838           0.8961            0.04s\n",
      "         9          42.6973           2.0138            0.04s\n",
      "        10          48.3787          -1.9061            0.05s\n",
      "        20          22.7478          -1.9083            0.03s\n",
      "        30          11.6458          -1.6155            0.03s\n",
      "        40           6.9165          -0.5915            0.02s\n",
      "        50           4.9428           0.0119            0.02s\n",
      "        60           2.1780          -0.2291            0.01s\n",
      "        70           1.7922          -0.0271            0.01s\n",
      "        80           1.0614          -0.0748            0.00s\n",
      "        90           0.7408          -0.0494            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.75, learning_rate=0.1, score=0.741989, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         236.5202          -6.5556            0.09s\n",
      "         2         206.0829           2.4892            0.04s\n",
      "         3         161.6424           0.3191            0.06s\n",
      "         4         147.4986           3.0073            0.04s\n",
      "         5          95.8493           3.2118            0.05s\n",
      "         6          96.7498          21.3187            0.06s\n",
      "         7          95.6117          -0.1053            0.05s\n",
      "         8          80.3913           7.6684            0.05s\n",
      "         9          81.4958           1.1355            0.05s\n",
      "        10          67.3661           6.5160            0.05s\n",
      "        20          29.8975           0.0603            0.03s\n",
      "        30          10.9573           0.1072            0.03s\n",
      "        40           7.1681          -0.2610            0.02s\n",
      "        50           3.6195          -0.3069            0.02s\n",
      "        60           1.6530          -0.3201            0.01s\n",
      "        70           1.3471          -0.0463            0.01s\n",
      "        80           0.7892          -0.1588            0.00s\n",
      "        90           0.5446          -0.0377            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.8, learning_rate=0.1, score=-0.687094, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         237.7680          -7.4811            0.09s\n",
      "         2         208.4878           1.3715            0.09s\n",
      "         3         161.8860          -0.0891            0.06s\n",
      "         4         144.6101           2.8569            0.06s\n",
      "         5          92.2313          -1.3031            0.07s\n",
      "         6          93.7766          19.0260            0.06s\n",
      "         7          93.8149           1.3667            0.06s\n",
      "         8          79.4476          12.0193            0.06s\n",
      "         9          78.8401           1.9034            0.05s\n",
      "        10          65.9160          -1.2967            0.06s\n",
      "        20          31.2080          -0.1639            0.04s\n",
      "        30          12.1865          -0.7915            0.03s\n",
      "        40           7.0650           0.0128            0.02s\n",
      "        50           3.8679          -0.4162            0.02s\n",
      "        60           1.8699          -0.4532            0.01s\n",
      "        70           1.5845          -0.0690            0.01s\n",
      "        80           1.0757          -0.1789            0.00s\n",
      "        90           0.7011          -0.0565            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.8, learning_rate=0.1, score=-0.592133, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         236.4401          -6.6425            0.09s\n",
      "         2         205.5058           1.6582            0.04s\n",
      "         3         161.2724          -1.6024            0.06s\n",
      "         4         143.9889           2.2850            0.06s\n",
      "         5          89.0190           4.2659            0.05s\n",
      "         6          95.0057          20.6741            0.06s\n",
      "         7          93.6789           3.6990            0.05s\n",
      "         8          74.9801          11.2001            0.05s\n",
      "         9          77.8527          -0.0749            0.05s\n",
      "        10          64.1170          -1.1040            0.05s\n",
      "        20          29.3921           0.3342            0.03s\n",
      "        30          10.0306          -0.7254            0.03s\n",
      "        40           7.4300          -0.0728            0.02s\n",
      "        50           3.9377          -0.3611            0.02s\n",
      "        60           2.0240          -0.4218            0.01s\n",
      "        70           1.7748          -0.0333            0.01s\n",
      "        80           0.9935          -0.1209            0.00s\n",
      "        90           0.6019          -0.0585            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.8, learning_rate=0.1, score=-0.027497, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         230.3734           1.1228            0.00s\n",
      "         2         198.0328           1.6821            0.04s\n",
      "         3         154.5906          -2.4774            0.06s\n",
      "         4         141.3734          -0.2815            0.06s\n",
      "         5          88.0733           1.2910            0.07s\n",
      "         6          92.0782          18.8025            0.07s\n",
      "         7          95.0809           1.6771            0.06s\n",
      "         8          70.1894           8.0632            0.06s\n",
      "         9          73.8739           2.7558            0.05s\n",
      "        10          57.9961           0.0827            0.06s\n",
      "        20          26.7782          -2.2641            0.03s\n",
      "        30           9.4275          -0.6672            0.03s\n",
      "        40           6.7577          -0.0043            0.02s\n",
      "        50           3.5351          -0.0092            0.02s\n",
      "        60           1.3930          -0.2216            0.01s\n",
      "        70           0.9987           0.0212            0.01s\n",
      "        80           0.5434          -0.0899            0.00s\n",
      "        90           0.3248          -0.0850            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.8, learning_rate=0.1, score=-0.159759, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         182.1397          -1.9354            0.00s\n",
      "         2         157.5296          -0.0847            0.09s\n",
      "         3         126.0536          -1.6761            0.09s\n",
      "         4         112.6346           0.3971            0.09s\n",
      "         5          55.9613           4.0620            0.08s\n",
      "         6          82.9701          -5.1848            0.08s\n",
      "         7          73.1678          -3.5716            0.08s\n",
      "         8          62.6832          -4.1683            0.07s\n",
      "         9          66.0019          -1.9104            0.07s\n",
      "        10          49.3426           0.1143            0.06s\n",
      "        20          22.4788           0.6244            0.04s\n",
      "        30          10.1968           0.1914            0.03s\n",
      "        40           6.0474          -0.1280            0.02s\n",
      "        50           2.9843          -0.0751            0.02s\n",
      "        60           1.6181          -0.2566            0.01s\n",
      "        70           1.0421          -0.0097            0.01s\n",
      "        80           0.6708          -0.0438            0.00s\n",
      "        90           0.4020          -0.0667            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.8, learning_rate=0.1, score=-0.728336, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         187.9873          41.7830            0.00s\n",
      "         2         171.9537          37.4702            0.04s\n",
      "         3         161.0043          -1.7492            0.03s\n",
      "         4         132.5319          -0.4276            0.04s\n",
      "         5          83.7036           3.4274            0.03s\n",
      "         6         108.0456          -1.5220            0.04s\n",
      "         7          84.8802          10.2830            0.05s\n",
      "         8          82.6213           0.3530            0.04s\n",
      "         9          70.1084          -1.6202            0.05s\n",
      "        10          64.2965           7.8351            0.04s\n",
      "        20          27.9639           0.7302            0.03s\n",
      "        30          12.1517          -0.3748            0.02s\n",
      "        40           6.6993          -0.2320            0.02s\n",
      "        50           3.8244          -0.2816            0.02s\n",
      "        60           2.2081          -0.1196            0.01s\n",
      "        70           1.4550          -0.0662            0.01s\n",
      "        80           0.9976          -0.0397            0.00s\n",
      "        90           0.5502          -0.0688            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.8, learning_rate=0.1, score=-1.719899, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         118.4191           7.2077            0.09s\n",
      "         2         111.4162          34.7246            0.04s\n",
      "         3         128.4961          -1.2471            0.06s\n",
      "         4         101.9903           0.0780            0.06s\n",
      "         5          90.5179          -0.2382            0.05s\n",
      "         6          84.1471          -0.9777            0.06s\n",
      "         7          55.0324          10.6068            0.06s\n",
      "         8          67.7334          -0.3540            0.05s\n",
      "         9          55.3630           1.6033            0.05s\n",
      "        10          49.1757          -0.2559            0.06s\n",
      "        20          21.8009          -0.2318            0.03s\n",
      "        30          11.1556          -0.1374            0.03s\n",
      "        40           5.0889          -0.0484            0.02s\n",
      "        50           3.3043          -0.1897            0.02s\n",
      "        60           1.7803          -0.1126            0.01s\n",
      "        70           1.0669          -0.0406            0.01s\n",
      "        80           0.6983          -0.0174            0.00s\n",
      "        90           0.4523          -0.0487            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.8, learning_rate=0.1, score=0.148360, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         193.2021          53.5973            0.00s\n",
      "         2         171.7450          37.9446            0.04s\n",
      "         3         167.3416           0.6678            0.06s\n",
      "         4         131.5012           2.9652            0.04s\n",
      "         5          86.9403           2.2613            0.05s\n",
      "         6         113.4580          -3.5376            0.04s\n",
      "         7          88.0329          16.0978            0.05s\n",
      "         8          86.4696          -0.7687            0.04s\n",
      "         9          52.3169           3.3993            0.04s\n",
      "        10          65.2144           8.5409            0.04s\n",
      "        20          29.6667          -0.3534            0.03s\n",
      "        30          13.2457          -1.3142            0.02s\n",
      "        40           6.8857          -0.3391            0.02s\n",
      "        50           4.1882          -0.3036            0.02s\n",
      "        60           2.2326          -0.1642            0.01s\n",
      "        70           1.3692          -0.0830            0.01s\n",
      "        80           0.8741          -0.0857            0.00s\n",
      "        90           0.5994          -0.0440            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.8, learning_rate=0.1, score=-4.016080, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         136.6496          95.9320            0.09s\n",
      "         2         180.2674          -2.4761            0.04s\n",
      "         3         132.6954          29.7444            0.06s\n",
      "         4         113.7503           0.7629            0.06s\n",
      "         5         110.0132           0.1133            0.05s\n",
      "         6          91.4702          -0.3071            0.06s\n",
      "         7          70.0900          15.0178            0.05s\n",
      "         8          68.4053           1.2771            0.05s\n",
      "         9          58.6432          -0.7747            0.04s\n",
      "        10          47.6259           2.3104            0.05s\n",
      "        20          22.4320          -0.8196            0.03s\n",
      "        30          11.1800          -1.4659            0.03s\n",
      "        40           5.1423          -0.2741            0.02s\n",
      "        50           3.8472          -0.1251            0.02s\n",
      "        60           2.0987          -0.1041            0.01s\n",
      "        70           1.4384          -0.0481            0.01s\n",
      "        80           0.8831          -0.0498            0.00s\n",
      "        90           0.5260          -0.0220            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.8, learning_rate=0.1, score=0.325368, total=   0.0s\n",
      "[CV] n_estimators=90, subsample=0.8, learning_rate=0.1 ...............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         146.7422          53.3235            0.09s\n",
      "         2         161.7998          -4.6665            0.09s\n",
      "         3         145.2594           0.4953            0.09s\n",
      "         4         112.4802           0.5597            0.06s\n",
      "         5         108.4693          -0.3235            0.07s\n",
      "         6          84.3720           2.2330            0.07s\n",
      "         7          69.9517          15.9506            0.06s\n",
      "         8          68.6523          -0.9784            0.06s\n",
      "         9          58.5079          -5.0482            0.05s\n",
      "        10          47.8218          -1.6201            0.06s\n",
      "        20          23.9498          -0.6134            0.03s\n",
      "        30          11.5019          -0.2085            0.03s\n",
      "        40           5.3056          -0.6555            0.02s\n",
      "        50           3.5691          -0.1247            0.02s\n",
      "        60           1.8081          -0.0877            0.01s\n",
      "        70           1.2804          -0.0736            0.01s\n",
      "        80           0.8933          -0.0127            0.00s\n",
      "        90           0.4573          -0.0504            0.00s\n",
      "[CV]  n_estimators=90, subsample=0.8, learning_rate=0.1, score=0.772815, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.7, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         262.8658          -2.9054            0.10s\n",
      "         2         220.9964           4.0227            0.05s\n",
      "         3         175.4706          -0.2296            0.06s\n",
      "         4         155.9681           2.3634            0.07s\n",
      "         5          93.0879           1.1133            0.06s\n",
      "         6          73.2691          17.2805            0.06s\n",
      "         7         106.9451           0.6327            0.05s\n",
      "         8          90.4306           6.0374            0.06s\n",
      "         9          90.6089           0.5271            0.05s\n",
      "        10          61.4069           6.2804            0.05s\n",
      "        20          27.3549          -2.3446            0.04s\n",
      "        30          13.3452          -0.3527            0.03s\n",
      "        40          10.7186          -0.6676            0.03s\n",
      "        50           5.4114          -0.0995            0.02s\n",
      "        60           2.6889          -0.2712            0.02s\n",
      "        70           2.2101          -0.0189            0.01s\n",
      "        80           1.2239          -0.1190            0.01s\n",
      "        90           0.8420          -0.0063            0.00s\n",
      "       100           0.5372           0.0064            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.7, learning_rate=0.1, score=-0.389188, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.7, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         264.5848          -3.7668            0.10s\n",
      "         2         222.3572          -1.0804            0.10s\n",
      "         3         178.0437          -0.3488            0.10s\n",
      "         4         153.9776           2.2977            0.10s\n",
      "         5          89.1182           1.1180            0.09s\n",
      "         6          70.7960          15.3296            0.08s\n",
      "         7         106.9559           3.3278            0.08s\n",
      "         8          90.7802           9.7359            0.08s\n",
      "         9          88.9477           1.8940            0.07s\n",
      "        10          61.5709           0.9214            0.07s\n",
      "        20          28.5320          -0.6776            0.04s\n",
      "        30          13.5926          -0.4935            0.03s\n",
      "        40           8.5681          -0.8864            0.03s\n",
      "        50           4.4795          -0.2587            0.02s\n",
      "        60           2.3636          -0.5981            0.02s\n",
      "        70           1.8063          -0.0357            0.01s\n",
      "        80           1.1920          -0.0675            0.01s\n",
      "        90           0.8484          -0.0464            0.00s\n",
      "       100           0.4848          -0.0122            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.7, learning_rate=0.1, score=-1.755624, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.7, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         262.8065          -2.4396            0.10s\n",
      "         2         218.9041           3.7570            0.05s\n",
      "         3         174.2150          -1.5867            0.06s\n",
      "         4         153.3974           0.4726            0.07s\n",
      "         5          87.8555           1.7901            0.08s\n",
      "         6          71.5664           9.2502            0.06s\n",
      "         7         108.5677           3.3918            0.07s\n",
      "         8          86.8464           9.0799            0.06s\n",
      "         9          89.7808           1.5033            0.06s\n",
      "        10          60.7715          -1.1748            0.06s\n",
      "        20          30.1439          -4.5142            0.04s\n",
      "        30          13.0760          -0.6942            0.03s\n",
      "        40           9.3088          -0.7189            0.03s\n",
      "        50           4.9462          -0.3992            0.02s\n",
      "        60           2.1532          -0.5493            0.02s\n",
      "        70           2.0892          -0.1252            0.01s\n",
      "        80           1.4059          -0.1153            0.01s\n",
      "        90           0.9292          -0.0555            0.00s\n",
      "       100           0.6334          -0.0056            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.7, learning_rate=0.1, score=-0.198422, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.7, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         256.1238          -0.3836            0.00s\n",
      "         2         211.7803           2.6240            0.05s\n",
      "         3         169.0250           0.0708            0.03s\n",
      "         4         148.4681           0.5472            0.05s\n",
      "         5          87.5807           0.3824            0.06s\n",
      "         6          64.5821           4.7040            0.05s\n",
      "         7         107.5384           2.2573            0.05s\n",
      "         8          78.2253           8.2995            0.05s\n",
      "         9          84.3936           2.3927            0.05s\n",
      "        10          57.3567          -0.9504            0.05s\n",
      "        20          26.6672          -2.7083            0.04s\n",
      "        30          13.1692          -0.8021            0.03s\n",
      "        40           8.9818          -0.1215            0.03s\n",
      "        50           4.5713          -0.2173            0.02s\n",
      "        60           1.8095          -0.2416            0.02s\n",
      "        70           1.4665          -0.0358            0.01s\n",
      "        80           0.7710          -0.0586            0.01s\n",
      "        90           0.5281          -0.0129            0.00s\n",
      "       100           0.2969          -0.0039            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.7, learning_rate=0.1, score=0.088878, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.7, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         198.0329          -0.0243            0.00s\n",
      "         2         161.7336           3.4997            0.05s\n",
      "         3         137.5545          -0.1031            0.06s\n",
      "         4         111.2589           1.4515            0.07s\n",
      "         5          54.1124           0.7492            0.08s\n",
      "         6          58.8313           5.8361            0.06s\n",
      "         7          83.1991          -0.5532            0.07s\n",
      "         8          73.7525          -1.5827            0.06s\n",
      "         9          70.2469          -0.0856            0.06s\n",
      "        10          53.4014          -1.4817            0.06s\n",
      "        20          21.7508           0.3439            0.04s\n",
      "        30          11.1034          -0.1016            0.03s\n",
      "        40           5.6875          -0.1346            0.03s\n",
      "        50           4.4160          -0.0298            0.02s\n",
      "        60           1.9120          -0.1330            0.02s\n",
      "        70           1.4304           0.0246            0.01s\n",
      "        80           1.0048          -0.0601            0.01s\n",
      "        90           0.6576          -0.0464            0.00s\n",
      "       100           0.3930          -0.0580            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.7, learning_rate=0.1, score=-0.634693, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.7, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         204.1237          30.8578            0.00s\n",
      "         2         176.2616          28.1649            0.05s\n",
      "         3         174.6204           2.2035            0.03s\n",
      "         4         132.3285           0.3386            0.05s\n",
      "         5          87.6627           0.8449            0.06s\n",
      "         6          86.9300          -2.1871            0.05s\n",
      "         7          85.0056          11.4036            0.05s\n",
      "         8          92.4498          -0.4039            0.05s\n",
      "         9          77.0537          -0.0198            0.05s\n",
      "        10          69.9551           6.5173            0.04s\n",
      "        20          30.4621          -1.8251            0.03s\n",
      "        30          17.7524           0.2619            0.03s\n",
      "        40           9.5849          -0.2988            0.03s\n",
      "        50           4.2173          -0.2147            0.02s\n",
      "        60           2.3130          -0.1748            0.02s\n",
      "        70           1.7250          -0.0905            0.01s\n",
      "        80           1.0800          -0.0423            0.01s\n",
      "        90           0.6444          -0.0724            0.00s\n",
      "       100           0.4285          -0.0508            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.7, learning_rate=0.1, score=-0.590292, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.7, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         123.7072           1.5255            0.00s\n",
      "         2         107.3706          28.2098            0.05s\n",
      "         3         139.4616           0.7118            0.03s\n",
      "         4         101.6939           1.9011            0.05s\n",
      "         5          94.7211          -1.5840            0.06s\n",
      "         6          95.5368           0.9291            0.05s\n",
      "         7          46.8264           8.6758            0.05s\n",
      "         8          75.9240          -0.4583            0.05s\n",
      "         9          60.5617           1.5385            0.05s\n",
      "        10          52.8697          -0.9924            0.05s\n",
      "        20          24.8743           0.2826            0.04s\n",
      "        30          14.0894           0.0077            0.03s\n",
      "        40           7.1751          -0.5242            0.03s\n",
      "        50           3.6592          -0.1535            0.02s\n",
      "        60           2.4073          -0.2283            0.02s\n",
      "        70           1.5628          -0.0877            0.01s\n",
      "        80           0.8685          -0.0603            0.01s\n",
      "        90           0.6701          -0.0429            0.00s\n",
      "       100           0.4802          -0.0349            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.7, learning_rate=0.1, score=0.187306, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.7, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         208.0202          30.0677            0.00s\n",
      "         2         175.4719          25.9461            0.05s\n",
      "         3         183.9487           0.2350            0.03s\n",
      "         4         140.4071           2.5427            0.05s\n",
      "         5          88.6856           0.3884            0.06s\n",
      "         6         124.3057           0.2204            0.05s\n",
      "         7          78.6821          12.0933            0.05s\n",
      "         8          89.8906          -2.7397            0.06s\n",
      "         9          57.7148           0.5756            0.05s\n",
      "        10          68.9297           4.1508            0.05s\n",
      "        20          31.8865           0.3512            0.04s\n",
      "        30          14.8773          -2.0780            0.03s\n",
      "        40           8.4074           0.1711            0.02s\n",
      "        50           3.8872          -0.3233            0.02s\n",
      "        60           2.3021          -0.0918            0.02s\n",
      "        70           1.6735          -0.0649            0.01s\n",
      "        80           0.8396          -0.1053            0.01s\n",
      "        90           0.5531          -0.0812            0.00s\n",
      "       100           0.3442          -0.0569            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.7, learning_rate=0.1, score=-5.297625, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.7, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         144.2561          67.0223            0.00s\n",
      "         2         187.6820          -3.7931            0.05s\n",
      "         3         144.9588          21.1933            0.03s\n",
      "         4         107.1331          13.7385            0.05s\n",
      "         5         120.0382           0.9391            0.04s\n",
      "         6         101.0801          -0.3243            0.05s\n",
      "         7          74.4217           8.9459            0.04s\n",
      "         8          72.5340           0.9129            0.05s\n",
      "         9          47.2228          -0.9725            0.04s\n",
      "        10          54.3601           0.3420            0.05s\n",
      "        20          24.1906           0.1054            0.03s\n",
      "        30          13.3715          -1.8196            0.03s\n",
      "        40           5.8459          -0.0281            0.03s\n",
      "        50           3.8378          -0.3121            0.02s\n",
      "        60           2.0764          -0.1366            0.02s\n",
      "        70           1.7798          -0.0225            0.01s\n",
      "        80           0.9801          -0.0229            0.01s\n",
      "        90           0.5575          -0.0328            0.00s\n",
      "       100           0.3794          -0.0287            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.7, learning_rate=0.1, score=0.305688, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.7, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         152.3957          34.5125            0.10s\n",
      "         2         166.4078          -6.6912            0.10s\n",
      "         3         160.8578           1.3137            0.10s\n",
      "         4         123.6751           0.6482            0.07s\n",
      "         5         116.3182           0.9625            0.08s\n",
      "         6          94.8785           1.5927            0.06s\n",
      "         7          73.5657           7.7550            0.07s\n",
      "         8          75.5867          -0.2429            0.06s\n",
      "         9          44.8079           3.5097            0.06s\n",
      "        10          52.9112          -2.0431            0.06s\n",
      "        20          22.5081          -0.8693            0.04s\n",
      "        30          13.8569          -1.3059            0.03s\n",
      "        40           8.3869          -0.4379            0.02s\n",
      "        50           5.4156          -0.2633            0.02s\n",
      "        60           2.8133          -0.1942            0.02s\n",
      "        70           2.0319          -0.0381            0.01s\n",
      "        80           1.4464          -0.0309            0.01s\n",
      "        90           0.8056          -0.0742            0.00s\n",
      "       100           0.5242          -0.0003            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.7, learning_rate=0.1, score=0.715515, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.75, learning_rate=0.1 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         244.9091          -4.7851            0.00s\n",
      "         2         204.8047           1.7528            0.05s\n",
      "         3         165.3122          -0.7743            0.03s\n",
      "         4         150.0433           2.3150            0.05s\n",
      "         5          94.9605           4.1643            0.04s\n",
      "         6         100.9927          17.7065            0.05s\n",
      "         7          99.5158           0.1175            0.04s\n",
      "         8          82.8676           4.2680            0.05s\n",
      "         9          85.1565           0.8391            0.04s\n",
      "        10          69.0982           1.0308            0.05s\n",
      "        20          30.0836          -0.4102            0.04s\n",
      "        30          13.6969          -0.0936            0.03s\n",
      "        40           8.6332          -0.8593            0.03s\n",
      "        50           5.2889          -0.3394            0.02s\n",
      "        60           2.5368          -0.0959            0.02s\n",
      "        70           2.6759          -0.2530            0.01s\n",
      "        80           1.3745          -0.1105            0.01s\n",
      "        90           0.9375          -0.0731            0.00s\n",
      "       100           0.6117          -0.0310            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.75, learning_rate=0.1, score=-0.122061, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.75, learning_rate=0.1 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         246.5297          -6.1481            0.00s\n",
      "         2         206.5334          -0.4408            0.05s\n",
      "         3         166.6904          -1.0804            0.03s\n",
      "         4         146.5628           3.5243            0.05s\n",
      "         5          88.8836           0.3732            0.04s\n",
      "         6          97.6289          15.4687            0.05s\n",
      "         7          97.8836          -3.5274            0.05s\n",
      "         8          82.9149          10.8805            0.06s\n",
      "         9          83.8288           3.1215            0.06s\n",
      "        10          69.5891          -1.3278            0.06s\n",
      "        20          32.2921          -0.0855            0.04s\n",
      "        30          13.7299          -0.4531            0.03s\n",
      "        40           8.8591           0.0329            0.03s\n",
      "        50           4.4111          -0.3667            0.02s\n",
      "        60           2.2717          -0.2322            0.02s\n",
      "        70           1.9045          -0.0337            0.01s\n",
      "        80           1.1721          -0.1335            0.01s\n",
      "        90           0.7883          -0.0520            0.00s\n",
      "       100           0.4706          -0.0332            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.75, learning_rate=0.1, score=-1.014025, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.75, learning_rate=0.1 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         247.6843          -5.9155            0.00s\n",
      "         2         206.6658           4.6904            0.05s\n",
      "         3         164.5391          -1.8892            0.03s\n",
      "         4         146.6786           4.5077            0.05s\n",
      "         5          88.9411           8.2152            0.06s\n",
      "         6          99.9737          13.6023            0.05s\n",
      "         7          99.8886           2.9253            0.05s\n",
      "         8          79.0966          10.5812            0.05s\n",
      "         9          81.2340           0.7805            0.05s\n",
      "        10          66.3535          -0.5691            0.05s\n",
      "        20          32.7656          -0.1217            0.04s\n",
      "        30          10.5839          -0.7432            0.04s\n",
      "        40           7.2422          -0.0295            0.03s\n",
      "        50           4.0204          -0.0575            0.02s\n",
      "        60           1.8403          -0.5365            0.02s\n",
      "        70           1.8852          -0.0092            0.01s\n",
      "        80           1.0279          -0.1075            0.01s\n",
      "        90           0.6905          -0.0302            0.00s\n",
      "       100           0.4935          -0.0205            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.75, learning_rate=0.1, score=-0.118393, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.75, learning_rate=0.1 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         241.3760           0.1692            0.00s\n",
      "         2         198.1967           2.7898            0.05s\n",
      "         3         159.3101          -0.7978            0.06s\n",
      "         4         143.5937           1.5462            0.07s\n",
      "         5          87.5214           1.9932            0.08s\n",
      "         6          96.7593          15.7438            0.06s\n",
      "         7          99.8412          -1.0981            0.07s\n",
      "         8          72.9228           8.1512            0.07s\n",
      "         9          79.8875           2.0719            0.07s\n",
      "        10          63.0211           5.0942            0.07s\n",
      "        20          28.8266          -0.2679            0.04s\n",
      "        30           9.9541          -0.6890            0.03s\n",
      "        40           7.6987          -0.0051            0.03s\n",
      "        50           3.7230           0.0512            0.02s\n",
      "        60           1.3225          -0.1323            0.02s\n",
      "        70           1.1714          -0.0116            0.01s\n",
      "        80           0.5393          -0.0714            0.01s\n",
      "        90           0.3042          -0.0578            0.00s\n",
      "       100           0.2200          -0.0205            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.75, learning_rate=0.1, score=-0.122605, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.75, learning_rate=0.1 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         186.3867          -1.1701            0.10s\n",
      "         2         154.0178           3.8243            0.10s\n",
      "         3         129.5736          -0.5592            0.06s\n",
      "         4         112.2960          -0.7840            0.07s\n",
      "         5          54.4220           7.8209            0.06s\n",
      "         6          87.8630          -1.8935            0.06s\n",
      "         7          74.6408          -2.0772            0.05s\n",
      "         8          64.4901          -2.5314            0.06s\n",
      "         9          64.2275          -1.2492            0.06s\n",
      "        10          47.7917          -1.3823            0.06s\n",
      "        20          22.4049           0.0228            0.04s\n",
      "        30          11.6620          -0.1287            0.03s\n",
      "        40           6.1861          -0.1299            0.03s\n",
      "        50           4.3740          -0.0734            0.02s\n",
      "        60           2.1731          -0.2737            0.02s\n",
      "        70           1.5243          -0.0220            0.01s\n",
      "        80           0.8794          -0.0599            0.01s\n",
      "        90           0.4843          -0.0506            0.00s\n",
      "       100           0.3232          -0.0365            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.75, learning_rate=0.1, score=-0.713937, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.75, learning_rate=0.1 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         190.6566          33.8868            0.10s\n",
      "         2         170.6149          30.9591            0.10s\n",
      "         3         167.5426           0.0545            0.06s\n",
      "         4         132.3537          -1.1084            0.07s\n",
      "         5          85.4612           2.4108            0.08s\n",
      "         6         112.3850          -2.1312            0.08s\n",
      "         7          86.1611           9.0458            0.07s\n",
      "         8          82.7949          -2.9607            0.07s\n",
      "         9          71.8612          -2.3986            0.06s\n",
      "        10          67.1836           5.8593            0.06s\n",
      "        20          30.9319          -0.0504            0.04s\n",
      "        30          14.1479          -0.7589            0.03s\n",
      "        40           7.6120          -0.0206            0.03s\n",
      "        50           3.8695          -0.4833            0.02s\n",
      "        60           2.7551          -0.3473            0.02s\n",
      "        70           1.8251          -0.1026            0.01s\n",
      "        80           1.1472          -0.0631            0.01s\n",
      "        90           0.6874          -0.0560            0.00s\n",
      "       100           0.4294          -0.0463            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.75, learning_rate=0.1, score=-1.673257, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.75, learning_rate=0.1 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         117.0397           0.1609            0.00s\n",
      "         2         104.4567           4.1667            0.05s\n",
      "         3         139.6583           1.3361            0.06s\n",
      "         4         108.3229          -1.9874            0.05s\n",
      "         5          99.8879          -0.6580            0.06s\n",
      "         6          92.9491          -0.8423            0.05s\n",
      "         7          57.3517           9.7576            0.05s\n",
      "         8          71.2306           0.9487            0.06s\n",
      "         9          57.7076           1.2155            0.05s\n",
      "        10          52.8153           6.2931            0.05s\n",
      "        20          24.1345          -0.0577            0.04s\n",
      "        30          12.5556          -0.2512            0.03s\n",
      "        40           5.1996           0.2031            0.03s\n",
      "        50           2.4617          -0.0543            0.02s\n",
      "        60           1.6969          -0.0651            0.02s\n",
      "        70           1.1247          -0.0042            0.01s\n",
      "        80           0.5474          -0.0258            0.01s\n",
      "        90           0.3505          -0.0508            0.00s\n",
      "       100           0.2596          -0.0327            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.75, learning_rate=0.1, score=0.167881, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.75, learning_rate=0.1 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         198.0561          43.9576            0.10s\n",
      "         2         172.4489          27.4678            0.05s\n",
      "         3         175.6636           2.2493            0.06s\n",
      "         4         136.1155           1.1267            0.07s\n",
      "         5          91.3650           1.6835            0.06s\n",
      "         6         122.2101          -1.0514            0.06s\n",
      "         7          91.1172          11.7353            0.05s\n",
      "         8          90.9978          -1.4523            0.06s\n",
      "         9          56.7388           0.4585            0.06s\n",
      "        10          68.2205           5.4793            0.05s\n",
      "        20          32.6598           0.6124            0.04s\n",
      "        30          15.1800          -0.8281            0.03s\n",
      "        40           6.9259          -0.4930            0.03s\n",
      "        50           3.1232          -0.1682            0.02s\n",
      "        60           2.0481          -0.1856            0.02s\n",
      "        70           1.5368          -0.0863            0.01s\n",
      "        80           0.8316          -0.0802            0.01s\n",
      "        90           0.5944          -0.0291            0.00s\n",
      "       100           0.3783          -0.0402            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.75, learning_rate=0.1, score=-7.807005, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.75, learning_rate=0.1 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         142.6835          71.2680            0.10s\n",
      "         2         189.0696           0.9837            0.10s\n",
      "         3         143.4282          22.9831            0.06s\n",
      "         4         122.4720          -0.7270            0.07s\n",
      "         5         119.0424           0.8025            0.06s\n",
      "         6          98.2204           0.2950            0.06s\n",
      "         7          73.7368          12.0137            0.05s\n",
      "         8          70.8693           1.2037            0.07s\n",
      "         9          48.2885          -0.8560            0.07s\n",
      "        10          52.8030           2.8342            0.07s\n",
      "        20          22.3888          -2.5022            0.04s\n",
      "        30          12.5633          -0.2258            0.04s\n",
      "        40           5.3020          -0.5017            0.03s\n",
      "        50           3.6867          -0.0364            0.03s\n",
      "        60           2.0083          -0.1133            0.02s\n",
      "        70           1.4393          -0.0710            0.01s\n",
      "        80           0.8701          -0.0771            0.01s\n",
      "        90           0.5492          -0.0176            0.00s\n",
      "       100           0.3844          -0.0109            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.75, learning_rate=0.1, score=0.321895, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.75, learning_rate=0.1 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         151.3252          41.1125            0.10s\n",
      "         2         167.9958           3.5696            0.05s\n",
      "         3         153.3046           0.3679            0.06s\n",
      "         4         117.9798           1.0669            0.05s\n",
      "         5         110.2722          -0.0815            0.06s\n",
      "         6          90.0852           1.0381            0.05s\n",
      "         7          71.3803          11.8296            0.05s\n",
      "         8          72.6838           0.8961            0.05s\n",
      "         9          42.6973           2.0138            0.05s\n",
      "        10          48.3787          -1.9061            0.05s\n",
      "        20          22.7478          -1.9083            0.04s\n",
      "        30          11.6458          -1.6155            0.03s\n",
      "        40           6.9165          -0.5915            0.03s\n",
      "        50           4.9428           0.0119            0.02s\n",
      "        60           2.1780          -0.2291            0.02s\n",
      "        70           1.7922          -0.0271            0.01s\n",
      "        80           1.0614          -0.0748            0.01s\n",
      "        90           0.7408          -0.0494            0.00s\n",
      "       100           0.3940          -0.0173            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.75, learning_rate=0.1, score=0.745463, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.8, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         236.5202          -6.5556            0.00s\n",
      "         2         206.0829           2.4892            0.05s\n",
      "         3         161.6424           0.3191            0.03s\n",
      "         4         147.4986           3.0073            0.05s\n",
      "         5          95.8493           3.2118            0.04s\n",
      "         6          96.7498          21.3187            0.05s\n",
      "         7          95.6117          -0.1053            0.05s\n",
      "         8          80.3913           7.6684            0.06s\n",
      "         9          81.4958           1.1355            0.05s\n",
      "        10          67.3661           6.5160            0.05s\n",
      "        20          29.8975           0.0603            0.04s\n",
      "        30          10.9573           0.1072            0.03s\n",
      "        40           7.1681          -0.2610            0.03s\n",
      "        50           3.6195          -0.3069            0.02s\n",
      "        60           1.6530          -0.3201            0.02s\n",
      "        70           1.3471          -0.0463            0.01s\n",
      "        80           0.7892          -0.1588            0.01s\n",
      "        90           0.5446          -0.0377            0.00s\n",
      "       100           0.3915          -0.0157            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.8, learning_rate=0.1, score=-0.725652, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.8, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         237.7680          -7.4811            0.10s\n",
      "         2         208.4878           1.3715            0.15s\n",
      "         3         161.8860          -0.0891            0.13s\n",
      "         4         144.6101           2.8569            0.12s\n",
      "         5          92.2313          -1.3031            0.11s\n",
      "         6          93.7766          19.0260            0.11s\n",
      "         7          93.8149           1.3667            0.12s\n",
      "         8          79.4476          12.0193            0.11s\n",
      "         9          78.8401           1.9034            0.11s\n",
      "        10          65.9160          -1.2967            0.12s\n",
      "        20          31.2080          -0.1639            0.07s\n",
      "        30          12.1865          -0.7915            0.05s\n",
      "        40           7.0650           0.0128            0.04s\n",
      "        50           3.8679          -0.4162            0.03s\n",
      "        60           1.8699          -0.4532            0.02s\n",
      "        70           1.5845          -0.0690            0.02s\n",
      "        80           1.0757          -0.1789            0.01s\n",
      "        90           0.7011          -0.0565            0.00s\n",
      "       100           0.4875          -0.0213            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.8, learning_rate=0.1, score=-0.549614, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.8, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         236.4401          -6.6425            0.20s\n",
      "         2         205.5058           1.6582            0.15s\n",
      "         3         161.2724          -1.6024            0.10s\n",
      "         4         143.9889           2.2850            0.10s\n",
      "         5          89.0190           4.2659            0.09s\n",
      "         6          95.0057          20.6741            0.09s\n",
      "         7          93.6789           3.6990            0.09s\n",
      "         8          74.9801          11.2001            0.09s\n",
      "         9          77.8527          -0.0749            0.08s\n",
      "        10          64.1170          -1.1040            0.08s\n",
      "        20          29.3921           0.3342            0.05s\n",
      "        30          10.0306          -0.7254            0.04s\n",
      "        40           7.4300          -0.0728            0.03s\n",
      "        50           3.9377          -0.3611            0.02s\n",
      "        60           2.0240          -0.4218            0.02s\n",
      "        70           1.7748          -0.0333            0.01s\n",
      "        80           0.9935          -0.1209            0.01s\n",
      "        90           0.6019          -0.0585            0.00s\n",
      "       100           0.4125          -0.0053            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.8, learning_rate=0.1, score=-0.021883, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.8, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         230.3734           1.1228            0.00s\n",
      "         2         198.0328           1.6821            0.05s\n",
      "         3         154.5906          -2.4774            0.03s\n",
      "         4         141.3734          -0.2815            0.05s\n",
      "         5          88.0733           1.2910            0.06s\n",
      "         6          92.0782          18.8025            0.05s\n",
      "         7          95.0809           1.6771            0.05s\n",
      "         8          70.1894           8.0632            0.05s\n",
      "         9          73.8739           2.7558            0.05s\n",
      "        10          57.9961           0.0827            0.05s\n",
      "        20          26.7782          -2.2641            0.04s\n",
      "        30           9.4275          -0.6672            0.03s\n",
      "        40           6.7577          -0.0043            0.02s\n",
      "        50           3.5351          -0.0092            0.02s\n",
      "        60           1.3930          -0.2216            0.02s\n",
      "        70           0.9987           0.0212            0.01s\n",
      "        80           0.5434          -0.0899            0.01s\n",
      "        90           0.3248          -0.0850            0.00s\n",
      "       100           0.2362           0.0049            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.8, learning_rate=0.1, score=-0.170463, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.8, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         182.1397          -1.9354            0.10s\n",
      "         2         157.5296          -0.0847            0.05s\n",
      "         3         126.0536          -1.6761            0.06s\n",
      "         4         112.6346           0.3971            0.05s\n",
      "         5          55.9613           4.0620            0.06s\n",
      "         6          82.9701          -5.1848            0.05s\n",
      "         7          73.1678          -3.5716            0.05s\n",
      "         8          62.6832          -4.1683            0.05s\n",
      "         9          66.0019          -1.9104            0.05s\n",
      "        10          49.3426           0.1143            0.04s\n",
      "        20          22.4788           0.6244            0.04s\n",
      "        30          10.1968           0.1914            0.03s\n",
      "        40           6.0474          -0.1280            0.02s\n",
      "        50           2.9843          -0.0751            0.02s\n",
      "        60           1.6181          -0.2566            0.02s\n",
      "        70           1.0421          -0.0097            0.01s\n",
      "        80           0.6708          -0.0438            0.01s\n",
      "        90           0.4020          -0.0667            0.00s\n",
      "       100           0.2838          -0.0147            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.8, learning_rate=0.1, score=-0.739069, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.8, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         187.9873          41.7830            0.00s\n",
      "         2         171.9537          37.4702            0.05s\n",
      "         3         161.0043          -1.7492            0.03s\n",
      "         4         132.5319          -0.4276            0.05s\n",
      "         5          83.7036           3.4274            0.06s\n",
      "         6         108.0456          -1.5220            0.05s\n",
      "         7          84.8802          10.2830            0.05s\n",
      "         8          82.6213           0.3530            0.05s\n",
      "         9          70.1084          -1.6202            0.05s\n",
      "        10          64.2965           7.8351            0.05s\n",
      "        20          27.9639           0.7302            0.03s\n",
      "        30          12.1517          -0.3748            0.03s\n",
      "        40           6.6993          -0.2320            0.02s\n",
      "        50           3.8244          -0.2816            0.02s\n",
      "        60           2.2081          -0.1196            0.02s\n",
      "        70           1.4550          -0.0662            0.01s\n",
      "        80           0.9976          -0.0397            0.01s\n",
      "        90           0.5502          -0.0688            0.00s\n",
      "       100           0.3665          -0.0935            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.8, learning_rate=0.1, score=-1.723572, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.8, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         118.4191           7.2077            0.10s\n",
      "         2         111.4162          34.7246            0.05s\n",
      "         3         128.4961          -1.2471            0.06s\n",
      "         4         101.9903           0.0780            0.05s\n",
      "         5          90.5179          -0.2382            0.06s\n",
      "         6          84.1471          -0.9777            0.05s\n",
      "         7          55.0324          10.6068            0.05s\n",
      "         8          67.7334          -0.3540            0.05s\n",
      "         9          55.3630           1.6033            0.05s\n",
      "        10          49.1757          -0.2559            0.04s\n",
      "        20          21.8009          -0.2318            0.04s\n",
      "        30          11.1556          -0.1374            0.03s\n",
      "        40           5.0889          -0.0484            0.02s\n",
      "        50           3.3043          -0.1897            0.02s\n",
      "        60           1.7803          -0.1126            0.02s\n",
      "        70           1.0669          -0.0406            0.01s\n",
      "        80           0.6983          -0.0174            0.01s\n",
      "        90           0.4523          -0.0487            0.00s\n",
      "       100           0.3234          -0.0472            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.8, learning_rate=0.1, score=0.148991, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.8, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         193.2021          53.5973            0.10s\n",
      "         2         171.7450          37.9446            0.05s\n",
      "         3         167.3416           0.6678            0.06s\n",
      "         4         131.5012           2.9652            0.07s\n",
      "         5          86.9403           2.2613            0.06s\n",
      "         6         113.4580          -3.5376            0.06s\n",
      "         7          88.0329          16.0978            0.07s\n",
      "         8          86.4696          -0.7687            0.06s\n",
      "         9          52.3169           3.3993            0.06s\n",
      "        10          65.2144           8.5409            0.05s\n",
      "        20          29.6667          -0.3534            0.04s\n",
      "        30          13.2457          -1.3142            0.03s\n",
      "        40           6.8857          -0.3391            0.03s\n",
      "        50           4.1882          -0.3036            0.02s\n",
      "        60           2.2326          -0.1642            0.02s\n",
      "        70           1.3692          -0.0830            0.01s\n",
      "        80           0.8741          -0.0857            0.01s\n",
      "        90           0.5994          -0.0440            0.00s\n",
      "       100           0.4081          -0.0607            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.8, learning_rate=0.1, score=-4.104483, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.8, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         136.6496          95.9320            0.10s\n",
      "         2         180.2674          -2.4761            0.10s\n",
      "         3         132.6954          29.7444            0.06s\n",
      "         4         113.7503           0.7629            0.07s\n",
      "         5         110.0132           0.1133            0.06s\n",
      "         6          91.4702          -0.3071            0.06s\n",
      "         7          70.0900          15.0178            0.05s\n",
      "         8          68.4053           1.2771            0.06s\n",
      "         9          58.6432          -0.7747            0.05s\n",
      "        10          47.6259           2.3104            0.05s\n",
      "        20          22.4320          -0.8196            0.04s\n",
      "        30          11.1800          -1.4659            0.03s\n",
      "        40           5.1423          -0.2741            0.02s\n",
      "        50           3.8472          -0.1251            0.02s\n",
      "        60           2.0987          -0.1041            0.02s\n",
      "        70           1.4384          -0.0481            0.01s\n",
      "        80           0.8831          -0.0498            0.01s\n",
      "        90           0.5260          -0.0220            0.00s\n",
      "       100           0.3497          -0.0591            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.8, learning_rate=0.1, score=0.311486, total=   0.0s\n",
      "[CV] n_estimators=100, subsample=0.8, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         146.7422          53.3235            0.00s\n",
      "         2         161.7998          -4.6665            0.05s\n",
      "         3         145.2594           0.4953            0.03s\n",
      "         4         112.4802           0.5597            0.05s\n",
      "         5         108.4693          -0.3235            0.06s\n",
      "         6          84.3720           2.2330            0.05s\n",
      "         7          69.9517          15.9506            0.05s\n",
      "         8          68.6523          -0.9784            0.06s\n",
      "         9          58.5079          -5.0482            0.06s\n",
      "        10          47.8218          -1.6201            0.05s\n",
      "        20          23.9498          -0.6134            0.04s\n",
      "        30          11.5019          -0.2085            0.03s\n",
      "        40           5.3056          -0.6555            0.03s\n",
      "        50           3.5691          -0.1247            0.02s\n",
      "        60           1.8081          -0.0877            0.02s\n",
      "        70           1.2804          -0.0736            0.01s\n",
      "        80           0.8933          -0.0127            0.01s\n",
      "        90           0.4573          -0.0504            0.00s\n",
      "       100           0.3232          -0.0329            0.00s\n",
      "[CV]  n_estimators=100, subsample=0.8, learning_rate=0.1, score=0.778107, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.7, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         262.8658          -2.9054            0.40s\n",
      "         2         220.9964           4.0227            0.30s\n",
      "         3         175.4706          -0.2296            0.26s\n",
      "         4         155.9681           2.3634            0.20s\n",
      "         5          93.0879           1.1133            0.19s\n",
      "         6          73.2691          17.2805            0.16s\n",
      "         7         106.9451           0.6327            0.17s\n",
      "         8          90.4306           6.0374            0.14s\n",
      "         9          90.6089           0.5271            0.15s\n",
      "        10          61.4069           6.2804            0.13s\n",
      "        20          27.3549          -2.3446            0.09s\n",
      "        30          13.3452          -0.3527            0.07s\n",
      "        40          10.7186          -0.6676            0.07s\n",
      "        50           5.4114          -0.0995            0.07s\n",
      "        60           2.6889          -0.2712            0.06s\n",
      "        70           2.2101          -0.0189            0.05s\n",
      "        80           1.2239          -0.1190            0.05s\n",
      "        90           0.8420          -0.0063            0.04s\n",
      "       100           0.5372           0.0064            0.04s\n",
      "       200           0.0087          -0.0003            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.7, learning_rate=0.1, score=-0.307747, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.7, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         264.5848          -3.7668            0.20s\n",
      "         2         222.3572          -1.0804            0.20s\n",
      "         3         178.0437          -0.3488            0.13s\n",
      "         4         153.9776           2.2977            0.15s\n",
      "         5          89.1182           1.1180            0.16s\n",
      "         6          70.7960          15.3296            0.13s\n",
      "         7         106.9559           3.3278            0.14s\n",
      "         8          90.7802           9.7359            0.14s\n",
      "         9          88.9477           1.8940            0.13s\n",
      "        10          61.5709           0.9214            0.13s\n",
      "        20          28.5320          -0.6776            0.09s\n",
      "        30          13.5926          -0.4935            0.07s\n",
      "        40           8.5681          -0.8864            0.06s\n",
      "        50           4.4795          -0.2587            0.06s\n",
      "        60           2.3636          -0.5981            0.05s\n",
      "        70           1.8063          -0.0357            0.05s\n",
      "        80           1.1920          -0.0675            0.04s\n",
      "        90           0.8484          -0.0464            0.04s\n",
      "       100           0.4848          -0.0122            0.04s\n",
      "       200           0.0080          -0.0000            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.7, learning_rate=0.1, score=-1.792297, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.7, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         262.8065          -2.4396            0.00s\n",
      "         2         218.9041           3.7570            0.10s\n",
      "         3         174.2150          -1.5867            0.07s\n",
      "         4         153.3974           0.4726            0.10s\n",
      "         5          87.8555           1.7901            0.08s\n",
      "         6          71.5664           9.2502            0.10s\n",
      "         7         108.5677           3.3918            0.08s\n",
      "         8          86.8464           9.0799            0.10s\n",
      "         9          89.7808           1.5033            0.11s\n",
      "        10          60.7715          -1.1748            0.09s\n",
      "        20          30.1439          -4.5142            0.08s\n",
      "        30          13.0760          -0.6942            0.07s\n",
      "        40           9.3088          -0.7189            0.06s\n",
      "        50           4.9462          -0.3992            0.06s\n",
      "        60           2.1532          -0.5493            0.06s\n",
      "        70           2.0892          -0.1252            0.05s\n",
      "        80           1.4059          -0.1153            0.05s\n",
      "        90           0.9292          -0.0555            0.04s\n",
      "       100           0.6334          -0.0056            0.04s\n",
      "       200           0.0163          -0.0014            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.7, learning_rate=0.1, score=-0.205818, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.7, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         256.1238          -0.3836            0.20s\n",
      "         2         211.7803           2.6240            0.10s\n",
      "         3         169.0250           0.0708            0.13s\n",
      "         4         148.4681           0.5472            0.15s\n",
      "         5          87.5807           0.3824            0.12s\n",
      "         6          64.5821           4.7040            0.13s\n",
      "         7         107.5384           2.2573            0.14s\n",
      "         8          78.2253           8.2995            0.12s\n",
      "         9          84.3936           2.3927            0.13s\n",
      "        10          57.3567          -0.9504            0.11s\n",
      "        20          26.6672          -2.7083            0.08s\n",
      "        30          13.1692          -0.8021            0.07s\n",
      "        40           8.9818          -0.1215            0.06s\n",
      "        50           4.5713          -0.2173            0.06s\n",
      "        60           1.8095          -0.2416            0.06s\n",
      "        70           1.4665          -0.0358            0.05s\n",
      "        80           0.7710          -0.0586            0.05s\n",
      "        90           0.5281          -0.0129            0.04s\n",
      "       100           0.2969          -0.0039            0.04s\n",
      "       200           0.0026          -0.0001            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.7, learning_rate=0.1, score=0.063326, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.7, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         198.0329          -0.0243            0.20s\n",
      "         2         161.7336           3.4997            0.20s\n",
      "         3         137.5545          -0.1031            0.13s\n",
      "         4         111.2589           1.4515            0.15s\n",
      "         5          54.1124           0.7492            0.16s\n",
      "         6          58.8313           5.8361            0.16s\n",
      "         7          83.1991          -0.5532            0.17s\n",
      "         8          73.7525          -1.5827            0.17s\n",
      "         9          70.2469          -0.0856            0.17s\n",
      "        10          53.4014          -1.4817            0.17s\n",
      "        20          21.7508           0.3439            0.12s\n",
      "        30          11.1034          -0.1016            0.11s\n",
      "        40           5.6875          -0.1346            0.09s\n",
      "        50           4.4160          -0.0298            0.08s\n",
      "        60           1.9120          -0.1330            0.07s\n",
      "        70           1.4304           0.0246            0.07s\n",
      "        80           1.0048          -0.0601            0.06s\n",
      "        90           0.6576          -0.0464            0.06s\n",
      "       100           0.3930          -0.0580            0.05s\n",
      "       200           0.0061          -0.0004            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.7, learning_rate=0.1, score=-0.666260, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.7, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         204.1237          30.8578            0.00s\n",
      "         2         176.2616          28.1649            0.10s\n",
      "         3         174.6204           2.2035            0.13s\n",
      "         4         132.3285           0.3386            0.10s\n",
      "         5          87.6627           0.8449            0.12s\n",
      "         6          86.9300          -2.1871            0.10s\n",
      "         7          85.0056          11.4036            0.11s\n",
      "         8          92.4498          -0.4039            0.10s\n",
      "         9          77.0537          -0.0198            0.11s\n",
      "        10          69.9551           6.5173            0.11s\n",
      "        20          30.4621          -1.8251            0.08s\n",
      "        30          17.7524           0.2619            0.07s\n",
      "        40           9.5849          -0.2988            0.07s\n",
      "        50           4.2173          -0.2147            0.07s\n",
      "        60           2.3130          -0.1748            0.06s\n",
      "        70           1.7250          -0.0905            0.06s\n",
      "        80           1.0800          -0.0423            0.05s\n",
      "        90           0.6444          -0.0724            0.05s\n",
      "       100           0.4285          -0.0508            0.04s\n",
      "       200           0.0097          -0.0007            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.7, learning_rate=0.1, score=-0.659893, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.7, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         123.7072           1.5255            0.20s\n",
      "         2         107.3706          28.2098            0.20s\n",
      "         3         139.4616           0.7118            0.13s\n",
      "         4         101.6939           1.9011            0.15s\n",
      "         5          94.7211          -1.5840            0.16s\n",
      "         6          95.5368           0.9291            0.13s\n",
      "         7          46.8264           8.6758            0.14s\n",
      "         8          75.9240          -0.4583            0.12s\n",
      "         9          60.5617           1.5385            0.13s\n",
      "        10          52.8697          -0.9924            0.11s\n",
      "        20          24.8743           0.2826            0.08s\n",
      "        30          14.0894           0.0077            0.07s\n",
      "        40           7.1751          -0.5242            0.07s\n",
      "        50           3.6592          -0.1535            0.06s\n",
      "        60           2.4073          -0.2283            0.06s\n",
      "        70           1.5628          -0.0877            0.05s\n",
      "        80           0.8685          -0.0603            0.05s\n",
      "        90           0.6701          -0.0429            0.04s\n",
      "       100           0.4802          -0.0349            0.04s\n",
      "       200           0.0070          -0.0002            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.7, learning_rate=0.1, score=0.171016, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.7, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         208.0202          30.0677            0.20s\n",
      "         2         175.4719          25.9461            0.10s\n",
      "         3         183.9487           0.2350            0.13s\n",
      "         4         140.4071           2.5427            0.15s\n",
      "         5          88.6856           0.3884            0.12s\n",
      "         6         124.3057           0.2204            0.13s\n",
      "         7          78.6821          12.0933            0.11s\n",
      "         8          89.8906          -2.7397            0.12s\n",
      "         9          57.7148           0.5756            0.11s\n",
      "        10          68.9297           4.1508            0.11s\n",
      "        20          31.8865           0.3512            0.09s\n",
      "        30          14.8773          -2.0780            0.09s\n",
      "        40           8.4074           0.1711            0.08s\n",
      "        50           3.8872          -0.3233            0.08s\n",
      "        60           2.3021          -0.0918            0.07s\n",
      "        70           1.6735          -0.0649            0.06s\n",
      "        80           0.8396          -0.1053            0.06s\n",
      "        90           0.5531          -0.0812            0.05s\n",
      "       100           0.3442          -0.0569            0.05s\n",
      "       200           0.0053          -0.0007            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.7, learning_rate=0.1, score=-5.263758, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.7, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         144.2561          67.0223            0.20s\n",
      "         2         187.6820          -3.7931            0.20s\n",
      "         3         144.9588          21.1933            0.26s\n",
      "         4         107.1331          13.7385            0.29s\n",
      "         5         120.0382           0.9391            0.31s\n",
      "         6         101.0801          -0.3243            0.29s\n",
      "         7          74.4217           8.9459            0.30s\n",
      "         8          72.5340           0.9129            0.29s\n",
      "         9          47.2228          -0.9725            0.28s\n",
      "        10          54.3601           0.3420            0.29s\n",
      "        20          24.1906           0.1054            0.18s\n",
      "        30          13.3715          -1.8196            0.13s\n",
      "        40           5.8459          -0.0281            0.12s\n",
      "        50           3.8378          -0.3121            0.11s\n",
      "        60           2.0764          -0.1366            0.09s\n",
      "        70           1.7798          -0.0225            0.08s\n",
      "        80           0.9801          -0.0229            0.07s\n",
      "        90           0.5575          -0.0328            0.07s\n",
      "       100           0.3794          -0.0287            0.06s\n",
      "       200           0.0101          -0.0004            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.7, learning_rate=0.1, score=0.333175, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.7, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         152.3957          34.5125            0.20s\n",
      "         2         166.4078          -6.6912            0.20s\n",
      "         3         160.8578           1.3137            0.20s\n",
      "         4         123.6751           0.6482            0.20s\n",
      "         5         116.3182           0.9625            0.23s\n",
      "         6          94.8785           1.5927            0.23s\n",
      "         7          73.5657           7.7550            0.22s\n",
      "         8          75.5867          -0.2429            0.22s\n",
      "         9          44.8079           3.5097            0.21s\n",
      "        10          52.9112          -2.0431            0.21s\n",
      "        20          22.5081          -0.8693            0.13s\n",
      "        30          13.8569          -1.3059            0.11s\n",
      "        40           8.3869          -0.4379            0.09s\n",
      "        50           5.4156          -0.2633            0.08s\n",
      "        60           2.8133          -0.1942            0.07s\n",
      "        70           2.0319          -0.0381            0.07s\n",
      "        80           1.4464          -0.0309            0.06s\n",
      "        90           0.8056          -0.0742            0.05s\n",
      "       100           0.5242          -0.0003            0.05s\n",
      "       200           0.0125          -0.0010            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.7, learning_rate=0.1, score=0.719511, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.75, learning_rate=0.1 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         244.9091          -4.7851            0.20s\n",
      "         2         204.8047           1.7528            0.10s\n",
      "         3         165.3122          -0.7743            0.13s\n",
      "         4         150.0433           2.3150            0.10s\n",
      "         5          94.9605           4.1643            0.12s\n",
      "         6         100.9927          17.7065            0.13s\n",
      "         7          99.5158           0.1175            0.11s\n",
      "         8          82.8676           4.2680            0.12s\n",
      "         9          85.1565           0.8391            0.13s\n",
      "        10          69.0982           1.0308            0.11s\n",
      "        20          30.0836          -0.4102            0.08s\n",
      "        30          13.6969          -0.0936            0.07s\n",
      "        40           8.6332          -0.8593            0.07s\n",
      "        50           5.2889          -0.3394            0.07s\n",
      "        60           2.5368          -0.0959            0.06s\n",
      "        70           2.6759          -0.2530            0.05s\n",
      "        80           1.3745          -0.1105            0.05s\n",
      "        90           0.9375          -0.0731            0.04s\n",
      "       100           0.6117          -0.0310            0.04s\n",
      "       200           0.0095          -0.0009            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.75, learning_rate=0.1, score=-0.084152, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.75, learning_rate=0.1 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         246.5297          -6.1481            0.00s\n",
      "         2         206.5334          -0.4408            0.20s\n",
      "         3         166.6904          -1.0804            0.20s\n",
      "         4         146.5628           3.5243            0.15s\n",
      "         5          88.8836           0.3732            0.16s\n",
      "         6          97.6289          15.4687            0.13s\n",
      "         7          97.8836          -3.5274            0.14s\n",
      "         8          82.9149          10.8805            0.14s\n",
      "         9          83.8288           3.1215            0.13s\n",
      "        10          69.5891          -1.3278            0.13s\n",
      "        20          32.2921          -0.0855            0.09s\n",
      "        30          13.7299          -0.4531            0.08s\n",
      "        40           8.8591           0.0329            0.07s\n",
      "        50           4.4111          -0.3667            0.07s\n",
      "        60           2.2717          -0.2322            0.06s\n",
      "        70           1.9045          -0.0337            0.06s\n",
      "        80           1.1721          -0.1335            0.05s\n",
      "        90           0.7883          -0.0520            0.05s\n",
      "       100           0.4706          -0.0332            0.04s\n",
      "       200           0.0064          -0.0004            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.75, learning_rate=0.1, score=-1.155313, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.75, learning_rate=0.1 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         247.6843          -5.9155            0.20s\n",
      "         2         206.6658           4.6904            0.10s\n",
      "         3         164.5391          -1.8892            0.13s\n",
      "         4         146.6786           4.5077            0.15s\n",
      "         5          88.9411           8.2152            0.16s\n",
      "         6          99.9737          13.6023            0.16s\n",
      "         7          99.8886           2.9253            0.17s\n",
      "         8          79.0966          10.5812            0.17s\n",
      "         9          81.2340           0.7805            0.15s\n",
      "        10          66.3535          -0.5691            0.15s\n",
      "        20          32.7656          -0.1217            0.10s\n",
      "        30          10.5839          -0.7432            0.09s\n",
      "        40           7.2422          -0.0295            0.08s\n",
      "        50           4.0204          -0.0575            0.07s\n",
      "        60           1.8403          -0.5365            0.06s\n",
      "        70           1.8852          -0.0092            0.06s\n",
      "        80           1.0279          -0.1075            0.05s\n",
      "        90           0.6905          -0.0302            0.05s\n",
      "       100           0.4935          -0.0205            0.04s\n",
      "       200           0.0085          -0.0005            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.75, learning_rate=0.1, score=-0.097652, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.75, learning_rate=0.1 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         241.3760           0.1692            0.20s\n",
      "         2         198.1967           2.7898            0.20s\n",
      "         3         159.3101          -0.7978            0.13s\n",
      "         4         143.5937           1.5462            0.15s\n",
      "         5          87.5214           1.9932            0.16s\n",
      "         6          96.7593          15.7438            0.13s\n",
      "         7          99.8412          -1.0981            0.14s\n",
      "         8          72.9228           8.1512            0.14s\n",
      "         9          79.8875           2.0719            0.15s\n",
      "        10          63.0211           5.0942            0.13s\n",
      "        20          28.8266          -0.2679            0.09s\n",
      "        30           9.9541          -0.6890            0.07s\n",
      "        40           7.6987          -0.0051            0.07s\n",
      "        50           3.7230           0.0512            0.06s\n",
      "        60           1.3225          -0.1323            0.06s\n",
      "        70           1.1714          -0.0116            0.06s\n",
      "        80           0.5393          -0.0714            0.05s\n",
      "        90           0.3042          -0.0578            0.05s\n",
      "       100           0.2200          -0.0205            0.04s\n",
      "       200           0.0023          -0.0002            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.75, learning_rate=0.1, score=-0.139677, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.75, learning_rate=0.1 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         186.3867          -1.1701            0.20s\n",
      "         2         154.0178           3.8243            0.20s\n",
      "         3         129.5736          -0.5592            0.20s\n",
      "         4         112.2960          -0.7840            0.15s\n",
      "         5          54.4220           7.8209            0.16s\n",
      "         6          87.8630          -1.8935            0.13s\n",
      "         7          74.6408          -2.0772            0.14s\n",
      "         8          64.4901          -2.5314            0.14s\n",
      "         9          64.2275          -1.2492            0.13s\n",
      "        10          47.7917          -1.3823            0.13s\n",
      "        20          22.4049           0.0228            0.09s\n",
      "        30          11.6620          -0.1287            0.08s\n",
      "        40           6.1861          -0.1299            0.07s\n",
      "        50           4.3740          -0.0734            0.06s\n",
      "        60           2.1731          -0.2737            0.06s\n",
      "        70           1.5243          -0.0220            0.06s\n",
      "        80           0.8794          -0.0599            0.05s\n",
      "        90           0.4843          -0.0506            0.05s\n",
      "       100           0.3232          -0.0365            0.04s\n",
      "       200           0.0039          -0.0003            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.75, learning_rate=0.1, score=-0.723029, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.75, learning_rate=0.1 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         190.6566          33.8868            0.20s\n",
      "         2         170.6149          30.9591            0.20s\n",
      "         3         167.5426           0.0545            0.13s\n",
      "         4         132.3537          -1.1084            0.20s\n",
      "         5          85.4612           2.4108            0.20s\n",
      "         6         112.3850          -2.1312            0.16s\n",
      "         7          86.1611           9.0458            0.17s\n",
      "         8          82.7949          -2.9607            0.14s\n",
      "         9          71.8612          -2.3986            0.15s\n",
      "        10          67.1836           5.8593            0.15s\n",
      "        20          30.9319          -0.0504            0.10s\n",
      "        30          14.1479          -0.7589            0.09s\n",
      "        40           7.6120          -0.0206            0.07s\n",
      "        50           3.8695          -0.4833            0.07s\n",
      "        60           2.7551          -0.3473            0.06s\n",
      "        70           1.8251          -0.1026            0.06s\n",
      "        80           1.1472          -0.0631            0.05s\n",
      "        90           0.6874          -0.0560            0.05s\n",
      "       100           0.4294          -0.0463            0.04s\n",
      "       200           0.0089          -0.0009            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.75, learning_rate=0.1, score=-1.772571, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.75, learning_rate=0.1 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         117.0397           0.1609            0.20s\n",
      "         2         104.4567           4.1667            0.10s\n",
      "         3         139.6583           1.3361            0.13s\n",
      "         4         108.3229          -1.9874            0.10s\n",
      "         5          99.8879          -0.6580            0.12s\n",
      "         6          92.9491          -0.8423            0.10s\n",
      "         7          57.3517           9.7576            0.11s\n",
      "         8          71.2306           0.9487            0.10s\n",
      "         9          57.7076           1.2155            0.11s\n",
      "        10          52.8153           6.2931            0.10s\n",
      "        20          24.1345          -0.0577            0.08s\n",
      "        30          12.5556          -0.2512            0.07s\n",
      "        40           5.1996           0.2031            0.06s\n",
      "        50           2.4617          -0.0543            0.06s\n",
      "        60           1.6969          -0.0651            0.05s\n",
      "        70           1.1247          -0.0042            0.05s\n",
      "        80           0.5474          -0.0258            0.05s\n",
      "        90           0.3505          -0.0508            0.04s\n",
      "       100           0.2596          -0.0327            0.04s\n",
      "       200           0.0046          -0.0005            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.75, learning_rate=0.1, score=0.158938, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.75, learning_rate=0.1 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         198.0561          43.9576            0.20s\n",
      "         2         172.4489          27.4678            0.10s\n",
      "         3         175.6636           2.2493            0.13s\n",
      "         4         136.1155           1.1267            0.10s\n",
      "         5          91.3650           1.6835            0.12s\n",
      "         6         122.2101          -1.0514            0.13s\n",
      "         7          91.1172          11.7353            0.14s\n",
      "         8          90.9978          -1.4523            0.12s\n",
      "         9          56.7388           0.4585            0.13s\n",
      "        10          68.2205           5.4793            0.11s\n",
      "        20          32.6598           0.6124            0.09s\n",
      "        30          15.1800          -0.8281            0.08s\n",
      "        40           6.9259          -0.4930            0.07s\n",
      "        50           3.1232          -0.1682            0.07s\n",
      "        60           2.0481          -0.1856            0.06s\n",
      "        70           1.5368          -0.0863            0.06s\n",
      "        80           0.8316          -0.0802            0.06s\n",
      "        90           0.5944          -0.0291            0.05s\n",
      "       100           0.3783          -0.0402            0.05s\n",
      "       200           0.0066          -0.0005            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.75, learning_rate=0.1, score=-7.789378, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.75, learning_rate=0.1 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         142.6835          71.2680            0.20s\n",
      "         2         189.0696           0.9837            0.20s\n",
      "         3         143.4282          22.9831            0.13s\n",
      "         4         122.4720          -0.7270            0.15s\n",
      "         5         119.0424           0.8025            0.16s\n",
      "         6          98.2204           0.2950            0.16s\n",
      "         7          73.7368          12.0137            0.14s\n",
      "         8          70.8693           1.2037            0.14s\n",
      "         9          48.2885          -0.8560            0.13s\n",
      "        10          52.8030           2.8342            0.13s\n",
      "        20          22.3888          -2.5022            0.11s\n",
      "        30          12.5633          -0.2258            0.09s\n",
      "        40           5.3020          -0.5017            0.08s\n",
      "        50           3.6867          -0.0364            0.08s\n",
      "        60           2.0083          -0.1133            0.07s\n",
      "        70           1.4393          -0.0710            0.07s\n",
      "        80           0.8701          -0.0771            0.06s\n",
      "        90           0.5492          -0.0176            0.06s\n",
      "       100           0.3844          -0.0109            0.05s\n",
      "       200           0.0083          -0.0002            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.75, learning_rate=0.1, score=0.336192, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.75, learning_rate=0.1 .............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         151.3252          41.1125            0.20s\n",
      "         2         167.9958           3.5696            0.20s\n",
      "         3         153.3046           0.3679            0.13s\n",
      "         4         117.9798           1.0669            0.15s\n",
      "         5         110.2722          -0.0815            0.12s\n",
      "         6          90.0852           1.0381            0.13s\n",
      "         7          71.3803          11.8296            0.11s\n",
      "         8          72.6838           0.8961            0.12s\n",
      "         9          42.6973           2.0138            0.13s\n",
      "        10          48.3787          -1.9061            0.11s\n",
      "        20          22.7478          -1.9083            0.08s\n",
      "        30          11.6458          -1.6155            0.07s\n",
      "        40           6.9165          -0.5915            0.07s\n",
      "        50           4.9428           0.0119            0.07s\n",
      "        60           2.1780          -0.2291            0.07s\n",
      "        70           1.7922          -0.0271            0.06s\n",
      "        80           1.0614          -0.0748            0.06s\n",
      "        90           0.7408          -0.0494            0.05s\n",
      "       100           0.3940          -0.0173            0.04s\n",
      "       200           0.0110          -0.0003            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.75, learning_rate=0.1, score=0.761379, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.8, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         236.5202          -6.5556            0.20s\n",
      "         2         206.0829           2.4892            0.10s\n",
      "         3         161.6424           0.3191            0.13s\n",
      "         4         147.4986           3.0073            0.10s\n",
      "         5          95.8493           3.2118            0.12s\n",
      "         6          96.7498          21.3187            0.10s\n",
      "         7          95.6117          -0.1053            0.11s\n",
      "         8          80.3913           7.6684            0.10s\n",
      "         9          81.4958           1.1355            0.11s\n",
      "        10          67.3661           6.5160            0.11s\n",
      "        20          29.8975           0.0603            0.09s\n",
      "        30          10.9573           0.1072            0.08s\n",
      "        40           7.1681          -0.2610            0.07s\n",
      "        50           3.6195          -0.3069            0.07s\n",
      "        60           1.6530          -0.3201            0.06s\n",
      "        70           1.3471          -0.0463            0.06s\n",
      "        80           0.7892          -0.1588            0.05s\n",
      "        90           0.5446          -0.0377            0.05s\n",
      "       100           0.3915          -0.0157            0.05s\n",
      "       200           0.0052          -0.0005            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.8, learning_rate=0.1, score=-0.768182, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.8, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         237.7680          -7.4811            0.00s\n",
      "         2         208.4878           1.3715            0.10s\n",
      "         3         161.8860          -0.0891            0.07s\n",
      "         4         144.6101           2.8569            0.10s\n",
      "         5          92.2313          -1.3031            0.08s\n",
      "         6          93.7766          19.0260            0.10s\n",
      "         7          93.8149           1.3667            0.08s\n",
      "         8          79.4476          12.0193            0.10s\n",
      "         9          78.8401           1.9034            0.11s\n",
      "        10          65.9160          -1.2967            0.11s\n",
      "        20          31.2080          -0.1639            0.08s\n",
      "        30          12.1865          -0.7915            0.07s\n",
      "        40           7.0650           0.0128            0.07s\n",
      "        50           3.8679          -0.4162            0.06s\n",
      "        60           1.8699          -0.4532            0.06s\n",
      "        70           1.5845          -0.0690            0.05s\n",
      "        80           1.0757          -0.1789            0.05s\n",
      "        90           0.7011          -0.0565            0.05s\n",
      "       100           0.4875          -0.0213            0.04s\n",
      "       200           0.0085          -0.0002            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.8, learning_rate=0.1, score=-0.571087, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.8, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         236.4401          -6.6425            0.20s\n",
      "         2         205.5058           1.6582            0.10s\n",
      "         3         161.2724          -1.6024            0.13s\n",
      "         4         143.9889           2.2850            0.10s\n",
      "         5          89.0190           4.2659            0.12s\n",
      "         6          95.0057          20.6741            0.10s\n",
      "         7          93.6789           3.6990            0.11s\n",
      "         8          74.9801          11.2001            0.10s\n",
      "         9          77.8527          -0.0749            0.11s\n",
      "        10          64.1170          -1.1040            0.09s\n",
      "        20          29.3921           0.3342            0.07s\n",
      "        30          10.0306          -0.7254            0.07s\n",
      "        40           7.4300          -0.0728            0.06s\n",
      "        50           3.9377          -0.3611            0.06s\n",
      "        60           2.0240          -0.4218            0.06s\n",
      "        70           1.7748          -0.0333            0.06s\n",
      "        80           0.9935          -0.1209            0.05s\n",
      "        90           0.6019          -0.0585            0.05s\n",
      "       100           0.4125          -0.0053            0.04s\n",
      "       200           0.0055          -0.0005            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.8, learning_rate=0.1, score=-0.037047, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.8, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         230.3734           1.1228            0.00s\n",
      "         2         198.0328           1.6821            0.10s\n",
      "         3         154.5906          -2.4774            0.13s\n",
      "         4         141.3734          -0.2815            0.10s\n",
      "         5          88.0733           1.2910            0.12s\n",
      "         6          92.0782          18.8025            0.13s\n",
      "         7          95.0809           1.6771            0.11s\n",
      "         8          70.1894           8.0632            0.12s\n",
      "         9          73.8739           2.7558            0.13s\n",
      "        10          57.9961           0.0827            0.11s\n",
      "        20          26.7782          -2.2641            0.09s\n",
      "        30           9.4275          -0.6672            0.07s\n",
      "        40           6.7577          -0.0043            0.06s\n",
      "        50           3.5351          -0.0092            0.06s\n",
      "        60           1.3930          -0.2216            0.06s\n",
      "        70           0.9987           0.0212            0.06s\n",
      "        80           0.5434          -0.0899            0.05s\n",
      "        90           0.3248          -0.0850            0.05s\n",
      "       100           0.2362           0.0049            0.05s\n",
      "       200           0.0022          -0.0000            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.8, learning_rate=0.1, score=-0.185814, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.8, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         182.1397          -1.9354            0.00s\n",
      "         2         157.5296          -0.0847            0.10s\n",
      "         3         126.0536          -1.6761            0.13s\n",
      "         4         112.6346           0.3971            0.20s\n",
      "         5          55.9613           4.0620            0.16s\n",
      "         6          82.9701          -5.1848            0.16s\n",
      "         7          73.1678          -3.5716            0.17s\n",
      "         8          62.6832          -4.1683            0.19s\n",
      "         9          66.0019          -1.9104            0.21s\n",
      "        10          49.3426           0.1143            0.21s\n",
      "        20          22.4788           0.6244            0.14s\n",
      "        30          10.1968           0.1914            0.12s\n",
      "        40           6.0474          -0.1280            0.10s\n",
      "        50           2.9843          -0.0751            0.10s\n",
      "        60           1.6181          -0.2566            0.09s\n",
      "        70           1.0421          -0.0097            0.08s\n",
      "        80           0.6708          -0.0438            0.07s\n",
      "        90           0.4020          -0.0667            0.07s\n",
      "       100           0.2838          -0.0147            0.06s\n",
      "       200           0.0026          -0.0001            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.8, learning_rate=0.1, score=-0.762320, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.8, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         187.9873          41.7830            0.20s\n",
      "         2         171.9537          37.4702            0.20s\n",
      "         3         161.0043          -1.7492            0.20s\n",
      "         4         132.5319          -0.4276            0.20s\n",
      "         5          83.7036           3.4274            0.19s\n",
      "         6         108.0456          -1.5220            0.19s\n",
      "         7          84.8802          10.2830            0.17s\n",
      "         8          82.6213           0.3530            0.17s\n",
      "         9          70.1084          -1.6202            0.15s\n",
      "        10          64.2965           7.8351            0.15s\n",
      "        20          27.9639           0.7302            0.10s\n",
      "        30          12.1517          -0.3748            0.09s\n",
      "        40           6.6993          -0.2320            0.08s\n",
      "        50           3.8244          -0.2816            0.07s\n",
      "        60           2.2081          -0.1196            0.07s\n",
      "        70           1.4550          -0.0662            0.06s\n",
      "        80           0.9976          -0.0397            0.05s\n",
      "        90           0.5502          -0.0688            0.05s\n",
      "       100           0.3665          -0.0935            0.04s\n",
      "       200           0.0053          -0.0004            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.8, learning_rate=0.1, score=-1.826490, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.8, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         118.4191           7.2077            0.00s\n",
      "         2         111.4162          34.7246            0.10s\n",
      "         3         128.4961          -1.2471            0.13s\n",
      "         4         101.9903           0.0780            0.10s\n",
      "         5          90.5179          -0.2382            0.12s\n",
      "         6          84.1471          -0.9777            0.13s\n",
      "         7          55.0324          10.6068            0.11s\n",
      "         8          67.7334          -0.3540            0.12s\n",
      "         9          55.3630           1.6033            0.13s\n",
      "        10          49.1757          -0.2559            0.11s\n",
      "        20          21.8009          -0.2318            0.09s\n",
      "        30          11.1556          -0.1374            0.08s\n",
      "        40           5.0889          -0.0484            0.07s\n",
      "        50           3.3043          -0.1897            0.07s\n",
      "        60           1.7803          -0.1126            0.06s\n",
      "        70           1.0669          -0.0406            0.05s\n",
      "        80           0.6983          -0.0174            0.05s\n",
      "        90           0.4523          -0.0487            0.05s\n",
      "       100           0.3234          -0.0472            0.04s\n",
      "       200           0.0042          -0.0002            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.8, learning_rate=0.1, score=0.139032, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.8, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         193.2021          53.5973            0.20s\n",
      "         2         171.7450          37.9446            0.10s\n",
      "         3         167.3416           0.6678            0.13s\n",
      "         4         131.5012           2.9652            0.15s\n",
      "         5          86.9403           2.2613            0.12s\n",
      "         6         113.4580          -3.5376            0.13s\n",
      "         7          88.0329          16.0978            0.11s\n",
      "         8          86.4696          -0.7687            0.12s\n",
      "         9          52.3169           3.3993            0.13s\n",
      "        10          65.2144           8.5409            0.11s\n",
      "        20          29.6667          -0.3534            0.08s\n",
      "        30          13.2457          -1.3142            0.07s\n",
      "        40           6.8857          -0.3391            0.06s\n",
      "        50           4.1882          -0.3036            0.06s\n",
      "        60           2.2326          -0.1642            0.06s\n",
      "        70           1.3692          -0.0830            0.06s\n",
      "        80           0.8741          -0.0857            0.05s\n",
      "        90           0.5994          -0.0440            0.05s\n",
      "       100           0.4081          -0.0607            0.04s\n",
      "       200           0.0073          -0.0007            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.8, learning_rate=0.1, score=-4.274215, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.8, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         136.6496          95.9320            0.20s\n",
      "         2         180.2674          -2.4761            0.20s\n",
      "         3         132.6954          29.7444            0.13s\n",
      "         4         113.7503           0.7629            0.15s\n",
      "         5         110.0132           0.1133            0.16s\n",
      "         6          91.4702          -0.3071            0.16s\n",
      "         7          70.0900          15.0178            0.14s\n",
      "         8          68.4053           1.2771            0.14s\n",
      "         9          58.6432          -0.7747            0.15s\n",
      "        10          47.6259           2.3104            0.15s\n",
      "        20          22.4320          -0.8196            0.11s\n",
      "        30          11.1800          -1.4659            0.09s\n",
      "        40           5.1423          -0.2741            0.08s\n",
      "        50           3.8472          -0.1251            0.07s\n",
      "        60           2.0987          -0.1041            0.07s\n",
      "        70           1.4384          -0.0481            0.06s\n",
      "        80           0.8831          -0.0498            0.05s\n",
      "        90           0.5260          -0.0220            0.05s\n",
      "       100           0.3497          -0.0591            0.04s\n",
      "       200           0.0061          -0.0002            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.8, learning_rate=0.1, score=0.302249, total=   0.0s\n",
      "[CV] n_estimators=200, subsample=0.8, learning_rate=0.1 ..............\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         146.7422          53.3235            0.20s\n",
      "         2         161.7998          -4.6665            0.20s\n",
      "         3         145.2594           0.4953            0.20s\n",
      "         4         112.4802           0.5597            0.15s\n",
      "         5         108.4693          -0.3235            0.16s\n",
      "         6          84.3720           2.2330            0.13s\n",
      "         7          69.9517          15.9506            0.14s\n",
      "         8          68.6523          -0.9784            0.14s\n",
      "         9          58.5079          -5.0482            0.13s\n",
      "        10          47.8218          -1.6201            0.13s\n",
      "        20          23.9498          -0.6134            0.10s\n",
      "        30          11.5019          -0.2085            0.08s\n",
      "        40           5.3056          -0.6555            0.08s\n",
      "        50           3.5691          -0.1247            0.07s\n",
      "        60           1.8081          -0.0877            0.06s\n",
      "        70           1.2804          -0.0736            0.06s\n",
      "        80           0.8933          -0.0127            0.05s\n",
      "        90           0.4573          -0.0504            0.05s\n",
      "       100           0.3232          -0.0329            0.04s\n",
      "       200           0.0088          -0.0004            0.00s\n",
      "[CV]  n_estimators=200, subsample=0.8, learning_rate=0.1, score=0.787335, total=   0.0s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         208.6087          17.9625            0.06s\n",
      "         2         178.3807          14.2912            0.03s\n",
      "         3         203.4171          -0.7123            0.03s\n",
      "         4         101.4758           7.0477            0.03s\n",
      "         5         180.2248           0.4087            0.02s\n",
      "         6         151.8623           8.1572            0.02s\n",
      "         7         166.4389           1.7580            0.02s\n",
      "         8         109.5110          14.5618            0.02s\n",
      "         9         101.5439           6.9116            0.02s\n",
      "        10          76.3824           5.9221            0.01s\n",
      "        20          52.9554          -0.6139            0.00s\n",
      "        30          47.6036          -0.3546            0.00s\n",
      "--- Grid Search Completed: 0.33 minutes ---\n",
      "Best Params:\n",
      "{'n_estimators': 30, 'subsample': 0.7, 'learning_rate': 0.05}\n",
      "Best CV Score:\n",
      "0.311037539833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 540 out of 540 | elapsed:   19.4s finished\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GridSearch寻找最佳参数, 这里做的是10-fold cross validation\n",
    "\"\"\"\n",
    "start_time = time.clock()\n",
    "gbr = GradientBoostingRegressor(random_state=2017, verbose=1,criterion='mse')\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [20,30,50,60,70,80,90,100,200],\n",
    "    'learning_rate': [0.05,0.1],\n",
    "    'subsample': [0.7,0.75,0.8]\n",
    "}\n",
    "model = GridSearchCV(estimator=gbr, param_grid=param_grid, cv=10, verbose=20)\n",
    "model.fit(X_train.values, y_train.values)\n",
    "\n",
    "print('--- Grid Search Completed: %s minutes ---' % round(((time.clock() - start_time) / 60), 2))\n",
    "print('Best Params:')\n",
    "print(model.best_params_)\n",
    "print('Best CV Score:')\n",
    "print(-model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mse:46.4867097091\n",
      "Test mse:118.960753781\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Best Params:\n",
    "{'n_estimators': 30, 'subsample': 0.7, 'learning_rate': 0.05}\n",
    "Best CV Score:\n",
    "0.497504469421\n",
    "\"\"\"\n",
    "gbr_best = GradientBoostingRegressor(n_estimators=30,subsample = 0.7,learning_rate=0.05)\n",
    "gbr_best.fit(X_train,y_train)\n",
    "gbr_train_pred = gbr_best.predict(X_train)\n",
    "gbr_test_pred = gbr_best.predict(X_test)\n",
    "print 'Training mse:{}'.format(mse(y_train,gbr_train_pred)) \n",
    "print 'Test mse:{}'.format(mse(y_test,gbr_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xceb37b8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTEyiBNOgm5iYmEQJ/x/WrizQHkV9XgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcfe9a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train_range = xrange(len(y_train))\n",
    "plt.plot(x_train_range, y_train, '-',label='Train')\n",
    "plt.plot(x_train_range, gbr_train_pred, '-',label='Predict')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x112e0860>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4YJuZpYR/wWG6/8iTslkqwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112a4978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test_range = xrange(len(y_test))\n",
    "plt.plot(x_test_range, y_test, '-',label='Test')\n",
    "plt.plot(x_test_range, gbr_test_pred, '-',label='Predict')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvMAAAHiCAYAAABlZ0N0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBwykBAepMSpbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcec5400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = gbr_best.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title(\"GBR Feature importances\")\n",
    "plt.barh(range(X_train.shape[1]), importances[indices],\n",
    "           color=\"r\", align=\"center\")\n",
    "\n",
    "plt.yticks(range(X_train.shape[1]), X_train.columns[indices],rotation='horizontal')\n",
    "plt.ylim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上图可知，前6个最重要的特征里有5个是新构造的特征，同时经测试，回归结果mse也比仅用原来的特征好，这说明了新加入特征的有效性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Extra Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "[CV] n_estimators=50 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=50, score=-0.254818, total=   0.2s\n",
      "[CV] n_estimators=50 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=50, score=-0.606505, total=   0.1s\n",
      "[CV] n_estimators=50 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. n_estimators=50, score=0.208136, total=   0.1s\n",
      "[CV] n_estimators=50 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. n_estimators=50, score=0.012319, total=   0.1s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] ................. n_estimators=50, score=-0.141086, total=   0.0s\n",
      "[CV] n_estimators=50 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    1.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=50, score=-1.981074, total=   0.1s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] .................. n_estimators=50, score=0.012539, total=   0.1s\n",
      "[CV] n_estimators=50 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    1.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=50, score=-5.287142, total=   0.1s\n",
      "[CV] n_estimators=50 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    1.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. n_estimators=50, score=0.427923, total=   0.1s\n",
      "[CV] n_estimators=50 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. n_estimators=50, score=0.133282, total=   0.1s\n",
      "[CV] n_estimators=80 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    2.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=80, score=-0.466950, total=   0.2s\n",
      "[CV] n_estimators=80 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    2.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=80, score=-0.441652, total=   0.1s\n",
      "[CV] n_estimators=80 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    3.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. n_estimators=80, score=0.143941, total=   0.2s\n",
      "[CV] n_estimators=80 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:    3.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=80, score=-0.046765, total=   0.1s\n",
      "[CV] n_estimators=80 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    3.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=80, score=-0.238260, total=   0.2s\n",
      "[CV] n_estimators=80 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    3.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=80, score=-2.145041, total=   0.2s\n",
      "[CV] n_estimators=80 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:    4.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. n_estimators=80, score=0.014352, total=   0.2s\n",
      "[CV] n_estimators=80 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    4.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=80, score=-4.899021, total=   0.2s\n",
      "[CV] n_estimators=80 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:    4.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. n_estimators=80, score=0.403299, total=   0.1s\n",
      "[CV] n_estimators=80 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. n_estimators=80, score=0.121375, total=   0.1s\n",
      "[CV] n_estimators=100 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ n_estimators=100, score=-0.533114, total=   0.2s\n",
      "[CV] n_estimators=100 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ n_estimators=100, score=-0.558930, total=   0.2s\n",
      "[CV] n_estimators=100 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=100, score=0.165111, total=   0.2s\n",
      "[CV] n_estimators=100 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ n_estimators=100, score=-0.119437, total=   0.2s\n",
      "[CV] n_estimators=100 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ n_estimators=100, score=-0.212171, total=   0.2s\n",
      "[CV] n_estimators=100 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ n_estimators=100, score=-2.272169, total=   0.2s\n",
      "[CV] n_estimators=100 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=100, score=0.020337, total=   0.2s\n",
      "[CV] n_estimators=100 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ n_estimators=100, score=-4.501438, total=   0.2s\n",
      "[CV] n_estimators=100 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=100, score=0.390817, total=   0.2s\n",
      "[CV] n_estimators=100 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=100, score=0.107919, total=   0.2s\n",
      "[CV] n_estimators=200 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ n_estimators=200, score=-0.402144, total=   0.5s\n",
      "[CV] n_estimators=200 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ n_estimators=200, score=-0.825350, total=   0.5s\n",
      "[CV] n_estimators=200 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=200, score=0.191150, total=   0.5s\n",
      "[CV] n_estimators=200 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ n_estimators=200, score=-0.062758, total=   0.6s\n",
      "[CV] n_estimators=200 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ n_estimators=200, score=-0.185098, total=   0.6s\n",
      "[CV] n_estimators=200 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ n_estimators=200, score=-2.379383, total=   0.6s\n",
      "[CV] n_estimators=200 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=200, score=0.051373, total=   0.5s\n",
      "[CV] n_estimators=200 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ n_estimators=200, score=-5.524102, total=   0.6s\n",
      "[CV] n_estimators=200 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=200, score=0.391236, total=   0.5s\n",
      "[CV] n_estimators=200 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=200, score=0.075833, total=   0.5s\n",
      "[CV] n_estimators=500 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ n_estimators=500, score=-0.401524, total=   1.4s\n",
      "[CV] n_estimators=500 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ n_estimators=500, score=-0.798265, total=   1.4s\n",
      "[CV] n_estimators=500 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=500, score=0.138532, total=   1.5s\n",
      "[CV] n_estimators=500 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ n_estimators=500, score=-0.053981, total=   1.6s\n",
      "[CV] n_estimators=500 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ n_estimators=500, score=-0.198042, total=   1.5s\n",
      "[CV] n_estimators=500 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ n_estimators=500, score=-2.358779, total=   1.5s\n",
      "[CV] n_estimators=500 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=500, score=0.062104, total=   1.4s\n",
      "[CV] n_estimators=500 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ n_estimators=500, score=-5.733734, total=   1.3s\n",
      "[CV] n_estimators=500 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=500, score=0.372853, total=   1.5s\n",
      "[CV] n_estimators=500 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. n_estimators=500, score=0.100925, total=   1.6s\n",
      "--- Grid Search Completed: 0.59 minutes ---\n",
      "Best Params:\n",
      "{'n_estimators': 50}\n",
      "Best CV Score:\n",
      "0.783099205186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   35.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GridSearch寻找最佳参数, 这里做的是10-fold cross validation\n",
    "\"\"\"\n",
    "start_time = time.clock()\n",
    "etr = ExtraTreesRegressor(random_state=2017, verbose=1,criterion='mse')\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50,80,100,200,500]\n",
    "}\n",
    "model = GridSearchCV(estimator=etr, param_grid=param_grid, cv=10, verbose=20)\n",
    "model.fit(X_train.values, y_train.values)\n",
    "\n",
    "print('--- Grid Search Completed: %s minutes ---' % round(((time.clock() - start_time) / 60), 2))\n",
    "print('Best Params:')\n",
    "print(model.best_params_)\n",
    "print('Best CV Score:')\n",
    "print(-model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mse:0.0\n",
      "Test mse:153.794144\n"
     ]
    }
   ],
   "source": [
    "etr_best = ExtraTreesRegressor(n_estimators=50)\n",
    "etr_best.fit(X_train,y_train)\n",
    "etr_train_pred = etr_best.predict(X_train)\n",
    "etr_test_pred = etr_best.predict(X_test)\n",
    "print 'Training mse:{}'.format(mse(y_train,etr_train_pred)) \n",
    "print 'Test mse:{}'.format(mse(y_test,etr_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xd22b0b8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1162f400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train_range = xrange(len(y_train))\n",
    "plt.plot(x_train_range, y_train, '-',label='Train')\n",
    "plt.plot(x_train_range, etr_train_pred, '-',label='Predict')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xd085828>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f53c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test_range = xrange(len(y_test))\n",
    "plt.plot(x_test_range, y_test, '-',label='Test')\n",
    "plt.plot(x_test_range, etr_test_pred, '-',label='Predict')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvMAAAHiCAYAAABlZ0N0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9VBuzJuZmZmZ9VD/PzLBg0YUmjW0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11046f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = etr_best.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title(\"ETR Feature importances\")\n",
    "plt.barh(range(X_train.shape[1]), importances[indices],\n",
    "           color=\"r\", align=\"center\")\n",
    "\n",
    "plt.yticks(range(X_train.shape[1]), X_train.columns[indices],rotation='horizontal')\n",
    "plt.ylim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "[CV] kernel=rbf, C=0.1 ...............................................\n",
      "[CV] ............... kernel=rbf, C=0.1, score=-0.453629, total=   0.0s\n",
      "[CV] kernel=rbf, C=0.1 ...............................................\n",
      "[CV] ............... kernel=rbf, C=0.1, score=-0.845435, total=   0.0s\n",
      "[CV] kernel=rbf, C=0.1 ...............................................\n",
      "[CV] ............... kernel=rbf, C=0.1, score=-0.118823, total=   0.0s\n",
      "[CV] kernel=rbf, C=0.1 ...............................................\n",
      "[CV] ............... kernel=rbf, C=0.1, score=-0.016377, total=   0.0s\n",
      "[CV] kernel=rbf, C=0.1 ...............................................\n",
      "[CV] ............... kernel=rbf, C=0.1, score=-0.581256, total=   0.0s\n",
      "[CV] kernel=rbf, C=0.1 ...............................................\n",
      "[CV] ............... kernel=rbf, C=0.1, score=-2.025472, total=   0.0s\n",
      "[CV] kernel=rbf, C=0.1 ...............................................\n",
      "[CV] ............... kernel=rbf, C=0.1, score=-0.277237, total=   0.0s\n",
      "[CV] kernel=rbf, C=0.1 ...............................................\n",
      "[CV] ............... kernel=rbf, C=0.1, score=-0.101772, total=   0.0s\n",
      "[CV] kernel=rbf, C=0.1 ...............................................\n",
      "[CV] ............... kernel=rbf, C=0.1, score=-0.000247, total=   0.0s\n",
      "[CV] kernel=rbf, C=0.1 ...............................................\n",
      "[CV] ............... kernel=rbf, C=0.1, score=-0.162401, total=   0.0s\n",
      "[CV] kernel=poly, C=0.1 ..............................................\n",
      "[CV] .............. kernel=poly, C=0.1, score=-0.457224, total=   0.0s\n",
      "[CV] kernel=poly, C=0.1 ..............................................\n",
      "[CV] .............. kernel=poly, C=0.1, score=-0.844090, total=   0.0s\n",
      "[CV] kernel=poly, C=0.1 ..............................................\n",
      "[CV] .............. kernel=poly, C=0.1, score=-0.117888, total=   0.0s\n",
      "[CV] kernel=poly, C=0.1 ..............................................\n",
      "[CV] .............. kernel=poly, C=0.1, score=-0.018414, total=   0.0s\n",
      "[CV] kernel=poly, C=0.1 ..............................................\n",
      "[CV] .............. kernel=poly, C=0.1, score=-0.580724, total=   0.0s\n",
      "[CV] kernel=poly, C=0.1 ..............................................\n",
      "[CV] .............. kernel=poly, C=0.1, score=-2.029351, total=   0.0s\n",
      "[CV] kernel=poly, C=0.1 ..............................................\n",
      "[CV] .............. kernel=poly, C=0.1, score=-0.277629, total=   0.0s\n",
      "[CV] kernel=poly, C=0.1 ..............................................\n",
      "[CV] .............. kernel=poly, C=0.1, score=-0.097405, total=   0.0s\n",
      "[CV] kernel=poly, C=0.1 ..............................................\n",
      "[CV] .............. kernel=poly, C=0.1, score=-0.000400, total=   0.0s\n",
      "[CV] kernel=poly, C=0.1 ..............................................\n",
      "[CV] .............. kernel=poly, C=0.1, score=-0.163384, total=   0.0s\n",
      "[CV] kernel=linear, C=0.1 ............................................\n",
      "[CV] ............ kernel=linear, C=0.1, score=-0.395036, total=   0.0s\n",
      "[CV] kernel=linear, C=0.1 ............................................\n",
      "[CV] ............ kernel=linear, C=0.1, score=-0.762800, total=   0.0s\n",
      "[CV] kernel=linear, C=0.1 ............................................\n",
      "[CV] ............ kernel=linear, C=0.1, score=-0.139433, total=   0.0s\n",
      "[CV] kernel=linear, C=0.1 ............................................\n",
      "[CV] ............. kernel=linear, C=0.1, score=0.039162, total=   0.0s\n",
      "[CV] kernel=linear, C=0.1 ............................................\n",
      "[CV] ............ kernel=linear, C=0.1, score=-0.565826, total=   0.0s\n",
      "[CV] kernel=linear, C=0.1 ............................................\n",
      "[CV] ............ kernel=linear, C=0.1, score=-2.071416, total=   0.0s\n",
      "[CV] kernel=linear, C=0.1 ............................................\n",
      "[CV] ............ kernel=linear, C=0.1, score=-0.254210, total=   0.0s\n",
      "[CV] kernel=linear, C=0.1 ............................................\n",
      "[CV] ............ kernel=linear, C=0.1, score=-0.195840, total=   0.0s\n",
      "[CV] kernel=linear, C=0.1 ............................................\n",
      "[CV] ............. kernel=linear, C=0.1, score=0.009258, total=   0.0s\n",
      "[CV] kernel=linear, C=0.1 ............................................\n",
      "[CV] ............ kernel=linear, C=0.1, score=-0.141297, total=   0.0s\n",
      "[CV] kernel=rbf, C=1 .................................................\n",
      "[CV] ................. kernel=rbf, C=1, score=-0.416499, total=   0.0s\n",
      "[CV] kernel=rbf, C=1 .................................................\n",
      "[CV] ................. kernel=rbf, C=1, score=-0.813969, total=   0.0s\n",
      "[CV] kernel=rbf, C=1 .................................................\n",
      "[CV] ................. kernel=rbf, C=1, score=-0.127862, total=   0.0s\n",
      "[CV] kernel=rbf, C=1 .................................................\n",
      "[CV] .................. kernel=rbf, C=1, score=0.007427, total=   0.0s\n",
      "[CV] kernel=rbf, C=1 .................................................\n",
      "[CV] ................. kernel=rbf, C=1, score=-0.585907, total=   0.0s\n",
      "[CV] kernel=rbf, C=1 .................................................\n",
      "[CV] ................. kernel=rbf, C=1, score=-2.031916, total=   0.0s\n",
      "[CV] kernel=rbf, C=1 .................................................\n",
      "[CV] ................. kernel=rbf, C=1, score=-0.273110, total=   0.0s\n",
      "[CV] kernel=rbf, C=1 .................................................\n",
      "[CV] ................. kernel=rbf, C=1, score=-0.152538, total=   0.0s\n",
      "[CV] kernel=rbf, C=1 .................................................\n",
      "[CV] .................. kernel=rbf, C=1, score=0.002551, total=   0.0s\n",
      "[CV] kernel=rbf, C=1 .................................................\n",
      "[CV] ................. kernel=rbf, C=1, score=-0.151616, total=   0.0s\n",
      "[CV] kernel=poly, C=1 ................................................\n",
      "[CV] ................ kernel=poly, C=1, score=-0.443944, total=   0.0s\n",
      "[CV] kernel=poly, C=1 ................................................\n",
      "[CV] ................ kernel=poly, C=1, score=-0.841036, total=   0.0s\n",
      "[CV] kernel=poly, C=1 ................................................\n",
      "[CV] ................ kernel=poly, C=1, score=-0.119132, total=   0.0s\n",
      "[CV] kernel=poly, C=1 ................................................\n",
      "[CV] ................ kernel=poly, C=1, score=-0.011140, total=   0.0s\n",
      "[CV] kernel=poly, C=1 ................................................\n",
      "[CV] ................ kernel=poly, C=1, score=-0.580161, total=   0.0s\n",
      "[CV] kernel=poly, C=1 ................................................\n",
      "[CV] ................ kernel=poly, C=1, score=-2.019488, total=   0.0s\n",
      "[CV] kernel=poly, C=1 ................................................\n",
      "[CV] ................ kernel=poly, C=1, score=-0.276255, total=   0.0s\n",
      "[CV] kernel=poly, C=1 ................................................\n",
      "[CV] ................ kernel=poly, C=1, score=-0.106837, total=   0.0s\n",
      "[CV] kernel=poly, C=1 ................................................\n",
      "[CV] ................ kernel=poly, C=1, score=-0.000470, total=   0.0s\n",
      "[CV] kernel=poly, C=1 ................................................\n",
      "[CV] ................ kernel=poly, C=1, score=-0.160994, total=   0.0s\n",
      "[CV] kernel=linear, C=1 ..............................................\n",
      "[CV] .............. kernel=linear, C=1, score=-0.755135, total=   0.0s\n",
      "[CV] kernel=linear, C=1 ..............................................\n",
      "[CV] .............. kernel=linear, C=1, score=-0.833662, total=   0.0s\n",
      "[CV] kernel=linear, C=1 ..............................................\n",
      "[CV] .............. kernel=linear, C=1, score=-0.228824, total=   0.0s\n",
      "[CV] kernel=linear, C=1 ..............................................\n",
      "[CV] ............... kernel=linear, C=1, score=0.170804, total=   0.0s\n",
      "[CV] kernel=linear, C=1 ..............................................\n",
      "[CV] .............. kernel=linear, C=1, score=-0.305084, total=   0.0s\n",
      "[CV] kernel=linear, C=1 ..............................................\n",
      "[CV] .............. kernel=linear, C=1, score=-1.724301, total=   0.0s\n",
      "[CV] kernel=linear, C=1 ..............................................\n",
      "[CV] .............. kernel=linear, C=1, score=-0.140614, total=   0.0s\n",
      "[CV] kernel=linear, C=1 ..............................................\n",
      "[CV] .............. kernel=linear, C=1, score=-0.310311, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] kernel=linear, C=1 ..............................................\n",
      "[CV] ............... kernel=linear, C=1, score=0.040630, total=   0.0s\n",
      "[CV] kernel=linear, C=1 ..............................................\n",
      "[CV] .............. kernel=linear, C=1, score=-0.021050, total=   0.0s\n",
      "[CV] kernel=rbf, C=10 ................................................\n",
      "[CV] ................ kernel=rbf, C=10, score=-0.648115, total=   0.0s\n",
      "[CV] kernel=rbf, C=10 ................................................\n",
      "[CV] ................ kernel=rbf, C=10, score=-0.728190, total=   0.0s\n",
      "[CV] kernel=rbf, C=10 ................................................\n",
      "[CV] ................ kernel=rbf, C=10, score=-0.184615, total=   0.0s\n",
      "[CV] kernel=rbf, C=10 ................................................\n",
      "[CV] ................. kernel=rbf, C=10, score=0.127611, total=   0.0s\n",
      "[CV] kernel=rbf, C=10 ................................................\n",
      "[CV] ................ kernel=rbf, C=10, score=-0.453913, total=   0.0s\n",
      "[CV] kernel=rbf, C=10 ................................................\n",
      "[CV] ................ kernel=rbf, C=10, score=-1.802145, total=   0.0s\n",
      "[CV] kernel=rbf, C=10 ................................................\n",
      "[CV] ................ kernel=rbf, C=10, score=-0.194747, total=   0.0s\n",
      "[CV] kernel=rbf, C=10 ................................................\n",
      "[CV] ................ kernel=rbf, C=10, score=-0.542170, total=   0.0s\n",
      "[CV] kernel=rbf, C=10 ................................................\n",
      "[CV] ................. kernel=rbf, C=10, score=0.027521, total=   0.0s\n",
      "[CV] kernel=rbf, C=10 ................................................\n",
      "[CV] ................ kernel=rbf, C=10, score=-0.080849, total=   0.0s\n",
      "[CV] kernel=poly, C=10 ...............................................\n",
      "[CV] ............... kernel=poly, C=10, score=-0.333661, total=   0.0s\n",
      "[CV] kernel=poly, C=10 ...............................................\n",
      "[CV] ............... kernel=poly, C=10, score=-0.750198, total=   0.0s\n",
      "[CV] kernel=poly, C=10 ...............................................\n",
      "[CV] ............... kernel=poly, C=10, score=-0.130477, total=   0.0s\n",
      "[CV] kernel=poly, C=10 ...............................................\n",
      "[CV] ................ kernel=poly, C=10, score=0.052323, total=   0.0s\n",
      "[CV] kernel=poly, C=10 ...............................................\n",
      "[CV] ............... kernel=poly, C=10, score=-0.566231, total=   0.0s\n",
      "[CV] kernel=poly, C=10 ...............................................\n",
      "[CV] ............... kernel=poly, C=10, score=-1.990395, total=   0.0s\n",
      "[CV] kernel=poly, C=10 ...............................................\n",
      "[CV] ............... kernel=poly, C=10, score=-0.255622, total=   0.0s\n",
      "[CV] kernel=poly, C=10 ...............................................\n",
      "[CV] ............... kernel=poly, C=10, score=-0.204512, total=   0.0s\n",
      "[CV] kernel=poly, C=10 ...............................................\n",
      "[CV] ................ kernel=poly, C=10, score=0.002945, total=   0.0s\n",
      "[CV] kernel=poly, C=10 ...............................................\n",
      "[CV] ............... kernel=poly, C=10, score=-0.140598, total=   0.0s\n",
      "[CV] kernel=linear, C=10 .............................................\n",
      "[CV] ............. kernel=linear, C=10, score=-0.472520, total=   0.0s\n",
      "[CV] kernel=linear, C=10 .............................................\n",
      "[CV] ............. kernel=linear, C=10, score=-0.634569, total=   0.0s\n",
      "[CV] kernel=linear, C=10 .............................................\n",
      "[CV] ............. kernel=linear, C=10, score=-0.211210, total=   0.0s\n",
      "[CV] kernel=linear, C=10 .............................................\n",
      "[CV] .............. kernel=linear, C=10, score=0.259280, total=   0.0s\n",
      "[CV] kernel=linear, C=10 .............................................\n",
      "[CV] .............. kernel=linear, C=10, score=0.136697, total=   0.0s\n",
      "[CV] kernel=linear, C=10 .............................................\n",
      "[CV] ............. kernel=linear, C=10, score=-1.447099, total=   0.0s\n",
      "[CV] kernel=linear, C=10 .............................................\n",
      "[CV] .............. kernel=linear, C=10, score=0.115499, total=   0.0s\n",
      "[CV] kernel=linear, C=10 .............................................\n",
      "[CV] ............. kernel=linear, C=10, score=-5.204771, total=   0.0s\n",
      "[CV] kernel=linear, C=10 .............................................\n",
      "[CV] .............. kernel=linear, C=10, score=0.102608, total=   0.0s\n",
      "[CV] kernel=linear, C=10 .............................................\n",
      "[CV] .............. kernel=linear, C=10, score=0.340733, total=   0.0s\n",
      "--- Grid Search Completed: 0.01 minutes ---\n",
      "Best Params:\n",
      "{'kernel': 'linear', 'C': 1}\n",
      "Best CV Score:\n",
      "0.425256345423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "start_time = time.clock()\n",
    "minmax = MinMaxScaler().fit(X_train)\n",
    "svr_X_train = minmax.transform(X_train)\n",
    "svr_X_test = minmax.transform(X_test)\n",
    "svr = SVR()\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1,1,10],\n",
    "    'kernel': ['rbf','poly','linear'],\n",
    "}\n",
    "model = GridSearchCV(estimator=svr, param_grid=param_grid, cv=10, verbose=20)\n",
    "model.fit(svr_X_train, y_train)\n",
    "\n",
    "print('--- Grid Search Completed: %s minutes ---' % round(((time.clock() - start_time) / 60), 2))\n",
    "print('Best Params:')\n",
    "print(model.best_params_)\n",
    "print('Best CV Score:')\n",
    "print(-model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mse: 177.833837162\n",
      "Testing mse: 77.5193453535\n"
     ]
    }
   ],
   "source": [
    "svr_best = SVR(kernel='linear',C=1)\n",
    "svr_best.fit(svr_X_train,y_train)\n",
    "svr_train_pred = svr_best.predict(svr_X_train)\n",
    "svr_test_pred = svr_best.predict(svr_X_test)\n",
    "print \"Training mse: {}\".format(mse(y_train,svr_train_pred)) \n",
    "print \"Testing mse: {}\".format(mse(y_test,svr_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xf0bd208>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112d0748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train_range = xrange(len(y_train))\n",
    "plt.plot(x_train_range, y_train, '-',label='Train')\n",
    "plt.plot(x_train_range, svr_train_pred, '-',label='Predict')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xf1c1400>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd110be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test_range = xrange(len(y_test))\n",
    "plt.plot(x_test_range, y_test, '-',label='Test')\n",
    "plt.plot(x_test_range, svr_test_pred, '-',label='Predict')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. 2-layer Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Stacking,因为后面可以看到，各个base model的学习性能相差不大，所以这里我用了简单平均法来做最后的stacking.\n",
    "\"\"\"\n",
    "class Ensemble(object):\n",
    "    def __init__(self, n_folds, stacker, base_models, norm=False):\n",
    "        self.n_folds = n_folds\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "        self.norm = norm\n",
    "        \n",
    "    def fit_predict(self, X, y, T):\n",
    "        if not self.norm:\n",
    "            X = np.array(X)\n",
    "            T = np.array(T)\n",
    "        else:\n",
    "            temp_minmax = MinMaxScaler().fit(X)\n",
    "            X = temp_minmax.transform(X)\n",
    "            T = temp_minmax.transform(T)\n",
    "        y = np.array(y)\n",
    "       \n",
    "\n",
    "        folds = list(KFold(len(y), n_folds=self.n_folds, shuffle=True, random_state=2016))\n",
    "\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_test = np.zeros((T.shape[0], len(self.base_models)))\n",
    "\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "\n",
    "            print('Fitting For Base Model #{0} / {1} ---'.format(i+1, len(self.base_models)))\n",
    "\n",
    "            S_test_i = np.zeros((T.shape[0], len(folds)))\n",
    "\n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "\n",
    "                print('--- Fitting For Fold #{0} / {1} ---'.format(j+1, self.n_folds))\n",
    "\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "                X_holdout = X[test_idx]\n",
    "                # y_holdout = y[test_idx]\n",
    "                \n",
    "                clf.fit(X_train, y_train)\n",
    "\n",
    "                print 'Classifier:{}'.format(clf)\n",
    "                y_pred = clf.predict(X_holdout)[:]\n",
    "                S_train[test_idx, i] = y_pred\n",
    "                S_test_i[:, j] = clf.predict(T)[:]\n",
    "\n",
    "                print('Elapsed: %s minutes ---' % round(((time.clock() - start_time) / 60), 2))\n",
    "\n",
    "            S_test[:, i] = S_test_i.mean(1)\n",
    "\n",
    "            print('Elapsed: %s minutes ---' % round(((time.clock() - start_time) / 60), 2))\n",
    "\n",
    "        print('--- Base Models Trained: %s minutes ---' % round(((time.clock() - start_time) / 60), 2))\n",
    "\n",
    "        param_grid = {\n",
    "             'n_estimators': [50,80,90,100,150,200],\n",
    "             'learning_rate': [0.1, 0.05, 0.2],\n",
    "             'subsample': [0.72, 0.75, 0.78]\n",
    "         }\n",
    "        \n",
    "        grid = grid_search.GridSearchCV(estimator=self.stacker, \n",
    "                                        param_grid=param_grid, n_jobs=3, cv=10, verbose=20, \n",
    "                                        scoring='neg_mean_squared_error')\n",
    "        grid.fit(S_train, y)\n",
    "\n",
    "        # a little memo\n",
    "        message = 'to determine local CV score of #28'\n",
    "\n",
    "        try:\n",
    "            print('Param grid:')\n",
    "            print(param_grid)\n",
    "            print('Best Params:')\n",
    "            print(grid.best_params_)\n",
    "            print('Best CV Score:')\n",
    "            print(-grid.best_score_)\n",
    "            print('Best estimator:')\n",
    "            print(grid.best_estimator_)\n",
    "            print(message)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        print('--- Stacker Trained: %s minutes ---' % round(((time.time() - start_time) / 60), 2))\n",
    "\n",
    "        y_pred = grid.predict(S_test)[:]\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验结果："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.取4个base model:[RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, XGBRegressor]做Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Base model有RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, XGBRegressor,\n",
    "每个base model使用调参后的最佳参数, stacker采用GradientBoostingRegressor.\n",
    "\"\"\"\n",
    "base_models = [\n",
    "        ExtraTreesRegressor(\n",
    "            n_jobs=1, random_state=2017, verbose=1,\n",
    "            n_estimators=50,\n",
    "        ),\n",
    "        GradientBoostingRegressor(\n",
    "            n_estimators=30,subsample = 0.7,learning_rate=0.05,random_state=2017\n",
    "        ),\n",
    "        XGBRegressor(\n",
    "            seed=2017,\n",
    "            n_estimators=80,subsample=0.8,learning_rate=0.05,max_depth=9\n",
    "        ),\n",
    "        RandomForestRegressor(\n",
    "            n_estimators=500,random_state=2017\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ensemble = Ensemble(\n",
    "        n_folds=5,\n",
    "        stacker=GradientBoostingRegressor(\n",
    "            random_state=2017, verbose=1\n",
    "        ),\n",
    "        base_models=base_models\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting For Base Model #1 / 4 ---\n",
      "--- Fitting For Fold #1 / 5 ---\n",
      "Classifier:ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=50, n_jobs=1, oob_score=False, random_state=2017,\n",
      "          verbose=1, warm_start=False)\n",
      "Elapsed: 0.02 minutes ---\n",
      "--- Fitting For Fold #2 / 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=50, n_jobs=1, oob_score=False, random_state=2017,\n",
      "          verbose=1, warm_start=False)\n",
      "Elapsed: 0.02 minutes ---\n",
      "--- Fitting For Fold #3 / 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=50, n_jobs=1, oob_score=False, random_state=2017,\n",
      "          verbose=1, warm_start=False)\n",
      "Elapsed: 0.03 minutes ---\n",
      "--- Fitting For Fold #4 / 5 ---\n",
      "Classifier:ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=50, n_jobs=1, oob_score=False, random_state=2017,\n",
      "          verbose=1, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 0.03 minutes ---\n",
      "--- Fitting For Fold #5 / 5 ---\n",
      "Classifier:ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=50, n_jobs=1, oob_score=False, random_state=2017,\n",
      "          verbose=1, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 0.03 minutes ---\n",
      "Elapsed: 0.03 minutes ---\n",
      "Fitting For Base Model #2 / 4 ---\n",
      "--- Fitting For Fold #1 / 5 ---\n",
      "Classifier:GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.05, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "             min_samples_leaf=1, min_samples_split=2,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=30, presort='auto',\n",
      "             random_state=2017, subsample=0.7, verbose=0, warm_start=False)\n",
      "Elapsed: 0.03 minutes ---\n",
      "--- Fitting For Fold #2 / 5 ---\n",
      "Classifier:GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.05, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "             min_samples_leaf=1, min_samples_split=2,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=30, presort='auto',\n",
      "             random_state=2017, subsample=0.7, verbose=0, warm_start=False)\n",
      "Elapsed: 0.03 minutes ---\n",
      "--- Fitting For Fold #3 / 5 ---\n",
      "Classifier:GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.05, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "             min_samples_leaf=1, min_samples_split=2,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=30, presort='auto',\n",
      "             random_state=2017, subsample=0.7, verbose=0, warm_start=False)\n",
      "Elapsed: 0.03 minutes ---\n",
      "--- Fitting For Fold #4 / 5 ---\n",
      "Classifier:GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.05, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "             min_samples_leaf=1, min_samples_split=2,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=30, presort='auto',\n",
      "             random_state=2017, subsample=0.7, verbose=0, warm_start=False)\n",
      "Elapsed: 0.03 minutes ---\n",
      "--- Fitting For Fold #5 / 5 ---\n",
      "Classifier:GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.05, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "             min_samples_leaf=1, min_samples_split=2,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=30, presort='auto',\n",
      "             random_state=2017, subsample=0.7, verbose=0, warm_start=False)\n",
      "Elapsed: 0.03 minutes ---\n",
      "Elapsed: 0.03 minutes ---\n",
      "Fitting For Base Model #3 / 4 ---\n",
      "--- Fitting For Fold #1 / 5 ---\n",
      "Classifier:XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.05, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=1, missing=None, n_estimators=80, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=2017, silent=True, subsample=0.8)\n",
      "Elapsed: 0.04 minutes ---\n",
      "--- Fitting For Fold #2 / 5 ---\n",
      "Classifier:XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.05, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=1, missing=None, n_estimators=80, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=2017, silent=True, subsample=0.8)\n",
      "Elapsed: 0.04 minutes ---\n",
      "--- Fitting For Fold #3 / 5 ---\n",
      "Classifier:XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.05, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=1, missing=None, n_estimators=80, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=2017, silent=True, subsample=0.8)\n",
      "Elapsed: 0.04 minutes ---\n",
      "--- Fitting For Fold #4 / 5 ---\n",
      "Classifier:XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.05, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=1, missing=None, n_estimators=80, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=2017, silent=True, subsample=0.8)\n",
      "Elapsed: 0.04 minutes ---\n",
      "--- Fitting For Fold #5 / 5 ---\n",
      "Classifier:XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.05, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=1, missing=None, n_estimators=80, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=2017, silent=True, subsample=0.8)\n",
      "Elapsed: 0.04 minutes ---\n",
      "Elapsed: 0.04 minutes ---\n",
      "Fitting For Base Model #4 / 4 ---\n",
      "--- Fitting For Fold #1 / 5 ---\n",
      "Classifier:RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=500, n_jobs=1, oob_score=False, random_state=2017,\n",
      "           verbose=0, warm_start=False)\n",
      "Elapsed: 0.07 minutes ---\n",
      "--- Fitting For Fold #2 / 5 ---\n",
      "Classifier:RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=500, n_jobs=1, oob_score=False, random_state=2017,\n",
      "           verbose=0, warm_start=False)\n",
      "Elapsed: 0.1 minutes ---\n",
      "--- Fitting For Fold #3 / 5 ---\n",
      "Classifier:RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=500, n_jobs=1, oob_score=False, random_state=2017,\n",
      "           verbose=0, warm_start=False)\n",
      "Elapsed: 0.13 minutes ---\n",
      "--- Fitting For Fold #4 / 5 ---\n",
      "Classifier:RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=500, n_jobs=1, oob_score=False, random_state=2017,\n",
      "           verbose=0, warm_start=False)\n",
      "Elapsed: 0.17 minutes ---\n",
      "--- Fitting For Fold #5 / 5 ---\n",
      "Classifier:RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=500, n_jobs=1, oob_score=False, random_state=2017,\n",
      "           verbose=0, warm_start=False)\n",
      "Elapsed: 0.2 minutes ---\n",
      "Elapsed: 0.2 minutes ---\n",
      "--- Base Models Trained: 0.2 minutes ---\n",
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   1 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=3)]: Done   3 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=3)]: Done   4 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=3)]: Done   5 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=3)]: Done   6 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=3)]: Done   8 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=3)]: Done   9 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=3)]: Done  10 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=3)]: Done  11 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=3)]: Done  13 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=3)]: Done  14 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=3)]: Done  15 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=3)]: Done  16 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=3)]: Done  17 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=3)]: Done  18 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=3)]: Done  20 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=3)]: Done  21 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=3)]: Done  22 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=3)]: Done  23 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=3)]: Done  24 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=3)]: Done  25 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=3)]: Done  27 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=3)]: Done  28 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=3)]: Done  29 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=3)]: Done  30 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=3)]: Done  31 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=3)]: Done  32 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=3)]: Done  33 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=3)]: Done  34 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=3)]: Done  36 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=3)]: Done  37 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=3)]: Done  38 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=3)]: Done  39 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=3)]: Done  40 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=3)]: Done  41 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=3)]: Done  42 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=3)]: Done  43 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=3)]: Done  45 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=3)]: Done  46 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=3)]: Done  47 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=3)]: Done  48 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=3)]: Done  49 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=3)]: Done  50 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=3)]: Done  51 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=3)]: Done  52 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=3)]: Done  53 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=3)]: Done  54 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=3)]: Done  55 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=3)]: Done  56 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=3)]: Done  57 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=3)]: Done  58 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=3)]: Done  59 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=3)]: Done  60 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=3)]: Done  61 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=3)]: Done  62 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=3)]: Done  63 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=3)]: Done  64 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=3)]: Done  65 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=3)]: Done  66 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=3)]: Done  67 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=3)]: Done  68 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=3)]: Done  69 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=3)]: Done  70 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=3)]: Done  71 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=3)]: Done  72 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=3)]: Done  73 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=3)]: Done  74 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=3)]: Done  75 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=3)]: Done  76 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=3)]: Done  77 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=3)]: Done  78 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=3)]: Done  79 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=3)]: Done  80 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=3)]: Done  81 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=3)]: Done  82 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=3)]: Done  83 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=3)]: Done  84 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=3)]: Done  85 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=3)]: Done  86 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=3)]: Done  87 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=3)]: Done  88 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=3)]: Done  89 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=3)]: Done  90 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=3)]: Done  91 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=3)]: Done  92 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=3)]: Done  93 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=3)]: Done  94 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=3)]: Done  95 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=3)]: Done  96 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=3)]: Done  97 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=3)]: Done  98 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=3)]: Done  99 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=3)]: Done 100 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=3)]: Done 101 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=3)]: Done 102 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=3)]: Done 103 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=3)]: Done 104 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=3)]: Done 105 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=3)]: Done 106 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=3)]: Done 107 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=3)]: Done 108 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=3)]: Done 109 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=3)]: Done 110 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=3)]: Done 111 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=3)]: Done 112 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=3)]: Done 113 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=3)]: Done 114 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=3)]: Done 115 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=3)]: Done 116 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=3)]: Done 117 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=3)]: Done 118 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=3)]: Done 119 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=3)]: Done 120 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=3)]: Done 121 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=3)]: Done 123 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=3)]: Done 124 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=3)]: Done 125 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=3)]: Done 126 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=3)]: Done 127 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=3)]: Done 128 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=3)]: Done 129 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=3)]: Done 130 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=3)]: Done 131 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=3)]: Done 132 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=3)]: Done 133 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=3)]: Done 134 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=3)]: Done 135 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=3)]: Done 136 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=3)]: Done 137 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=3)]: Done 138 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=3)]: Done 139 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=3)]: Done 140 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=3)]: Done 141 tasks      | elapsed:   27.3s\n",
      "[Parallel(n_jobs=3)]: Done 142 tasks      | elapsed:   27.4s\n",
      "[Parallel(n_jobs=3)]: Done 143 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=3)]: Done 144 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=3)]: Done 145 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=3)]: Done 146 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=3)]: Done 147 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=3)]: Done 148 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=3)]: Done 149 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=3)]: Done 150 tasks      | elapsed:   29.1s\n",
      "[Parallel(n_jobs=3)]: Done 151 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=3)]: Done 152 tasks      | elapsed:   29.3s\n",
      "[Parallel(n_jobs=3)]: Done 153 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=3)]: Done 154 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=3)]: Done 155 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=3)]: Done 157 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=3)]: Done 158 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=3)]: Done 159 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=3)]: Done 160 tasks      | elapsed:   31.1s\n",
      "[Parallel(n_jobs=3)]: Done 161 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=3)]: Done 162 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=3)]: Done 163 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=3)]: Done 164 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=3)]: Done 165 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=3)]: Done 166 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=3)]: Done 167 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=3)]: Done 168 tasks      | elapsed:   32.8s\n",
      "[Parallel(n_jobs=3)]: Done 169 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=3)]: Done 170 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=3)]: Done 171 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=3)]: Done 172 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=3)]: Done 173 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=3)]: Done 174 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=3)]: Done 175 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=3)]: Done 176 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=3)]: Done 177 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=3)]: Done 178 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=3)]: Done 179 tasks      | elapsed:   35.0s\n",
      "[Parallel(n_jobs=3)]: Done 180 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=3)]: Done 181 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=3)]: Done 182 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=3)]: Done 183 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=3)]: Done 184 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=3)]: Done 185 tasks      | elapsed:   35.9s\n",
      "[Parallel(n_jobs=3)]: Done 186 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=3)]: Done 187 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=3)]: Done 188 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=3)]: Done 189 tasks      | elapsed:   36.7s\n",
      "[Parallel(n_jobs=3)]: Done 190 tasks      | elapsed:   36.7s\n",
      "[Parallel(n_jobs=3)]: Done 191 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=3)]: Done 192 tasks      | elapsed:   37.1s\n",
      "[Parallel(n_jobs=3)]: Done 193 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=3)]: Done 195 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=3)]: Done 196 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=3)]: Done 197 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=3)]: Done 198 tasks      | elapsed:   38.1s\n",
      "[Parallel(n_jobs=3)]: Done 199 tasks      | elapsed:   38.1s\n",
      "[Parallel(n_jobs=3)]: Done 200 tasks      | elapsed:   38.2s\n",
      "[Parallel(n_jobs=3)]: Done 201 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=3)]: Done 202 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=3)]: Done 203 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=3)]: Done 204 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=3)]: Done 205 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=3)]: Done 206 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=3)]: Done 207 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=3)]: Done 208 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=3)]: Done 209 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=3)]: Done 210 tasks      | elapsed:   39.9s\n",
      "[Parallel(n_jobs=3)]: Done 211 tasks      | elapsed:   40.0s\n",
      "[Parallel(n_jobs=3)]: Done 212 tasks      | elapsed:   40.2s\n",
      "[Parallel(n_jobs=3)]: Done 213 tasks      | elapsed:   40.5s\n",
      "[Parallel(n_jobs=3)]: Done 214 tasks      | elapsed:   40.5s\n",
      "[Parallel(n_jobs=3)]: Done 215 tasks      | elapsed:   40.7s\n",
      "[Parallel(n_jobs=3)]: Done 216 tasks      | elapsed:   40.9s\n",
      "[Parallel(n_jobs=3)]: Done 217 tasks      | elapsed:   41.0s\n",
      "[Parallel(n_jobs=3)]: Done 218 tasks      | elapsed:   41.2s\n",
      "[Parallel(n_jobs=3)]: Done 219 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=3)]: Done 220 tasks      | elapsed:   41.6s\n",
      "[Parallel(n_jobs=3)]: Done 221 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=3)]: Done 222 tasks      | elapsed:   42.0s\n",
      "[Parallel(n_jobs=3)]: Done 223 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=3)]: Done 224 tasks      | elapsed:   42.3s\n",
      "[Parallel(n_jobs=3)]: Done 225 tasks      | elapsed:   42.5s\n",
      "[Parallel(n_jobs=3)]: Done 226 tasks      | elapsed:   42.6s\n",
      "[Parallel(n_jobs=3)]: Done 227 tasks      | elapsed:   42.8s\n",
      "[Parallel(n_jobs=3)]: Done 228 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=3)]: Done 229 tasks      | elapsed:   43.2s\n",
      "[Parallel(n_jobs=3)]: Done 230 tasks      | elapsed:   43.4s\n",
      "[Parallel(n_jobs=3)]: Done 231 tasks      | elapsed:   43.7s\n",
      "[Parallel(n_jobs=3)]: Done 232 tasks      | elapsed:   43.7s\n",
      "[Parallel(n_jobs=3)]: Done 233 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=3)]: Done 234 tasks      | elapsed:   44.2s\n",
      "[Parallel(n_jobs=3)]: Done 235 tasks      | elapsed:   44.3s\n",
      "[Parallel(n_jobs=3)]: Done 236 tasks      | elapsed:   44.6s\n",
      "[Parallel(n_jobs=3)]: Done 237 tasks      | elapsed:   44.8s\n",
      "[Parallel(n_jobs=3)]: Done 238 tasks      | elapsed:   44.8s\n",
      "[Parallel(n_jobs=3)]: Done 239 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=3)]: Done 240 tasks      | elapsed:   45.3s\n",
      "[Parallel(n_jobs=3)]: Done 241 tasks      | elapsed:   45.4s\n",
      "[Parallel(n_jobs=3)]: Done 242 tasks      | elapsed:   45.7s\n",
      "[Parallel(n_jobs=3)]: Done 243 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=3)]: Done 244 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=3)]: Done 245 tasks      | elapsed:   46.3s\n",
      "[Parallel(n_jobs=3)]: Done 246 tasks      | elapsed:   46.5s\n",
      "[Parallel(n_jobs=3)]: Done 247 tasks      | elapsed:   46.5s\n",
      "[Parallel(n_jobs=3)]: Done 248 tasks      | elapsed:   46.8s\n",
      "[Parallel(n_jobs=3)]: Done 249 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=3)]: Done 250 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=3)]: Done 251 tasks      | elapsed:   47.4s\n",
      "[Parallel(n_jobs=3)]: Done 252 tasks      | elapsed:   47.6s\n",
      "[Parallel(n_jobs=3)]: Done 253 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=3)]: Done 254 tasks      | elapsed:   48.0s\n",
      "[Parallel(n_jobs=3)]: Done 255 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=3)]: Done 256 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=3)]: Done 257 tasks      | elapsed:   48.6s\n",
      "[Parallel(n_jobs=3)]: Done 258 tasks      | elapsed:   48.8s\n",
      "[Parallel(n_jobs=3)]: Done 259 tasks      | elapsed:   48.8s\n",
      "[Parallel(n_jobs=3)]: Done 260 tasks      | elapsed:   49.1s\n",
      "[Parallel(n_jobs=3)]: Done 261 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=3)]: Done 262 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=3)]: Done 263 tasks      | elapsed:   49.7s\n",
      "[Parallel(n_jobs=3)]: Done 264 tasks      | elapsed:   49.9s\n",
      "[Parallel(n_jobs=3)]: Done 265 tasks      | elapsed:   50.0s\n",
      "[Parallel(n_jobs=3)]: Done 266 tasks      | elapsed:   50.3s\n",
      "[Parallel(n_jobs=3)]: Done 267 tasks      | elapsed:   50.5s\n",
      "[Parallel(n_jobs=3)]: Done 268 tasks      | elapsed:   50.5s\n",
      "[Parallel(n_jobs=3)]: Done 269 tasks      | elapsed:   50.9s\n",
      "[Parallel(n_jobs=3)]: Done 270 tasks      | elapsed:   51.0s\n",
      "[Parallel(n_jobs=3)]: Done 271 tasks      | elapsed:   51.1s\n",
      "[Parallel(n_jobs=3)]: Done 272 tasks      | elapsed:   51.6s\n",
      "[Parallel(n_jobs=3)]: Done 273 tasks      | elapsed:   51.6s\n",
      "[Parallel(n_jobs=3)]: Done 274 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=3)]: Done 275 tasks      | elapsed:   52.1s\n",
      "[Parallel(n_jobs=3)]: Done 276 tasks      | elapsed:   52.2s\n",
      "[Parallel(n_jobs=3)]: Done 277 tasks      | elapsed:   52.3s\n",
      "[Parallel(n_jobs=3)]: Done 278 tasks      | elapsed:   52.7s\n",
      "[Parallel(n_jobs=3)]: Done 279 tasks      | elapsed:   52.8s\n",
      "[Parallel(n_jobs=3)]: Done 280 tasks      | elapsed:   53.0s\n",
      "[Parallel(n_jobs=3)]: Done 281 tasks      | elapsed:   53.3s\n",
      "[Parallel(n_jobs=3)]: Done 282 tasks      | elapsed:   53.4s\n",
      "[Parallel(n_jobs=3)]: Done 283 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=3)]: Done 284 tasks      | elapsed:   54.0s\n",
      "[Parallel(n_jobs=3)]: Done 285 tasks      | elapsed:   54.0s\n",
      "[Parallel(n_jobs=3)]: Done 286 tasks      | elapsed:   54.1s\n",
      "[Parallel(n_jobs=3)]: Done 287 tasks      | elapsed:   54.6s\n",
      "[Parallel(n_jobs=3)]: Done 288 tasks      | elapsed:   54.7s\n",
      "[Parallel(n_jobs=3)]: Done 289 tasks      | elapsed:   54.7s\n",
      "[Parallel(n_jobs=3)]: Done 290 tasks      | elapsed:   55.2s\n",
      "[Parallel(n_jobs=3)]: Done 291 tasks      | elapsed:   55.3s\n",
      "[Parallel(n_jobs=3)]: Done 292 tasks      | elapsed:   55.3s\n",
      "[Parallel(n_jobs=3)]: Done 293 tasks      | elapsed:   55.8s\n",
      "[Parallel(n_jobs=3)]: Done 294 tasks      | elapsed:   55.8s\n",
      "[Parallel(n_jobs=3)]: Done 295 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=3)]: Done 296 tasks      | elapsed:   56.4s\n",
      "[Parallel(n_jobs=3)]: Done 297 tasks      | elapsed:   56.5s\n",
      "[Parallel(n_jobs=3)]: Done 298 tasks      | elapsed:   56.6s\n",
      "[Parallel(n_jobs=3)]: Done 299 tasks      | elapsed:   57.0s\n",
      "[Parallel(n_jobs=3)]: Done 300 tasks      | elapsed:   57.0s\n",
      "[Parallel(n_jobs=3)]: Done 301 tasks      | elapsed:   57.3s\n",
      "[Parallel(n_jobs=3)]: Done 302 tasks      | elapsed:   57.7s\n",
      "[Parallel(n_jobs=3)]: Done 303 tasks      | elapsed:   57.7s\n",
      "[Parallel(n_jobs=3)]: Done 304 tasks      | elapsed:   57.9s\n",
      "[Parallel(n_jobs=3)]: Done 305 tasks      | elapsed:   58.2s\n",
      "[Parallel(n_jobs=3)]: Done 306 tasks      | elapsed:   58.3s\n",
      "[Parallel(n_jobs=3)]: Done 307 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=3)]: Done 308 tasks      | elapsed:   58.8s\n",
      "[Parallel(n_jobs=3)]: Done 309 tasks      | elapsed:   58.9s\n",
      "[Parallel(n_jobs=3)]: Done 310 tasks      | elapsed:   59.0s\n",
      "[Parallel(n_jobs=3)]: Done 311 tasks      | elapsed:   59.4s\n",
      "[Parallel(n_jobs=3)]: Done 312 tasks      | elapsed:   59.5s\n",
      "[Parallel(n_jobs=3)]: Done 313 tasks      | elapsed:   59.6s\n",
      "[Parallel(n_jobs=3)]: Done 314 tasks      | elapsed:   60.0s\n",
      "[Parallel(n_jobs=3)]: Done 315 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 316 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 317 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 318 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 319 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 320 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 321 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 322 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 323 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 324 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 325 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 326 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 327 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 328 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 329 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 330 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 331 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 332 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 333 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 334 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 335 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 336 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 337 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 338 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 339 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 340 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 341 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 342 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 343 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 344 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 345 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 346 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 347 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 348 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 349 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 350 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 351 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 352 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 353 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 354 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 355 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 356 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 357 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 358 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 359 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 360 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 361 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 362 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 363 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 364 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 365 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 366 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 367 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 368 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 369 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 370 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 371 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 372 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 373 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 374 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 375 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 376 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 377 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 378 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 379 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 380 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 381 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 382 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 383 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 384 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 385 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 386 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 387 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 388 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 389 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 390 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 391 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 392 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 393 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 394 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 395 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 396 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 397 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 398 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 399 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 400 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 401 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 402 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 403 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 404 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 405 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 406 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 407 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 408 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 409 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 410 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 411 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 412 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 413 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 414 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 415 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 416 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 417 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 418 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 419 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 420 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 421 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 422 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 423 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 424 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 425 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 426 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 427 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 428 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 429 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 430 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 431 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 432 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 433 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 434 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 435 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 436 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 437 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 438 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 439 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 440 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 441 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 442 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 443 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 445 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 446 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 447 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 448 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 449 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 450 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 451 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 452 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 453 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 454 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 455 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 456 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 457 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 458 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 459 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 460 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 461 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 462 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 463 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 464 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 465 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 466 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 467 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 468 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 469 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 470 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 471 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 472 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 473 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 474 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 475 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 476 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 477 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 478 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 479 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 480 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 481 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 482 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 483 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 484 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 485 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 486 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 487 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 488 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 489 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 490 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 491 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 492 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 493 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 494 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 495 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 496 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 497 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 498 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 499 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 500 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 501 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 502 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 503 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 504 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 505 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 506 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 507 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 508 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 509 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 510 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 511 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 512 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 513 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 514 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 515 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 516 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 517 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 518 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 519 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 520 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 521 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 522 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 523 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 524 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 525 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 526 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 527 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 528 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 529 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 530 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 531 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 532 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 533 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 534 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 535 tasks      | elapsed:  1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         178.9497           5.2328            0.00s\n",
      "         2         153.5300          28.2191            0.00s\n",
      "         3         157.6947          -2.6442            0.00s\n",
      "         4         140.9010          -0.1426            0.00s\n",
      "         5         116.4762          -0.6246            0.00s\n",
      "         6          97.8805           9.8872            0.00s\n",
      "         7          96.6559          -2.2164            0.00s\n",
      "         8          64.8975           4.8892            0.00s\n",
      "         9          58.1083           0.1968            0.00s\n",
      "        10          51.9422           2.0890            0.00s\n",
      "        20          33.6659          -1.2512            0.02s\n",
      "        30          21.3656          -0.9216            0.01s\n",
      "        40          16.0313          -0.6377            0.00s\n",
      "        50          10.2861          -0.7818            0.00s\n",
      "Param grid:\n",
      "{'n_estimators': [50, 80, 90, 100, 150, 200], 'subsample': [0.72, 0.75, 0.78], 'learning_rate': [0.1, 0.05, 0.2]}\n",
      "Best Params:\n",
      "{'n_estimators': 50, 'subsample': 0.75, 'learning_rate': 0.1}\n",
      "Best CV Score:\n",
      "195.948037079\n",
      "Best estimator:\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "             min_samples_leaf=1, min_samples_split=2,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=50, presort='auto',\n",
      "             random_state=2017, subsample=0.75, verbose=1,\n",
      "             warm_start=False)\n",
      "to determine local CV score of #28\n",
      "--- Stacker Trained: 24850163.21 minutes ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 540 out of 540 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "stack_pred = ensemble.fit_predict(X=X_train,y=y_train,T=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127.950453814\n"
     ]
    }
   ],
   "source": [
    "print mse(y_test,stack_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xf4ca940>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf026358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test_range = xrange(len(y_test))\n",
    "plt.plot(x_test_range, y_test, '-',label = 'Test')\n",
    "plt.plot(x_test_range, stack_pred, '-',label='Pred')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>etr</th>\n",
       "      <th>gbr</th>\n",
       "      <th>rf</th>\n",
       "      <th>stacking</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165.035616</td>\n",
       "      <td>106.82249</td>\n",
       "      <td>141.494666</td>\n",
       "      <td>150.501649</td>\n",
       "      <td>157.566032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          etr        gbr          rf    stacking         xgb\n",
       "0  165.035616  106.82249  141.494666  150.501649  157.566032"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "MSE比较\n",
    "\"\"\"\n",
    "res = pd.DataFrame({'xgb':[157.566031983], 'rf':[141.4946664], \n",
    "                    'gbr':[106.822489988], 'stacking':[127.950453814],'etr':[165.035616]})\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_test_pred & rf_test_pred corr: (0.98375166626436683, 1.1703082546184178e-18)\n",
      "xgb_test_pred & gbr_test_pred corr: (0.98270593905203796, 2.3856377173661601e-18)\n",
      "xgb_test_pred & etr_test_pred corr: (0.95975715124540484, 3.523432652822512e-14)\n",
      "xgb_test_pred & svr_test_pred corr: (0.7942773907837527, 2.1339737130562782e-06)\n",
      "rf_test_pred & gbr_test_pred corr: (0.99271990896177398, 1.1953090992882995e-22)\n",
      "rf_test_pred & etr_test_pred corr: (0.96981577399118557, 1.3550050312761772e-15)\n",
      "rf_test_pred & svr_test_pred corr: (0.83237444132033445, 2.4728823142044077e-07)\n",
      "gbr_test_pred & etr_test_pred corr: (0.94918614126215972, 4.8890313685199533e-13)\n",
      "gbr_test_pred & svr_test_pred corr: (0.83168400231429718, 2.5832848723135855e-07)\n",
      "etr_test_pred & svr_test_pred corr: (0.81289693072582048, 7.9069786512880522e-07)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "xgb, rf, gbr和etr预测结果的Pearson相关系数\n",
    "\"\"\"\n",
    "import scipy as sp\n",
    "test_pred = [xgb_test_pred,rf_test_pred,gbr_test_pred,etr_test_pred,svr_test_pred]\n",
    "names = ['xgb_test_pred','rf_test_pred','gbr_test_pred','etr_test_pred','svr_test_pred']\n",
    "\n",
    "for i in xrange(len(test_pred)-1):\n",
    "    for j in xrange(i+1,len(test_pred)):\n",
    "        print '{} & {} corr: {}'.format(names[i],names[j],sp.stats.pearsonr(test_pred[i],test_pred[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**结果分析及改进：**\n",
    "上面的结果计算了xgb, rf, gbr,etr, svr预测结果的Pearson相关系数，可见xgb, rf, gbr,etr,这几个模型预测结果实在是太相像了，这也导致了Stacking的mse比单模型的要差。然后我选了相关系数最小的三个模型**XGB, ETR, SVR**重新做一遍stacking以改进."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.XGB, ETR, SVR Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_base_models2 = [\n",
    "        ExtraTreesRegressor(\n",
    "            n_jobs=1, random_state=2017, verbose=1,\n",
    "            n_estimators=50,\n",
    "        ),\n",
    "        SVR(kernel='linear',C=1),\n",
    "        XGBRegressor(\n",
    "            seed=2017,\n",
    "            n_estimators=80,subsample=0.8,learning_rate=0.05,max_depth=9\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting For Base Model #1 / 3 ---\n",
      "--- Fitting For Fold #1 / 5 ---\n",
      "Classifier:ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=50, n_jobs=1, oob_score=False, random_state=2017,\n",
      "          verbose=1, warm_start=False)\n",
      "Elapsed: 1.94 minutes ---\n",
      "--- Fitting For Fold #2 / 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=50, n_jobs=1, oob_score=False, random_state=2017,\n",
      "          verbose=1, warm_start=False)\n",
      "Elapsed: 1.94 minutes ---\n",
      "--- Fitting For Fold #3 / 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=50, n_jobs=1, oob_score=False, random_state=2017,\n",
      "          verbose=1, warm_start=False)\n",
      "Elapsed: 1.95 minutes ---\n",
      "--- Fitting For Fold #4 / 5 ---\n",
      "Classifier:ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=50, n_jobs=1, oob_score=False, random_state=2017,\n",
      "          verbose=1, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 1.95 minutes ---\n",
      "--- Fitting For Fold #5 / 5 ---\n",
      "Classifier:ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=50, n_jobs=1, oob_score=False, random_state=2017,\n",
      "          verbose=1, warm_start=False)\n",
      "Elapsed: 1.95 minutes ---\n",
      "Elapsed: 1.95 minutes ---\n",
      "Fitting For Base Model #2 / 3 ---\n",
      "--- Fitting For Fold #1 / 5 ---\n",
      "Classifier:SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "Elapsed: 1.95 minutes ---\n",
      "--- Fitting For Fold #2 / 5 ---\n",
      "Classifier:SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "Elapsed: 1.95 minutes ---\n",
      "--- Fitting For Fold #3 / 5 ---\n",
      "Classifier:SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "Elapsed: 1.95 minutes ---\n",
      "--- Fitting For Fold #4 / 5 ---\n",
      "Classifier:SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "Elapsed: 1.95 minutes ---\n",
      "--- Fitting For Fold #5 / 5 ---\n",
      "Classifier:SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "Elapsed: 1.95 minutes ---\n",
      "Elapsed: 1.95 minutes ---\n",
      "Fitting For Base Model #3 / 3 ---\n",
      "--- Fitting For Fold #1 / 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.05, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=1, missing=None, n_estimators=80, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=2017, silent=True, subsample=0.8)\n",
      "Elapsed: 1.95 minutes ---\n",
      "--- Fitting For Fold #2 / 5 ---\n",
      "Classifier:XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.05, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=1, missing=None, n_estimators=80, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=2017, silent=True, subsample=0.8)\n",
      "Elapsed: 1.96 minutes ---\n",
      "--- Fitting For Fold #3 / 5 ---\n",
      "Classifier:XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.05, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=1, missing=None, n_estimators=80, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=2017, silent=True, subsample=0.8)\n",
      "Elapsed: 1.96 minutes ---\n",
      "--- Fitting For Fold #4 / 5 ---\n",
      "Classifier:XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.05, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=1, missing=None, n_estimators=80, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=2017, silent=True, subsample=0.8)\n",
      "Elapsed: 1.96 minutes ---\n",
      "--- Fitting For Fold #5 / 5 ---\n",
      "Classifier:XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.05, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=1, missing=None, n_estimators=80, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=2017, silent=True, subsample=0.8)\n",
      "Elapsed: 1.96 minutes ---\n",
      "Elapsed: 1.96 minutes ---\n",
      "--- Base Models Trained: 1.96 minutes ---\n",
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   1 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=3)]: Done   3 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=3)]: Done   4 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=3)]: Done   5 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=3)]: Done   6 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=3)]: Done   8 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=3)]: Done   9 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=3)]: Done  10 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=3)]: Done  11 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=3)]: Done  13 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=3)]: Done  14 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=3)]: Done  15 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=3)]: Done  16 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=3)]: Done  17 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=3)]: Done  18 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=3)]: Done  20 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=3)]: Done  21 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=3)]: Done  22 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=3)]: Done  23 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=3)]: Done  24 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=3)]: Done  25 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=3)]: Done  27 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=3)]: Done  28 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=3)]: Done  29 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=3)]: Done  30 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=3)]: Done  31 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=3)]: Done  32 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=3)]: Done  33 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=3)]: Done  34 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=3)]: Done  36 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=3)]: Done  37 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=3)]: Done  38 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=3)]: Done  39 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=3)]: Done  40 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=3)]: Done  41 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=3)]: Done  42 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=3)]: Done  43 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=3)]: Done  45 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=3)]: Done  46 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=3)]: Done  47 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=3)]: Done  48 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=3)]: Done  49 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=3)]: Done  50 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=3)]: Done  51 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=3)]: Done  52 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=3)]: Done  53 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=3)]: Done  54 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=3)]: Done  55 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=3)]: Done  56 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=3)]: Done  57 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=3)]: Done  58 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=3)]: Done  59 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=3)]: Done  60 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=3)]: Done  61 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=3)]: Done  62 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=3)]: Done  63 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=3)]: Done  64 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=3)]: Done  65 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=3)]: Done  66 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=3)]: Done  67 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=3)]: Done  68 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=3)]: Done  69 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=3)]: Done  70 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=3)]: Done  71 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=3)]: Done  72 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=3)]: Done  73 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=3)]: Done  74 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=3)]: Done  75 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=3)]: Done  76 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=3)]: Done  77 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=3)]: Done  78 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=3)]: Done  79 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=3)]: Done  80 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=3)]: Done  81 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=3)]: Done  82 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=3)]: Done  83 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=3)]: Done  84 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=3)]: Done  85 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=3)]: Done  86 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=3)]: Done  87 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=3)]: Done  88 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=3)]: Done  89 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=3)]: Done  90 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=3)]: Done  91 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=3)]: Done  92 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=3)]: Done  93 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=3)]: Done  94 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=3)]: Done  95 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=3)]: Done  96 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=3)]: Done  97 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=3)]: Done  98 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=3)]: Done  99 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=3)]: Done 100 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=3)]: Done 101 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=3)]: Done 102 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=3)]: Done 103 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=3)]: Done 104 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=3)]: Done 105 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=3)]: Done 106 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=3)]: Done 107 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=3)]: Done 108 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=3)]: Done 109 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=3)]: Done 110 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=3)]: Done 111 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=3)]: Done 112 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=3)]: Done 113 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=3)]: Done 114 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=3)]: Done 115 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=3)]: Done 116 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=3)]: Done 117 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=3)]: Done 118 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=3)]: Done 119 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=3)]: Done 120 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=3)]: Done 121 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=3)]: Done 123 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=3)]: Done 124 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=3)]: Done 125 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=3)]: Done 126 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=3)]: Done 127 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=3)]: Done 128 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=3)]: Done 129 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=3)]: Done 130 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=3)]: Done 131 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=3)]: Done 132 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=3)]: Done 133 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=3)]: Done 134 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=3)]: Done 135 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=3)]: Done 136 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=3)]: Done 137 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=3)]: Done 138 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=3)]: Done 139 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=3)]: Done 140 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=3)]: Done 141 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=3)]: Done 142 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=3)]: Done 143 tasks      | elapsed:   27.4s\n",
      "[Parallel(n_jobs=3)]: Done 144 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=3)]: Done 145 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=3)]: Done 146 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=3)]: Done 147 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=3)]: Done 148 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=3)]: Done 149 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=3)]: Done 150 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=3)]: Done 151 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=3)]: Done 152 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=3)]: Done 153 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=3)]: Done 154 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=3)]: Done 155 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=3)]: Done 157 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=3)]: Done 158 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=3)]: Done 159 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=3)]: Done 160 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=3)]: Done 161 tasks      | elapsed:   31.1s\n",
      "[Parallel(n_jobs=3)]: Done 162 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=3)]: Done 163 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=3)]: Done 164 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=3)]: Done 165 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=3)]: Done 166 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=3)]: Done 167 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=3)]: Done 168 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=3)]: Done 169 tasks      | elapsed:   32.8s\n",
      "[Parallel(n_jobs=3)]: Done 170 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=3)]: Done 171 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=3)]: Done 172 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=3)]: Done 173 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=3)]: Done 174 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=3)]: Done 175 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=3)]: Done 176 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=3)]: Done 177 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=3)]: Done 178 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=3)]: Done 179 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=3)]: Done 180 tasks      | elapsed:   34.9s\n",
      "[Parallel(n_jobs=3)]: Done 181 tasks      | elapsed:   35.0s\n",
      "[Parallel(n_jobs=3)]: Done 182 tasks      | elapsed:   35.2s\n",
      "[Parallel(n_jobs=3)]: Done 183 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=3)]: Done 184 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=3)]: Done 185 tasks      | elapsed:   35.8s\n",
      "[Parallel(n_jobs=3)]: Done 186 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=3)]: Done 187 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=3)]: Done 188 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=3)]: Done 189 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=3)]: Done 190 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=3)]: Done 191 tasks      | elapsed:   36.7s\n",
      "[Parallel(n_jobs=3)]: Done 192 tasks      | elapsed:   36.9s\n",
      "[Parallel(n_jobs=3)]: Done 193 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=3)]: Done 195 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=3)]: Done 196 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=3)]: Done 197 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=3)]: Done 198 tasks      | elapsed:   37.9s\n",
      "[Parallel(n_jobs=3)]: Done 199 tasks      | elapsed:   38.0s\n",
      "[Parallel(n_jobs=3)]: Done 200 tasks      | elapsed:   38.1s\n",
      "[Parallel(n_jobs=3)]: Done 201 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=3)]: Done 202 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=3)]: Done 203 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=3)]: Done 204 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=3)]: Done 205 tasks      | elapsed:   38.9s\n",
      "[Parallel(n_jobs=3)]: Done 206 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=3)]: Done 207 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=3)]: Done 208 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=3)]: Done 209 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=3)]: Done 210 tasks      | elapsed:   39.8s\n",
      "[Parallel(n_jobs=3)]: Done 211 tasks      | elapsed:   39.9s\n",
      "[Parallel(n_jobs=3)]: Done 212 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=3)]: Done 213 tasks      | elapsed:   40.3s\n",
      "[Parallel(n_jobs=3)]: Done 214 tasks      | elapsed:   40.4s\n",
      "[Parallel(n_jobs=3)]: Done 215 tasks      | elapsed:   40.6s\n",
      "[Parallel(n_jobs=3)]: Done 216 tasks      | elapsed:   40.9s\n",
      "[Parallel(n_jobs=3)]: Done 217 tasks      | elapsed:   41.0s\n",
      "[Parallel(n_jobs=3)]: Done 218 tasks      | elapsed:   41.2s\n",
      "[Parallel(n_jobs=3)]: Done 219 tasks      | elapsed:   41.4s\n",
      "[Parallel(n_jobs=3)]: Done 220 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=3)]: Done 221 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=3)]: Done 222 tasks      | elapsed:   42.0s\n",
      "[Parallel(n_jobs=3)]: Done 223 tasks      | elapsed:   42.0s\n",
      "[Parallel(n_jobs=3)]: Done 224 tasks      | elapsed:   42.3s\n",
      "[Parallel(n_jobs=3)]: Done 225 tasks      | elapsed:   42.5s\n",
      "[Parallel(n_jobs=3)]: Done 226 tasks      | elapsed:   42.6s\n",
      "[Parallel(n_jobs=3)]: Done 227 tasks      | elapsed:   42.8s\n",
      "[Parallel(n_jobs=3)]: Done 228 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=3)]: Done 229 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=3)]: Done 230 tasks      | elapsed:   43.3s\n",
      "[Parallel(n_jobs=3)]: Done 231 tasks      | elapsed:   43.6s\n",
      "[Parallel(n_jobs=3)]: Done 232 tasks      | elapsed:   43.7s\n",
      "[Parallel(n_jobs=3)]: Done 233 tasks      | elapsed:   43.9s\n",
      "[Parallel(n_jobs=3)]: Done 234 tasks      | elapsed:   44.2s\n",
      "[Parallel(n_jobs=3)]: Done 235 tasks      | elapsed:   44.2s\n",
      "[Parallel(n_jobs=3)]: Done 236 tasks      | elapsed:   44.4s\n",
      "[Parallel(n_jobs=3)]: Done 237 tasks      | elapsed:   44.8s\n",
      "[Parallel(n_jobs=3)]: Done 238 tasks      | elapsed:   44.8s\n",
      "[Parallel(n_jobs=3)]: Done 239 tasks      | elapsed:   44.9s\n",
      "[Parallel(n_jobs=3)]: Done 240 tasks      | elapsed:   45.3s\n",
      "[Parallel(n_jobs=3)]: Done 241 tasks      | elapsed:   45.4s\n",
      "[Parallel(n_jobs=3)]: Done 242 tasks      | elapsed:   45.5s\n",
      "[Parallel(n_jobs=3)]: Done 243 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=3)]: Done 244 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=3)]: Done 245 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=3)]: Done 246 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=3)]: Done 247 tasks      | elapsed:   46.5s\n",
      "[Parallel(n_jobs=3)]: Done 248 tasks      | elapsed:   46.5s\n",
      "[Parallel(n_jobs=3)]: Done 249 tasks      | elapsed:   47.0s\n",
      "[Parallel(n_jobs=3)]: Done 250 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=3)]: Done 251 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=3)]: Done 252 tasks      | elapsed:   47.6s\n",
      "[Parallel(n_jobs=3)]: Done 253 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=3)]: Done 254 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=3)]: Done 255 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=3)]: Done 256 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=3)]: Done 257 tasks      | elapsed:   48.3s\n",
      "[Parallel(n_jobs=3)]: Done 258 tasks      | elapsed:   48.7s\n",
      "[Parallel(n_jobs=3)]: Done 259 tasks      | elapsed:   48.8s\n",
      "[Parallel(n_jobs=3)]: Done 260 tasks      | elapsed:   48.8s\n",
      "[Parallel(n_jobs=3)]: Done 261 tasks      | elapsed:   49.2s\n",
      "[Parallel(n_jobs=3)]: Done 262 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=3)]: Done 263 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=3)]: Done 264 tasks      | elapsed:   49.8s\n",
      "[Parallel(n_jobs=3)]: Done 265 tasks      | elapsed:   50.0s\n",
      "[Parallel(n_jobs=3)]: Done 266 tasks      | elapsed:   50.1s\n",
      "[Parallel(n_jobs=3)]: Done 267 tasks      | elapsed:   50.4s\n",
      "[Parallel(n_jobs=3)]: Done 268 tasks      | elapsed:   50.6s\n",
      "[Parallel(n_jobs=3)]: Done 269 tasks      | elapsed:   50.6s\n",
      "[Parallel(n_jobs=3)]: Done 270 tasks      | elapsed:   50.9s\n",
      "[Parallel(n_jobs=3)]: Done 271 tasks      | elapsed:   51.2s\n",
      "[Parallel(n_jobs=3)]: Done 272 tasks      | elapsed:   51.2s\n",
      "[Parallel(n_jobs=3)]: Done 273 tasks      | elapsed:   51.6s\n",
      "[Parallel(n_jobs=3)]: Done 274 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=3)]: Done 275 tasks      | elapsed:   51.8s\n",
      "[Parallel(n_jobs=3)]: Done 276 tasks      | elapsed:   52.1s\n",
      "[Parallel(n_jobs=3)]: Done 277 tasks      | elapsed:   52.4s\n",
      "[Parallel(n_jobs=3)]: Done 278 tasks      | elapsed:   52.4s\n",
      "[Parallel(n_jobs=3)]: Done 279 tasks      | elapsed:   52.8s\n",
      "[Parallel(n_jobs=3)]: Done 280 tasks      | elapsed:   53.0s\n",
      "[Parallel(n_jobs=3)]: Done 281 tasks      | elapsed:   53.0s\n",
      "[Parallel(n_jobs=3)]: Done 282 tasks      | elapsed:   53.4s\n",
      "[Parallel(n_jobs=3)]: Done 283 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=3)]: Done 284 tasks      | elapsed:   53.6s\n",
      "[Parallel(n_jobs=3)]: Done 285 tasks      | elapsed:   54.0s\n",
      "[Parallel(n_jobs=3)]: Done 286 tasks      | elapsed:   54.1s\n",
      "[Parallel(n_jobs=3)]: Done 287 tasks      | elapsed:   54.2s\n",
      "[Parallel(n_jobs=3)]: Done 288 tasks      | elapsed:   54.6s\n",
      "[Parallel(n_jobs=3)]: Done 289 tasks      | elapsed:   54.7s\n",
      "[Parallel(n_jobs=3)]: Done 290 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=3)]: Done 291 tasks      | elapsed:   55.1s\n",
      "[Parallel(n_jobs=3)]: Done 292 tasks      | elapsed:   55.3s\n",
      "[Parallel(n_jobs=3)]: Done 293 tasks      | elapsed:   55.5s\n",
      "[Parallel(n_jobs=3)]: Done 294 tasks      | elapsed:   55.7s\n",
      "[Parallel(n_jobs=3)]: Done 295 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=3)]: Done 296 tasks      | elapsed:   56.1s\n",
      "[Parallel(n_jobs=3)]: Done 297 tasks      | elapsed:   56.3s\n",
      "[Parallel(n_jobs=3)]: Done 298 tasks      | elapsed:   56.5s\n",
      "[Parallel(n_jobs=3)]: Done 299 tasks      | elapsed:   56.8s\n",
      "[Parallel(n_jobs=3)]: Done 300 tasks      | elapsed:   57.0s\n",
      "[Parallel(n_jobs=3)]: Done 301 tasks      | elapsed:   57.1s\n",
      "[Parallel(n_jobs=3)]: Done 302 tasks      | elapsed:   57.5s\n",
      "[Parallel(n_jobs=3)]: Done 303 tasks      | elapsed:   57.6s\n",
      "[Parallel(n_jobs=3)]: Done 304 tasks      | elapsed:   57.7s\n",
      "[Parallel(n_jobs=3)]: Done 305 tasks      | elapsed:   58.1s\n",
      "[Parallel(n_jobs=3)]: Done 306 tasks      | elapsed:   58.2s\n",
      "[Parallel(n_jobs=3)]: Done 307 tasks      | elapsed:   58.3s\n",
      "[Parallel(n_jobs=3)]: Done 308 tasks      | elapsed:   58.7s\n",
      "[Parallel(n_jobs=3)]: Done 309 tasks      | elapsed:   58.8s\n",
      "[Parallel(n_jobs=3)]: Done 310 tasks      | elapsed:   58.9s\n",
      "[Parallel(n_jobs=3)]: Done 311 tasks      | elapsed:   59.3s\n",
      "[Parallel(n_jobs=3)]: Done 312 tasks      | elapsed:   59.3s\n",
      "[Parallel(n_jobs=3)]: Done 313 tasks      | elapsed:   59.5s\n",
      "[Parallel(n_jobs=3)]: Done 314 tasks      | elapsed:   59.9s\n",
      "[Parallel(n_jobs=3)]: Done 315 tasks      | elapsed:   59.9s\n",
      "[Parallel(n_jobs=3)]: Done 316 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 317 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 318 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 319 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 320 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 321 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 322 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 323 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 324 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 325 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 326 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 327 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 328 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 329 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 330 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 331 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 332 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 333 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 334 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 335 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 336 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 337 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 338 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 339 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 340 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 341 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 342 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 343 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 344 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 345 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 346 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 347 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 348 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 349 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 350 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 351 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 352 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 353 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 354 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 355 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 356 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 357 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 358 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 359 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 360 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 361 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 362 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 363 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 364 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 365 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 366 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 367 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 368 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 369 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 370 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 371 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 372 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 373 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 374 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 375 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 376 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 377 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 378 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 379 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 380 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 381 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 382 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 383 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 384 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 385 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 386 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 387 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 388 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 389 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 390 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 391 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 392 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 393 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 394 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 395 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 396 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 397 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 398 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 399 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 400 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 401 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 402 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 403 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 404 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 405 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 406 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 407 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 408 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 409 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 410 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 411 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 412 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 413 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 414 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 415 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 416 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 417 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 418 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 419 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 420 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 421 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 422 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 423 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 424 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 425 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 426 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 427 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 428 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 429 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 430 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 431 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 432 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 433 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 434 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 435 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 436 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 437 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 438 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 439 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 440 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 441 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 442 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 443 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 445 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 446 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 447 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 448 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 449 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 450 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 451 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 452 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 453 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 454 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 455 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 456 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 457 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 458 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 459 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 460 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 461 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 462 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 463 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 464 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 465 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 466 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 467 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 468 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 469 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 470 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 471 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 472 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 473 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 474 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 475 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 476 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 477 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 478 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 479 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 480 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 481 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 482 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 483 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 484 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 485 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 486 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 487 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 488 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 489 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 490 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 491 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 492 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 493 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 494 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 495 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 496 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 497 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 498 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 499 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 500 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 501 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 502 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 503 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 504 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 505 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 506 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 507 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 508 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 509 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 510 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 511 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 512 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 513 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 514 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 515 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 516 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 517 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 518 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 519 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 520 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 521 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 522 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 523 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 524 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 525 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 526 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 527 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 528 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 529 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 530 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 531 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 532 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 533 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 534 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 535 tasks      | elapsed:  1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         198.1388           4.8703            0.00s\n",
      "         2         180.6222          16.1606            0.00s\n",
      "         3         201.9604          -0.0236            0.00s\n",
      "         4         190.0097           0.5183            0.00s\n",
      "         5         168.3732          -0.0277            0.00s\n",
      "         6         144.6892           8.8127            0.00s\n",
      "         7         156.8560           0.3399            0.00s\n",
      "         8         101.5647           9.1507            0.00s\n",
      "         9         102.3345           7.4359            0.00s\n",
      "        10          79.6244           0.5638            0.00s\n",
      "        20          68.7809           0.3703            0.00s\n",
      "        30          51.2067          -0.1702            0.00s\n",
      "        40          41.6618          -0.3765            0.00s\n",
      "        50          30.2718           0.1906            0.00s\n",
      "Param grid:\n",
      "{'n_estimators': [50, 80, 90, 100, 150, 200], 'subsample': [0.72, 0.75, 0.78], 'learning_rate': [0.1, 0.05, 0.2]}\n",
      "Best Params:\n",
      "{'n_estimators': 50, 'subsample': 0.75, 'learning_rate': 0.05}\n",
      "Best CV Score:\n",
      "198.146311057\n",
      "Best estimator:\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.05, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "             min_samples_leaf=1, min_samples_split=2,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=50, presort='auto',\n",
      "             random_state=2017, subsample=0.75, verbose=1,\n",
      "             warm_start=False)\n",
      "to determine local CV score of #28\n",
      "--- Stacker Trained: 24850164.97 minutes ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 540 out of 540 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "new_ensemble2 = Ensemble(\n",
    "        n_folds=5,\n",
    "        stacker=GradientBoostingRegressor(\n",
    "            random_state=2017, verbose=1\n",
    "        ),\n",
    "        base_models=new_base_models2,\n",
    "        norm = True\n",
    "    )\n",
    "new_stack_pred2 = new_ensemble2.fit_predict(X=X_train,y=y_train,T=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:108.584511465\n"
     ]
    }
   ],
   "source": [
    "print 'Test Error:{}'.format(mse(y_test,new_stack_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xf94a470>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWEE3xhifsIJujDE+YQXdGGN84n9xskpjrGwXggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1167f240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test_range = xrange(len(y_test))\n",
    "plt.plot(x_test_range, y_test, '-',label = 'Test')\n",
    "plt.plot(x_test_range, new_stack_pred2, '-',label='Pred')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**结果分析**：这次用**XGB, ETR, SVR**做stacking， MSE降低了15%, 从127降到了108, 且好于所有树模型，虽然高于SVR,但是从SVR的预测销售率和实际销售率看,SVR的预测结果相当平滑，对实际销售率的指导意义不大。  \n",
    "**结论**：1.做Stacking时，各base model的预测结果相关系数需要尽量低。2.最后决定采用**XGB, ETR, SVR**的stacking对gid = 42, 18：00场次的销售率做预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对要预测数据做与测试集相同的处理，用XGB, ETR, SVR的stacking预测，并将结果输出为'submission.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'42'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('seckillListGid42.json','rb') as data_file:\n",
    "    data1 = json.load(data_file)\n",
    "df1 = data1['seckillInfo']\n",
    "df1['gid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discount</th>\n",
       "      <th>jdPrice</th>\n",
       "      <th>miaoShaPrice</th>\n",
       "      <th>startRemainTime</th>\n",
       "      <th>endRemainTime</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>26459</td>\n",
       "      <td>112858</td>\n",
       "      <td>0.663866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>39.9</td>\n",
       "      <td>26459</td>\n",
       "      <td>112858</td>\n",
       "      <td>0.578261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>26459</td>\n",
       "      <td>112858</td>\n",
       "      <td>0.775281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.2</td>\n",
       "      <td>120.0</td>\n",
       "      <td>28.8</td>\n",
       "      <td>26459</td>\n",
       "      <td>112858</td>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128.2</td>\n",
       "      <td>158.0</td>\n",
       "      <td>29.8</td>\n",
       "      <td>26459</td>\n",
       "      <td>112858</td>\n",
       "      <td>0.188608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discount  jdPrice  miaoShaPrice  startRemainTime  endRemainTime      rate\n",
       "0      40.0    119.0          79.0            26459         112858  0.663866\n",
       "1      29.1     69.0          39.9            26459         112858  0.578261\n",
       "2      20.0     89.0          69.0            26459         112858  0.775281\n",
       "3      91.2    120.0          28.8            26459         112858  0.240000\n",
       "4     128.2    158.0          29.8            26459         112858  0.188608"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.DataFrame(df1['itemList'])[part_cols]\n",
    "test_data.drop('rate',axis=1,inplace=True)\n",
    "test_data = test_data.apply(pd.to_numeric)\n",
    "test_data['rate'] = test_data['miaoShaPrice'] / test_data['jdPrice']\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "part_cols = ['discount','jdPrice','miaoShaPrice','rate','startRemainTime','endRemainTime']\n",
    "for id1 in xrange(len(part_cols)-1):\n",
    "    for id2 in xrange(id1+1, len(part_cols)):\n",
    "        new_col1 = '{}*{}'.format(part_cols[id1],part_cols[id2])\n",
    "        test_data[new_col1] = test_data[part_cols[id1]] * test_data[part_cols[id2]]\n",
    "        new_col2 = '{}/{}'.format(part_cols[id1],part_cols[id2])\n",
    "        test_data[new_col2] = test_data[part_cols[id1]] / test_data[part_cols[id2]]\n",
    "test_data['startTimeShow'] = 3\n",
    "print len(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting For Base Model #1 / 3 ---\n",
      "--- Fitting For Fold #1 / 5 ---\n",
      "Classifier:ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=50, n_jobs=1, oob_score=False, random_state=2017,\n",
      "          verbose=1, warm_start=False)\n",
      "Elapsed: 3.7 minutes ---\n",
      "--- Fitting For Fold #2 / 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=50, n_jobs=1, oob_score=False, random_state=2017,\n",
      "          verbose=1, warm_start=False)\n",
      "Elapsed: 3.7 minutes ---\n",
      "--- Fitting For Fold #3 / 5 ---\n",
      "Classifier:ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=50, n_jobs=1, oob_score=False, random_state=2017,\n",
      "          verbose=1, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 3.71 minutes ---\n",
      "--- Fitting For Fold #4 / 5 ---\n",
      "Classifier:ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=50, n_jobs=1, oob_score=False, random_state=2017,\n",
      "          verbose=1, warm_start=False)\n",
      "Elapsed: 3.71 minutes ---\n",
      "--- Fitting For Fold #5 / 5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=50, n_jobs=1, oob_score=False, random_state=2017,\n",
      "          verbose=1, warm_start=False)\n",
      "Elapsed: 3.71 minutes ---\n",
      "Elapsed: 3.71 minutes ---\n",
      "Fitting For Base Model #2 / 3 ---\n",
      "--- Fitting For Fold #1 / 5 ---\n",
      "Classifier:SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "Elapsed: 3.71 minutes ---\n",
      "--- Fitting For Fold #2 / 5 ---\n",
      "Classifier:SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "Elapsed: 3.71 minutes ---\n",
      "--- Fitting For Fold #3 / 5 ---\n",
      "Classifier:SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "Elapsed: 3.71 minutes ---\n",
      "--- Fitting For Fold #4 / 5 ---\n",
      "Classifier:SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "Elapsed: 3.71 minutes ---\n",
      "--- Fitting For Fold #5 / 5 ---\n",
      "Classifier:SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "Elapsed: 3.71 minutes ---\n",
      "Elapsed: 3.71 minutes ---\n",
      "Fitting For Base Model #3 / 3 ---\n",
      "--- Fitting For Fold #1 / 5 ---\n",
      "Classifier:XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.05, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=1, missing=None, n_estimators=80, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=2017, silent=True, subsample=0.8)\n",
      "Elapsed: 3.71 minutes ---\n",
      "--- Fitting For Fold #2 / 5 ---\n",
      "Classifier:XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.05, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=1, missing=None, n_estimators=80, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=2017, silent=True, subsample=0.8)\n",
      "Elapsed: 3.72 minutes ---\n",
      "--- Fitting For Fold #3 / 5 ---\n",
      "Classifier:XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.05, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=1, missing=None, n_estimators=80, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=2017, silent=True, subsample=0.8)\n",
      "Elapsed: 3.72 minutes ---\n",
      "--- Fitting For Fold #4 / 5 ---\n",
      "Classifier:XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.05, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=1, missing=None, n_estimators=80, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=2017, silent=True, subsample=0.8)\n",
      "Elapsed: 3.72 minutes ---\n",
      "--- Fitting For Fold #5 / 5 ---\n",
      "Classifier:XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.05, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=1, missing=None, n_estimators=80, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=2017, silent=True, subsample=0.8)\n",
      "Elapsed: 3.72 minutes ---\n",
      "Elapsed: 3.72 minutes ---\n",
      "--- Base Models Trained: 3.72 minutes ---\n",
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   1 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=3)]: Done   3 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=3)]: Done   4 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=3)]: Done   5 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=3)]: Done   6 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=3)]: Done   8 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=3)]: Done   9 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=3)]: Done  10 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=3)]: Done  11 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=3)]: Done  13 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=3)]: Done  14 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=3)]: Done  15 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=3)]: Done  16 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=3)]: Done  17 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=3)]: Done  18 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=3)]: Done  20 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=3)]: Done  21 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=3)]: Done  22 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=3)]: Done  23 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=3)]: Done  24 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=3)]: Done  25 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=3)]: Done  27 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=3)]: Done  28 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=3)]: Done  29 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=3)]: Done  30 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=3)]: Done  31 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=3)]: Done  32 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=3)]: Done  33 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=3)]: Done  34 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=3)]: Done  36 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=3)]: Done  37 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=3)]: Done  38 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=3)]: Done  39 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=3)]: Done  40 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=3)]: Done  41 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=3)]: Done  42 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=3)]: Done  43 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=3)]: Done  45 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=3)]: Done  46 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=3)]: Done  47 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=3)]: Done  48 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=3)]: Done  49 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=3)]: Done  50 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=3)]: Done  51 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=3)]: Done  52 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=3)]: Done  53 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=3)]: Done  54 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=3)]: Done  55 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=3)]: Done  56 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=3)]: Done  57 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=3)]: Done  58 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=3)]: Done  59 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=3)]: Done  60 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=3)]: Done  61 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=3)]: Done  62 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=3)]: Done  63 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=3)]: Done  64 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=3)]: Done  65 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=3)]: Done  66 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=3)]: Done  67 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=3)]: Done  68 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=3)]: Done  69 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=3)]: Done  70 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=3)]: Done  71 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=3)]: Done  72 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=3)]: Done  73 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=3)]: Done  74 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=3)]: Done  75 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=3)]: Done  76 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=3)]: Done  77 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=3)]: Done  78 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=3)]: Done  79 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=3)]: Done  80 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=3)]: Done  81 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=3)]: Done  82 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=3)]: Done  83 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=3)]: Done  84 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=3)]: Done  85 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=3)]: Done  86 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=3)]: Done  87 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=3)]: Done  88 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=3)]: Done  89 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=3)]: Done  90 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=3)]: Done  91 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=3)]: Done  92 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=3)]: Done  93 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=3)]: Done  94 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=3)]: Done  95 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=3)]: Done  96 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=3)]: Done  97 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=3)]: Done  98 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=3)]: Done  99 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=3)]: Done 100 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=3)]: Done 101 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=3)]: Done 102 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=3)]: Done 103 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=3)]: Done 104 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=3)]: Done 105 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=3)]: Done 106 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=3)]: Done 107 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=3)]: Done 108 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=3)]: Done 109 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=3)]: Done 110 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=3)]: Done 111 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=3)]: Done 112 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=3)]: Done 113 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=3)]: Done 114 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=3)]: Done 115 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=3)]: Done 116 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=3)]: Done 117 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=3)]: Done 118 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=3)]: Done 119 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=3)]: Done 120 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=3)]: Done 121 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=3)]: Done 123 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=3)]: Done 124 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=3)]: Done 125 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=3)]: Done 126 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=3)]: Done 127 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=3)]: Done 128 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=3)]: Done 129 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=3)]: Done 130 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=3)]: Done 131 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=3)]: Done 132 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=3)]: Done 133 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=3)]: Done 134 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=3)]: Done 135 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=3)]: Done 136 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=3)]: Done 137 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=3)]: Done 138 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=3)]: Done 139 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=3)]: Done 140 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=3)]: Done 141 tasks      | elapsed:   27.4s\n",
      "[Parallel(n_jobs=3)]: Done 142 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=3)]: Done 143 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=3)]: Done 144 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=3)]: Done 145 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=3)]: Done 146 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=3)]: Done 147 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=3)]: Done 148 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=3)]: Done 149 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=3)]: Done 150 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=3)]: Done 151 tasks      | elapsed:   29.3s\n",
      "[Parallel(n_jobs=3)]: Done 152 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=3)]: Done 153 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=3)]: Done 154 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=3)]: Done 155 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=3)]: Done 157 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=3)]: Done 158 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=3)]: Done 159 tasks      | elapsed:   31.1s\n",
      "[Parallel(n_jobs=3)]: Done 160 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=3)]: Done 161 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=3)]: Done 162 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=3)]: Done 163 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=3)]: Done 164 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=3)]: Done 165 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=3)]: Done 166 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=3)]: Done 167 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=3)]: Done 168 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=3)]: Done 169 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=3)]: Done 170 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=3)]: Done 171 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=3)]: Done 172 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=3)]: Done 173 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=3)]: Done 174 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=3)]: Done 175 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=3)]: Done 176 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=3)]: Done 177 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=3)]: Done 178 tasks      | elapsed:   35.1s\n",
      "[Parallel(n_jobs=3)]: Done 179 tasks      | elapsed:   35.1s\n",
      "[Parallel(n_jobs=3)]: Done 180 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=3)]: Done 181 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=3)]: Done 182 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=3)]: Done 183 tasks      | elapsed:   35.9s\n",
      "[Parallel(n_jobs=3)]: Done 184 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=3)]: Done 185 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=3)]: Done 186 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=3)]: Done 187 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=3)]: Done 188 tasks      | elapsed:   36.6s\n",
      "[Parallel(n_jobs=3)]: Done 189 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=3)]: Done 190 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=3)]: Done 191 tasks      | elapsed:   37.1s\n",
      "[Parallel(n_jobs=3)]: Done 192 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=3)]: Done 193 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:   37.5s\n",
      "[Parallel(n_jobs=3)]: Done 195 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=3)]: Done 196 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=3)]: Done 197 tasks      | elapsed:   38.0s\n",
      "[Parallel(n_jobs=3)]: Done 198 tasks      | elapsed:   38.2s\n",
      "[Parallel(n_jobs=3)]: Done 199 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=3)]: Done 200 tasks      | elapsed:   38.5s\n",
      "[Parallel(n_jobs=3)]: Done 201 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=3)]: Done 202 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=3)]: Done 203 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=3)]: Done 204 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=3)]: Done 205 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=3)]: Done 206 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=3)]: Done 207 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=3)]: Done 208 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=3)]: Done 209 tasks      | elapsed:   40.0s\n",
      "[Parallel(n_jobs=3)]: Done 210 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=3)]: Done 211 tasks      | elapsed:   40.2s\n",
      "[Parallel(n_jobs=3)]: Done 212 tasks      | elapsed:   40.5s\n",
      "[Parallel(n_jobs=3)]: Done 213 tasks      | elapsed:   40.6s\n",
      "[Parallel(n_jobs=3)]: Done 214 tasks      | elapsed:   40.8s\n",
      "[Parallel(n_jobs=3)]: Done 215 tasks      | elapsed:   41.0s\n",
      "[Parallel(n_jobs=3)]: Done 216 tasks      | elapsed:   41.2s\n",
      "[Parallel(n_jobs=3)]: Done 217 tasks      | elapsed:   41.3s\n",
      "[Parallel(n_jobs=3)]: Done 218 tasks      | elapsed:   41.6s\n",
      "[Parallel(n_jobs=3)]: Done 219 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=3)]: Done 220 tasks      | elapsed:   41.9s\n",
      "[Parallel(n_jobs=3)]: Done 221 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=3)]: Done 222 tasks      | elapsed:   42.3s\n",
      "[Parallel(n_jobs=3)]: Done 223 tasks      | elapsed:   42.5s\n",
      "[Parallel(n_jobs=3)]: Done 224 tasks      | elapsed:   42.7s\n",
      "[Parallel(n_jobs=3)]: Done 225 tasks      | elapsed:   42.9s\n",
      "[Parallel(n_jobs=3)]: Done 226 tasks      | elapsed:   43.0s\n",
      "[Parallel(n_jobs=3)]: Done 227 tasks      | elapsed:   43.3s\n",
      "[Parallel(n_jobs=3)]: Done 228 tasks      | elapsed:   43.5s\n",
      "[Parallel(n_jobs=3)]: Done 229 tasks      | elapsed:   43.6s\n",
      "[Parallel(n_jobs=3)]: Done 230 tasks      | elapsed:   43.9s\n",
      "[Parallel(n_jobs=3)]: Done 231 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=3)]: Done 232 tasks      | elapsed:   44.1s\n",
      "[Parallel(n_jobs=3)]: Done 233 tasks      | elapsed:   44.4s\n",
      "[Parallel(n_jobs=3)]: Done 234 tasks      | elapsed:   44.6s\n",
      "[Parallel(n_jobs=3)]: Done 235 tasks      | elapsed:   44.7s\n",
      "[Parallel(n_jobs=3)]: Done 236 tasks      | elapsed:   44.9s\n",
      "[Parallel(n_jobs=3)]: Done 237 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=3)]: Done 238 tasks      | elapsed:   45.2s\n",
      "[Parallel(n_jobs=3)]: Done 239 tasks      | elapsed:   45.5s\n",
      "[Parallel(n_jobs=3)]: Done 240 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=3)]: Done 241 tasks      | elapsed:   45.8s\n",
      "[Parallel(n_jobs=3)]: Done 242 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=3)]: Done 243 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=3)]: Done 244 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=3)]: Done 245 tasks      | elapsed:   46.6s\n",
      "[Parallel(n_jobs=3)]: Done 246 tasks      | elapsed:   46.7s\n",
      "[Parallel(n_jobs=3)]: Done 247 tasks      | elapsed:   47.0s\n",
      "[Parallel(n_jobs=3)]: Done 248 tasks      | elapsed:   47.2s\n",
      "[Parallel(n_jobs=3)]: Done 249 tasks      | elapsed:   47.3s\n",
      "[Parallel(n_jobs=3)]: Done 250 tasks      | elapsed:   47.6s\n",
      "[Parallel(n_jobs=3)]: Done 251 tasks      | elapsed:   47.8s\n",
      "[Parallel(n_jobs=3)]: Done 252 tasks      | elapsed:   47.9s\n",
      "[Parallel(n_jobs=3)]: Done 253 tasks      | elapsed:   48.1s\n",
      "[Parallel(n_jobs=3)]: Done 254 tasks      | elapsed:   48.4s\n",
      "[Parallel(n_jobs=3)]: Done 255 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=3)]: Done 256 tasks      | elapsed:   48.7s\n",
      "[Parallel(n_jobs=3)]: Done 257 tasks      | elapsed:   49.0s\n",
      "[Parallel(n_jobs=3)]: Done 258 tasks      | elapsed:   49.0s\n",
      "[Parallel(n_jobs=3)]: Done 259 tasks      | elapsed:   49.2s\n",
      "[Parallel(n_jobs=3)]: Done 260 tasks      | elapsed:   49.6s\n",
      "[Parallel(n_jobs=3)]: Done 261 tasks      | elapsed:   49.6s\n",
      "[Parallel(n_jobs=3)]: Done 262 tasks      | elapsed:   49.8s\n",
      "[Parallel(n_jobs=3)]: Done 263 tasks      | elapsed:   50.2s\n",
      "[Parallel(n_jobs=3)]: Done 264 tasks      | elapsed:   50.2s\n",
      "[Parallel(n_jobs=3)]: Done 265 tasks      | elapsed:   50.4s\n",
      "[Parallel(n_jobs=3)]: Done 266 tasks      | elapsed:   50.7s\n",
      "[Parallel(n_jobs=3)]: Done 267 tasks      | elapsed:   50.8s\n",
      "[Parallel(n_jobs=3)]: Done 268 tasks      | elapsed:   51.0s\n",
      "[Parallel(n_jobs=3)]: Done 269 tasks      | elapsed:   51.3s\n",
      "[Parallel(n_jobs=3)]: Done 270 tasks      | elapsed:   51.4s\n",
      "[Parallel(n_jobs=3)]: Done 271 tasks      | elapsed:   51.6s\n",
      "[Parallel(n_jobs=3)]: Done 272 tasks      | elapsed:   51.9s\n",
      "[Parallel(n_jobs=3)]: Done 273 tasks      | elapsed:   52.0s\n",
      "[Parallel(n_jobs=3)]: Done 274 tasks      | elapsed:   52.3s\n",
      "[Parallel(n_jobs=3)]: Done 275 tasks      | elapsed:   52.6s\n",
      "[Parallel(n_jobs=3)]: Done 276 tasks      | elapsed:   52.6s\n",
      "[Parallel(n_jobs=3)]: Done 277 tasks      | elapsed:   52.9s\n",
      "[Parallel(n_jobs=3)]: Done 278 tasks      | elapsed:   53.2s\n",
      "[Parallel(n_jobs=3)]: Done 279 tasks      | elapsed:   53.2s\n",
      "[Parallel(n_jobs=3)]: Done 280 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=3)]: Done 281 tasks      | elapsed:   53.8s\n",
      "[Parallel(n_jobs=3)]: Done 282 tasks      | elapsed:   53.8s\n",
      "[Parallel(n_jobs=3)]: Done 283 tasks      | elapsed:   54.1s\n",
      "[Parallel(n_jobs=3)]: Done 284 tasks      | elapsed:   54.4s\n",
      "[Parallel(n_jobs=3)]: Done 285 tasks      | elapsed:   54.4s\n",
      "[Parallel(n_jobs=3)]: Done 286 tasks      | elapsed:   54.7s\n",
      "[Parallel(n_jobs=3)]: Done 287 tasks      | elapsed:   55.0s\n",
      "[Parallel(n_jobs=3)]: Done 288 tasks      | elapsed:   55.0s\n",
      "[Parallel(n_jobs=3)]: Done 289 tasks      | elapsed:   55.3s\n",
      "[Parallel(n_jobs=3)]: Done 290 tasks      | elapsed:   55.6s\n",
      "[Parallel(n_jobs=3)]: Done 291 tasks      | elapsed:   55.6s\n",
      "[Parallel(n_jobs=3)]: Done 292 tasks      | elapsed:   56.0s\n",
      "[Parallel(n_jobs=3)]: Done 293 tasks      | elapsed:   56.2s\n",
      "[Parallel(n_jobs=3)]: Done 294 tasks      | elapsed:   56.2s\n",
      "[Parallel(n_jobs=3)]: Done 295 tasks      | elapsed:   56.5s\n",
      "[Parallel(n_jobs=3)]: Done 296 tasks      | elapsed:   56.8s\n",
      "[Parallel(n_jobs=3)]: Done 297 tasks      | elapsed:   56.8s\n",
      "[Parallel(n_jobs=3)]: Done 298 tasks      | elapsed:   57.2s\n",
      "[Parallel(n_jobs=3)]: Done 299 tasks      | elapsed:   57.4s\n",
      "[Parallel(n_jobs=3)]: Done 300 tasks      | elapsed:   57.4s\n",
      "[Parallel(n_jobs=3)]: Done 301 tasks      | elapsed:   57.8s\n",
      "[Parallel(n_jobs=3)]: Done 302 tasks      | elapsed:   58.0s\n",
      "[Parallel(n_jobs=3)]: Done 303 tasks      | elapsed:   58.0s\n",
      "[Parallel(n_jobs=3)]: Done 304 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=3)]: Done 305 tasks      | elapsed:   58.6s\n",
      "[Parallel(n_jobs=3)]: Done 306 tasks      | elapsed:   58.7s\n",
      "[Parallel(n_jobs=3)]: Done 307 tasks      | elapsed:   59.0s\n",
      "[Parallel(n_jobs=3)]: Done 308 tasks      | elapsed:   59.2s\n",
      "[Parallel(n_jobs=3)]: Done 309 tasks      | elapsed:   59.3s\n",
      "[Parallel(n_jobs=3)]: Done 310 tasks      | elapsed:   59.6s\n",
      "[Parallel(n_jobs=3)]: Done 311 tasks      | elapsed:   59.8s\n",
      "[Parallel(n_jobs=3)]: Done 312 tasks      | elapsed:   59.9s\n",
      "[Parallel(n_jobs=3)]: Done 313 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 314 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 315 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 316 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 317 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 318 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 319 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 320 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 321 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 322 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 323 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 324 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 325 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 326 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 327 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 328 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 329 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 330 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 331 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 332 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 333 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 334 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 335 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 336 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 337 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 338 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 339 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 340 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 341 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 342 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 343 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 344 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 345 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 346 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 347 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 348 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 349 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 350 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 351 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 352 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 353 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 354 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 355 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 356 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 357 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 358 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 359 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 360 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 361 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 362 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 363 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 364 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 365 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 366 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 367 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 368 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 369 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 370 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 371 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 372 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 373 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 374 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 375 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 376 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 377 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 378 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 379 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 380 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 381 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 382 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 383 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 384 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 385 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 386 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 387 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 388 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 389 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 390 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 391 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 392 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 393 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 394 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 395 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 396 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 397 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 398 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 399 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 400 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 401 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 402 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 403 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 404 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 405 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 406 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 407 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 408 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 409 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 410 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 411 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 412 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 413 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 414 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 415 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 416 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 417 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 418 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 419 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 420 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 421 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 422 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 423 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 424 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 425 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done 426 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 427 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 428 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 429 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 430 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 431 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 432 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 433 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 434 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 435 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 436 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 437 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 438 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 439 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 440 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 441 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 442 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 443 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 445 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 446 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 447 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 448 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 449 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 450 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 451 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 452 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 453 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 454 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 455 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 456 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 457 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 458 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 459 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 460 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 461 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 462 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 463 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 464 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 465 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 466 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 467 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 468 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 469 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 470 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 471 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 472 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 473 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 474 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 475 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 476 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 477 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 478 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 479 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 480 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 481 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 482 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 483 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 484 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 485 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 486 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 487 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 488 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 489 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 490 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 491 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 492 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 493 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 494 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 495 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 496 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 497 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 498 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 499 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 500 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 501 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 502 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 503 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 504 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 505 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 506 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 507 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 508 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 509 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 510 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 511 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 512 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 513 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 514 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 515 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 516 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 517 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 518 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 519 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 520 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 521 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 522 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 523 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 524 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 525 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 526 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 527 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 528 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 529 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 530 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 531 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 532 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 533 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 534 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 535 tasks      | elapsed:  1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         198.1388           4.8703            0.10s\n",
      "         2         180.6222          16.1606            0.07s\n",
      "         3         201.9604          -0.0236            0.06s\n",
      "         4         190.0097           0.5183            0.07s\n",
      "         5         168.3732          -0.0277            0.07s\n",
      "         6         144.6892           8.8127            0.07s\n",
      "         7         156.8560           0.3399            0.06s\n",
      "         8         101.5647           9.1507            0.06s\n",
      "         9         102.3345           7.4359            0.06s\n",
      "        10          79.6244           0.5638            0.06s\n",
      "        20          68.7809           0.3703            0.03s\n",
      "        30          51.2067          -0.1702            0.01s\n",
      "        40          41.6618          -0.3765            0.01s\n",
      "        50          30.2718           0.1906            0.00s\n",
      "Param grid:\n",
      "{'n_estimators': [50, 80, 90, 100, 150, 200], 'subsample': [0.72, 0.75, 0.78], 'learning_rate': [0.1, 0.05, 0.2]}\n",
      "Best Params:\n",
      "{'n_estimators': 50, 'subsample': 0.75, 'learning_rate': 0.05}\n",
      "Best CV Score:\n",
      "198.146311057\n",
      "Best estimator:\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.05, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "             min_samples_leaf=1, min_samples_split=2,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=50, presort='auto',\n",
      "             random_state=2017, subsample=0.75, verbose=1,\n",
      "             warm_start=False)\n",
      "to determine local CV score of #28\n",
      "--- Stacker Trained: 24850166.74 minutes ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 540 out of 540 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "res_stack_pred = new_ensemble2.fit_predict(X=X_train,y=y_train,T=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25.19597811,  25.58521316,  25.58521316,  23.81030122,\n",
       "        30.08820497,  25.58521316,  30.08820497,  30.08820497,\n",
       "        23.63080689,  23.63080689,  36.02084894,  25.58521316,\n",
       "        23.63080689,  38.48776139,  31.51695005,  38.48776139,\n",
       "        23.81030122,  36.02084894,  25.58521316,  38.48776139,\n",
       "        25.58521316,  25.58521316,  23.81030122,  36.02084894,\n",
       "        38.48776139,  23.81030122,  36.02084894,  36.02084894,\n",
       "        23.31553861,  38.48776139,  23.63080689,  38.48776139,\n",
       "        38.48776139,  29.0049268 ,  25.58521316,  25.89918376,\n",
       "        25.89918376,  38.48776139,  23.81030122,  38.48776139,\n",
       "        29.0049268 ,  25.58521316,  38.48776139,  23.31553861,\n",
       "        25.58521316,  25.58521316,  29.0049268 ,  23.81030122,\n",
       "        25.58521316,  36.02084894,  25.58521316,  25.19597811,\n",
       "        38.48776139,  38.48776139])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_stack_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(df1['itemList'])\n",
    "submit['Pred_soldRate'] = res_stack_pred\n",
    "submit.to_csv('submission.csv',index=False,encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
